<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>NLP - 分类 - DAY By DAY</title>
    <link>https://liudongdong1.github.io/categories/nlp/</link>
    <description>NLP - 分类 - DAY By DAY</description>
    <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>3463264078@qq.cn (LiuDongdong)</managingEditor>
      <webMaster>3463264078@qq.cn (LiuDongdong)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Wed, 27 Apr 2022 08:56:09 &#43;0000</lastBuildDate><atom:link href="https://liudongdong1.github.io/categories/nlp/" rel="self" type="application/rss+xml" /><item>
  <title>PoetryGen</title>
  <link>https://liudongdong1.github.io/poetrygen/</link>
  <pubDate>Wed, 27 Apr 2022 08:56:09 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/poetrygen/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.pixabay.com/photo/2014/12/22/19/59/macbook-577758__340.jpg" referrerpolicy="no-referrer">
      </div>AI和文学艺术不断交融，产生了很多有趣的研究方向，如自动绘画生成、诗歌生成、音乐生成、小说生成等。这些研究在学术界和普通人群中都引起了热烈的]]></description>
</item>
<item>
  <title>Framework_Transformers</title>
  <link>https://liudongdong1.github.io/framework_transformers/</link>
  <pubDate>Sat, 01 May 2021 21:31:56 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/framework_transformers/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.stocksnap.io/img-thumbs/280h/DYRNHWZGAN.jpg" referrerpolicy="no-referrer">
      </div>provides thousands of pretrained models to perform tasks on texts such as classification, information extraction, question answering, summarization, translation, text generation and more. [code] tutorial Transformers is backed by the three most popular deep learning libraries&ndash;Jax, PyTorch, and TensorFlow. Masked word completion with BERT Name Entity Recognition with Electra Text generation with GPT-2 Natural Language Inference with RoBERTa Summarization with BART Question answering with DistilBERT Translation with T5 1. Example]]></description>
</item>
<item>
  <title>OpenNREPaper</title>
  <link>https://liudongdong1.github.io/opennrepaper/</link>
  <pubDate>Sun, 24 Jan 2021 07:56:09 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/opennrepaper/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210501113211.png" referrerpolicy="no-referrer">
      </div> Han, X., Gao, T., Yao, Y., Ye, D., Liu, Z., &amp; Sun, M. (2019). OpenNRE: An open and extensible toolkit for neural relation extraction. arXiv preprint arXiv:1909.13078.
Paper: OpenNRE Summary train custom models to extract structured relational facts from the plain text, and supports quick model validation for researchers. source code: http://github.com/thunlp/OpenNRE, supports Entity-Oriented Application, Setence-Level Relation Extraction, Bag-Level Relation Extraction, Document-Level Relation Extraction, Few-Shot Relation Extraction, Architecture of OpenNRE ]]></description>
</item>
<item>
  <title>QA_relative</title>
  <link>https://liudongdong1.github.io/qa_relative/</link>
  <pubDate>Sun, 13 Dec 2020 09:14:57 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/qa_relative/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210501113233.png" referrerpolicy="no-referrer">
      </div>]]></description>
</item>
<item>
  <title>Rec_paper</title>
  <link>https://liudongdong1.github.io/rec_paper/</link>
  <pubDate>Sat, 12 Dec 2020 18:14:57 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/rec_paper/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201212194845004.png" referrerpolicy="no-referrer">
      </div>Liu, Hongtao, et al. &ldquo;NRPA: Neural Recommendation with Personalized Attention.&rdquo; Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2019. Paper: NRPA Summary propose a neural recommendation approach with personalized attention to learn personalized representations of users and items from reviews, to select different important words and reviews for different users/items. review encoder to learn representations of reviews from words and user/item encoder to]]></description>
</item>
<item>
  <title></title>
  <link>https://liudongdong1.github.io/opensource/</link>
  <pubDate>Thu, 03 Dec 2020 08:14:57 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/opensource/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/caudata-strelitzia-bird-of-paradise-flower-1.jpg" referrerpolicy="no-referrer">
      </div>1. FinBert 网络结构：其中前者采用了 12 层 Transformer 结构，后者采用了 24 层 Transformer 结构。 训练语料： 金融财经类新闻：从公开渠道采集的最近十年的金融财经类新闻资讯，约 100 万]]></description>
</item>
<item>
  <title>Recommandation</title>
  <link>https://liudongdong1.github.io/recommandation/</link>
  <pubDate>Sun, 15 Nov 2020 07:56:09 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/recommandation/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201129142519025.png" referrerpolicy="no-referrer">
      </div>Recommendation Summary User 数据（用户的基础属性数据，如性别、年龄、关系链、兴趣偏好等） 对于用户兴趣偏好，一般简单地采用文本 embedding 方法来得到各标签的 embedding 向量，然后根据用]]></description>
</item>
<item>
  <title>Torchtext</title>
  <link>https://liudongdong1.github.io/torchtext_vocab/</link>
  <pubDate>Tue, 27 Oct 2020 08:56:09 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/torchtext_vocab/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.stocksnap.io/img-thumbs/280h/9BOCPBLGRV.jpg" referrerpolicy="no-referrer">
      </div>torchtext.data.Example : 用来表示一个样本，数据+标签 torchtext.vocab.Vocab: 词汇表相关 torchtext.data.Datasets: 数据集类，getitem 返回 Example实例 torchtext.data.Field : 用来定义字段的处理方法（文本字段，标签字段）]]></description>
</item>
<item>
  <title>AllenNLPIntroduce</title>
  <link>https://liudongdong1.github.io/allennlpintroduce/</link>
  <pubDate>Tue, 20 Oct 2020 07:56:09 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/allennlpintroduce/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210501113113.png" referrerpolicy="no-referrer">
      </div>you can write your own script to construct the dataset reader and model and run the training loop, or you can write a configuration file and use the allennlp train command 1. Text Classification Spam filtering Detect and filter spam emails Email Spam / Not spam Sentiment analysis Detect the polarity of text Tweet, review Positive / Negative Topic detection Detect the topic of text News article, blog post Business]]></description>
</item>
<item>
  <title>WordEmbedding</title>
  <link>https://liudongdong1.github.io/wordembedding/</link>
  <pubDate>Tue, 20 Oct 2020 07:56:09 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/wordembedding/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/view-of-coffee-beans.jpg" referrerpolicy="no-referrer">
      </div>TEXT processing deals with humongous amount of text to perform different range of tasks like clustering in the g oogle search example, classification in the second and Machine Translation. How to create a representation for words that capture their meanings, semantic relationships and the different types of contexts they are used in. 作为 Embedding 层嵌入到深度模型中，实现将高维]]></description>
</item>
</channel>
</rss>
