<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>视觉AI - 分类 - DAY By DAY</title>
    <link>https://liudongdong1.github.io/categories/%E8%A7%86%E8%A7%89ai/</link>
    <description>视觉AI - 分类 - DAY By DAY</description>
    <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>3463264078@qq.cn (LiuDongdong)</managingEditor>
      <webMaster>3463264078@qq.cn (LiuDongdong)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Fri, 21 Oct 2022 21:59:57 &#43;0000</lastBuildDate><atom:link href="https://liudongdong1.github.io/categories/%E8%A7%86%E8%A7%89ai/" rel="self" type="application/rss+xml" /><item>
  <title>3DkeyPointPaper</title>
  <link>https://liudongdong1.github.io/3dkeypointpaper/</link>
  <pubDate>Fri, 21 Oct 2022 21:59:57 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/3dkeypointpaper/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.stocksnap.io/img-thumbs/280h/ZVCXJVXL75.jpg" referrerpolicy="no-referrer">
      </div>level: 2020, CCF_A CVPR author: Yang You, Shanghai Jiao Tong University date: 2020 keyword: 3D keypoint You, Y., Lou, Y., Li, C., Cheng, Z., Li, L., Ma, L., &hellip; &amp; Wang, W. (2020). KeypointNet: A Large-scale 3D Keypoint Dataset Aggregated from Numerous Human Annotations. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 13647-13656). Paper: KeypointNet Summary present keypointnet, the first large-scale and diverse 3D keypoint]]></description>
</item>
<item>
  <title>InNomalDetection</title>
  <link>https://liudongdong1.github.io/innomaldetection/</link>
  <pubDate>Sat, 30 Apr 2022 08:57:33 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/innomaldetection/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.stocksnap.io/img-thumbs/280h/TFGZBZ1EEV.jpg" referrerpolicy="no-referrer">
      </div>异常是指偏离预期的事件或项目。与标准事件的频率相比，异常事件的频率较低。产品中可能出现的异常通常是随机的，例如颜色或纹理的变化、划痕、错位、]]></description>
</item>
<item>
  <title>Eye-Tracking Introduce</title>
  <link>https://liudongdong1.github.io/eye-tracking-introduce/</link>
  <pubDate>Fri, 29 Apr 2022 15:57:50 &#43;0000</pubDate>
  <author>LiuDongdong</author>
  <guid>https://liudongdong1.github.io/eye-tracking-introduce/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/pexels-photo-840810.jpeg" referrerpolicy="no-referrer">
      </div>Paper: Weakly-Supervised Physically Unconstrained Gaze Estimation 本次工作所探讨的问题是从人类互动的视频中进行弱监督的视线估计，基本原理是利用人们在进行 &ldquo;相互注视&rdquo;（LA]]></description>
</item>
<item>
  <title>TemplateMatching</title>
  <link>https://liudongdong1.github.io/templatematching/</link>
  <pubDate>Tue, 26 Apr 2022 18:04:14 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/templatematching/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.pixabay.com/photo/2021/06/08/11/27/mushrooms-6320451__340.jpg" referrerpolicy="no-referrer">
      </div>1. 识别空的货架空间 如果使用模板匹配，轻微倾斜/移动，就很难找到这种方法。我们需要多个不同尺寸的模板来捕获这张图片中的所有空货架区域。 import cv2 import matplotlib.pyplot]]></description>
</item>
<item>
  <title>YOLO4 Object Detection</title>
  <link>https://liudongdong1.github.io/yolo4-object-detection/</link>
  <pubDate>Tue, 26 Apr 2022 18:04:14 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/yolo4-object-detection/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/close-up-of-vintage-camera-on-piano-keys.jpg" referrerpolicy="no-referrer">
      </div>Yolo5 自定义数据检测教程： https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data google云盘教程： https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb#scrollTo=V0AJnSeCIHyJ 1. Darknet ​ darknet是一个较为轻型的完全基于C与CUDA的开源深度学习框架，其主要特点就是容]]></description>
</item>
<item>
  <title>CircleGan</title>
  <link>https://liudongdong1.github.io/circlegan/</link>
  <pubDate>Sat, 20 Nov 2021 22:45:45 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/circlegan/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.stocksnap.io/img-thumbs/280h/TDAU1ERCD4.jpg" referrerpolicy="no-referrer">
      </div>Zhu, Jun-Yan, et al. &ldquo;Unpaired image-to-image translation using cycle-consistent adversarial networks.&rdquo; Proceedings of the IEEE international conference on computer vision. 2017. cite 10600 [pdf] [code] Paper: CircleGAN Summary present a method that can learn to do the same, capturing special characteristics of one image collection and figureing out how these characteristics could be translated into the other image collection. Research Objective Application Area: Collection style transfer: learns to mimic the]]></description>
</item>
<item>
  <title>EIT</title>
  <link>https://liudongdong1.github.io/eit/</link>
  <pubDate>Tue, 02 Nov 2021 21:59:57 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/eit/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.stocksnap.io/img-thumbs/280h/EKIMATYVZF.jpg" referrerpolicy="no-referrer">
      </div>生物电阻抗断层成像(Electrical Impedance Tomography，EIT)技术是一种新型医学功能成像技术，它的原理是在人体表面电极上施加一微弱]]></description>
</item>
<item>
  <title>HumanPosePaper</title>
  <link>https://liudongdong1.github.io/humanposepaper/</link>
  <pubDate>Tue, 02 Nov 2021 10:30:29 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/humanposepaper/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.stocksnap.io/img-thumbs/280h/9YZ9JQIHRH.jpg" referrerpolicy="no-referrer">
      </div>Zhang S, Zhang Y, Bogo F, et al. Learning motion priors for 4d human body capture in 3d scenes[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021: 11343-11353. [pdf] [code] Paper: LEMO Summary a marker-based motion smoothness prior and a contact-aware motion infillter wihcih is fine-tuned per-instance in a self-supervised fashion. a novel marker-based moiton smoothness prior that encodes the whole-body motion in a learned latent space, which can]]></description>
</item>
<item>
  <title>动态实例化与Register</title>
  <link>https://liudongdong1.github.io/%E5%8A%A8%E6%80%81%E5%AE%9E%E4%BE%8B%E5%8C%96%E4%B8%8Eregister/</link>
  <pubDate>Mon, 01 Nov 2021 21:45:45 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/%E5%8A%A8%E6%80%81%E5%AE%9E%E4%BE%8B%E5%8C%96%E4%B8%8Eregister/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.stocksnap.io/img-thumbs/280h/3H1PTCEQYT.jpg" referrerpolicy="no-referrer">
      </div>写具体的网络结构，它往往是一个Class，并且往往是一个单独的文件 配置文件中会指定我们使用哪一个网络结构，往往是Class name 在训练过程的某一]]></description>
</item>
<item>
  <title>Frame_BasicSR</title>
  <link>https://liudongdong1.github.io/frame_basicsr/</link>
  <pubDate>Sat, 23 Oct 2021 21:45:45 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/frame_basicsr/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.stocksnap.io/img-thumbs/280h/5U2FV0UNXF.jpg" referrerpolicy="no-referrer">
      </div>BasicSR (Basic Super Restoration) 是一个基于 PyTorch 的开源图像视频复原工具箱, 比如 超分辨率, 去噪, 去模糊, 去 JPEG 压缩噪声等. Real-ESRGAN: 通用图像复原的实用算法 GFPGAN: 真实场景人脸复原的实用算]]></description>
</item>
</channel>
</rss>
