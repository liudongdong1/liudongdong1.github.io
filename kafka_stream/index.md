# kafka_Stream


From: http://www.jasongj.com/kafka/kafka_stream/

# ä¸€ã€Kafka StreamèƒŒæ™¯

## 1. Kafka Streamæ˜¯ä»€ä¹ˆ

Kafka Streamæ˜¯Apache Kafkaä»0.10ç‰ˆæœ¬å¼•å…¥çš„ä¸€ä¸ªæ–°Featureã€‚å®ƒæ˜¯`æä¾›äº†å¯¹å­˜å‚¨äºKafkaå†…çš„æ•°æ®è¿›è¡Œæµå¼å¤„ç†å’Œåˆ†æçš„åŠŸèƒ½`ã€‚

Kafka Streamçš„ç‰¹ç‚¹å¦‚ä¸‹ï¼š

- Kafka Streamæä¾›äº†ä¸€ä¸ªéå¸¸ç®€å•è€Œè½»é‡çš„Libraryï¼Œå®ƒå¯ä»¥éå¸¸`æ–¹ä¾¿åœ°åµŒå…¥ä»»æ„Javaåº”ç”¨ä¸­ï¼Œä¹Ÿå¯ä»¥ä»»æ„æ–¹å¼æ‰“åŒ…å’Œéƒ¨ç½²`
- `é™¤äº†Kafkaå¤–ï¼Œæ— ä»»ä½•å¤–éƒ¨ä¾èµ–`
- å……åˆ†`åˆ©ç”¨Kafkaåˆ†åŒºæœºåˆ¶å®ç°æ°´å¹³æ‰©å±•å’Œé¡ºåºæ€§ä¿è¯`
- é€šè¿‡å¯å®¹é”™çš„state storeå®ç°é«˜æ•ˆçš„çŠ¶æ€æ“ä½œï¼ˆå¦‚windowed joinå’Œaggregationï¼‰
- æ”¯æŒ`æ­£å¥½ä¸€æ¬¡å¤„ç†è¯­ä¹‰`
- æä¾›`è®°å½•çº§çš„å¤„ç†èƒ½åŠ›ï¼Œä»è€Œå®ç°æ¯«ç§’çº§çš„ä½å»¶è¿Ÿ`
- æ”¯æŒ`åŸºäºäº‹ä»¶æ—¶é—´çš„çª—å£æ“ä½œï¼Œå¹¶ä¸”å¯å¤„ç†æ™šåˆ°çš„æ•°æ®ï¼ˆlate arrival of recordsï¼‰`
- åŒæ—¶`æä¾›åº•å±‚çš„å¤„ç†åŸè¯­Processorï¼ˆç±»ä¼¼äºStormçš„spoutå’Œboltï¼‰`ï¼Œä»¥åŠ`é«˜å±‚æŠ½è±¡çš„DSLï¼ˆç±»ä¼¼äºSparkçš„map/group/reduceï¼‰`

## 2. ä»€ä¹ˆæ˜¯æµå¼è®¡ç®—

ä¸€èˆ¬æµå¼è®¡ç®—ä¼šä¸æ‰¹é‡è®¡ç®—ç›¸æ¯”è¾ƒã€‚åœ¨æµå¼è®¡ç®—æ¨¡å‹ä¸­ï¼Œè¾“å…¥æ˜¯æŒç»­çš„ï¼Œå¯ä»¥è®¤ä¸ºåœ¨æ—¶é—´ä¸Šæ˜¯æ— ç•Œçš„ï¼Œä¹Ÿå°±æ„å‘³ç€ï¼Œæ°¸è¿œæ‹¿ä¸åˆ°å…¨é‡æ•°æ®å»åšè®¡ç®—ã€‚åŒæ—¶ï¼Œè®¡ç®—ç»“æœæ˜¯æŒç»­è¾“å‡ºçš„ï¼Œä¹Ÿå³è®¡ç®—ç»“æœåœ¨æ—¶é—´ä¸Šä¹Ÿæ˜¯æ— ç•Œçš„ã€‚æµå¼è®¡ç®—ä¸€èˆ¬å¯¹å®æ—¶æ€§è¦æ±‚è¾ƒé«˜ï¼ŒåŒæ—¶ä¸€èˆ¬æ˜¯å…ˆå®šä¹‰ç›®æ ‡è®¡ç®—ï¼Œç„¶åæ•°æ®åˆ°æ¥ä¹‹åå°†è®¡ç®—é€»è¾‘åº”ç”¨äºæ•°æ®ã€‚åŒæ—¶ä¸ºäº†æé«˜è®¡ç®—æ•ˆç‡ï¼Œå¾€å¾€å°½å¯èƒ½é‡‡ç”¨å¢é‡è®¡ç®—ä»£æ›¿å…¨é‡è®¡ç®—ã€‚

![](https://gitee.com/github-25970295/blogpictureV2/raw/master/963903-20180823011917613-280268935.png)

æ‰¹é‡å¤„ç†æ¨¡å‹ä¸­ï¼Œä¸€èˆ¬å…ˆæœ‰å…¨é‡æ•°æ®é›†ï¼Œç„¶åå®šä¹‰è®¡ç®—é€»è¾‘ï¼Œå¹¶å°†è®¡ç®—åº”ç”¨äºå…¨é‡æ•°æ®ã€‚ç‰¹ç‚¹æ˜¯å…¨é‡è®¡ç®—ï¼Œå¹¶ä¸”è®¡ç®—ç»“æœä¸€æ¬¡æ€§å…¨é‡è¾“å‡ºã€‚

![](https://gitee.com/github-25970295/blogpictureV2/raw/master/963903-20180823011948353-603485187.png)

## 3. ä¸ºä»€ä¹ˆè¦æœ‰Kafka Stream

å½“å‰å·²ç»æœ‰éå¸¸å¤šçš„æµå¼å¤„ç†ç³»ç»Ÿï¼Œæœ€çŸ¥åä¸”åº”ç”¨æœ€å¤šçš„å¼€æºæµå¼å¤„ç†ç³»ç»Ÿæœ‰`Spark Streaming`å’Œ`Apache Storm`ã€‚Apache Stormå‘å±•å¤šå¹´ï¼Œåº”ç”¨å¹¿æ³›ï¼Œæä¾›è®°å½•çº§åˆ«çš„å¤„ç†èƒ½åŠ›ï¼Œå½“å‰ä¹Ÿæ”¯æŒSQL on Streamã€‚è€ŒSpark StreamingåŸºäºApache Sparkï¼Œå¯ä»¥éå¸¸æ–¹ä¾¿ä¸å›¾è®¡ç®—ï¼ŒSQLå¤„ç†ç­‰é›†æˆï¼ŒåŠŸèƒ½å¼ºå¤§ï¼Œå¯¹äºç†Ÿæ‚‰å…¶å®ƒSparkåº”ç”¨å¼€å‘çš„ç”¨æˆ·è€Œè¨€ä½¿ç”¨é—¨æ§›ä½ã€‚å¦å¤–ï¼Œç›®å‰ä¸»æµçš„Hadoopå‘è¡Œç‰ˆï¼Œå¦‚MapRï¼ŒClouderaå’ŒHortonworksï¼Œéƒ½é›†æˆäº†Apache Stormå’ŒApache Sparkï¼Œä½¿å¾—éƒ¨ç½²æ›´å®¹æ˜“ã€‚

æ—¢ç„¶Apache Sparkä¸Apache Stormæ‹¥ç”¨å¦‚æ­¤å¤šçš„ä¼˜åŠ¿ï¼Œé‚£ä¸ºä½•è¿˜éœ€è¦Kafka Streamå‘¢ï¼Ÿç¬”è€…è®¤ä¸ºä¸»è¦æœ‰å¦‚ä¸‹åŸå› ã€‚

ç¬¬ä¸€ï¼Œ`Sparkå’ŒStorméƒ½æ˜¯æµå¼å¤„ç†æ¡†æ¶ï¼Œè€ŒKafka Streamæä¾›çš„æ˜¯ä¸€ä¸ªåŸºäºKafkaçš„æµå¼å¤„ç†ç±»åº“`**ã€‚æ¡†æ¶è¦æ±‚å¼€å‘è€…æŒ‰ç…§ç‰¹å®šçš„æ–¹å¼å»å¼€å‘é€»è¾‘éƒ¨åˆ†ï¼Œä¾›æ¡†æ¶è°ƒç”¨ã€‚å¼€å‘è€…å¾ˆéš¾äº†è§£æ¡†æ¶çš„å…·ä½“è¿è¡Œæ–¹å¼ï¼Œä»è€Œä½¿å¾—è°ƒè¯•æˆæœ¬é«˜ï¼Œå¹¶ä¸”ä½¿ç”¨å—é™ã€‚è€ŒKafka Streamä½œä¸ºæµå¼å¤„ç†**ç±»åº“**ï¼Œç›´æ¥æä¾›å…·ä½“çš„ç±»ç»™å¼€å‘è€…è°ƒç”¨ï¼Œ`æ•´ä¸ªåº”ç”¨çš„è¿è¡Œæ–¹å¼ä¸»è¦ç”±å¼€å‘è€…æ§åˆ¶ï¼Œæ–¹ä¾¿ä½¿ç”¨å’Œè°ƒè¯•ã€‚`

![](https://gitee.com/github-25970295/blogpictureV2/raw/master/963903-20180823012034870-605607318.png)

ç¬¬äºŒï¼Œè™½ç„¶Clouderaä¸Hortonworksæ–¹ä¾¿äº†Stormå’ŒSparkçš„éƒ¨ç½²ï¼Œä½†æ˜¯è¿™äº›æ¡†æ¶çš„`éƒ¨ç½²`ä»ç„¶ç›¸å¯¹å¤æ‚ã€‚è€ŒKafka Streamä½œä¸ºç±»åº“ï¼Œå¯ä»¥éå¸¸æ–¹ä¾¿çš„åµŒå…¥åº”ç”¨ç¨‹åºä¸­ï¼Œå®ƒå¯¹åº”ç”¨çš„æ‰“åŒ…å’Œéƒ¨ç½²åŸºæœ¬æ²¡æœ‰ä»»ä½•è¦æ±‚ã€‚æ›´ä¸ºé‡è¦çš„æ˜¯ï¼ŒKafka Streamå……åˆ†åˆ©ç”¨äº†[Kafkaçš„åˆ†åŒºæœºåˆ¶](http://www.jasongj.com/2015/03/10/KafkaColumn1/#Topic-amp-Partition)å’Œ[Consumerçš„Rebalanceæœºåˆ¶](http://www.jasongj.com/2015/08/09/KafkaColumn4/#High-Level-Consumer-Rebalance)ï¼Œä½¿å¾—Kafka Streamå¯ä»¥`éå¸¸æ–¹ä¾¿çš„æ°´å¹³æ‰©å±•`ï¼Œ`å¹¶ä¸”å„ä¸ªå®ä¾‹å¯ä»¥ä½¿ç”¨ä¸åŒçš„éƒ¨ç½²æ–¹å¼`ã€‚å…·ä½“æ¥è¯´ï¼Œæ¯ä¸ªè¿è¡ŒKafka Streamçš„åº”ç”¨ç¨‹åºå®ä¾‹éƒ½åŒ…å«äº†Kafka Consumerå®ä¾‹ï¼Œå¤šä¸ªåŒä¸€åº”ç”¨çš„å®ä¾‹ä¹‹é—´å¹¶è¡Œå¤„ç†æ•°æ®é›†ã€‚è€Œä¸åŒå®ä¾‹ä¹‹é—´çš„éƒ¨ç½²æ–¹å¼å¹¶ä¸è¦æ±‚ä¸€è‡´ï¼Œæ¯”å¦‚éƒ¨åˆ†å®ä¾‹å¯ä»¥è¿è¡Œåœ¨Webå®¹å™¨ä¸­ï¼Œéƒ¨åˆ†å®ä¾‹å¯è¿è¡Œåœ¨Dockeræˆ–Kubernetesä¸­ã€‚

ç¬¬ä¸‰ï¼Œ`å°±æµå¼å¤„ç†ç³»ç»Ÿè€Œè¨€ï¼ŒåŸºæœ¬éƒ½æ”¯æŒKafkaä½œä¸ºæ•°æ®æº`ã€‚ä¾‹å¦‚Stormå…·æœ‰ä¸“é—¨çš„kafka-spoutï¼Œè€ŒSparkä¹Ÿæä¾›ä¸“é—¨çš„spark-streaming-kafkaæ¨¡å—ã€‚äº‹å®ä¸Šï¼ŒKafkaåŸºæœ¬ä¸Šæ˜¯ä¸»æµçš„æµå¼å¤„ç†ç³»ç»Ÿçš„æ ‡å‡†æ•°æ®æºã€‚æ¢è¨€ä¹‹ï¼Œå¤§éƒ¨åˆ†æµå¼ç³»ç»Ÿä¸­éƒ½å·²éƒ¨ç½²äº†Kafkaï¼Œæ­¤æ—¶`ä½¿ç”¨Kafka Streamçš„æˆæœ¬éå¸¸ä½`ã€‚

ç¬¬å››ï¼Œä½¿ç”¨Stormæˆ–Spark Streamingæ—¶ï¼Œéœ€è¦ä¸ºæ¡†æ¶æœ¬èº«çš„è¿›ç¨‹é¢„ç•™èµ„æºï¼Œå¦‚Stormçš„supervisorå’ŒSpark on YARNçš„node managerã€‚å³ä½¿å¯¹äºåº”ç”¨å®ä¾‹è€Œè¨€ï¼Œ`æ¡†æ¶æœ¬èº«ä¹Ÿä¼šå ç”¨éƒ¨åˆ†èµ„æº`ï¼Œå¦‚Spark Streamingéœ€è¦ä¸ºshuffleå’Œstorageé¢„ç•™å†…å­˜ã€‚

ç¬¬äº”ï¼Œç”±äº`Kafkaæœ¬èº«æä¾›æ•°æ®æŒä¹…åŒ–`ï¼Œå› æ­¤Kafka Stream`æä¾›æ»šåŠ¨éƒ¨ç½²å’Œæ»šåŠ¨å‡çº§ä»¥åŠé‡æ–°è®¡ç®—çš„èƒ½åŠ›ã€‚`

ç¬¬å…­ï¼Œç”±äºKafka Consumer Rebalanceæœºåˆ¶ï¼Œ`Kafka Streamå¯ä»¥åœ¨çº¿åŠ¨æ€è°ƒæ•´å¹¶è¡Œåº¦ã€‚`

# äºŒã€Kafka Streamæ¶æ„

## 1. Kafka Streamæ•´ä½“æ¶æ„

![](https://gitee.com/github-25970295/blogpictureV2/raw/master/963903-20180823012221127-657291327.png)

```java
KStream<String, String> stream = builder.stream("words-stream");
KTable<String, String> table = builder.table("words-table", "words-store");
```

å¦å¤–ï¼Œä¸Šå›¾ä¸­çš„Consumerå’ŒProducerå¹¶ä¸éœ€è¦å¼€å‘è€…åœ¨åº”ç”¨ä¸­æ˜¾ç¤ºå®ä¾‹åŒ–ï¼Œè€Œæ˜¯`ç”±Kafka Streamæ ¹æ®å‚æ•°éšå¼å®ä¾‹åŒ–å’Œç®¡ç†`ï¼Œä»è€Œé™ä½äº†ä½¿ç”¨é—¨æ§›ã€‚`å¼€å‘è€…åªéœ€è¦ä¸“æ³¨äºå¼€å‘æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ï¼Œä¹Ÿå³ä¸Šå›¾ä¸­Taskå†…çš„éƒ¨åˆ†`ã€‚

## 2. Processor Topology

åŸºäºKafka Streamçš„æµå¼åº”ç”¨çš„ä¸šåŠ¡é€»è¾‘`å…¨éƒ¨é€šè¿‡ä¸€ä¸ªè¢«ç§°ä¸ºProcessor Topologyçš„åœ°æ–¹æ‰§è¡Œ`ã€‚å®ƒä¸Stormçš„Topologyå’ŒSparkçš„DAGç±»ä¼¼ï¼Œéƒ½å®šä¹‰äº†æ•°æ®åœ¨å„ä¸ªå¤„ç†å•å…ƒï¼ˆåœ¨Kafka Streamä¸­è¢«ç§°ä½œProcessorï¼‰é—´çš„æµåŠ¨æ–¹å¼ï¼Œæˆ–è€…è¯´å®šä¹‰äº†æ•°æ®çš„å¤„ç†é€»è¾‘ã€‚

```java
public class WordCountProcessor implements Processor<String, String> {
    private ProcessorContext context;
    private KeyValueStore<String, Integer> kvStore;
    @SuppressWarnings("unchecked")
    @Override
    //init()æ–¹æ³•ï¼šå¯ä»¥è·å–ProcessorContextå®ä¾‹ï¼Œç”¨æ¥ç»´æŠ¤å½“å‰ä¸Šä¸‹æ–‡ï¼›é€šè¿‡ä¸Šä¸‹æ–‡ProcessorContextå¾—åˆ°çŠ¶æ€ä»“åº“å®ä¾‹ä»¥åŠä½¿ç”¨ä¸Šä¸‹æ–‡ç”¨äºåŸºäºæ—¶é—´æ¨ç§»å‘¨æœŸæ€§çš„æ‰§è¡Œï¼›
    public void init(ProcessorContext context) {
        this.context = context;
        this.context.schedule(1000);
        this.kvStore = (KeyValueStore<String, Integer>) context.getStateStore("Counts");
    }
    //processæ–¹æ³•ï¼šç”¨äºå¯¹æ”¶åˆ°çš„æ•°æ®é›†æ‰§è¡Œå¯¹çŠ¶æ€ä»“åº“çš„æ“ä½œï¼›
    @Override
    public void process(String key, String value) {
        Stream.of(value.toLowerCase().split(" ")).forEach((String word) -> {
            Optional<Integer> counts = Optional.ofNullable(kvStore.get(word));
            int count = counts.map(wordcount -> wordcount + 1).orElse(1);
            kvStore.put(word, count);
        });
    }
    @Override
    public void punctuate(long timestamp) {   //punctuate():ç”¨äºåŸºäºæ—¶é—´æ¨ç§»å‘¨æœŸæ€§æ‰§è¡Œï¼›
        KeyValueIterator<String, Integer> iterator = this.kvStore.all();
        iterator.forEachRemaining(entry -> {
            context.forward(entry.key, entry.value);
            this.kvStore.delete(entry.key);
        });
        context.commit();
    }
    @Override   //close:å…³é—­ç›¸åº”èµ„æºæ“ä½œ
    public void close() {
        this.kvStore.close();
    }
}
```

- `processå®šä¹‰äº†å¯¹æ¯æ¡è®°å½•çš„å¤„ç†é€»è¾‘`ï¼Œä¹Ÿå°è¯äº†Kafkaå¯å…·æœ‰è®°å½•çº§çš„æ•°æ®å¤„ç†èƒ½åŠ›ã€‚
- context.schedulerå®šä¹‰äº†`punctuateè¢«æ‰§è¡Œçš„å‘¨æœŸ`ï¼Œä»è€Œæä¾›äº†å®ç°çª—å£æ“ä½œçš„èƒ½åŠ›ã€‚
- context.getStateStoreæä¾›çš„`çŠ¶æ€å­˜å‚¨ä¸ºæœ‰çŠ¶æ€è®¡ç®—ï¼ˆå¦‚çª—å£ï¼Œèšåˆï¼‰æä¾›äº†å¯èƒ½ã€‚`

## 3. Kafka Streamå¹¶è¡Œæ¨¡å‹

Kafka Streamçš„å¹¶è¡Œæ¨¡å‹ä¸­ï¼Œ`æœ€å°ç²’åº¦ä¸ºTask`ï¼Œè€Œ`æ¯ä¸ªTaskåŒ…å«ä¸€ä¸ªç‰¹å®šå­Topologyçš„æ‰€æœ‰Processor`ã€‚å› æ­¤æ¯ä¸ªTaskæ‰€æ‰§è¡Œçš„ä»£ç å®Œå…¨ä¸€æ ·ï¼Œå”¯ä¸€çš„ä¸åŒåœ¨äºæ‰€å¤„ç†çš„æ•°æ®é›†äº’è¡¥ã€‚è¿™ä¸€ç‚¹è·ŸStormçš„Topologyå®Œå…¨ä¸ä¸€æ ·ã€‚Stormçš„Topologyçš„æ¯ä¸€ä¸ªTaskåªåŒ…å«ä¸€ä¸ªSpoutæˆ–Boltçš„å®ä¾‹ã€‚å› æ­¤Stormçš„ä¸€ä¸ªTopologyå†…çš„ä¸åŒTaskä¹‹é—´éœ€è¦é€šè¿‡ç½‘ç»œé€šä¿¡ä¼ é€’æ•°æ®ï¼Œè€ŒKafka Streamçš„TaskåŒ…å«äº†å®Œæ•´çš„å­Topologyï¼Œæ‰€ä»¥`Taskä¹‹é—´ä¸éœ€è¦ä¼ é€’æ•°æ®ï¼Œä¹Ÿå°±ä¸éœ€è¦ç½‘ç»œé€šä¿¡`ã€‚è¿™ä¸€ç‚¹é™ä½äº†ç³»ç»Ÿå¤æ‚åº¦ï¼Œä¹Ÿæé«˜äº†å¤„ç†æ•ˆç‡ã€‚

å¦‚æœæŸä¸ªStreamçš„è¾“å…¥Topicæœ‰å¤šä¸ª(æ¯”å¦‚2ä¸ªTopicï¼Œ1ä¸ªPartitionæ•°ä¸º4ï¼Œå¦ä¸€ä¸ªPartitionæ•°ä¸º3)ï¼Œåˆ™æ€»çš„Taskæ•°ç­‰äºPartitionæ•°æœ€å¤šçš„é‚£ä¸ªTopicçš„Partitionæ•°ï¼ˆmax(4,3)=4ï¼‰ã€‚è¿™æ˜¯å› ä¸ºKafka Streamä½¿ç”¨äº†Consumerçš„Rebalanceæœºåˆ¶ï¼Œæ¯ä¸ªPartitionå¯¹åº”ä¸€ä¸ªTaskã€‚

ä¸‹å›¾å±•ç¤ºäº†åœ¨ä¸€ä¸ªè¿›ç¨‹ï¼ˆInstanceï¼‰ä¸­`ä»¥2ä¸ªTopicï¼ˆPartitionæ•°å‡ä¸º4ï¼‰ä¸ºæ•°æ®æºçš„Kafka Streamåº”ç”¨çš„å¹¶è¡Œæ¨¡å‹ã€‚`ä»å›¾ä¸­å¯ä»¥çœ‹åˆ°ï¼Œç”±äºKafka Streamåº”ç”¨çš„é»˜è®¤çº¿ç¨‹æ•°ä¸º1ï¼Œæ‰€ä»¥4ä¸ªTaskå…¨éƒ¨åœ¨ä¸€ä¸ªçº¿ç¨‹ä¸­è¿è¡Œã€‚

![](https://gitee.com/github-25970295/blogpictureV2/raw/master/963903-20180823012423201-1891805178.png)

ä¸ºäº†å……åˆ†åˆ©ç”¨å¤šçº¿ç¨‹çš„ä¼˜åŠ¿ï¼Œå¯ä»¥è®¾ç½®Kafka Streamçš„çº¿ç¨‹æ•°ã€‚ä¸‹å›¾å±•ç¤ºäº†çº¿ç¨‹æ•°ä¸º2æ—¶çš„å¹¶è¡Œæ¨¡å‹ã€‚

![](https://gitee.com/github-25970295/blogpictureV2/raw/master/963903-20180823012446423-1214824884.png)

å‰æ–‡æœ‰æåˆ°ï¼ŒKafka Streamå¯è¢«åµŒå…¥ä»»æ„Javaåº”ç”¨ï¼ˆç†è®ºä¸ŠåŸºäºJVMçš„åº”ç”¨éƒ½å¯ä»¥ï¼‰ä¸­ï¼Œä¸‹å›¾å±•ç¤ºäº†åœ¨`åŒä¸€å°æœºå™¨çš„ä¸åŒè¿›ç¨‹ä¸­åŒæ—¶å¯åŠ¨åŒä¸€Kafka Streamåº”ç”¨æ—¶çš„å¹¶è¡Œæ¨¡å‹`ã€‚æ³¨æ„ï¼Œè¿™é‡Œè¦ä¿è¯ä¸¤ä¸ªè¿›ç¨‹çš„StreamsConfig.`APPLICATION_ID_CONFIGå®Œå…¨ä¸€æ ·`ã€‚å› ä¸º`Kafka Streamå°†APPLICATION_ID_CONFIGä½œä¸ºéšå¼å¯åŠ¨çš„Consumerçš„Group ID`ã€‚åªæœ‰ä¿è¯APPLICATION_ID_CONFIGç›¸åŒï¼Œæ‰èƒ½ä¿è¯è¿™ä¸¤ä¸ªè¿›ç¨‹çš„Consumerå±äºåŒä¸€ä¸ªGroupï¼Œä»è€Œå¯ä»¥é€šè¿‡Consumer Rebalanceæœºåˆ¶æ‹¿åˆ°äº’è¡¥çš„æ•°æ®é›†ã€‚

![](https://gitee.com/github-25970295/blogpictureV2/raw/master/963903-20180823012616004-1473262041.png)

æ—¢ç„¶å®ç°äº†å¤šè¿›ç¨‹éƒ¨ç½²ï¼Œå¯ä»¥ä»¥åŒæ ·çš„æ–¹å¼å®ç°å¤šæœºå™¨éƒ¨ç½²ã€‚è¯¥éƒ¨ç½²æ–¹å¼ä¹Ÿè¦æ±‚æ‰€æœ‰è¿›ç¨‹çš„APPLICATION_ID_CONFIGå®Œå…¨ä¸€æ ·ã€‚ä»å›¾ä¸Šä¹Ÿå¯ä»¥çœ‹åˆ°ï¼Œæ¯ä¸ªå®ä¾‹ä¸­çš„çº¿ç¨‹æ•°å¹¶ä¸è¦æ±‚ä¸€æ ·ã€‚ä½†æ˜¯æ— è®ºå¦‚ä½•éƒ¨ç½²ï¼ŒTaskæ€»æ•°æ€»ä¼šä¿è¯ä¸€è‡´ã€‚

![](https://gitee.com/github-25970295/blogpictureV2/raw/master/963903-20180823012703011-1321655264.png)

è¿™é‡Œå¯¹æ¯”ä¸€ä¸‹Kafka Streamçš„Processor Topologyä¸Stormçš„Topologyã€‚

- `Stormçš„Topologyç”±Spoutå’ŒBoltç»„æˆï¼ŒSpoutæä¾›æ•°æ®æºï¼Œè€ŒBoltæä¾›è®¡ç®—å’Œæ•°æ®å¯¼å‡º`ã€‚Kafka Streamçš„Processor Topologyå®Œå…¨`ç”±Processorç»„æˆï¼Œå› ä¸ºå®ƒçš„æ•°æ®å›ºå®šç”±Kafkaçš„Topicæä¾›`ã€‚
- Stormçš„ä¸åŒBoltè¿è¡Œåœ¨ä¸åŒçš„Executorä¸­ï¼Œå¾ˆå¯èƒ½ä½äºä¸åŒçš„æœºå™¨ï¼Œéœ€è¦é€šè¿‡ç½‘ç»œé€šä¿¡ä¼ è¾“æ•°æ®ã€‚è€ŒKafka Streamçš„Processor Topologyçš„`ä¸åŒProcessorå®Œå…¨è¿è¡ŒäºåŒä¸€ä¸ªTaskä¸­`ï¼Œä¹Ÿå°±å®Œå…¨å¤„äºåŒä¸€ä¸ªçº¿ç¨‹ï¼Œæ— éœ€ç½‘ç»œé€šä¿¡ã€‚
- Stormçš„Topologyå¯ä»¥åŒæ—¶åŒ…å«Shuffleéƒ¨åˆ†å’ŒéShuffleéƒ¨åˆ†ï¼Œå¹¶ä¸”å¾€å¾€ä¸€ä¸ªTopologyå°±æ˜¯ä¸€ä¸ªå®Œæ•´çš„åº”ç”¨ã€‚è€ŒKafka Streamçš„ä¸€ä¸ªç‰©ç†TopologyåªåŒ…å«éShuffleéƒ¨åˆ†ï¼Œè€ŒShuffleéƒ¨åˆ†éœ€è¦é€šè¿‡throughæ“ä½œæ˜¾ç¤ºå®Œæˆï¼Œè¯¥æ“ä½œå°†ä¸€ä¸ªå¤§çš„Topologyåˆ†æˆäº†2ä¸ªå­Topologyã€‚
- Stormçš„Topologyå†…ï¼Œä¸åŒBolt/Spoutçš„å¹¶è¡Œåº¦å¯ä»¥ä¸ä¸€æ ·ï¼Œè€ŒKafka Streamçš„å­Topologyå†…ï¼Œæ‰€æœ‰Processorçš„å¹¶è¡Œåº¦å®Œå…¨ä¸€æ ·ã€‚
- Stormçš„ä¸€ä¸ªTaskåªåŒ…å«ä¸€ä¸ªSpoutæˆ–è€…Boltçš„å®ä¾‹ï¼Œè€Œ`Kafka Streamçš„ä¸€ä¸ªTaskåŒ…å«äº†ä¸€ä¸ªå­Topologyçš„æ‰€æœ‰Processorã€‚`

## 4. KTable vs. KStream

`KTableå’ŒKStream`æ˜¯Kafka Streamä¸­éå¸¸é‡è¦çš„ä¸¤ä¸ªæ¦‚å¿µï¼Œå®ƒä»¬æ˜¯Kafkaå®ç°å„ç§è¯­ä¹‰çš„åŸºç¡€ã€‚å› æ­¤è¿™é‡Œæœ‰å¿…è¦åˆ†æä¸‹äºŒè€…çš„åŒºåˆ«ã€‚

- `KStreamæ˜¯ä¸€ä¸ªæ•°æ®æµ`ï¼Œå¯ä»¥è®¤ä¸º`æ‰€æœ‰è®°å½•éƒ½é€šè¿‡Insert onlyçš„æ–¹å¼æ’å…¥è¿›è¿™ä¸ªæ•°æ®æµé‡Œ`ã€‚

- `KTableä»£è¡¨ä¸€ä¸ªå®Œæ•´çš„æ•°æ®é›†`ï¼Œå¯ä»¥`ç†è§£ä¸ºæ•°æ®åº“ä¸­çš„è¡¨`ã€‚ç”±äºæ¯æ¡è®°å½•éƒ½æ˜¯Key-Valueå¯¹ï¼Œè¿™é‡Œå¯ä»¥å°†Keyç†è§£ä¸ºæ•°æ®åº“ä¸­çš„Primary Keyï¼Œè€ŒValueå¯ä»¥ç†è§£ä¸ºä¸€è¡Œè®°å½•ã€‚å¯ä»¥è®¤ä¸ºKTableä¸­çš„æ•°æ®éƒ½æ˜¯`é€šè¿‡Update onlyçš„æ–¹å¼è¿›å…¥çš„`ã€‚ä¹Ÿå°±æ„å‘³ç€ï¼Œ`å¦‚æœKTableå¯¹åº”çš„Topicä¸­æ–°è¿›å…¥çš„æ•°æ®çš„Keyå·²ç»å­˜åœ¨ï¼Œé‚£ä¹ˆä»KTableåªä¼šå–å‡ºåŒä¸€Keyå¯¹åº”çš„æœ€åä¸€æ¡æ•°æ®ï¼Œç›¸å½“äºæ–°çš„æ•°æ®æ›´æ–°äº†æ—§çš„æ•°æ®ã€‚`

ä»¥ä¸‹å›¾ä¸ºä¾‹ï¼Œå‡è®¾æœ‰ä¸€ä¸ªKStreamå’ŒKTableï¼ŒåŸºäºåŒä¸€ä¸ªTopicåˆ›å»ºï¼Œå¹¶ä¸”è¯¥Topicä¸­åŒ…å«å¦‚ä¸‹å›¾æ‰€ç¤º5æ¡æ•°æ®ã€‚æ­¤æ—¶éå†KStreamå°†å¾—åˆ°ä¸Topicå†…æ•°æ®å®Œå…¨ä¸€æ ·çš„æ‰€æœ‰5æ¡æ•°æ®ï¼Œä¸”é¡ºåºä¸å˜ã€‚è€Œæ­¤æ—¶éå†KTableæ—¶ï¼Œå› ä¸ºè¿™5æ¡è®°å½•ä¸­æœ‰3ä¸ªä¸åŒçš„Keyï¼Œæ‰€ä»¥å°†å¾—åˆ°3æ¡è®°å½•ï¼Œæ¯ä¸ªKeyå¯¹åº”æœ€æ–°çš„å€¼ï¼Œå¹¶ä¸”è¿™ä¸‰æ¡æ•°æ®ä¹‹é—´çš„é¡ºåºä¸åŸæ¥åœ¨Topicä¸­çš„é¡ºåºä¿æŒä¸€è‡´ã€‚è¿™ä¸€ç‚¹ä¸Kafkaçš„æ—¥å¿—compactç›¸åŒã€‚

![](https://gitee.com/github-25970295/blogpictureV2/raw/master/963903-20180823012822162-142241598.png)

æ­¤æ—¶å¦‚æœå¯¹è¯¥KStreamå’ŒKTableåˆ†åˆ«åŸºäºkeyåšGroupï¼Œå¯¹Valueè¿›è¡ŒSumï¼Œå¾—åˆ°çš„ç»“æœå°†ä¼šä¸åŒã€‚å¯¹KStreamçš„è®¡ç®—ç»“æœæ˜¯<Jackï¼Œ4>ï¼Œ<Lilyï¼Œ7>ï¼Œ<Mikeï¼Œ4>ã€‚è€Œå¯¹Ktableçš„è®¡ç®—ç»“æœæ˜¯<Mikeï¼Œ4>ï¼Œ<Jackï¼Œ3>ï¼Œ<Lilyï¼Œ5>ã€‚

## 5. State store

æµå¼å¤„ç†ä¸­ï¼Œéƒ¨åˆ†æ“ä½œæ˜¯æ— çŠ¶æ€çš„ï¼Œä¾‹å¦‚è¿‡æ»¤æ“ä½œï¼ˆKafka Stream DSLä¸­ç”¨`filer`æ–¹æ³•å®ç°ï¼‰ã€‚è€Œéƒ¨åˆ†æ“ä½œæ˜¯æœ‰çŠ¶æ€çš„ï¼Œéœ€è¦è®°å½•ä¸­é—´çŠ¶æ€ï¼Œå¦‚Windowæ“ä½œå’Œèšåˆè®¡ç®—ã€‚`State storeè¢«ç”¨æ¥å­˜å‚¨ä¸­é—´çŠ¶æ€ã€‚å®ƒå¯ä»¥æ˜¯ä¸€ä¸ªæŒä¹…åŒ–çš„Key-Valueå­˜å‚¨ï¼Œä¹Ÿå¯ä»¥æ˜¯å†…å­˜ä¸­çš„HashMapï¼Œæˆ–è€…æ˜¯æ•°æ®åº“ã€‚Kafkaæä¾›äº†åŸºäºTopicçš„çŠ¶æ€å­˜å‚¨ã€‚`

# ä¸‰ã€Kafka Streamå¦‚ä½•è§£å†³æµå¼ç³»ç»Ÿä¸­å…³é”®é—®é¢˜

## 1. æ—¶é—´

åœ¨æµå¼æ•°æ®å¤„ç†ä¸­ï¼Œ`æ—¶é—´æ˜¯æ•°æ®çš„ä¸€ä¸ªéå¸¸é‡è¦çš„å±æ€§`ã€‚ä»`Kafka 0.10å¼€å§‹`ï¼Œæ¯æ¡è®°å½•é™¤äº†Keyå’ŒValueå¤–ï¼Œè¿˜å¢åŠ äº†timestampå±æ€§ã€‚ç›®å‰Kafka Streamæ”¯æŒä¸‰ç§æ—¶é—´

- **äº‹ä»¶å‘ç”Ÿæ—¶é—´**ã€‚äº‹ä»¶å‘ç”Ÿçš„æ—¶é—´ï¼ŒåŒ…å«åœ¨æ•°æ®è®°å½•ä¸­ã€‚å‘ç”Ÿæ—¶é—´`ç”±Produceråœ¨æ„é€ ProducerRecordæ—¶æŒ‡å®š`ã€‚å¹¶ä¸”`éœ€è¦Brokeræˆ–è€…Topicå°†message.timestamp.typeè®¾ç½®ä¸ºCreateTimeï¼ˆé»˜è®¤å€¼ï¼‰æ‰èƒ½ç”Ÿæ•ˆã€‚`
- **æ¶ˆæ¯æ¥æ”¶æ—¶é—´**ã€‚ä¹Ÿå³`æ¶ˆæ¯å­˜å…¥Brokerçš„æ—¶é—´`ã€‚å½“`Brokeræˆ–Topicå°†message.timestamp.typeè®¾ç½®ä¸ºLogAppendTimeæ—¶ç”Ÿæ•ˆ`ã€‚æ­¤æ—¶Brokerä¼šåœ¨`æ¥æ”¶åˆ°æ¶ˆæ¯åï¼Œå­˜å…¥ç£ç›˜å‰`ï¼Œå°†å…¶timestampå±æ€§å€¼è®¾ç½®ä¸ºå½“å‰æœºå™¨æ—¶é—´ã€‚ä¸€èˆ¬æ¶ˆæ¯æ¥æ”¶æ—¶é—´æ¯”è¾ƒæ¥è¿‘äºäº‹ä»¶å‘ç”Ÿæ—¶é—´ï¼Œéƒ¨åˆ†åœºæ™¯ä¸‹å¯ä»£æ›¿äº‹ä»¶å‘ç”Ÿæ—¶é—´ã€‚
- **æ¶ˆæ¯å¤„ç†æ—¶é—´**ã€‚ä¹Ÿå³Kafka Stream`å¤„ç†æ¶ˆæ¯æ—¶çš„æ—¶é—´`ã€‚

> æ³¨ï¼šKafka Streamå…è®¸é€šè¿‡å®ç°org.apache.kafka.streams.processor.TimestampExtractoræ¥å£è‡ªå®šä¹‰è®°å½•æ—¶é—´ã€‚

## 2. çª—å£

æµå¼æ•°æ®æ˜¯åœ¨æ—¶é—´ä¸Šæ— ç•Œçš„æ•°æ®ã€‚è€Œèšåˆæ“ä½œåªèƒ½ä½œç”¨åœ¨ç‰¹å®šçš„æ•°æ®é›†ï¼Œä¹Ÿå³æœ‰ç•Œçš„æ•°æ®é›†ä¸Šã€‚å› æ­¤éœ€è¦é€šè¿‡æŸç§æ–¹å¼ä»æ— ç•Œçš„æ•°æ®é›†ä¸ŠæŒ‰ç‰¹å®šçš„è¯­ä¹‰é€‰å–å‡ºæœ‰ç•Œçš„æ•°æ®ã€‚çª—å£æ˜¯ä¸€ç§éå¸¸å¸¸ç”¨çš„è®¾å®šè®¡ç®—è¾¹ç•Œçš„æ–¹å¼ã€‚ä¸åŒçš„æµå¼å¤„ç†ç³»ç»Ÿæ”¯æŒçš„çª—å£ç±»ä¼¼ï¼Œä½†ä¸å°½ç›¸åŒã€‚

Kafka Streamæ”¯æŒçš„çª—å£å¦‚ä¸‹ã€‚

ï¼ˆ1ï¼‰**Hopping Time Window** è¯¥çª—å£å®šä¹‰å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚å®ƒæœ‰ä¸¤ä¸ªå±æ€§ï¼Œä¸€ä¸ªæ˜¯`Window sizeï¼Œä¸€ä¸ªæ˜¯Advance interval`ã€‚`Window sizeæŒ‡å®šäº†çª—å£çš„å¤§å°`ï¼Œä¹Ÿå³æ¯æ¬¡è®¡ç®—çš„æ•°æ®é›†çš„å¤§å°ã€‚è€Œ`Advance intervalå®šä¹‰è¾“å‡ºçš„æ—¶é—´é—´éš”`ã€‚ä¸€ä¸ªå…¸å‹çš„åº”ç”¨åœºæ™¯æ˜¯ï¼Œæ¯éš”5ç§’é’Ÿè¾“å‡ºä¸€æ¬¡è¿‡å»1ä¸ªå°æ—¶å†…ç½‘ç«™çš„PVæˆ–è€…UVã€‚

 

![img](https://images2018.cnblogs.com/blog/963903/201808/963903-20180823013127357-1860834711.gif)

ï¼ˆ2ï¼‰**Tumbling Time Window**è¯¥çª—å£å®šä¹‰å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚å¯ä»¥è®¤ä¸ºå®ƒæ˜¯Hopping Time Windowçš„ä¸€ç§ç‰¹ä¾‹ï¼Œä¹Ÿå³**Window sizeå’ŒAdvance intervalç›¸ç­‰**ã€‚å®ƒçš„ç‰¹ç‚¹æ˜¯å„ä¸ªWindowä¹‹é—´å®Œå…¨ä¸ç›¸äº¤ã€‚

![img](https://images2018.cnblogs.com/blog/963903/201808/963903-20180823013225516-1830552448.gif)

ï¼ˆ3ï¼‰**Sliding Window** è¯¥çª—å£`åªç”¨äº2ä¸ªKStreamè¿›è¡ŒJoinè®¡ç®—æ—¶`ã€‚è¯¥çª—å£çš„å¤§å°å®šä¹‰`äº†Joinä¸¤ä¾§KStreamçš„æ•°æ®è®°å½•è¢«è®¤ä¸ºåœ¨åŒä¸€ä¸ªçª—å£çš„æœ€å¤§æ—¶é—´å·®`ã€‚å‡è®¾è¯¥çª—å£çš„å¤§å°ä¸º5ç§’ï¼Œåˆ™å‚ä¸Joinçš„2ä¸ªKStreamä¸­ï¼Œè®°å½•æ—¶é—´å·®å°äº5çš„è®°å½•è¢«è®¤ä¸ºåœ¨åŒä¸€ä¸ªçª—å£ä¸­ï¼Œå¯ä»¥è¿›è¡ŒJoinè®¡ç®—ã€‚

ï¼ˆ4ï¼‰**Session Window**è¯¥çª—å£ç”¨äºå¯¹KeyåšGroupåçš„èšåˆæ“ä½œä¸­ã€‚å®ƒéœ€è¦å¯¹Keyåšåˆ†ç»„ï¼Œç„¶åå¯¹ç»„å†…çš„æ•°æ®æ ¹æ®ä¸šåŠ¡éœ€æ±‚å®šä¹‰ä¸€ä¸ªçª—å£çš„èµ·å§‹ç‚¹å’Œç»“æŸç‚¹ã€‚ä¸€ä¸ªå…¸å‹çš„æ¡ˆä¾‹æ˜¯ï¼Œå¸Œæœ›é€šè¿‡Session Windowè®¡ç®—æŸä¸ªç”¨æˆ·è®¿é—®ç½‘ç«™çš„æ—¶é—´ã€‚å¯¹äºä¸€ä¸ªç‰¹å®šçš„ç”¨æˆ·ï¼ˆç”¨Keyè¡¨ç¤ºï¼‰è€Œè¨€ï¼Œå½“å‘ç”Ÿç™»å½•æ“ä½œæ—¶ï¼Œè¯¥ç”¨æˆ·ï¼ˆKeyï¼‰çš„çª—å£å³å¼€å§‹ï¼Œå½“å‘ç”Ÿé€€å‡ºæ“ä½œæˆ–è€…è¶…æ—¶æ—¶ï¼Œè¯¥ç”¨æˆ·ï¼ˆKeyï¼‰çš„çª—å£å³ç»“æŸã€‚çª—å£ç»“æŸæ—¶ï¼Œå¯è®¡ç®—è¯¥ç”¨æˆ·çš„è®¿é—®æ—¶é—´æˆ–è€…ç‚¹å‡»æ¬¡æ•°ç­‰ã€‚

## 3. Join

Kafka Streamç”±äºåŒ…å«`KStream`å’Œ`Ktable`ä¸¤ç§æ•°æ®é›†ï¼Œå› æ­¤æä¾›å¦‚ä¸‹Joinè®¡ç®—

- `KTable Join KTable ç»“æœä»ä¸ºKTable`ã€‚ä»»æ„ä¸€è¾¹æœ‰æ›´æ–°ï¼Œç»“æœKTableéƒ½ä¼šæ›´æ–°ã€‚
- `KStream Join KStream ç»“æœä¸ºKStream`ã€‚å¿…é¡»å¸¦çª—å£æ“ä½œï¼Œå¦åˆ™ä¼šé€ æˆJoinæ“ä½œä¸€ç›´ä¸ç»“æŸã€‚
- `KStream Join KTable / GlobalKTable ç»“æœä¸ºKStream`ã€‚åªæœ‰å½“KStreamä¸­æœ‰æ–°æ•°æ®æ—¶ï¼Œæ‰ä¼šè§¦å‘Joinè®¡ç®—å¹¶è¾“å‡ºç»“æœã€‚KStreamæ— æ–°æ•°æ®æ—¶ï¼ŒKTableçš„æ›´æ–°å¹¶ä¸ä¼šè§¦å‘Joinè®¡ç®—ï¼Œä¹Ÿä¸ä¼šè¾“å‡ºæ•°æ®ã€‚å¹¶ä¸”è¯¥æ›´æ–°åªå¯¹ä¸‹æ¬¡Joinç”Ÿæ•ˆã€‚ä¸€ä¸ªå…¸å‹çš„ä½¿ç”¨åœºæ™¯æ˜¯ï¼ŒKStreamä¸­çš„è®¢å•ä¿¡æ¯ä¸KTableä¸­çš„ç”¨æˆ·ä¿¡æ¯åšå…³è”è®¡ç®—ã€‚

`å¯¹äºJoinæ“ä½œï¼Œå¦‚æœè¦å¾—åˆ°æ­£ç¡®çš„è®¡ç®—ç»“æœï¼Œéœ€è¦ä¿è¯å‚ä¸Joinçš„KTableæˆ–KStreamä¸­Keyç›¸åŒçš„æ•°æ®è¢«åˆ†é…åˆ°åŒä¸€ä¸ªTask`ã€‚å…·ä½“æ–¹æ³•æ˜¯

- å‚ä¸Joinçš„KTableæˆ–KStreamçš„`Keyç±»å‹ç›¸åŒ`ï¼ˆå®é™…ä¸Šï¼Œä¸šåŠ¡å«æ„ä¹Ÿåº”è¯¥ç›¸åŒï¼‰
- å‚ä¸Joinçš„KTableæˆ–KStream`å¯¹åº”çš„Topicçš„Partitionæ•°ç›¸åŒ`
- Partitionerç­–ç•¥çš„æœ€ç»ˆç»“æœç­‰æ•ˆï¼ˆå®ç°ä¸éœ€è¦å®Œå…¨ä¸€æ ·ï¼Œåªè¦æ•ˆæœä¸€æ ·å³å¯ï¼‰ï¼Œä¹Ÿå³Keyç›¸åŒçš„æƒ…å†µä¸‹ï¼Œè¢«åˆ†é…åˆ°IDç›¸åŒçš„Partitionå†…

å¦‚æœä¸Šè¿°æ¡ä»¶ä¸æ»¡è¶³ï¼Œå¯é€šè¿‡è°ƒç”¨å¦‚ä¸‹æ–¹æ³•ä½¿å¾—å®ƒæ»¡è¶³ä¸Šè¿°æ¡ä»¶ã€‚

```java
KStream<K, V> through(Serde<K> keySerde, Serde<V> valSerde, StreamPartitioner<K, V> partitioner, String topic)
```

## 4. èšåˆä¸ä¹±åºå¤„ç†

èšåˆæ“ä½œå¯åº”ç”¨äºKStreamå’ŒKTableã€‚å½“`èšåˆå‘ç”Ÿåœ¨KStreamä¸Šæ—¶å¿…é¡»æŒ‡å®šçª—å£ï¼Œä»è€Œé™å®šè®¡ç®—çš„ç›®æ ‡æ•°æ®é›†ã€‚`

éœ€è¦è¯´æ˜çš„æ˜¯ï¼Œèšåˆæ“ä½œçš„`ç»“æœè‚¯å®šæ˜¯KTable`ã€‚å› ä¸ºKTableæ˜¯å¯æ›´æ–°çš„ï¼Œå¯ä»¥åœ¨æ™šåˆ°çš„æ•°æ®åˆ°æ¥æ—¶ï¼ˆä¹Ÿå³å‘ç”Ÿæ•°æ®ä¹±åºæ—¶ï¼‰æ›´æ–°ç»“æœKTableã€‚

ä½†éœ€è¦è¯´æ˜çš„æ˜¯ï¼Œ`Kafka Streamå¹¶ä¸ä¼šå¯¹æ‰€æœ‰æ™šåˆ°çš„æ•°æ®éƒ½é‡æ–°è®¡ç®—å¹¶æ›´æ–°ç»“æœé›†`ï¼Œè€Œæ˜¯è®©ç”¨æˆ·è®¾ç½®ä¸€ä¸ª`retention period`ï¼Œå°†æ¯ä¸ªçª—å£çš„ç»“æœé›†åœ¨å†…å­˜ä¸­ä¿ç•™ä¸€å®šæ—¶é—´ï¼Œè¯¥çª—å£å†…çš„æ•°æ®æ™šåˆ°æ—¶ï¼Œç›´æ¥åˆå¹¶è®¡ç®—ï¼Œå¹¶æ›´æ–°ç»“æœKTableã€‚è¶…è¿‡`retention period`åï¼Œè¯¥çª—å£ç»“æœå°†ä»å†…å­˜ä¸­åˆ é™¤ï¼Œå¹¶ä¸”æ™šåˆ°çš„æ•°æ®å³ä½¿è½å…¥çª—å£ï¼Œä¹Ÿä¼šè¢«ç›´æ¥ä¸¢å¼ƒã€‚

## 5. å®¹é”™

Kafka Streamä»å¦‚ä¸‹å‡ ä¸ªæ–¹é¢è¿›è¡Œå®¹é”™

- `é«˜å¯ç”¨çš„Partitionä¿è¯æ— æ•°æ®ä¸¢å¤±`ã€‚æ¯ä¸ªTaskè®¡ç®—ä¸€ä¸ªPartitionï¼Œè€ŒKafkaæ•°æ®å¤åˆ¶æœºåˆ¶ä¿è¯äº†Partitionå†…æ•°æ®çš„é«˜å¯ç”¨æ€§ï¼Œæ•…æ— æ•°æ®ä¸¢å¤±é£é™©ã€‚åŒæ—¶ç”±äºæ•°æ®æ˜¯æŒä¹…åŒ–çš„ï¼Œå³ä½¿ä»»åŠ¡å¤±è´¥ï¼Œä¾ç„¶å¯ä»¥é‡æ–°è®¡ç®—ã€‚
- `çŠ¶æ€å­˜å‚¨å®ç°å¿«é€Ÿæ•…éšœæ¢å¤å’Œä»æ•…éšœç‚¹ç»§ç»­å¤„ç†`ã€‚å¯¹äºJoinå’ŒèšåˆåŠçª—å£ç­‰æœ‰çŠ¶æ€è®¡ç®—ï¼ŒçŠ¶æ€å­˜å‚¨å¯ä¿å­˜ä¸­é—´çŠ¶æ€ã€‚å³ä½¿å‘ç”ŸFailoveræˆ–Consumer Rebalanceï¼Œä»ç„¶å¯ä»¥é€šè¿‡çŠ¶æ€å­˜å‚¨æ¢å¤ä¸­é—´çŠ¶æ€ï¼Œä»è€Œå¯ä»¥ç»§ç»­ä»Failoveræˆ–Consumer Rebalanceå‰çš„ç‚¹ç»§ç»­è®¡ç®—ã€‚
- `KTableä¸retention periodæä¾›äº†å¯¹ä¹±åºæ•°æ®çš„å¤„ç†èƒ½åŠ›`ã€‚

# å››ã€Kafka Streamåº”ç”¨ç¤ºä¾‹

- **åˆ›å»ºKTableå’ŒKStream**

```java
StreamsBuilder builder = new StreamsBuilder();
//StreamsBuilder.table(final String topic)åˆ›å»ºKTableå®ä¾‹çš„åŒæ—¶ï¼Œå†…éƒ¨ä¼šåˆ›å»ºä¸€ä¸ªStateStoreæ¥è·Ÿè¸ªæµçš„çŠ¶æ€ï¼Œä½†å®ƒä¸å¯ç”¨äºäº¤äº’å¼æŸ¥è¯¢ã€‚
// åˆ›å»ºKTableå®ä¾‹
KTable<String, StockTickerData> stockTickerTable = builder.table("stock-ticker-table");
// åˆ›å»ºKStreamå®ä¾‹
KStream<String, StockTickerData> stockTickerStream = builder.stream("stock-ticker-stream");
// æ‰“å°ç»“æœåˆ°æ§åˆ¶å°
stockTickerTable.toStream().print(Printed.<String, StockTickerData>toSysOut().withLabel("Stocks-KTable"));
stockTickerStream.print(Printed.<String, StockTickerData>toSysOut().withLabel("Stocks-KStream"));
```

- **å±æ€§é…ç½®**

```java
//application idç›¸å½“äºgroup idï¼Œbootstrap serversé…ç½®kafkaçš„brokersåœ°å€ï¼Œå¹¶é…ç½®keyä¸valueçš„åºåˆ—åŒ–ã€ååºåˆ—åŒ–å®ç°ç±»ã€‚
Properties props = new Properties();
props.put(StreamsConfig.APPLICATION_ID_CONFIG, "streams-pipe");
props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());
props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());
```

- **è¯»å–å¹¶å¤„ç†è¾“å‡º**

```java
//æœ€åé€šè¿‡StreamsBuilderæ¥åˆ›å»ºKStreamï¼Œè¿›è¡Œæ•°æ®å¤„ç†è½¬æ¢åè¾“å‡ºåˆ°ä¸€ä¸ªæ–°çš„topicæˆ–è€…å…¶ä»–å¤–éƒ¨å­˜å‚¨å™¨ä¸­ã€‚
builder.stream("streams-plaintext-input").to("streams-pipe-output");
final Topology topology = builder.build();
final KafkaStreams streams = new KafkaStreams(topology, props);
```

- **æ¨å‡ºæ—¶å¤„ç†é€»è¾‘**

```java
// attach shutdown handler to catch control-c
Runtime.getRuntime().addShutdownHook(new Thread("streams-shutdown-hook") { @Override public void run() { streams.close(); latch.countDown(); }
});
```

```java
package cc.gmem.study.kafka;

import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.KTable;
import org.apache.kafka.streams.kstream.Materialized;
import org.apache.kafka.streams.kstream.Produced;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;

import java.util.Arrays;
import java.util.Properties;
import java.util.concurrent.TimeUnit;

public class NameCountApplication {

    private static final Logger LOGGER = LogManager.getLogger( NameCountApplication.class );

    public static void main( final String[] args ) throws Exception {
        Properties config = new Properties();
        // åº”ç”¨çš„æ ‡è¯†ç¬¦ï¼Œä¸åŒçš„å®ä¾‹ä¾æ®æ­¤æ ‡è¯†ç¬¦ç›¸äº’å‘ç°
        config.put( StreamsConfig.APPLICATION_ID_CONFIG, "names-counter-application" );
        // å¯åŠ¨æ—¶ä½¿ç”¨çš„KafkaæœåŠ¡å™¨
        config.put( StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "kafka-1.gmem.cc:9092" );
        // é”®å€¼ä¸²è¡ŒåŒ–ç±»
        config.put( StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass() );
        config.put( StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass() );
        // High Level DSL for building topologies
        StreamsBuilder builder = new StreamsBuilder();
        // KStreamæ˜¯è®°å½•ï¼ˆKeyValueï¼‰æµçš„æŠ½è±¡
        KStream<String, String> nameBatches = builder.stream( "names" );
        KTable<String, Long> nameCounts = nameBatches
            // ä¸€åˆ°å¤šæ˜ å°„ï¼Œåˆ†å‰²å­—ç¬¦ä¸²
            .flatMapValues( nameBatch -> Arrays.asList( nameBatch.split( "\\W+" ) ) )
            // æ ¹æ®äººååˆ†ç»„
            .groupBy( ( key, name ) -> name )
            // è¿›è¡Œèšåˆï¼Œç»“æœå­˜æ”¾åˆ°StateStoreä¸­
            .count( Materialized.as( "names-count-store" ) );
        // è¾“å‡ºåˆ°ç›®æ ‡
        nameCounts.toStream().to( "names-count", Produced.with( Serdes.String(), Serdes.Long() ) );
        // æ„å»ºæµå¤„ç†ç¨‹åºå¹¶å¯åŠ¨
        KafkaStreams streams = new KafkaStreams( builder.build(), config );
        LOGGER.trace( "Prepare to start stream processing." );
        streams.start();

        TimeUnit.DAYS.sleep( 1 );  // é˜»å¡ä¸»çº¿ç¨‹
    }
}
```

# äº”ã€API

## 1. Topology

```java
Topology topology = new Topology();
// æŒ‡å®šæ‹“æ‰‘çš„è¾“å…¥ï¼Œä¹Ÿå°±æ˜¯Kafkaä¸»é¢˜
topology.addSource( "SOURCE", "src-topic" )
        // æ·»åŠ ä¸€ä¸ªå¤„ç†å™¨PROCESS1ï¼Œå…¶ä¸Šæ¸¸ä¸ºæ‹“æ‰‘è¾“å…¥ï¼ˆé€šè¿‡åç§°å¼•ç”¨ï¼‰
        .addProcessor( "PROCESS1", () -> new Processor1(), "SOURCE" )
        // æ·»åŠ å¦ä¸€ä¸ªå¤„ç†å™¨PROCESS2ï¼Œä»¥PROCESS1ä¸ºä¸Šæ¸¸
        .addProcessor( "PROCESS2", () -> new Processor2(), "PROCESS1" )
        // æ·»åŠ å¦ä¸€ä¸ªå¤„ç†å™¨PROCESS3ï¼Œä»ç„¶ä»¥PROCESS1ä¸ºä¸Šæ¸¸ï¼Œæ³¨æ„æ‹“æ‰‘åˆ†å‰äº†
        .addProcessor( "PROCESS3", () -> new Processor3(), "PROCESS1" )
        // æ·»åŠ ä¸€ä¸ªè¾“å‡ºå¤„ç†å™¨ï¼Œè¾“å‡ºåˆ°sink-topic1ï¼Œä»¥PROCESS1ä¸ºä¸Šæ¸¸
        .addSink( "SINK1", "sink-topic1", "PROCESS1" )
        // æ·»åŠ ä¸€ä¸ªè¾“å‡ºå¤„ç†å™¨ï¼Œè¾“å‡ºåˆ°sink-topic2ï¼Œä»¥PROCESS2ä¸ºä¸Šæ¸¸
        .addSink( "SINK2", "sink-topic2", "PROCESS2" )
        // æ·»åŠ ä¸€ä¸ªè¾“å‡ºå¤„ç†å™¨ï¼Œè¾“å‡ºåˆ°sink-topic3ï¼Œä»¥PROCESS3ä¸ºä¸Šæ¸¸
        .addSink( "SINK3", "sink-topic3", "PROCESS3" );
```

## 2.Processor

> è¯¥æ¥å£ç”¨äºå®šä¹‰ä¸€ä¸ªæµå¤„ç†å™¨ï¼Œä¹Ÿå°±æ˜¯`å¤„ç†å™¨æ‹“æ‰‘ä¸­çš„èŠ‚ç‚¹`ã€‚æµå¤„ç†å™¨ä»¥å‚æ•°åŒ–ç±»å‹çš„æ–¹å¼é™å®šäº†`å…¶é”®ã€å€¼çš„ç±»å‹`ã€‚ä½ å¯ä»¥å®šä¹‰ä»»æ„æ•°é‡çš„æµå¤„ç†å™¨ï¼Œå¹¶ä¸”è¿åŒå®ƒä»¬å…³è”çš„çŠ¶æ€å­˜å‚¨ä¸€èµ·ï¼Œç»„è£…å‡ºæ‹“æ‰‘ã€‚Processor.process()æ–¹æ³•é’ˆå¯¹æ”¶åˆ°çš„æ¯ä¸€ä¸ªè®°å½•è¿›è¡Œå¤„ç†ã€‚`Processor.init()æ–¹æ³•å®ä¾‹åŒ–äº†ä¸€ä¸ªProcessorContext`ï¼Œæµå¤„ç†å™¨å¯ä»¥è°ƒç”¨ä¸Šä¸‹æ–‡ï¼š
>
> 1. `context().scheduleï¼Œè°ƒåº¦ä¸€ä¸ªPunctuationå‡½æ•°ï¼Œå‘¨æœŸæ€§æ‰§è¡Œ`
> 2. `context().forwardï¼Œè½¬å‘æ–°çš„æˆ–è€…è¢«ä¿®æ”¹çš„é”®å€¼å¯¹ç»™ä¸‹æ¸¸å¤„ç†å™¨`
> 3. `context().commitï¼Œæäº¤å½“å‰å¤„ç†è¿›åº¦`

```java
package cc.gmem.study.kafka.streams.low;
 
import org.apache.kafka.streams.KeyValue;
import org.apache.kafka.streams.processor.Processor;
import org.apache.kafka.streams.processor.ProcessorContext;
import org.apache.kafka.streams.processor.PunctuationType;
import org.apache.kafka.streams.state.KeyValueIterator;
import org.apache.kafka.streams.state.KeyValueStore;
 
public class NameCounterProcessor implements Processor<String, String> {
    private ProcessorContext context;
    private KeyValueStore<String, Long> kvStore;
    @Override
    public void init( ProcessorContext context ) {
        // ä¿å­˜å¼•ç”¨ï¼Œç±»ä¼¼äºStormçš„TopologyContext
        this.context = context;
        // ä»ä¸Šä¸‹æ–‡ä¸­å–å›ä¸€ä¸ªçŠ¶æ€å­˜å‚¨
        this.kvStore = (KeyValueStore<String, Long>) context.getStateStore( "NameCounts" );
        // ä»¥å¢™ä¸Šæ—¶é—´ä¸ºå‡†ï¼Œæ¯ç§’æ‰§è¡ŒPunctuatoré€»è¾‘
        this.context.schedule( 1000, PunctuationType.WALL_CLOCK_TIME, timestamp -> {
            NameCounterProcessor.this.punctuate( timestamp );
        } );
    }
    /**
     * æ¥æ”¶ä¸€ä¸ªè®°å½•ï¼ˆäººååˆ—è¡¨ï¼‰å¹¶å¤„ç†
     *
     * @param dummy è®°å½•çš„é”®ï¼Œæ— ç”¨
     * @param line  è®°å½•çš„å€¼
     */
    @Override
    public void process( String dummy, String line ) {
        String[] names = line.toLowerCase().split( " " );
        // åœ¨é”®å€¼å­˜å‚¨ä¸­æ›´æ–°äººåè®¡æ•°
        for ( String name : names ) {
            Long oldCount = this.kvStore.get( name );
            if ( oldCount == null ) {
                this.kvStore.put( name, 1L );
            } else {
                this.kvStore.put( name, oldCount + 1L );
            }
        }
    }
    @Override
    public void punctuate( long timestamp ) {
        // è·å¾—é”®å€¼å­˜å‚¨çš„è¿­ä»£å™¨
        KeyValueIterator<String, Long> iter = this.kvStore.all();
        while ( iter.hasNext() ) {
            KeyValue<String, Long> entry = iter.next();
            // è½¬å‘è®°å½•ç»™ä¸‹æ¸¸å¤„ç†å™¨
            context.forward( entry.key, entry.value.toString() );
        }
        /**
         * è°ƒç”¨è€…å¿…é¡»è¦è´Ÿè´£å…³é—­çŠ¶æ€å­˜å‚¨ä¸Šçš„è¿­ä»£å™¨
         * å¦åˆ™å¯èƒ½ï¼ˆå–å†³äºåº•å±‚çŠ¶æ€å­˜å‚¨çš„å®ç°ï¼‰å¯¼è‡´å†…å­˜ã€æ–‡ä»¶å¥æŸ„çš„æ³„æ¼
         */
        iter.close();
        // è¯·æ±‚æäº¤å½“å‰æµçŠ¶æ€ï¼ˆæ¶ˆè´¹è¿›åº¦ï¼‰
        context.commit();
    }
    @Override
    public void close() {
        // åœ¨æ­¤å…³é—­æ‰€æœ‰æŒæœ‰çš„èµ„æºï¼Œä½†æ˜¯çŠ¶æ€å­˜å‚¨ä¸éœ€è¦å…³é—­ï¼Œç”±Kafka Streamè‡ªå·±ç»´æŠ¤å…¶ç”Ÿå‘½å‘¨æœŸ
    }
}
```

## 3. **StateStore**

#### .1. ä½¿ç”¨çŠ¶æ€å­˜å‚¨

> ä½¿ç”¨çŠ¶æ€å­˜å‚¨: è¦ä½æ‹“æ‰‘ä¸­æ¯ä¸ªProcessoræä¾›çŠ¶æ€å­˜å‚¨ï¼Œè°ƒç”¨ï¼š

```java
Topology topology = new Topology();
topology.addSource("Source", "source-topic")
    .addProcessor("Process", () -> new WordCountProcessor(), "Source")
    // ä¸ºå¤„ç†å™¨Processæä¾›ä¸€ä¸ªçŠ¶æ€å­˜å‚¨ 
    .addStateStore(countStoreSupplier, "Process");
```

#### 2. changelog

> ä¸ºäº†æ”¯æŒå®¹é”™ã€æ”¯æŒ`æ— æ•°æ®ä¸¢å¤±çš„çŠ¶æ€è¿ç§»`ï¼Œ çŠ¶æ€å­˜å‚¨å¯ä»¥`æŒç»­ä¸æ–­çš„ã€åœ¨åå°å¤‡ä»½åˆ°Kafkaä¸»é¢˜ä¸­`ã€‚ä¸Šè¿°ç”¨äºä¸»é¢˜è¢«ç§°ä¸ºçŠ¶æ€å­˜å‚¨çš„changelogä¸»é¢˜ï¼Œæˆ–è€…ç›´æ¥å«changelogã€‚ä½ å¯ä»¥å¯ç”¨æˆ–è€…ç¦ç”¨çŠ¶æ€å­˜å‚¨çš„å¤‡ä»½ç‰¹æ€§ã€‚æŒä¹…æ€§çš„KVå­˜å‚¨æ˜¯å®¹é”™çš„ï¼Œå®ƒå¤‡ä»½åœ¨ä¸€ä¸ªç´§å‡‘æ ¼å¼çš„changelogä¸»é¢˜ä¸­ã€‚ä½¿ç”¨ç´§å‡‘æ ¼å¼çš„åŸå› æ˜¯ï¼š
>
> 1. `é˜²æ­¢ä¸»é¢˜æ— é™å¢é•¿`
> 2. `å‡å°‘ä¸»é¢˜å ç”¨çš„å­˜å‚¨ç©ºé—´`
> 3. `å½“çŠ¶æ€å­˜å‚¨éœ€è¦é€šè¿‡Changelogæ¢å¤æ—¶ï¼Œç¼©çŸ­éœ€è¦çš„æ—¶é—´`
>
> æŒä¹…æ€§çš„çª—å£åŒ–å­˜å‚¨ä¹Ÿæ˜¯å®¹é”™çš„ï¼Œå®ƒåŸºäºç´§å‡‘æ ¼å¼ã€æ”¯æŒåˆ é™¤æœºåˆ¶çš„ä¸»é¢˜å¤‡ä»½ã€‚çª—å£åŒ–å­˜å‚¨çš„changelogçš„é”®çš„ä¸€éƒ¨åˆ†æ˜¯çª—å£æ—¶é—´æˆ³ï¼Œè¿‡æœŸçš„çª—å£å¯¹åº”çš„æ®µä¼šè¢«Kafkaçš„æ—¥å¿—æ¸…ç†å™¨æ¸…ç†ã€‚changelogçš„é»˜è®¤å­˜ç•™æ—¶é—´æ˜¯Windows#maintainMs() + 1å¤©ã€‚æŒ‡å®šStreamsConfig.WINDOW_STORE_CHANGE_LOG_ADDITIONAL_RETENTION_MS_CONFIGå¯ä»¥è¦†ç›–ä¹‹ã€‚

#### .3. ç›‘æ§çŠ¶æ€æ¢å¤

> `å¯åŠ¨åº”ç”¨ç¨‹åºæ—¶ï¼ŒçŠ¶æ€å­˜å‚¨é€šå¸¸ä¸éœ€è¦æ ¹æ®changelogæ¥æ¢å¤`ï¼Œ`ç›´æ¥åŠ è½½ç£ç›˜ä¸ŠæŒä¹…åŒ–çš„æ•°æ®`å°±å¯ä»¥ã€‚ä½†ä»¥ä¸‹åœºæ™¯ä¸­ï¼š
>
> 1. å®•æœºå¯¼è‡´æœ¬åœ°çŠ¶æ€ä¸¢å¤±
> 2. è¿è¡Œåœ¨æ— çŠ¶æ€ç¯å¢ƒä¸‹çš„åº”ç”¨ç¨‹åºé‡å¯
>
> çŠ¶æ€å­˜å‚¨éœ€è¦åŸºäºchangelogè¿›è¡Œå®Œæ•´çš„æ¢å¤ã€‚å¦‚æœchangelogä¸­çš„æ•°æ®é‡å¾ˆå¤§ï¼Œåˆ™æ¢å¤è¿‡ç¨‹å¯èƒ½ç›¸å½“çš„è€—æ—¶ã€‚åœ¨æ¢å¤å®Œæˆä¹‹å‰ï¼Œå¤„ç†å™¨æ‹“æ‰‘ä¸èƒ½å¤„ç†æ–°çš„æ•°æ®ã€‚
>
> è¦ç›‘æ§çŠ¶æ€å­˜å‚¨çš„æ¢å¤è¿›åº¦ï¼Œä½ éœ€è¦å®ç°org.apache.kafka.streams.processor.`StateRestoreListeneræ¥å£`ï¼Œå¹¶è°ƒç”¨KafkaStreams#`setGlobalStateRestoreListeneræ³¨å†Œä¹‹`

```java
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.streams.processor.StateRestoreListener;
// ç›‘å¬å™¨ä¼šè¢«æ‰€æœ‰org.apache.kafka.streams.processor.internals.StreamThreadå®ä¾‹å…±äº«ï¼Œå¹¶å¿…é¡»çº¿ç¨‹å®‰å…¨
public class ConsoleGlobalRestoreListerner implements StateRestoreListener {
    // åœ¨æ¢å¤è¿‡ç¨‹å¼€å§‹æ—¶å›è°ƒ
    public void onRestoreStart(
            final TopicPartition topicPartition,  // ä¸»é¢˜åˆ†åŒº
            final String storeName,               // çŠ¶æ€å­˜å‚¨åç§°
            final long startingOffset,            // éœ€è¦æ¢å¤çš„èµ·ç‚¹
            final long endingOffset               // éœ€è¦æ¢å¤çš„ç»ˆç‚¹
    ) {}
 
    // åœ¨æ¢å¤ä¸€æ‰¹æ¬¡æ•°æ®åå›è°ƒ
    public void onBatchRestored( final TopicPartition topicPartition,
            final String storeName,
            final long batchEndOffset,
            final long numRestored 
    ) {}
 
    // æ¢å¤å®Œæˆåå›è°ƒ
    public void onRestoreEnd( final TopicPartition topicPartition,
            final String storeName,
            final long totalRestored ) {}
}
```

#### 4. **å¯/ç¦changelog**

```java
// å¯ç”¨ï¼šStateStoreBuilder#withLoggingEnabled(Map<String, String>);
// ç¦ç”¨ï¼šStateStoreBuilder#withLoggingDisabled();
KeyValueBytesStoreSupplier countStoreSupplier = Stores.inMemoryKeyValueStore("Counts");
StateStoreBuilder builder = Stores
    .keyValueStoreBuilder(countStoreSupplier,Serdes.String(),Serdes.Long())
    .withLoggingDisabled();
```

### 4. æµè¡¨äºŒå…ƒæ€§

- Stream as Tableï¼š`ä¸€ä¸ªæµå¯ä»¥çœ‹åšæ˜¯ä¸€ä¸ªè¡¨çš„changelog`ã€‚æµä¸­çš„æ¯æ¡è®°å½•éƒ½æ•è·äº†è¡¨çš„ä¸€æ¬¡çŠ¶æ€å˜æ›´ï¼Œé€šè¿‡Replay changelogï¼Œæµå¯ä»¥è½¬å˜ä¸ºè¡¨ã€‚æµè®°å½•å’Œè¡¨è¡Œä¸ä¸€å®šæ˜¯1:1å¯¹åº”å…³ç³»ï¼Œæµè®°å½•å¯èƒ½ç»è¿‡èšåˆï¼Œæ›´æ–°åˆ°è¡¨ä¸­çš„ä¸€è¡Œ
- Table as Streamï¼š`è¡¨å¯ä»¥çœ‹åšæ˜¯æŸä¸ªç¬é—´çš„ã€æµä¸­æ¯ä¸ªé”®çš„æœ€ç»ˆå€¼æ„æˆçš„å¿«ç…§ã€‚`è¿­ä»£è¡¨ä¸­çš„é”®å€¼å¯¹å¾ˆå®¹æ˜“å°†å…¶è½¬æ¢ä¸ºæµ

```java
//é€šè¿‡è¯»å–Kafkaä¸»é¢˜ï¼Œå³å¯ä¸ºKafka Streamsæä¾›è¾“å…¥æµã€‚é¦–å…ˆä½ éœ€è¦å®ä¾‹åŒ–ä¸€ä¸ªStreamsBuilderï¼š
StreamsBuilder builder = new StreamsBuilder();
//åˆ›å»º KStream æµ
KStream<String, Long> nameCounts = builder.stream( 
    "names-counts-input-topic",  // è¾“å…¥ä¸»é¢˜åç§°
    Consumed.with(Serdes.String(), Serdes.Long()) // æŒ‡å®šé”®å€¼çš„ä¸²è¡ŒåŒ–å™¨
);

//åˆ›å»º KTable
KTable<String, Long> nameCounts = builder.table(
    Serdes.String(), /* é”®ä¸²è¡ŒåŒ–å™¨ */
    Serdes.Long(),   /* å€¼ä¸²è¡ŒåŒ–å™¨ */
    "name-counts-input-topic", /* è¾“å…¥ä¸»é¢˜ */
    "name-counts-partitioned-store" /* è¡¨å */);

//åˆ›å»ºGlobalKTable
GlobalKTable<String, Long> nameCounts = builder.globalTable(
    Serdes.String(), /* é”®ä¸²è¡ŒåŒ–å™¨ */
    Serdes.Long(),   /* å€¼ä¸²è¡ŒåŒ–å™¨ */
    "name-counts-input-topic", /* è¾“å…¥ä¸»é¢˜ */
    "name-counts-global-store" /* è¡¨å */);
```

`å¯ä»¥æŠŠä»»ä½•ä¸»é¢˜çœ‹åšæ˜¯changelogï¼Œå¹¶å°†å…¶è¯»å…¥åˆ°KTable`ã€‚å½“ï¼š

1. è®°å½•çš„é”®`ä¸å­˜åœ¨æ—¶`ï¼Œç›¸å½“äºæ‰§è¡Œ`INSERTæ“ä½œ`
2. è®°å½•çš„é”®å­˜åœ¨ï¼Œå€¼ä¸ä¸ºnullæ—¶ï¼Œç›¸å½“äºæ‰§è¡Œ`UPDATEæ“ä½œ`
3. è®°å½•çš„é”®å­˜åœ¨ï¼Œ`å€¼ä¸ºnullæ—¶`ï¼Œç›¸å½“äºæ‰§è¡Œ`DELETEæ“ä½œ`

KTableå¯¹åº”äº†ä»è¾“å…¥ä¸»é¢˜è¯»å–çš„ã€åˆ†åŒºåŒ–çš„è®°å½•çš„æµã€‚æµå¤„ç†ç¨‹åºçš„æ¯ä¸ªå®ä¾‹ï¼Œéƒ½ä¼šæ¶ˆè´¹è¾“å…¥ä¸»é¢˜çš„åˆ†åŒºçš„å­é›†ï¼Œå¹¶ä¸”åœ¨æ•´ä½“ä¸Šä¿è¯æ‰€æœ‰åˆ†åŒºéƒ½è¢«æ¶ˆè´¹ã€‚

### 5. æµè½¬æ¢æ“ä½œ

#### .1. æ— çŠ¶æ€è½¬åŒ–

- ä¸ä¾èµ–äºä»»ä½•çŠ¶æ€å³å¯å®Œæˆè½¬æ¢ï¼Œä¸è¦æ±‚æµå¤„ç†å™¨æœ‰å…³è”çš„StateStoreã€‚
- **branch**

> IOï¼šKStream â†’ KStreamï¼Œ`åŸºäºç»™å®šçš„æ–­è¨€é›†åˆ†å‰²KStreamï¼Œå°†å…¶åˆ†å‰²ä¸º1-Nä¸ªKStreamå®ä¾‹`ã€‚æ–­è¨€æŒ‰ç…§å£°æ˜çš„é¡ºåºä¾æ¬¡ä¼°ç®—ï¼Œæ¯ä¸ªè®°å½•åªè¢«è½¬å‘åˆ°ç¬¬ä¸€ä¸ªåŒ¹é…çš„ä¸‹æ¸¸æµä¸­ï¼š

```java
KStream<String, Long> stream = ...;
KStream<String, Long>[] branches = stream.branch(
        (key, value) -> key.startsWith("A"), /* ä»¥Aå¼€å¤´çš„é”®  */
        (key, value) -> key.startsWith("B"), /* ä»¥Bå¼€å¤´çš„é”® */
        (key, value) -> true                 /* æ‰€æœ‰å…¶å®ƒçš„è®°å½•å‡å‘å¾€æ­¤æµ  */
);
```

- **Filter**   **filterNot**

> IOï¼šKStream â†’ KStream æˆ– KTable â†’ KTable; åŸºäºç»™å®šçš„æ–­è¨€ï¼Œ`é’ˆå¯¹æ¯ä¸ªè®°å½•è¿›è¡Œä¼°ç®—ã€‚ä¼°ç®—ç»“æœä¸ºtrueçš„è®°å½•è¿›å…¥ä¸‹æ¸¸æµï¼š`

```java
// ä»…ä¿ç•™æ­£æ•°å€¼
stream.filter((key, value) -> value > 0);
// é’ˆå¯¹ä¸€ä¸ªKTableè¿›è¡Œè¿‡æ»¤ï¼Œç»“æœç‰©åŒ–åˆ°ä¸€ä¸ªStageStoreä¸­
Materialized m = Materialized.<String, Long, KeyValueStore<Bytes, byte[]>>as("filtered")
table.filter((key, value) -> value != 0, m);
```

- **flatMap**

> IOï¼šKStream â†’ KStream; åŸºäºä¸€ä¸ªè®°å½•ï¼Œäº§ç”Ÿ0-Nä¸ªè¾“å‡ºè®°å½•ï¼š

```java
KStream<String, Integer> transformed = stream.flatMap(
    (key, value) -> {
        // é”®å€¼å¯¹çš„åˆ—è¡¨
        List<KeyValue<String, Integer>> result = new LinkedList<>();
        result.add(KeyValue.pair(value.toUpperCase(), 1000));
        result.add(KeyValue.pair(value.toLowerCase(), 9000));
        return result;
    }
);
```

- **foreach**

> IOï¼šKStream â†’ void; ç»ˆç»“æ€§æ“ä½œï¼Œ`é’ˆå¯¹æ¯ä¸ªè®°å½•æ‰§è¡Œæ— çŠ¶æ€çš„æ“ä½œ`; éœ€è¦æ³¨æ„ï¼šæ“ä½œçš„å‰¯ä½œç”¨ï¼ˆä¾‹å¦‚å¯¹å¤–éƒ¨ç³»ç»Ÿçš„å†™ï¼‰æ— æ³•è¢«Kafkaè·Ÿè¸ªï¼Œä¹Ÿå°±æ˜¯è¯´`æ— æ³•è·å¾—Kafkaçš„å¤„ç†è¯­ä¹‰ä¿è¯`
>
> ç¤ºä¾‹ï¼š stream.**foreach**((key, value) -> System.out.println(key + " => " + value)); 

- **groupByKey**

>  IOï¼šKStream â†’ KGroupedStream; `åˆ†ç»„æ˜¯è¿›è¡Œæµ/è¡¨çš„èšåˆæ“ä½œçš„å‰æ`ã€‚åˆ†ç»„ä¿è¯äº†æ•°æ®è¢«æ­£ç¡®çš„åˆ†åŒºï¼Œä¿è¯åç»­æ“ä½œçš„æ­£å¸¸è¿›è¡Œå’Œåˆ†ç»„ç›¸å…³çš„ä¸€ä¸ªæ“ä½œæ˜¯çª—å£åŒ–ã€‚`åˆ©ç”¨çª—å£åŒ–ï¼Œå¯ä»¥å°†åˆ†ç»„åçš„è®°å½•äºŒæ¬¡åˆ†ç»„ï¼Œå½¢æˆä¸€ä¸ªä¸ªçª—å£ï¼Œç„¶åä»¥çª—å£ä¸ºå•ä½è¿›è¡Œèšåˆã€Joinä»…å½“æµè¢«æ ‡è®°ç”¨äºé‡æ–°åˆ†åŒº`ï¼Œåˆ™æ­¤æ“ä½œæ‰ä¼šå¯¼è‡´é‡æ–°åˆ†åŒºã€‚è¯¥æ“ä½œä¸å…è®¸ä¿®æ”¹é”®æˆ–è€…é”®ç±»å‹

```java
KGroupedStream<byte[], String> groupedStream = stream.groupByKey(
    // å¦‚æœé”®å€¼çš„ç±»å‹ä¸åŒ¹é…é…ç½®çš„é»˜è®¤ä¸²è¡ŒåŒ–å™¨ï¼Œåˆ™éœ€è¦æ˜ç¡®æŒ‡å®šï¼š
    Serialized.with(
         Serdes.ByteArray(),
         Serdes.String())
);
```

- **groupBy**

> IOï¼šKStream â†’ KGroupedStream æˆ– KTable â†’ KGroupedTable; å®é™…ä¸Šæ˜¯`selectKey+groupByKeyçš„ç»„åˆ`; åŸºäº`ä¸€ä¸ªæ–°çš„é”®æ¥åˆ†ç»„è®°å½•ï¼Œæ–°é”®çš„ç±»å‹å¯èƒ½å’Œè®°å½•æ—§çš„é”®ç±»å‹ä¸åŒã€‚`å½“å¯¹è¡¨è¿›è¡Œåˆ†ç»„æ—¶ï¼Œè¿˜å¯ä»¥æŒ‡å®šæ–°çš„å€¼ã€å€¼ç±»å‹; è¯¥æ“ä½œæ€»æ˜¯ä¼šå¯¼è‡´æ•°æ®çš„é‡æ–°åˆ†åŒºï¼Œå› æ­¤åœ¨å¯èƒ½çš„æƒ…å†µä¸‹ä½ åº”è¯¥ä¼˜é€‰groupByKeyï¼Œåè€…ä»…åœ¨å¿…è¦çš„æ—¶å€™åˆ†åŒº.

```java
KGroupedStream<String, String> groupedStream = stream.groupBy(
    (key, value) -> value,  // äº§ç”Ÿé”®å€¼å¯¹value:valueå¹¶ä¾æ­¤åˆ†ç»„
    Serialize.with(
         Serdes.String(), /* é”®çš„ç±»å‹å‘ç”Ÿæ”¹å˜ */
         Serdes.String())  /* value */
); 
KGroupedTable<String, Integer> groupedTable = table.groupBy(
    // äº§ç”Ÿé”®å€¼å¯¹  value:length(value)ï¼Œå¹¶ä¾æ­¤åˆ†ç»„
    (key, value) -> KeyValue.pair(value, value.length()),
    Serialized.with(
        Serdes.String(), /* é”®çš„ç±»å‘ç”Ÿæ”¹å˜ */
        Serdes.Integer()) /* å€¼çš„ç±»å‹å‘ç”Ÿæ”¹å˜  */
);
```

- **map**

> IOï¼šKStream â†’ KStream;  `æ ¹æ®ä¸€ä¸ªè¾“å…¥è®°å½•äº§ç”Ÿä¸€ä¸ªè¾“å‡ºè®°å½•ï¼Œä½ å¯ä»¥ä¿®æ”¹é”®å€¼çš„ç±»å‹`

```java
KStream<byte[], String> stream = ...;
KStream<String, Integer> transformed = stream.map(
    (key, value) -> KeyValue.pair(value.toLowerCase(), value.length()));
```

- **mapValues**: ç±»ä¼¼ä¸Šé¢ï¼Œä½†æ˜¯ä»…ä»…æ˜ å°„å€¼ï¼Œé”®ä¸å˜ 
- **print**: IOï¼šKStream â†’ void; `ç»ˆç»“æ“ä½œ`ï¼Œ`æ‰“å°è®°å½•åˆ°è¾“å‡ºæµä¸­ã€‚`stream.print(Printed.toFile("stream.out"));
- **selectKey**

> IOï¼šKStream â†’ KStream;  å¯¹æ¯ä¸ªè®°å½•åˆ†é…ä¸€ä¸ªæ–°çš„é”®ï¼Œé”®ç±»å‹å¯èƒ½æ”¹å˜ã€‚

```java
KStream<String, String> rekeyed = stream.selectKey((key, value) -> value.split(" ")[0])
```

- **toStream**

> IOï¼šKTable â†’ KStream;  å°†è¡¨è½¬æ¢ä¸ºæµï¼š table.toStream();

- **WriteAsText**

>  IOï¼šKStream â†’ void; `ç»ˆç»“æ€§æ“ä½œï¼Œå°†æµå†™å‡ºåˆ°æ–‡ä»¶`

#### .2. æœ‰çŠ¶æ€è½¬è½¬åŒ–

> è¿™ç±»è½¬æ¢æ“ä½œ`éœ€è¦ä¾èµ–äºæŸäº›çŠ¶æ€ä¿¡æ¯`ã€‚ä¾‹å¦‚åœ¨èšåˆæ€§æ“ä½œä¸­ï¼Œä¼š`ä½¿ç”¨çª—å£åŒ–çŠ¶æ€å­˜å‚¨æ¥ä¿å­˜ä¸Šä¸€ä¸ªçª—å£çš„èšåˆç»“æœ`ã€‚åœ¨Joinæ“ä½œä¸­ï¼Œä¼šä½¿ç”¨çª—`å£åŒ–çŠ¶æ€å­˜å‚¨åˆ°ç›®å‰ä¸ºæ­¢æ¥æ”¶åˆ°çš„ã€çª—å£è¾¹ç•Œå†…éƒ¨çš„æ‰€æœ‰è®°å½•`ã€‚çŠ¶æ€å­˜å‚¨é»˜è®¤æ”¯æŒå®¹é”™ï¼Œ`å¦‚æœå‡ºç°å¤±è´¥ï¼Œåˆ™Kafka Streamsä¼šé¦–å…ˆæ¢å¤æ‰€æœ‰çš„çŠ¶æ€å­˜å‚¨ï¼Œç„¶åå†è¿›è¡Œåç»­çš„å¤„ç†`ã€‚é«˜çº§çš„æœ‰çŠ¶æ€è½¬æ¢æ“ä½œåŒ…æ‹¬ï¼šèšåˆã€Joinï¼Œä»¥åŠé’ˆå¯¹ä¸¤è€…çš„çª—å£åŒ–æ”¯æŒã€‚

- **aggregate**

> IOï¼šKGroupedStream â†’ KTable æˆ– KGroupedTable â†’ KTable; æ»šåŠ¨èšåˆï¼ˆRolling Aggregationï¼‰æ“ä½œï¼Œæ ¹æ®åˆ†ç»„é”®å¯¹éçª—å£åŒ–çš„è®°å½•çš„å€¼è¿›è¡Œèšåˆ
>
> å½“å¯¹å·²åˆ†ç»„æµè¿›è¡Œèšåˆæ—¶ï¼Œä½ éœ€è¦æä¾›åˆå§‹åŒ–å™¨ï¼ˆç¡®å®šèšåˆåˆå€¼ï¼‰ã€èšåˆå™¨adderã€‚å½“èšåˆå·²åˆ†ç»„è¡¨æ—¶ï¼Œä½ éœ€è¦é¢å¤–æä¾›èšåˆå™¨subtractorã€‚

```java
KGroupedStream<Bytes, String> groupedStream = null;
KGroupedTable<Bytes, String> groupedTable = null;
// èšåˆä¸€ä¸ªåˆ†ç»„æµï¼Œå€¼ç±»å‹ä»å­—ç¬¦ä¸²å˜ä¸ºæ•´æ•°
KTable<Bytes, Long> aggregatedStream = groupedStream.aggregate(
    () -> 0L, /* åˆå§‹åŒ–å™¨ */
    ( aggKey, newValue, aggValue ) -> aggValue + newValue.length(), /* ç´¯åŠ å™¨ */
    Serdes.Long(), /* å€¼çš„ä¸²è¡ŒåŒ–å™¨ */
    "aggregated-stream-store" /* çŠ¶æ€å­˜å‚¨çš„åç§° */ );

KTable<Bytes, Long> aggregatedTable = groupedTable.aggregate(
    () -> 0L, /* åˆå§‹åŒ–å™¨ */
    ( aggKey, newValue, aggValue ) -> aggValue + newValue.length(), /* ç´¯åŠ å™¨ */
    ( aggKey, oldValue, aggValue ) -> aggValue - oldValue.length(), /* å‡æ³•å™¨ */
    Serdes.Long(), /* å€¼çš„ä¸²è¡ŒåŒ–å™¨ */
    "aggregated-table-store" /* çŠ¶æ€å­˜å‚¨çš„åç§° */ );
```

KGroupedStreamçš„èšåˆæ“ä½œçš„è¡Œä¸ºï¼š

1. å€¼ä¸ºnullçš„è®°å½•è¢«å¿½ç•¥
2. å½“é¦–æ¬¡æ”¶åˆ°æŸä¸ªæ–°çš„è®°å½•é”®æ—¶ï¼Œåˆå§‹åŒ–å™¨è¢«è°ƒç”¨
3. æ¯å½“æ¥æ”¶åˆ°énullå€¼çš„è®°å½•æ—¶ï¼Œç´¯åŠ å™¨è¢«è°ƒç”¨

KGroupedTableçš„èšåˆæ“ä½œçš„è¡Œä¸ºï¼š

1. å€¼ä¸ºnullçš„è®°å½•è¢«å¿½ç•¥
2. å½“é¦–æ¬¡æ”¶åˆ°æŸä¸ªæ–°çš„è®°å½•é”®æ—¶ï¼Œåˆå§‹åŒ–å™¨è¢«è°ƒç”¨ï¼ˆåœ¨è°ƒç”¨ç´¯åŠ å™¨/å‡æ³•å™¨ä¹‹å‰ï¼‰ã€‚ä¸KGroupedStreamä¸åŒï¼Œéšç€æ—¶é—´çš„æ¨ç§»ï¼Œé’ˆå¯¹ä¸€ä¸ªé”®ï¼Œå¯èƒ½è°ƒç”¨åˆå§‹åŒ–å™¨å¤šæ¬¡ã€‚åªè¦æ¥æ”¶åˆ°ç›®æ ‡é”®çš„å¢“ç¢‘è®°å½•
3. å½“é¦–æ¬¡æ”¶åˆ°æŸä¸ªé”®çš„énullå€¼æ—¶ï¼ˆINSERTæ“ä½œï¼‰ï¼Œè°ƒç”¨ç´¯åŠ å™¨
4. å½“éé¦–æ¬¡æ”¶åˆ°æŸä¸ªé”®çš„énullå€¼æ—¶ï¼ˆUPDATEæ“ä½œï¼‰ï¼š
   1. è°ƒç”¨å‡æ³•å™¨ï¼Œä¼ å…¥å­˜å‚¨åœ¨KTableè¡¨ä¸­çš„æ—§å€¼
   2. è°ƒç”¨ç´¯åŠ å™¨ï¼Œä¼ å…¥åˆšåˆšæ¥æ”¶åˆ°çš„æ–°å€¼
   3. ä¸Šè¿°ä¸¤ä¸ªèšåˆå™¨çš„æ‰§è¡Œé¡ºåºæœªå®šä¹‰
5. å½“æ¥æ”¶åˆ°å¢“ç¢‘è®°å½•ï¼ˆDELETEæ“ä½œï¼‰äº¦å³nullå€¼çš„è®°å½•æ—¶ï¼Œè°ƒç”¨å‡æ³•å™¨
6. ä¸è®ºä½•æ—¶ï¼Œå‡æ³•å™¨è¿”å›nullæ—¶éƒ½ä¼šå¯¼è‡´ç›¸åº”çš„é”®ä»ç»“æœKTableè¡¨ä¸­åˆ é™¤ã€‚é‡åˆ°ç›¸åŒé”®çš„ä¸‹ä¸€ä¸ªè®°å½•æ—¶ï¼Œä¼šæ‰§è¡Œç¬¬3æ­¥çš„è¡Œä¸º

- **KGroupedStream â†’ KTable**

> çª—å£åŒ–èšåˆï¼š`ä»¥çª—å£ä¸ºå•ä½ï¼Œæ ¹æ®åˆ†ç»„é”®`ï¼Œå¯¹KGroupedStreamä¸­çš„è®°å½•è¿›è¡Œèšåˆæ“ä½œï¼Œå¹¶æŠŠç»“æœå­˜æ”¾åˆ°çª—å£åŒ–çš„KTable

```java
KGroupedStream<String, Long> groupedStream = null;

// åŸºäºæ—¶é—´çš„çª—å£åŒ–ï¼ˆæ»šåŠ¨çª—å£ï¼‰
KTable<Windowed<String>, Long> timeWindowedAggregatedStream = groupedStream
    .windowedBy( TimeWindows.of( TimeUnit.MINUTES.toMillis( 5 ) ) )
    .aggregate(
    () -> 0L, /* åˆå§‹åŒ–å™¨ */
    ( aggKey, newValue, aggValue ) -> aggValue + newValue, /* ç´¯åŠ å™¨ */
    /* çŠ¶æ€å­˜å‚¨ */
    Materialized.<String, Long, WindowStore<Bytes, byte[]>>as( "time-windowed-aggregated-stream-store" )
    .withValueSerde( Serdes.Long() ) );
// åŸºäºä¼šè¯çš„çª—å£åŒ–
KTable<Windowed<String>, Long> sessionizedAggregatedStream = groupedStream
    .windowedBy( SessionWindows.with( TimeUnit.MINUTES.toMillis( 5 ) ) ) /* çª—å£å®šä¹‰ */
    .aggregate(
    () -> 0L, /* åˆå§‹åŒ–å™¨ */
    ( aggKey, newValue, aggValue ) -> aggValue + newValue, /* ç´¯åŠ å™¨ */
    ( aggKey, leftAggValue, rightAggValue ) -> leftAggValue + rightAggValue, /* ä¼šè¯åˆå¹¶å™¨ */
    Materialized.<String, Long, SessionStore<Bytes, byte[]>>as( "sessionized-aggregated-stream-store" ).withValueSerde( Serdes.Long() ) );
```



---

> ä½œè€…: liudongdong1  
> URL: https://liudongdong1.github.io/kafka_stream/  

