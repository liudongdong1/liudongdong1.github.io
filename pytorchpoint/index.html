<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <head>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>PytorchPoint - DAY By DAY</title><meta name="author" content="LiuDongdong">
<meta name="author-link" content="https://liudongdong1.github.io/">
<meta name="description" content="1.代码片段 1.1.导入配置 import torch import torch.nn as nn import torchvision print(torch.__version__) print(torch.version.cuda) print(torch.backends.cudnn.version()) print(torch.cuda.get_device_name(0)) 1.2. 显卡设置 # Device configuration device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;) #这只指定多张显卡 import os os.environ[&#39;CUDA_VISIBLE_DEVICES&#39;] = &#39;0,1&#39; #清除显存 torch.cuda.empty_cache() 1.3. Tensor 处理 tensor = torch.randn(3,4,5) print(tensor.type()) #" /><meta name="keywords" content='Pytorch' /><meta itemprop="name" content="PytorchPoint">
<meta itemprop="description" content="1.代码片段 1.1.导入配置 import torch import torch.nn as nn import torchvision print(torch.__version__) print(torch.version.cuda) print(torch.backends.cudnn.version()) print(torch.cuda.get_device_name(0)) 1.2. 显卡设置 # Device configuration device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;) #这只指定多张显卡 import os os.environ[&#39;CUDA_VISIBLE_DEVICES&#39;] = &#39;0,1&#39; #清除显存 torch.cuda.empty_cache() 1.3. Tensor 处理 tensor = torch.randn(3,4,5) print(tensor.type()) #"><meta itemprop="datePublished" content="2020-07-13T21:59:57+00:00" />
<meta itemprop="dateModified" content="2023-12-31T13:47:03+08:00" />
<meta itemprop="wordCount" content="1258"><meta itemprop="image" content="https://liudongdong1.github.io/logo.png"/>
<meta itemprop="keywords" content="Pytorch," /><meta property="og:title" content="PytorchPoint" />
<meta property="og:description" content="1.代码片段 1.1.导入配置 import torch import torch.nn as nn import torchvision print(torch.__version__) print(torch.version.cuda) print(torch.backends.cudnn.version()) print(torch.cuda.get_device_name(0)) 1.2. 显卡设置 # Device configuration device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;) #这只指定多张显卡 import os os.environ[&#39;CUDA_VISIBLE_DEVICES&#39;] = &#39;0,1&#39; #清除显存 torch.cuda.empty_cache() 1.3. Tensor 处理 tensor = torch.randn(3,4,5) print(tensor.type()) #" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://liudongdong1.github.io/pytorchpoint/" /><meta property="og:image" content="https://liudongdong1.github.io/logo.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-07-13T21:59:57+00:00" />
<meta property="article:modified_time" content="2023-12-31T13:47:03+08:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://liudongdong1.github.io/logo.png"/>

<meta name="twitter:title" content="PytorchPoint"/>
<meta name="twitter:description" content="1.代码片段 1.1.导入配置 import torch import torch.nn as nn import torchvision print(torch.__version__) print(torch.version.cuda) print(torch.backends.cudnn.version()) print(torch.cuda.get_device_name(0)) 1.2. 显卡设置 # Device configuration device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;) #这只指定多张显卡 import os os.environ[&#39;CUDA_VISIBLE_DEVICES&#39;] = &#39;0,1&#39; #清除显存 torch.cuda.empty_cache() 1.3. Tensor 处理 tensor = torch.randn(3,4,5) print(tensor.type()) #"/>
<meta name="application-name" content="DAY By DAY">
<meta name="apple-mobile-web-app-title" content="DAY By DAY"><meta name="theme-color" data-light="#f8f8f8" data-dark="#252627" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://liudongdong1.github.io/pytorchpoint/" /><link rel="prev" href="https://liudongdong1.github.io/dataset-record/" /><link rel="next" href="https://liudongdong1.github.io/pyspark/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "PytorchPoint",
    "inLanguage": "zh-CN",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https:\/\/liudongdong1.github.io\/pytorchpoint\/"
    },"genre": "posts","keywords": "Pytorch","wordcount":  1258 ,
    "url": "https:\/\/liudongdong1.github.io\/pytorchpoint\/","datePublished": "2020-07-13T21:59:57+00:00","dateModified": "2023-12-31T13:47:03+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
      "@type": "Organization",
      "name": "LiuDongdong","logo": "https:\/\/liudongdong1.github.io\/images\/person.png"},"author": {
        "@type": "Person",
        "name": "liudongdong1"
      },"description": ""
  }
  </script></head>
  <body data-header-desktop="auto" data-header-mobile="auto"><script>(window.localStorage?.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('data-theme', 'dark');</script><div class="wrapper"><script type="text/javascript"
        async
        src="https://cdnjs.cloudflare.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>
<header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper" data-github-corner="right">
    <div class="header-title">
      <a href="/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="DAY By DAY"
    title="DAY By DAY"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-desktop" class="typeit header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a
                class="menu-link"
                href="/posts/"
                
                
              ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/categories/"
                
                
              ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/tags/"
                
                
              ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/friends/"
                title="友情链接"
                
              ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/about/"
                
                
              ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li class="menu-item delimiter"></li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <ul class="sub-menu"><li class="menu-item">没有更多翻译</li></ul>
          </li><li class="menu-item search" id="search-desktop">
            <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-desktop">
            <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
              <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
            </a>
            <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
              <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
            </a>
            <span class="search-button search-loading" id="search-loading-desktop">
              <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
            </span>
          </li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li>
      </ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="/fixit.min.svg"
    title="/fixit.min.svg"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-mobile" class="typeit header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li class="search-wrapper">
            <div class="search mobile" id="search-mobile">
              <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-mobile">
              <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
              </a>
              <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
              </a>
              <span class="search-button search-loading" id="search-loading-mobile">
                <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
              </span>
            </div>
            <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
              取消
            </a>
          </li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/posts/"
                  
                  
                ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/categories/"
                  
                  
                ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/tags/"
                  
                  
                ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/friends/"
                  title="友情链接"
                  
                ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/about/"
                  
                  
                ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li
              class="menu-item text-center"
            ><a
                  class="menu-link"
                  href="/"
                  title="GitHub"
                  
                ><i class='fa-brands fa-github fa-fw' aria-hidden='true'></i> </a></li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <select class="language-select" onchange="location = this.value;"><option disabled>没有更多翻译</option></select>
          </li></ul>
    </nav>
  </div>
</header><div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
  </div>
  <div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
  </div><main class="container" data-page-style="normal"><aside class="toc" id="toc-auto"><h2 class="toc-title">目录 <i class="toc-icon fa-solid fa-angle-down fa-fw"></i></h2>
      <div class="toc-content" id="toc-content-auto"></div></aside>

  <aside class="aside-custom" id="aside-sakana">
    

<div class="sakana-widget">
  <div class="sakana-item" id="takina-widget"></div>
  <div class="sakana-item" id="chisato-widget"></div>
</div>
<script>
  function initSakanaWidget() {
    const takina = SakanaWidget.getCharacter('takina')
    SakanaWidget.registerCharacter('takina-slow', takina);
    new SakanaWidget({
      character: 'takina-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#takina-widget');

    const chisato = SakanaWidget.getCharacter('chisato')
    SakanaWidget.registerCharacter('chisato-slow', chisato);
    new SakanaWidget({
      character: 'chisato-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#chisato-widget');
  }
</script>
<script async onload="initSakanaWidget()" src="https://cdn.jsdelivr.net/npm/sakana-widget@2.3.0/lib/sakana.min.js">
</script></aside>

  <article class="page single">
    <div class="header"><h1 class="single-title animate__animated animate__flipInX">
        <span>PytorchPoint</span>
      </h1></div><div class="post-meta">
      <div class="post-meta-line"><span class="post-author"><span class="author"><i class="fa-solid fa-user-circle" aria-hidden="true"></i>
      liudongdong1</span></span>
          <span class="post-category">收录于 <a href="/categories/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;Categories</a>&ensp;<a href="/categories/framework/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;Framework</a></span></div>
      <div class="post-meta-line"><span title=2020-07-13&#32;21:59:57>
            <i class="fa-regular fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2020-07-13" >2020-07-13</time>
          </span>&nbsp;<i class="fa-solid fa-pencil-alt fa-fw"></i>&nbsp;约 1258 字&nbsp;
        <i class="fa-regular fa-clock fa-fw"></i>&nbsp;预计阅读 3 分钟&nbsp;<span id="busuanzi_container_page_pv" class="busuanzi_visitors comment-visitors" data-flag-title="PytorchPoint">
            <i class="fa-regular fa-eye fa-fw"></i>&nbsp;<span id="busuanzi_value_page_pv">-</span>&nbsp;次阅读
          </span>&nbsp;</div>
    </div><div class="featured-image"><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/sentences-and-symbols-on-wooden-wall.jpg"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/sentences-and-symbols-on-wooden-wall.jpg, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/sentences-and-symbols-on-wooden-wall.jpg 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/sentences-and-symbols-on-wooden-wall.jpg 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/sentences-and-symbols-on-wooden-wall.jpg"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/sentences-and-symbols-on-wooden-wall.jpg"/></div><div class="details toc" id="toc-static" kept="true">
        <div class="details-summary toc-title">
          <span>目录</span>
          <span><i class="details-icon fa-solid fa-angle-right"></i></span>
        </div>
        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#1代码片段">1.代码片段</a>
      <ul>
        <li></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li></li>
      </ul>
    </li>
  </ul>
</nav></div>
      </div><div
      class="content"
      id="content"
      
      
    ><h2 id="1代码片段">1.代码片段</h2>
<h4 id="11导入配置">1.1.导入配置</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torchvision
</span></span><span style="display:flex;"><span>print(torch<span style="color:#f92672">.</span>__version__)
</span></span><span style="display:flex;"><span>print(torch<span style="color:#f92672">.</span>version<span style="color:#f92672">.</span>cuda)
</span></span><span style="display:flex;"><span>print(torch<span style="color:#f92672">.</span>backends<span style="color:#f92672">.</span>cudnn<span style="color:#f92672">.</span>version())
</span></span><span style="display:flex;"><span>print(torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>get_device_name(<span style="color:#ae81ff">0</span>))
</span></span></code></pre></div><h4 id="12-显卡设置">1.2. 显卡设置</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Device configuration</span>
</span></span><span style="display:flex;"><span>device <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>device(<span style="color:#e6db74">&#39;cuda&#39;</span> <span style="color:#66d9ef">if</span> torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>is_available() <span style="color:#66d9ef">else</span> <span style="color:#e6db74">&#39;cpu&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e">#这只指定多张显卡</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span>os<span style="color:#f92672">.</span>environ[<span style="color:#e6db74">&#39;CUDA_VISIBLE_DEVICES&#39;</span>] <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;0,1&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#清除显存</span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>empty_cache()
</span></span></code></pre></div><h4 id="13-tensor-处理">1.3. Tensor 处理</h4>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200830084404.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200830084404.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200830084404.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200830084404.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200830084404.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200830084404.png"/></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tensor <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">4</span>,<span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>print(tensor<span style="color:#f92672">.</span>type())  <span style="color:#75715e"># 数据类型</span>
</span></span><span style="display:flex;"><span>print(tensor<span style="color:#f92672">.</span>size())  <span style="color:#75715e"># 张量的shape，是个元组</span>
</span></span><span style="display:flex;"><span>print(tensor<span style="color:#f92672">.</span>dim())   <span style="color:#75715e"># 维度的数量</span>
</span></span></code></pre></div><ul>
<li>torch reshape操作</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>d<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>reshape(c,(<span style="color:#ae81ff">5</span>,<span style="color:#ae81ff">2</span>))
</span></span></code></pre></div><ul>
<li>数据类型转化</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 设置默认类型，pytorch中的FloatTensor远远快于DoubleTensor</span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>set_default_tensor_type(torch<span style="color:#f92672">.</span>FloatTensor)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 类型转换</span>
</span></span><span style="display:flex;"><span>tensor <span style="color:#f92672">=</span> tensor<span style="color:#f92672">.</span>cuda()
</span></span><span style="display:flex;"><span>tensor <span style="color:#f92672">=</span> tensor<span style="color:#f92672">.</span>cpu()
</span></span><span style="display:flex;"><span>tensor <span style="color:#f92672">=</span> tensor<span style="color:#f92672">.</span>float()
</span></span><span style="display:flex;"><span>tensor <span style="color:#f92672">=</span> tensor<span style="color:#f92672">.</span>long()
</span></span></code></pre></div><ul>
<li>torch.Tensor&amp;&amp; np.ndarray</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#除了CharTensor，其他所有CPU上的张量都支持转换为numpy格式然后再转换回来。</span>
</span></span><span style="display:flex;"><span>ndarray <span style="color:#f92672">=</span> tensor<span style="color:#f92672">.</span>cpu()<span style="color:#f92672">.</span>numpy()
</span></span><span style="display:flex;"><span>tensor <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>from_numpy(ndarray)<span style="color:#f92672">.</span>float()
</span></span><span style="display:flex;"><span>tensor <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>from_numpy(ndarray<span style="color:#f92672">.</span>copy())<span style="color:#f92672">.</span>float() <span style="color:#75715e"># If ndarray has negative stride</span>
</span></span></code></pre></div><ul>
<li>torch.Tensor&amp;&amp;PIL.Image</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># pytorch中的张量默认采用[N, C, H, W]的顺序，并且数据范围在[0,1]，需要进行转置和规范化</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># torch.Tensor -&gt; PIL.Image</span>
</span></span><span style="display:flex;"><span>image <span style="color:#f92672">=</span> PIL<span style="color:#f92672">.</span>Image<span style="color:#f92672">.</span>fromarray(torch<span style="color:#f92672">.</span>clamp(tensor<span style="color:#f92672">*</span><span style="color:#ae81ff">255</span>, min<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, max<span style="color:#f92672">=</span><span style="color:#ae81ff">255</span>)<span style="color:#f92672">.</span>byte()<span style="color:#f92672">.</span>permute(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">0</span>)<span style="color:#f92672">.</span>cpu()<span style="color:#f92672">.</span>numpy())
</span></span><span style="display:flex;"><span>image <span style="color:#f92672">=</span> torchvision<span style="color:#f92672">.</span>transforms<span style="color:#f92672">.</span>functional<span style="color:#f92672">.</span>to_pil_image(tensor)  <span style="color:#75715e"># Equivalently way</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># PIL.Image -&gt; torch.Tensor</span>
</span></span><span style="display:flex;"><span>path <span style="color:#f92672">=</span> <span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;./figure.jpg&#39;</span>
</span></span><span style="display:flex;"><span>tensor <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>from_numpy(np<span style="color:#f92672">.</span>asarray(PIL<span style="color:#f92672">.</span>Image<span style="color:#f92672">.</span>open(path)))<span style="color:#f92672">.</span>permute(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>float() <span style="color:#f92672">/</span> <span style="color:#ae81ff">255</span>
</span></span><span style="display:flex;"><span>tensor <span style="color:#f92672">=</span> torchvision<span style="color:#f92672">.</span>transforms<span style="color:#f92672">.</span>functional<span style="color:#f92672">.</span>to_tensor(PIL<span style="color:#f92672">.</span>Image<span style="color:#f92672">.</span>open(path)) <span style="color:#75715e"># Equivalently way</span>
</span></span></code></pre></div><ul>
<li>np.ndarray&amp;&amp;PIL.Image</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>image<span style="color:#f92672">=</span>PIL<span style="color:#f92672">.</span>Image<span style="color:#f92672">.</span>fromarray(ndarray<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>uint8))
</span></span><span style="display:flex;"><span>ndarray<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>asarray(PIL<span style="color:#f92672">.</span>Image<span style="color:#f92672">.</span>open(path))
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 从只包含一个元素的张量中取值</span>
</span></span><span style="display:flex;"><span>value<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>rand(<span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span><span style="color:#75715e">#张量形变</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#相比于torch.view, torch.reshape可以自动处理张量不连续的情况</span>
</span></span><span style="display:flex;"><span>tensor<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>rand(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">6</span>,<span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>tensor<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>reshape(tensor,shape)
</span></span><span style="display:flex;"><span><span style="color:#75715e">#打乱顺序</span>
</span></span><span style="display:flex;"><span>tensor<span style="color:#f92672">=</span>tensor[torch<span style="color:#f92672">.</span>randperm(tensor<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>))] <span style="color:#75715e">#打乱第一维度</span>
</span></span></code></pre></div><ul>
<li>张量复制</li>
</ul>
<table>
<thead>
<tr>
<th>Operation</th>
<th>New/Shared memory</th>
<th>Still in computation graph</th>
</tr>
</thead>
<tbody>
<tr>
<td>tensor.clone()</td>
<td>New</td>
<td>Yes</td>
</tr>
<tr>
<td>tensor.detach()</td>
<td>shared</td>
<td>no</td>
</tr>
<tr>
<td>tensor.detach.clone()</td>
<td>new</td>
<td>no</td>
</tr>
</tbody>
</table>
<ul>
<li>张量拼接</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#e6db74">&#39;&#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">注意torch.cat和torch.stack的区别在于torch.cat沿着给定的维度拼接，
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">而torch.stack会新增一维。例如当参数是3个10x5的张量，torch.cat的结果是30x5的张量，
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">而torch.stack的结果是3x10x5的张量。
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>tensor <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat(list_of_tensors, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>tensor <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>stack(list_of_tensors, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span></code></pre></div><ul>
<li>one-hot编码</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># pytorch的标记默认从0开始</span>
</span></span><span style="display:flex;"><span>tensor <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">3</span>])
</span></span><span style="display:flex;"><span>N <span style="color:#f92672">=</span> tensor<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>num_classes <span style="color:#f92672">=</span> <span style="color:#ae81ff">4</span>
</span></span><span style="display:flex;"><span>one_hot <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>zeros(N, num_classes)<span style="color:#f92672">.</span>long()
</span></span><span style="display:flex;"><span>one_hot<span style="color:#f92672">.</span>scatter_(dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, index<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>unsqueeze(tensor, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>), src<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>ones(N, num_classes)<span style="color:#f92672">.</span>long())
</span></span></code></pre></div><ul>
<li>张量相等</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>allclose(tensor1, tensor2)  <span style="color:#75715e"># float tensor</span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>equal(tensor1, tensor2)     <span style="color:#75715e"># int tensor</span>
</span></span></code></pre></div><ul>
<li>张量乘法</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Matrix multiplcation: (m*n) * (n*p) * -&gt; (m*p).</span>
</span></span><span style="display:flex;"><span>result <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>mm(tensor1, tensor2)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Batch matrix multiplication: (b*m*n) * (b*n*p) -&gt; (b*m*p)</span>
</span></span><span style="display:flex;"><span>result <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>bmm(tensor1, tensor2)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Element-wise multiplication.</span>
</span></span><span style="display:flex;"><span>result <span style="color:#f92672">=</span> tensor1 <span style="color:#f92672">*</span> tensor2
</span></span></code></pre></div><h4 id="14-模型定义操作">1.4. 模型定义操作</h4>
<ul>
<li>俩层卷积</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># convolutional neural network (2 convolutional layers)</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">ConvNet</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, num_classes<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>):
</span></span><span style="display:flex;"><span>        super(ConvNet, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>layer1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">16</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>BatchNorm2d(<span style="color:#ae81ff">16</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>MaxPool2d(kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>))
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>layer2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">16</span>, <span style="color:#ae81ff">32</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>BatchNorm2d(<span style="color:#ae81ff">32</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>MaxPool2d(kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>))
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>fc <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">7</span><span style="color:#f92672">*</span><span style="color:#ae81ff">7</span><span style="color:#f92672">*</span><span style="color:#ae81ff">32</span>, num_classes)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>layer1(x)
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>layer2(out)
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> out<span style="color:#f92672">.</span>reshape(out<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>), <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>fc(out)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> out
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> ConvNet(num_classes)<span style="color:#f92672">.</span>to(device)
</span></span></code></pre></div><ul>
<li>将已有网络的所有BN层改为同步BN层</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">convertBNtoSyncBN</span>(module, process_group<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;Recursively replace all BN layers to SyncBN layer.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Args:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        module[torch.nn.Module]. Network
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> isinstance(module, torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>modules<span style="color:#f92672">.</span>batchnorm<span style="color:#f92672">.</span>_BatchNorm):
</span></span><span style="display:flex;"><span>        sync_bn <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>SyncBatchNorm(module<span style="color:#f92672">.</span>num_features, module<span style="color:#f92672">.</span>eps, module<span style="color:#f92672">.</span>momentum, 
</span></span><span style="display:flex;"><span>                                         module<span style="color:#f92672">.</span>affine, module<span style="color:#f92672">.</span>track_running_stats, process_group)
</span></span><span style="display:flex;"><span>        sync_bn<span style="color:#f92672">.</span>running_mean <span style="color:#f92672">=</span> module<span style="color:#f92672">.</span>running_mean
</span></span><span style="display:flex;"><span>        sync_bn<span style="color:#f92672">.</span>running_var <span style="color:#f92672">=</span> module<span style="color:#f92672">.</span>running_var
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> module<span style="color:#f92672">.</span>affine:
</span></span><span style="display:flex;"><span>            sync_bn<span style="color:#f92672">.</span>weight <span style="color:#f92672">=</span> module<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>clone()<span style="color:#f92672">.</span>detach()
</span></span><span style="display:flex;"><span>            sync_bn<span style="color:#f92672">.</span>bias <span style="color:#f92672">=</span> module<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>clone()<span style="color:#f92672">.</span>detach()
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> sync_bn
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> name, child_module <span style="color:#f92672">in</span> module<span style="color:#f92672">.</span>named_children():
</span></span><span style="display:flex;"><span>            setattr(module, name) <span style="color:#f92672">=</span> convert_syncbn_model(child_module, process_group<span style="color:#f92672">=</span>process_group))
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> module
</span></span></code></pre></div><ul>
<li>查看网络参数</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>params <span style="color:#f92672">=</span> list(model<span style="color:#f92672">.</span>named_parameters())
</span></span><span style="display:flex;"><span>(name, param) <span style="color:#f92672">=</span> params[<span style="color:#ae81ff">28</span>]
</span></span><span style="display:flex;"><span>print(name)
</span></span><span style="display:flex;"><span>print(param<span style="color:#f92672">.</span>grad)
</span></span></code></pre></div><ul>
<li><a href="szagoruyko/pytorchvizgithub.com">模型可视化</a></li>
<li>模型权重初始化</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Common practise for initialization.</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> layer <span style="color:#f92672">in</span> model<span style="color:#f92672">.</span>modules():
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> isinstance(layer, torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Conv2d):
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>kaiming_normal_(layer<span style="color:#f92672">.</span>weight, mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;fan_out&#39;</span>,
</span></span><span style="display:flex;"><span>                                      nonlinearity<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> layer<span style="color:#f92672">.</span>bias <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>            torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>constant_(layer<span style="color:#f92672">.</span>bias, val<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">elif</span> isinstance(layer, torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>BatchNorm2d):
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>constant_(layer<span style="color:#f92672">.</span>weight, val<span style="color:#f92672">=</span><span style="color:#ae81ff">1.0</span>)
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>constant_(layer<span style="color:#f92672">.</span>bias, val<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">elif</span> isinstance(layer, torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Linear):
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>xavier_normal_(layer<span style="color:#f92672">.</span>weight)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> layer<span style="color:#f92672">.</span>bias <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>            torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>constant_(layer<span style="color:#f92672">.</span>bias, val<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialization with given tensor.</span>
</span></span><span style="display:flex;"><span>layer<span style="color:#f92672">.</span>weight <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Parameter(tensor)
</span></span></code></pre></div><ul>
<li>提取网络中某一层</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 取模型中的前两层</span>
</span></span><span style="display:flex;"><span>new_model <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(<span style="color:#f92672">*</span>list(model<span style="color:#f92672">.</span>children())[:<span style="color:#ae81ff">2</span>] 
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 如果希望提取出模型中的所有卷积层，可以像下面这样操作：</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> layer <span style="color:#f92672">in</span> model<span style="color:#f92672">.</span>named_modules():
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> isinstance(layer[<span style="color:#ae81ff">1</span>],nn<span style="color:#f92672">.</span>Conv2d):
</span></span><span style="display:flex;"><span>         conv_model<span style="color:#f92672">.</span>add_module(layer[<span style="color:#ae81ff">0</span>],layer[<span style="color:#ae81ff">1</span>])
</span></span></code></pre></div><ul>
<li>模型加载</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>model<span style="color:#f92672">.</span>load_state_dict(torch<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#39;model.pth&#39;</span>), strict<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>load_state_dict(torch<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#39;model.pth&#39;</span>, map_location<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;cpu&#39;</span>))
</span></span><span style="display:flex;"><span><span style="color:#75715e">#导入另一个模型的相同部分到新的模型</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># model_new代表新的模型</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># model_saved代表其他模型，比如用torch.load导入的已保存的模型</span>
</span></span><span style="display:flex;"><span>model_new_dict <span style="color:#f92672">=</span> model_new<span style="color:#f92672">.</span>state_dict()
</span></span><span style="display:flex;"><span>model_common_dict <span style="color:#f92672">=</span> {k:v <span style="color:#66d9ef">for</span> k, v <span style="color:#f92672">in</span> model_saved<span style="color:#f92672">.</span>items() <span style="color:#66d9ef">if</span> k <span style="color:#f92672">in</span> model_new_dict<span style="color:#f92672">.</span>keys()}
</span></span><span style="display:flex;"><span>model_new_dict<span style="color:#f92672">.</span>update(model_common_dict)
</span></span><span style="display:flex;"><span>model_new<span style="color:#f92672">.</span>load_state_dict(model_new_dict)
</span></span></code></pre></div><h4 id="15-数据处理">1.5. 数据处理</h4>
<ul>
<li>计算数据集均值&amp;标准差</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> cv2
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torch.utils.data <span style="color:#f92672">import</span> Dataset
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> PIL <span style="color:#f92672">import</span> Image
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">compute_mean_and_std</span>(dataset):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 输入PyTorch的dataset，输出均值和标准差</span>
</span></span><span style="display:flex;"><span>    mean_r <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    mean_g <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    mean_b <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> img, _ <span style="color:#f92672">in</span> dataset:
</span></span><span style="display:flex;"><span>        img <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>asarray(img) <span style="color:#75715e"># change PIL Image to numpy array</span>
</span></span><span style="display:flex;"><span>        mean_b <span style="color:#f92672">+=</span> np<span style="color:#f92672">.</span>mean(img[:, :, <span style="color:#ae81ff">0</span>])
</span></span><span style="display:flex;"><span>        mean_g <span style="color:#f92672">+=</span> np<span style="color:#f92672">.</span>mean(img[:, :, <span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>        mean_r <span style="color:#f92672">+=</span> np<span style="color:#f92672">.</span>mean(img[:, :, <span style="color:#ae81ff">2</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    mean_b <span style="color:#f92672">/=</span> len(dataset)
</span></span><span style="display:flex;"><span>    mean_g <span style="color:#f92672">/=</span> len(dataset)
</span></span><span style="display:flex;"><span>    mean_r <span style="color:#f92672">/=</span> len(dataset)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    diff_r <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    diff_g <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    diff_b <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    N <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> img, _ <span style="color:#f92672">in</span> dataset:
</span></span><span style="display:flex;"><span>        img <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>asarray(img)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        diff_b <span style="color:#f92672">+=</span> np<span style="color:#f92672">.</span>sum(np<span style="color:#f92672">.</span>power(img[:, :, <span style="color:#ae81ff">0</span>] <span style="color:#f92672">-</span> mean_b, <span style="color:#ae81ff">2</span>))
</span></span><span style="display:flex;"><span>        diff_g <span style="color:#f92672">+=</span> np<span style="color:#f92672">.</span>sum(np<span style="color:#f92672">.</span>power(img[:, :, <span style="color:#ae81ff">1</span>] <span style="color:#f92672">-</span> mean_g, <span style="color:#ae81ff">2</span>))
</span></span><span style="display:flex;"><span>        diff_r <span style="color:#f92672">+=</span> np<span style="color:#f92672">.</span>sum(np<span style="color:#f92672">.</span>power(img[:, :, <span style="color:#ae81ff">2</span>] <span style="color:#f92672">-</span> mean_r, <span style="color:#ae81ff">2</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        N <span style="color:#f92672">+=</span> np<span style="color:#f92672">.</span>prod(img[:, :, <span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>shape)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    std_b <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sqrt(diff_b <span style="color:#f92672">/</span> N)
</span></span><span style="display:flex;"><span>    std_g <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sqrt(diff_g <span style="color:#f92672">/</span> N)
</span></span><span style="display:flex;"><span>    std_r <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sqrt(diff_r <span style="color:#f92672">/</span> N)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    mean <span style="color:#f92672">=</span> (mean_b<span style="color:#f92672">.</span>item() <span style="color:#f92672">/</span> <span style="color:#ae81ff">255.0</span>, mean_g<span style="color:#f92672">.</span>item() <span style="color:#f92672">/</span> <span style="color:#ae81ff">255.0</span>, mean_r<span style="color:#f92672">.</span>item() <span style="color:#f92672">/</span> <span style="color:#ae81ff">255.0</span>)
</span></span><span style="display:flex;"><span>    std <span style="color:#f92672">=</span> (std_b<span style="color:#f92672">.</span>item() <span style="color:#f92672">/</span> <span style="color:#ae81ff">255.0</span>, std_g<span style="color:#f92672">.</span>item() <span style="color:#f92672">/</span> <span style="color:#ae81ff">255.0</span>, std_r<span style="color:#f92672">.</span>item() <span style="color:#f92672">/</span> <span style="color:#ae81ff">255.0</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> mean, std
</span></span></code></pre></div><p>后续学习链接: <a href="https://mp.weixin.qq.com/s/JnIO_HjTrC0DCWtKrkYC8A"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/JnIO_HjTrC0DCWtKrkYC8A<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<h1 id="pytorch-书籍">pytorch 书籍</h1>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPotLDYAianDupMzw2shaQ9voSo3EpvNMV5YTHKSRDMFapGheP3eARD9Ew/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"
    data-srcset="https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPotLDYAianDupMzw2shaQ9voSo3EpvNMV5YTHKSRDMFapGheP3eARD9Ew/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1, https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPotLDYAianDupMzw2shaQ9voSo3EpvNMV5YTHKSRDMFapGheP3eARD9Ew/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1 1.5x, https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPotLDYAianDupMzw2shaQ9voSo3EpvNMV5YTHKSRDMFapGheP3eARD9Ew/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1 2x"
    data-sizes="auto"
    alt="img"
    title="img"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPol4iavYh9dyghIC59B7G0IFyROII0odKCLLicSJEVUAsKk8PMXYRFRGsA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"
    data-srcset="https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPol4iavYh9dyghIC59B7G0IFyROII0odKCLLicSJEVUAsKk8PMXYRFRGsA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1, https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPol4iavYh9dyghIC59B7G0IFyROII0odKCLLicSJEVUAsKk8PMXYRFRGsA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1 1.5x, https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPol4iavYh9dyghIC59B7G0IFyROII0odKCLLicSJEVUAsKk8PMXYRFRGsA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1 2x"
    data-sizes="auto"
    alt="img"
    title="img"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPohOYu7cL2ia33q4kk840JYZJWU06mFcknicj4eFD05jSs35EviaEiad9RFw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"
    data-srcset="https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPohOYu7cL2ia33q4kk840JYZJWU06mFcknicj4eFD05jSs35EviaEiad9RFw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1, https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPohOYu7cL2ia33q4kk840JYZJWU06mFcknicj4eFD05jSs35EviaEiad9RFw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1 1.5x, https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPohOYu7cL2ia33q4kk840JYZJWU06mFcknicj4eFD05jSs35EviaEiad9RFw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1 2x"
    data-sizes="auto"
    alt="img"
    title="img"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPoP5e4Y8dgHvwYZOjiabvBzHlhpUTTEYicJqibGHqKPz30BWlgyictjYT2Tg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"
    data-srcset="https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPoP5e4Y8dgHvwYZOjiabvBzHlhpUTTEYicJqibGHqKPz30BWlgyictjYT2Tg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1, https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPoP5e4Y8dgHvwYZOjiabvBzHlhpUTTEYicJqibGHqKPz30BWlgyictjYT2Tg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1 1.5x, https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPoP5e4Y8dgHvwYZOjiabvBzHlhpUTTEYicJqibGHqKPz30BWlgyictjYT2Tg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1 2x"
    data-sizes="auto"
    alt="img"
    title="img"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPo0rFPgzldhfoqZ6n5TW1fZk4icpUgF127moNSrO65S3sgMJCzP5Bz5uA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"
    data-srcset="https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPo0rFPgzldhfoqZ6n5TW1fZk4icpUgF127moNSrO65S3sgMJCzP5Bz5uA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1, https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPo0rFPgzldhfoqZ6n5TW1fZk4icpUgF127moNSrO65S3sgMJCzP5Bz5uA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1 1.5x, https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPo0rFPgzldhfoqZ6n5TW1fZk4icpUgF127moNSrO65S3sgMJCzP5Bz5uA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1 2x"
    data-sizes="auto"
    alt="img"
    title="img"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPozKO6je8bjk5REukz24LP7I19wFCe37v0vokI0mN1ABatbwo4a5Dpcw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"
    data-srcset="https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPozKO6je8bjk5REukz24LP7I19wFCe37v0vokI0mN1ABatbwo4a5Dpcw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1, https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPozKO6je8bjk5REukz24LP7I19wFCe37v0vokI0mN1ABatbwo4a5Dpcw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1 1.5x, https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPozKO6je8bjk5REukz24LP7I19wFCe37v0vokI0mN1ABatbwo4a5Dpcw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1 2x"
    data-sizes="auto"
    alt="img"
    title="img"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPocADHMqrwKwmZD80ibb3xQOicf8qMpLfX2w4VPOHgl6U6gZlTg3sFFsCw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"
    data-srcset="https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPocADHMqrwKwmZD80ibb3xQOicf8qMpLfX2w4VPOHgl6U6gZlTg3sFFsCw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1, https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPocADHMqrwKwmZD80ibb3xQOicf8qMpLfX2w4VPOHgl6U6gZlTg3sFFsCw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1 1.5x, https://mmbiz.qpic.cn/mmbiz_png/teF4oHzZ4IRTj9icBYLjWTcTrM8QTCtPocADHMqrwKwmZD80ibb3xQOicf8qMpLfX2w4VPOHgl6U6gZlTg3sFFsCw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1 2x"
    data-sizes="auto"
    alt="img"
    title="img"/></p>
<h4 id="learning-from--httpswwwlearnopencvcom">learning from:  <a href="https://www.learnopencv.com/"target="_blank" rel="external nofollow noopener noreferrer">https://www.learnopencv.com/<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></h4>
</div>
<div class="post-footer" id="post-footer">
  <div class="post-info">
    <div class="post-info-line">
      <div class="post-info-mod">
        <span title=2023-12-31&#32;13:47:03>更新于 2023-12-31&nbsp;</span>
      </div><div class="post-info-license">
          <span><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span>
        </div></div>
    <div class="post-info-line">
      <div class="post-info-md"><span><a href="/pytorchpoint/index.md" title="阅读原始文档" class="link-to-markdown">阅读原始文档</a></span><span><a href="https://liudongdong1.github.io/edit/master/content/posts%5c%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%5cpytorch%5cPytorchPoint.md" title="编辑此页"target="_blank" rel="external nofollow noopener noreferrer" class="link-to-edit">编辑此页</a></span></div>
      <div class="post-info-share">
        <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="https://liudongdong1.github.io/pytorchpoint/" data-title="PytorchPoint" data-hashtags="Pytorch"><i class="fa-brands fa-twitter fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="https://liudongdong1.github.io/pytorchpoint/" data-hashtag="Pytorch"><i class="fa-brands fa-facebook-square fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="https://liudongdong1.github.io/pytorchpoint/" data-title="PytorchPoint" data-image="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/sentences-and-symbols-on-wooden-wall.jpg"><i class="fa-brands fa-weibo fa-fw" aria-hidden="true"></i></a>
  </span>
      </div>
    </div>
  </div>

  <div class="post-info-more">
    <section class="post-tags"><i class="fa-solid fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/pytorch/">pytorch</a></section>
    <section>
      <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
    </section>
  </div>

  <div class="post-nav"><a href="/dataset-record/" class="prev" rel="prev" title="DataSet_Record"><i class="fa-solid fa-angle-left fa-fw" aria-hidden="true"></i>DataSet_Record</a>
      <a href="/pyspark/" class="next" rel="next" title="PySpark">PySpark<i class="fa-solid fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article></main><footer class="footer">
    <div class="footer-container"><div class="footer-line powered">由 <a href="https://gohugo.io/" target="_blank" rel="external nofollow noopener noreferrer" title="Hugo 0.118.2">Hugo</a> 强力驱动 | 主题 - <a href="https://github.com/hugo-fixit/FixIt" target="_blank" rel="external" title="FixIt v0.2.17-RC"><img class="fixit-icon" src="/fixit.min.svg" alt="FixIt logo" />&nbsp;FixIt</a>
        </div><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">2020 - 2024</span><span class="author" itemprop="copyrightHolder">
              <a href="https://liudongdong1.github.io/"target="_blank" rel="external nofollow noopener noreferrer">LiuDongdong</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div><div class="footer-line statistics"><span class="site-time" title='网站运行中 ...'><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden="true"></i>&nbsp;<span class="run-times">网站运行中 ...</span></span></div><div class="footer-line ibruce">
          <span id="busuanzi_container_site_uv" title='总访客数'><i class="fa-regular fa-user fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span><span id="busuanzi_container_site_pv" class="footer-divider" title='总访问量'><i class="fa-regular fa-eye fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span>
        </div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="回到顶部"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric">0%</span>
        </div></div><a href="https://liudongdong1.github.io/" title="在 GitHub 上查看源代码"target="_blank" rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><div id="mask"></div><div class="reading-progress-bar" style="left: 0;top: 0;--bg-progress: #0076ff;--bg-progress-dark: #fff;"></div><noscript>
    <div class="noscript-warning">FixIt 主题在启用 JavaScript 的情况下效果最佳。</div>
  </noscript>
</div><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script src="/lib/autocomplete/autocomplete.min.js" defer></script><script src="/lib/algoliasearch/algoliasearch-lite.umd.min.js" defer></script><script src="/lib/lazysizes/lazysizes.min.js" async defer></script><script src="/lib/sharer/sharer.min.js" async defer></script><script src="/lib/typeit/index.umd.js" defer></script><script src="/lib/katex/katex.min.js" defer></script><script src="/lib/katex/auto-render.min.js" defer></script><script src="/lib/katex/copy-tex.min.js" defer></script><script src="/lib/katex/mhchem.min.js" defer></script><script src="/lib/cookieconsent/cookieconsent.min.js" defer></script><script src="/lib/pangu/pangu.min.js" defer></script><script src="/lib/cell-watermark/watermark.min.js" defer></script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async defer></script><script>window.config={"code":{"copyTitle":"复制到剪贴板","editLockTitle":"锁定可编辑代码块","editUnLockTitle":"解锁可编辑代码块","editable":true,"maxShownLines":10},"comment":{"enable":false},"cookieconsent":{"content":{"dismiss":"同意","link":"了解更多","message":"本网站使用 Cookies 来改善您的浏览体验。"},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"data":{"typeit-header-subtitle-desktop":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e","typeit-header-subtitle-mobile":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e"},"enablePWA":true,"enablePangu":true,"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"2R1K9SKLQZ","algoliaIndex":"index.zh-cn","algoliaSearchKey":"4a226aa1c5c98d6859e4d1386adb2bc7","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"},"siteTime":"2020-12-18T16:15:22+08:00","typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"typeit-header-subtitle-desktop":["typeit-header-subtitle-desktop"],"typeit-header-subtitle-mobile":["typeit-header-subtitle-mobile"]},"duration":-1,"speed":100},"watermark":{"appendto":".wrapper\u003emain","colspacing":30,"content":"\u003cimg class=\"fixit-icon\" src=\"/fixit.min.svg\" alt=\"FixIt logo\" /\u003e FixIt 主题","enable":true,"fontfamily":"inherit","fontsize":0.85,"height":21,"opacity":0.0125,"rotate":15,"rowspacing":60,"width":150}};</script><script src="/js/theme.min.js" defer></script><script src="/js/custom.min.js" defer></script></body>
</html>
