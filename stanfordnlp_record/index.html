<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <head>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>Standfordnlp - DAY By DAY</title><meta name="author" content="LiuDongdong">
<meta name="author-link" content="https://liudongdong1.github.io/">
<meta name="description" content="NLTK 是一款著名的 Python 自然语言处理(Natural Language Processing, NLP)工具包，在其收集的大量公开数据集、模型上提供了全面、易用的接口，涵盖了分词、词性标注" /><meta name="keywords" content='NLP' /><meta itemprop="name" content="Standfordnlp">
<meta itemprop="description" content="NLTK 是一款著名的 Python 自然语言处理(Natural Language Processing, NLP)工具包，在其收集的大量公开数据集、模型上提供了全面、易用的接口，涵盖了分词、词性标注"><meta itemprop="datePublished" content="2020-08-15T07:56:09+00:00" />
<meta itemprop="dateModified" content="2023-09-28T23:29:20+08:00" />
<meta itemprop="wordCount" content="7372"><meta itemprop="image" content="/logo.png"/>
<meta itemprop="keywords" content="NLP," /><meta property="og:title" content="Standfordnlp" />
<meta property="og:description" content="NLTK 是一款著名的 Python 自然语言处理(Natural Language Processing, NLP)工具包，在其收集的大量公开数据集、模型上提供了全面、易用的接口，涵盖了分词、词性标注" />
<meta property="og:type" content="article" />
<meta property="og:url" content="liudongdong1.github.io/stanfordnlp_record/" /><meta property="og:image" content="/logo.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-08-15T07:56:09+00:00" />
<meta property="article:modified_time" content="2023-09-28T23:29:20+08:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="/logo.png"/>

<meta name="twitter:title" content="Standfordnlp"/>
<meta name="twitter:description" content="NLTK 是一款著名的 Python 自然语言处理(Natural Language Processing, NLP)工具包，在其收集的大量公开数据集、模型上提供了全面、易用的接口，涵盖了分词、词性标注"/>
<meta name="application-name" content="DAY By DAY">
<meta name="apple-mobile-web-app-title" content="DAY By DAY"><meta name="theme-color" data-light="#f8f8f8" data-dark="#252627" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="liudongdong1.github.io/stanfordnlp_record/" /><link rel="prev" href="liudongdong1.github.io/picturecompress/" /><link rel="next" href="liudongdong1.github.io/nlprelative/" /><link rel="stylesheet" href="/liudongdong1.github.io/css/style.min.css"><link rel="stylesheet" href="/liudongdong1.github.io/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/liudongdong1.github.io/lib/animate/animate.min.css"><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "Standfordnlp",
    "inLanguage": "zh-CN",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "liudongdong1.github.io\/stanfordnlp_record\/"
    },"genre": "posts","keywords": "NLP","wordcount":  7372 ,
    "url": "liudongdong1.github.io\/stanfordnlp_record\/","datePublished": "2020-08-15T07:56:09+00:00","dateModified": "2023-09-28T23:29:20+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
      "@type": "Organization",
      "name": "LiuDongdong","logo": "\/images\/person.png"},"author": {
        "@type": "Person",
        "name": "liudongdong1"
      },"description": ""
  }
  </script></head>
  <body data-header-desktop="auto" data-header-mobile="auto"><script>(window.localStorage?.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('data-theme', 'dark');</script><div class="wrapper"><header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper" data-github-corner="right">
    <div class="header-title">
      <a href="liudongdong1.github.io/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="DAY By DAY"
    title="DAY By DAY"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-desktop" class="typeit header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/posts/"
                
                
              ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/categories/"
                
                
              ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/tags/"
                
                
              ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/friends/"
                title="友情链接"
                
              ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/about/"
                
                
              ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li class="menu-item delimiter"></li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <ul class="sub-menu"><li class="menu-item">没有更多翻译</li></ul>
          </li><li class="menu-item search" id="search-desktop">
            <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-desktop">
            <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
              <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
            </a>
            <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
              <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
            </a>
            <span class="search-button search-loading" id="search-loading-desktop">
              <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
            </span>
          </li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li>
      </ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="liudongdong1.github.io/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="/fixit.min.svg"
    title="/fixit.min.svg"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-mobile" class="typeit header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li class="search-wrapper">
            <div class="search mobile" id="search-mobile">
              <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-mobile">
              <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
              </a>
              <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
              </a>
              <span class="search-button search-loading" id="search-loading-mobile">
                <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
              </span>
            </div>
            <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
              取消
            </a>
          </li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/posts/"
                  
                  
                ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/categories/"
                  
                  
                ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/tags/"
                  
                  
                ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/friends/"
                  title="友情链接"
                  
                ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/about/"
                  
                  
                ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li
              class="menu-item text-center"
            ><a
                  class="menu-link"
                  href="https://liudongdong1.github.io/"
                  title="GitHub"
                  rel="noopener noreferrer" target="_blank"
                ><i class='fa-brands fa-github fa-fw' aria-hidden='true'></i> </a></li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <select class="language-select" onchange="location = this.value;"><option disabled>没有更多翻译</option></select>
          </li></ul>
    </nav>
  </div>
</header><div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
  </div>
  <div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
  </div><main class="container" data-page-style="normal"><aside class="toc" id="toc-auto"><h2 class="toc-title">目录 <i class="toc-icon fa-solid fa-angle-down fa-fw"></i></h2>
      <div class="toc-content" id="toc-content-auto"></div></aside>

  <aside class="aside-custom" id="aside-sakana">
    

<div class="sakana-widget">
  <div class="sakana-item" id="takina-widget"></div>
  <div class="sakana-item" id="chisato-widget"></div>
</div>
<script>
  function initSakanaWidget() {
    const takina = SakanaWidget.getCharacter('takina')
    SakanaWidget.registerCharacter('takina-slow', takina);
    new SakanaWidget({
      character: 'takina-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#takina-widget');

    const chisato = SakanaWidget.getCharacter('chisato')
    SakanaWidget.registerCharacter('chisato-slow', chisato);
    new SakanaWidget({
      character: 'chisato-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#chisato-widget');
  }
</script>
<script async onload="initSakanaWidget()" src="https://cdn.jsdelivr.net/npm/sakana-widget@2.3.0/lib/sakana.min.js">
</script></aside>

  <article class="page single">
    <div class="header"><h1 class="single-title animate__animated animate__flipInX">
        <span>Standfordnlp</span>
      </h1></div><div class="post-meta">
      <div class="post-meta-line"><span class="post-author"><span class="author"><i class="fa-solid fa-user-circle" aria-hidden="true"></i>
      liudongdong1</span></span>
          <span class="post-category">收录于 <a href="liudongdong1.github.io/categories/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;Categories</a>&ensp;<a href="liudongdong1.github.io/categories/nlp/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;NLP</a></span></div>
      <div class="post-meta-line"><span title=2020-08-15&#32;07:56:09>
            <i class="fa-regular fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2020-08-15" >2020-08-15</time>
          </span>&nbsp;<i class="fa-solid fa-pencil-alt fa-fw"></i>&nbsp;约 7372 字&nbsp;
        <i class="fa-regular fa-clock fa-fw"></i>&nbsp;预计阅读 15 分钟&nbsp;<span id="busuanzi_container_page_pv" class="busuanzi_visitors comment-visitors" data-flag-title="Standfordnlp">
            <i class="fa-regular fa-eye fa-fw"></i>&nbsp;<span id="busuanzi_value_page_pv">-</span>&nbsp;次阅读
          </span>&nbsp;</div>
    </div><div class="featured-image"><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/82.jpeg"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/82.jpeg, https://gitee.com/github-25970295/blogImage/raw/master/img/82.jpeg 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/82.jpeg 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/82.jpeg"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/82.jpeg"/></div><div class="details toc" id="toc-static" kept="true">
        <div class="details-summary toc-title">
          <span>目录</span>
          <span><i class="details-icon fa-solid fa-angle-right"></i></span>
        </div>
        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#1-命名实体识别">1. 命名实体识别</a></li>
        <li><a href="#11-nltk">1.1. NLTK</a></li>
      </ul>
    </li>
    <li><a href="#2stanfordnlp">2.StanfordNlp</a></li>
    <li><a href="#3-jieba-分词">3. jieba 分词</a>
      <ul>
        <li><a href="#31-分词">3.1. 分词</a></li>
        <li><a href="#32-搜索引擎模式">3.2. 搜索引擎模式</a></li>
        <li><a href="#33-关键词提取">3.3. 关键词提取</a></li>
        <li><a href="#34-词性标注">3.4. 词性标注</a></li>
      </ul>
    </li>
    <li><a href="#4-nlp-pyltp">4. nlp-pyltp</a></li>
    <li><a href="#5-学习链接">5. 学习链接</a></li>
  </ul>
</nav></div>
      </div><div
      class="content"
      id="content"
      
      
    ><blockquote>
<p>NLTK 是一款著名的 Python 自然语言处理(Natural Language Processing, NLP)工具包，在其收集的大量公开数据集、模型上提供了全面、易用的接口，涵盖了分词、词性标注(Part-Of-Speech tag, POS-tag)、命名实体识别(Named Entity Recognition, NER)、句法分析(Syntactic Parse)等各项 NLP 领域的功能。</p>
</blockquote>
<blockquote>
<p>Stanford NLP 是由斯坦福大学的 NLP 小组开源的 Java 实现的 NLP 工具包，同样对 NLP 领域的各个问题提供了解决办法。斯坦福大学的 NLP 小组是世界知名的研究小组，如果能将 NLTK 和 Stanford NLP 这两个工具包结合起来使用，那自然是极好的！在 2004 年 Steve Bird 在 NLTK 中加上了对 Stanford NLP 工具包的支持，通过调用外部的 jar 文件来使用 Stanford NLP 工具包的功能。现在的 NLTK 中，通过封装提供了 Stanford NLP 中的以下几个功能:</p>
<ol>
<li>分词</li>
<li>词性标注</li>
<li>命名实体识别</li>
<li>句法分析</li>
<li>依存句法分析</li>
</ol>
</blockquote>
<h3 id="1-命名实体识别">1. 命名实体识别</h3>
<blockquote>
<p>命名实体识别（Named Entity Recognition，简称NER）是信息提取、问答系统、句法分析、机器翻译等应用领域的重要基础工具，在自然语言处理技术走向实用化的过程中占有重要地位。一般来说，<strong>命名实体识别的任务就是识别出待处理文本中三大类（实体类、时间类和数字类）、七小类（人名、机构名、地名、时间、日期、货币和百分比）命名实体。</strong></p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116085824037.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116085824037.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116085824037.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116085824037.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116085824037.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116085824037.png"/></p>
<h3 id="11-nltk">1.1. NLTK</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>pip install nltk
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> nltk
</span></span><span style="display:flex;"><span>nltk<span style="color:#f92672">.</span>download()
</span></span></code></pre></div><p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116094247020.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116094247020.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116094247020.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116094247020.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116094247020.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116094247020.png"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116094708285.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116094708285.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116094708285.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116094708285.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116094708285.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116094708285.png"/></p>
<h4 id="111-语料库">1.1.1. 语料库</h4>
<table>
<thead>
<tr>
<th><strong>语料库</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>gutenberg</strong></td>
<td><strong>一个有若干万部的小说语料库，多是古典作品</strong></td>
</tr>
<tr>
<td><strong>webtext</strong></td>
<td><strong>收集的网络广告等内容</strong></td>
</tr>
<tr>
<td><strong>nps_chat</strong></td>
<td><strong>有上万条聊天消息语料库，即时聊天消息为主</strong></td>
</tr>
<tr>
<td><strong>brown</strong></td>
<td><strong>一个百万词级的英语语料库，按文体进行分类</strong></td>
</tr>
<tr>
<td><strong>reuters</strong></td>
<td><strong>路透社语料库，上万篇新闻方档，约有1百万字，分90个主题，并分为训练集和测试集两组</strong></td>
</tr>
<tr>
<td><strong>inaugural</strong></td>
<td><strong>演讲语料库，几十个文本，都是总统演说</strong></td>
</tr>
</tbody>
</table>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> brown
</span></span><span style="display:flex;"><span>print(brown<span style="color:#f92672">.</span>categories())   <span style="color:#75715e">#输出brown语料库的类别</span>
</span></span><span style="display:flex;"><span>print(len(brown<span style="color:#f92672">.</span>sents()))   <span style="color:#75715e">#输出brown语料库的句子数量</span>
</span></span><span style="display:flex;"><span>print(len(brown<span style="color:#f92672">.</span>words()))   <span style="color:#75715e">#输出brown语料库的词数量</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;&#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">结果为：
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[&#39;adventure&#39;, &#39;belles_lettres&#39;, &#39;editorial&#39;, &#39;fiction&#39;, &#39;government&#39;, &#39;hobbies&#39;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;humor&#39;, &#39;learned&#39;, &#39;lore&#39;, &#39;mystery&#39;, &#39;news&#39;, &#39;religion&#39;, &#39;reviews&#39;, &#39;romance&#39;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;science_fiction&#39;]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">57340
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">1161192
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;&#39;&#39;</span>
</span></span></code></pre></div><h4 id="112-词频统计frequency">1.1.2. 词频统计(frequency)</h4>
<table>
<thead>
<tr>
<th><strong>方法</strong></th>
<th><strong>作用</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>B()</strong></td>
<td><strong>返回词典的长度</strong></td>
</tr>
<tr>
<td><strong>plot(title,cumulative=False)</strong></td>
<td><strong>绘制频率分布图，若cumu为True，则是累积频率分布图</strong></td>
</tr>
<tr>
<td><strong>tabulate()</strong></td>
<td><strong>生成频率分布的表格形式</strong></td>
</tr>
<tr>
<td><strong>most_common()</strong></td>
<td><strong>返回出现次数最频繁的词与频度</strong></td>
</tr>
<tr>
<td><strong>hapaxes()</strong></td>
<td><strong>返回只出现过一次的词</strong></td>
</tr>
</tbody>
</table>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> nltk
</span></span><span style="display:flex;"><span>tokens<span style="color:#f92672">=</span>[ <span style="color:#e6db74">&#39;my&#39;</span>,<span style="color:#e6db74">&#39;dog&#39;</span>,<span style="color:#e6db74">&#39;has&#39;</span>,<span style="color:#e6db74">&#39;flea&#39;</span>,<span style="color:#e6db74">&#39;problems&#39;</span>,<span style="color:#e6db74">&#39;help&#39;</span>,<span style="color:#e6db74">&#39;please&#39;</span>,
</span></span><span style="display:flex;"><span>         <span style="color:#e6db74">&#39;maybe&#39;</span>,<span style="color:#e6db74">&#39;not&#39;</span>,<span style="color:#e6db74">&#39;take&#39;</span>,<span style="color:#e6db74">&#39;him&#39;</span>,<span style="color:#e6db74">&#39;to&#39;</span>,<span style="color:#e6db74">&#39;dog&#39;</span>,<span style="color:#e6db74">&#39;park&#39;</span>,<span style="color:#e6db74">&#39;stupid&#39;</span>,
</span></span><span style="display:flex;"><span>         <span style="color:#e6db74">&#39;my&#39;</span>,<span style="color:#e6db74">&#39;dalmation&#39;</span>,<span style="color:#e6db74">&#39;is&#39;</span>,<span style="color:#e6db74">&#39;so&#39;</span>,<span style="color:#e6db74">&#39;cute&#39;</span>,<span style="color:#e6db74">&#39;I&#39;</span>,<span style="color:#e6db74">&#39;love&#39;</span>,<span style="color:#e6db74">&#39;him&#39;</span>  ]
</span></span><span style="display:flex;"><span><span style="color:#75715e">#统计词频</span>
</span></span><span style="display:flex;"><span>freq <span style="color:#f92672">=</span> nltk<span style="color:#f92672">.</span>FreqDist(tokens)
</span></span><span style="display:flex;"><span><span style="color:#75715e">#输出词和相应的频率</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> key,val <span style="color:#f92672">in</span> freq<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>    print (str(key) <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;:&#39;</span> <span style="color:#f92672">+</span> str(val))
</span></span><span style="display:flex;"><span><span style="color:#75715e">#可以把最常用的5个单词拿出来</span>
</span></span><span style="display:flex;"><span>standard_freq<span style="color:#f92672">=</span>freq<span style="color:#f92672">.</span>most_common(<span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>print(standard_freq)
</span></span><span style="display:flex;"><span><span style="color:#75715e">#绘图函数为这些词频绘制一个图形</span>
</span></span><span style="display:flex;"><span>freq<span style="color:#f92672">.</span>plot(<span style="color:#ae81ff">20</span>, cumulative<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span></code></pre></div><h4 id="113-停用分词stopwords">1.1.3. 停用分词(stopwords)</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#英文停用分词</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
</span></span><span style="display:flex;"><span>tokens<span style="color:#f92672">=</span>[ <span style="color:#e6db74">&#39;my&#39;</span>,<span style="color:#e6db74">&#39;dog&#39;</span>,<span style="color:#e6db74">&#39;has&#39;</span>,<span style="color:#e6db74">&#39;flea&#39;</span>,<span style="color:#e6db74">&#39;problems&#39;</span>,<span style="color:#e6db74">&#39;help&#39;</span>,<span style="color:#e6db74">&#39;please&#39;</span>,
</span></span><span style="display:flex;"><span>         <span style="color:#e6db74">&#39;maybe&#39;</span>,<span style="color:#e6db74">&#39;not&#39;</span>,<span style="color:#e6db74">&#39;take&#39;</span>,<span style="color:#e6db74">&#39;him&#39;</span>,<span style="color:#e6db74">&#39;to&#39;</span>,<span style="color:#e6db74">&#39;dog&#39;</span>,<span style="color:#e6db74">&#39;park&#39;</span>,<span style="color:#e6db74">&#39;stupid&#39;</span>,
</span></span><span style="display:flex;"><span>         <span style="color:#e6db74">&#39;my&#39;</span>,<span style="color:#e6db74">&#39;dalmation&#39;</span>,<span style="color:#e6db74">&#39;is&#39;</span>,<span style="color:#e6db74">&#39;so&#39;</span>,<span style="color:#e6db74">&#39;cute&#39;</span>,<span style="color:#e6db74">&#39;I&#39;</span>,<span style="color:#e6db74">&#39;love&#39;</span>,<span style="color:#e6db74">&#39;him&#39;</span>  ]
</span></span><span style="display:flex;"><span>clean_tokens<span style="color:#f92672">=</span>tokens[:]
</span></span><span style="display:flex;"><span>stwords<span style="color:#f92672">=</span>stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#39;english&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> token <span style="color:#f92672">in</span> tokens:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> token <span style="color:#f92672">in</span> stwords:
</span></span><span style="display:flex;"><span>        clean_tokens<span style="color:#f92672">.</span>remove(token)
</span></span><span style="display:flex;"><span>print(clean_tokens)
</span></span></code></pre></div><h4 id="114-分词分句tokenize">1.1.4. 分词&amp;&amp;分句(tokenize)</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#--- 分句</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> sent_tokenize
</span></span><span style="display:flex;"><span>mytext <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Hello Adam, how are you? I hope everything is going well. Today is a good day, see you dude.&#34;</span>
</span></span><span style="display:flex;"><span>print(sent_tokenize(mytext))
</span></span><span style="display:flex;"><span><span style="color:#75715e">#--- 分词</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span>mytext <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Hello Mr. Adam, how are you? I hope everything is going well. Today is a good day, see you dude.&#34;</span>
</span></span><span style="display:flex;"><span>print(word_tokenize(mytext))
</span></span></code></pre></div><h4 id="115-词干提取stemming">1.1.5. 词干提取（Stemming)</h4>
<blockquote>
<p>单词词干提取就是<code>从单词中去除词缀并返回词根</code>。（<code>比方说 working 的词干是 work。</code>）搜索引擎在索引页面的时候使用这种技术，所以很多人通过同一个单词的不同形式进行搜索，返回的都是相同的，有关这个词干的页面。词干提取的算法有很多，但最常用的算法是 <strong>Porter 提取算法</strong>。NLTK 有一个 PorterStemmer 类，使用的就是 Porter 提取算法。</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#    PorterStemmer算法</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> PorterStemmer
</span></span><span style="display:flex;"><span>porter_stemmer <span style="color:#f92672">=</span> PorterStemmer()
</span></span><span style="display:flex;"><span>print(porter_stemmer<span style="color:#f92672">.</span>stem(<span style="color:#e6db74">&#39;working&#39;</span>))
</span></span><span style="display:flex;"><span><span style="color:#75715e">#结果为：work </span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#    LancasterStemmer算法</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> LancasterStemmer
</span></span><span style="display:flex;"><span>lancaster_stemmer <span style="color:#f92672">=</span> LancasterStemmer()
</span></span><span style="display:flex;"><span>print(lancaster_stemmer<span style="color:#f92672">.</span>stem(<span style="color:#e6db74">&#39;working&#39;</span>))
</span></span><span style="display:flex;"><span><span style="color:#75715e">#结果为：work </span>
</span></span></code></pre></div><h4 id="116-词干还原lemmatization">1.1.6. 词干还原（Lemmatization）</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#词形还原与词干提取类似， 但不同之处在于词干提取经常可能创造出不存在的词汇，词形还原的结果是一个真正的词汇</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> WordNetLemmatizer
</span></span><span style="display:flex;"><span>lemmatizer <span style="color:#f92672">=</span> WordNetLemmatizer()
</span></span><span style="display:flex;"><span>print(lemmatizer<span style="color:#f92672">.</span>lemmatize(<span style="color:#e6db74">&#39;playing&#39;</span>, pos<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;v&#34;</span>))
</span></span><span style="display:flex;"><span>print(lemmatizer<span style="color:#f92672">.</span>lemmatize(<span style="color:#e6db74">&#39;playing&#39;</span>, pos<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;n&#34;</span>))
</span></span><span style="display:flex;"><span>print(lemmatizer<span style="color:#f92672">.</span>lemmatize(<span style="color:#e6db74">&#39;playing&#39;</span>, pos<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;a&#34;</span>))
</span></span><span style="display:flex;"><span>print(lemmatizer<span style="color:#f92672">.</span>lemmatize(<span style="color:#e6db74">&#39;playing&#39;</span>, pos<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;r&#34;</span>))
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;&#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">结果为：
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">play
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">playing
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">playing
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">playing
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;&#39;&#39;</span>
</span></span></code></pre></div><h4 id="117-词性标注postag">1.1.7. 词性标注（PosTag）</h4>
<blockquote>
<p><strong>词性标注是把一个句子中的单词标注为名词，形容词，动词等。</strong></p>
</blockquote>
<table>
<thead>
<tr>
<th><strong>标记（Tag）</strong></th>
<th><strong>含义（Meaning）</strong></th>
<th><strong>例子（Examples）</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ADJ</strong></td>
<td><strong>形容词（adjective）</strong></td>
<td><strong>new，good，high，special，big</strong></td>
</tr>
<tr>
<td><strong>ADV</strong></td>
<td><strong>副词（adverb）</strong></td>
<td><strong>really,，already，still，early，now</strong></td>
</tr>
<tr>
<td><strong>CNJ</strong></td>
<td><strong>连词（conjunction）</strong></td>
<td><strong>and，or，but，if，while</strong></td>
</tr>
<tr>
<td><strong>DET</strong></td>
<td><strong>限定词（determiner）</strong></td>
<td><strong>the，a，some，most，every</strong></td>
</tr>
<tr>
<td><strong>EX</strong></td>
<td><strong>存在量词（existential）</strong></td>
<td><strong>there，there&rsquo;s</strong></td>
</tr>
<tr>
<td><strong>FW</strong></td>
<td><strong>外来词（foreign word）</strong></td>
<td><strong>dolce，ersatz，esprit，quo，maitre</strong></td>
</tr>
<tr>
<td><strong>MOD</strong></td>
<td><strong>情态动词（modal verb）</strong></td>
<td><strong>will，can，would，may，must</strong></td>
</tr>
<tr>
<td><strong>N</strong></td>
<td><strong>名词（noun）</strong></td>
<td><strong>year，home，costs，time</strong></td>
</tr>
<tr>
<td><strong>NP</strong></td>
<td><strong>专有名词（proper noun）</strong></td>
<td><strong>Alison，Africa，April，Washington</strong></td>
</tr>
<tr>
<td><strong>NUM</strong></td>
<td><strong>数词（number）</strong></td>
<td><strong>twenty-four，fourth，1991，14:24</strong></td>
</tr>
<tr>
<td><strong>PRO</strong></td>
<td><strong>代词（pronoun）</strong></td>
<td><strong>he，their，her，its，my，I，us</strong></td>
</tr>
<tr>
<td><strong>P</strong></td>
<td><strong>介词（preposition）</strong></td>
<td><strong>on，of，at，with，by，into，under</strong></td>
</tr>
<tr>
<td><strong>TO</strong></td>
<td><strong>词 to（the word to）</strong></td>
<td><strong>to</strong></td>
</tr>
<tr>
<td><strong>UH</strong></td>
<td><strong>感叹词（interjection）</strong></td>
<td><strong>ah，bang，ha，whee，hmpf，oops</strong></td>
</tr>
<tr>
<td><strong>V</strong></td>
<td><strong>动词（verb）</strong></td>
<td><strong>is，has，get，do，make，see，run</strong></td>
</tr>
<tr>
<td><strong>VD</strong></td>
<td><strong>过去式（past tense）</strong></td>
<td><strong>said，took，told，made，asked</strong></td>
</tr>
<tr>
<td><strong>VG</strong></td>
<td><strong>现在分词（present participle）</strong></td>
<td><strong>making，going，playing，working</strong></td>
</tr>
<tr>
<td><strong>VN</strong></td>
<td><strong>过去分词（past participle）</strong></td>
<td><strong>given，taken，begun，sung</strong></td>
</tr>
<tr>
<td><strong>WH</strong></td>
<td><strong>wh限定词（wh determiner）</strong></td>
<td><strong>who，which，when，what，where</strong></td>
</tr>
</tbody>
</table>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> nltk
</span></span><span style="display:flex;"><span>text<span style="color:#f92672">=</span>nltk<span style="color:#f92672">.</span>word_tokenize(<span style="color:#e6db74">&#39;what does the fox say&#39;</span>)
</span></span><span style="display:flex;"><span>print(text)
</span></span><span style="display:flex;"><span>print(nltk<span style="color:#f92672">.</span>pos_tag(text))
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;&#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">结果为：
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[&#39;what&#39;, &#39;does&#39;, &#39;the&#39;, &#39;fox&#39;, &#39;say&#39;]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">输出是元组列表，元组中的第一个元素是单词，第二个元素是词性标签
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[(&#39;what&#39;, &#39;WDT&#39;), (&#39;does&#39;, &#39;VBZ&#39;), (&#39;the&#39;, &#39;DT&#39;), (&#39;fox&#39;, &#39;NNS&#39;), (&#39;say&#39;, &#39;VBP&#39;)]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;&#39;&#39;</span>
</span></span></code></pre></div><h4 id="118-wordnet">1.1.8. wordnet</h4>
<blockquote>
<p><strong>wordnet</strong> 是为自然语言处理构建的数据库。它包括部分词语的一个同义词组和一个简短的定义和反义词。</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> wordnet
</span></span><span style="display:flex;"><span>syn <span style="color:#f92672">=</span> wordnet<span style="color:#f92672">.</span>synsets(<span style="color:#e6db74">&#34;pain&#34;</span>)  <span style="color:#75715e">#获取“pain”的同义词集</span>
</span></span><span style="display:flex;"><span>print(syn[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>definition())  <span style="color:#75715e">#定义</span>
</span></span><span style="display:flex;"><span>print(syn[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>examples())<span style="color:#75715e"># 例句</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>synonyms <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> syn <span style="color:#f92672">in</span> wordnet<span style="color:#f92672">.</span>synsets(<span style="color:#e6db74">&#39;Computer&#39;</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> lemma <span style="color:#f92672">in</span> syn<span style="color:#f92672">.</span>lemmas():
</span></span><span style="display:flex;"><span>        synonyms<span style="color:#f92672">.</span>append(lemma<span style="color:#f92672">.</span>name()) <span style="color:#75715e">#同义词</span>
</span></span><span style="display:flex;"><span>print(synonyms)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> wordnet
</span></span><span style="display:flex;"><span>antonyms <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> syn <span style="color:#f92672">in</span> wordnet<span style="color:#f92672">.</span>synsets(<span style="color:#e6db74">&#34;small&#34;</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> l <span style="color:#f92672">in</span> syn<span style="color:#f92672">.</span>lemmas():
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> l<span style="color:#f92672">.</span>antonyms():   <span style="color:#75715e">#判断是否是正确的反义词</span>
</span></span><span style="display:flex;"><span>            antonyms<span style="color:#f92672">.</span>append(l<span style="color:#f92672">.</span>antonyms()[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>name())
</span></span><span style="display:flex;"><span>print(antonyms)
</span></span></code></pre></div><h4 id="119--命名实体识别">1.1.9.  命名实体识别</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> nltk
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">parse_document</span>(document):
</span></span><span style="display:flex;"><span>   document <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, document)
</span></span><span style="display:flex;"><span>   <span style="color:#66d9ef">if</span> isinstance(document, str):
</span></span><span style="display:flex;"><span>       document <span style="color:#f92672">=</span> document
</span></span><span style="display:flex;"><span>   <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>       <span style="color:#66d9ef">raise</span> <span style="color:#a6e22e">ValueError</span>(<span style="color:#e6db74">&#39;Document is not string!&#39;</span>)
</span></span><span style="display:flex;"><span>   document <span style="color:#f92672">=</span> document<span style="color:#f92672">.</span>strip()
</span></span><span style="display:flex;"><span>   sentences <span style="color:#f92672">=</span> nltk<span style="color:#f92672">.</span>sent_tokenize(document)
</span></span><span style="display:flex;"><span>   sentences <span style="color:#f92672">=</span> [sentence<span style="color:#f92672">.</span>strip() <span style="color:#66d9ef">for</span> sentence <span style="color:#f92672">in</span> sentences]
</span></span><span style="display:flex;"><span>   <span style="color:#66d9ef">return</span> sentences
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># sample document</span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">FIFA was founded in 1904 to oversee international competition among the national associations of Belgium, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Denmark, France, Germany, the Netherlands, Spain, Sweden, and Switzerland. Headquartered in Zürich, its 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">membership now comprises 211 national associations. Member countries must each also be members of one of 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">the six regional confederations into which the world is divided: Africa, Asia, Europe, North &amp; Central America 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">and the Caribbean, Oceania, and South America.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># tokenize sentences</span>
</span></span><span style="display:flex;"><span>sentences <span style="color:#f92672">=</span> parse_document(text)
</span></span><span style="display:flex;"><span>tokenized_sentences <span style="color:#f92672">=</span> [nltk<span style="color:#f92672">.</span>word_tokenize(sentence) <span style="color:#66d9ef">for</span> sentence <span style="color:#f92672">in</span> sentences]
</span></span><span style="display:flex;"><span><span style="color:#75715e"># tag sentences and use nltk&#39;s Named Entity Chunker</span>
</span></span><span style="display:flex;"><span>tagged_sentences <span style="color:#f92672">=</span> [nltk<span style="color:#f92672">.</span>pos_tag(sentence) <span style="color:#66d9ef">for</span> sentence <span style="color:#f92672">in</span> tokenized_sentences]
</span></span><span style="display:flex;"><span>ne_chunked_sents <span style="color:#f92672">=</span> [nltk<span style="color:#f92672">.</span>ne_chunk(tagged) <span style="color:#66d9ef">for</span> tagged <span style="color:#f92672">in</span> tagged_sentences]
</span></span><span style="display:flex;"><span><span style="color:#75715e"># extract all named entities</span>
</span></span><span style="display:flex;"><span>named_entities <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> ne_tagged_sentence <span style="color:#f92672">in</span> ne_chunked_sents:
</span></span><span style="display:flex;"><span>   <span style="color:#66d9ef">for</span> tagged_tree <span style="color:#f92672">in</span> ne_tagged_sentence:
</span></span><span style="display:flex;"><span>       <span style="color:#75715e"># extract only chunks having NE labels</span>
</span></span><span style="display:flex;"><span>       <span style="color:#66d9ef">if</span> hasattr(tagged_tree, <span style="color:#e6db74">&#39;label&#39;</span>):
</span></span><span style="display:flex;"><span>           entity_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39; &#39;</span><span style="color:#f92672">.</span>join(c[<span style="color:#ae81ff">0</span>] <span style="color:#66d9ef">for</span> c <span style="color:#f92672">in</span> tagged_tree<span style="color:#f92672">.</span>leaves()) <span style="color:#75715e">#get NE name</span>
</span></span><span style="display:flex;"><span>           entity_type <span style="color:#f92672">=</span> tagged_tree<span style="color:#f92672">.</span>label() <span style="color:#75715e"># get NE category</span>
</span></span><span style="display:flex;"><span>           named_entities<span style="color:#f92672">.</span>append((entity_name, entity_type))
</span></span><span style="display:flex;"><span>           <span style="color:#75715e"># get unique named entities</span>
</span></span><span style="display:flex;"><span>           named_entities <span style="color:#f92672">=</span> list(set(named_entities))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># store named entities in a data frame</span>
</span></span><span style="display:flex;"><span>entity_frame <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(named_entities, columns<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;Entity Name&#39;</span>, <span style="color:#e6db74">&#39;Entity Type&#39;</span>])
</span></span><span style="display:flex;"><span><span style="color:#75715e"># display results</span>
</span></span><span style="display:flex;"><span>print(entity_frame)
</span></span></code></pre></div><ul>
<li>NLTK 中集成了standordnlp</li>
</ul>
<blockquote>
<p>StanfordNERTagger(&rsquo;./stanford-ner/classifiers/english.muc.7class.distsim.crf.ser.gz&rsquo;,
path_to_jar=&rsquo;./stanford-ner/stanford-ner.jar')</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tag <span style="color:#f92672">import</span> StanfordNERTagger
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> nltk
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">parse_document</span>(document):
</span></span><span style="display:flex;"><span>   document <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, document)
</span></span><span style="display:flex;"><span>   <span style="color:#66d9ef">if</span> isinstance(document, str):
</span></span><span style="display:flex;"><span>       document <span style="color:#f92672">=</span> document
</span></span><span style="display:flex;"><span>   <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>       <span style="color:#66d9ef">raise</span> <span style="color:#a6e22e">ValueError</span>(<span style="color:#e6db74">&#39;Document is not string!&#39;</span>)
</span></span><span style="display:flex;"><span>   document <span style="color:#f92672">=</span> document<span style="color:#f92672">.</span>strip()
</span></span><span style="display:flex;"><span>   sentences <span style="color:#f92672">=</span> nltk<span style="color:#f92672">.</span>sent_tokenize(document)
</span></span><span style="display:flex;"><span>   sentences <span style="color:#f92672">=</span> [sentence<span style="color:#f92672">.</span>strip() <span style="color:#66d9ef">for</span> sentence <span style="color:#f92672">in</span> sentences]
</span></span><span style="display:flex;"><span>   <span style="color:#66d9ef">return</span> sentences
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># sample document</span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">FIFA was founded in 1904 to oversee international competition among the national associations of Belgium, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Denmark, France, Germany, the Netherlands, Spain, Sweden, and Switzerland. Headquartered in Zürich, its 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">membership now comprises 211 national associations. Member countries must each also be members of one of 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">the six regional confederations into which the world is divided: Africa, Asia, Europe, North &amp; Central America 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">and the Caribbean, Oceania, and South America.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Intel\Shared Libraries\redist\intel64\compiler;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\Git\cmd;C:\Users\dell\Anaconda3;C:\Users\dell\Anaconda3\Scripts;C:\Users\dell\Anaconda3\Library\bin;C:\Program Files\nodejs\;C:\Program Files (x86)\Microsoft SQL Server\110\Tools\Binn\;C:\Program Files\Microsoft SQL Server\110\Tools\Binn\;C:\Program Files\Microsoft SQL Server\110\DTS\Binn\;C:\Users\dell\AppData\Local\Android\Sdk\tools\;C:\Users\dell\AppData\Local\Android\Sdk\platform-tools\;D:\latex\texlive\2020\bin\win32;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\MATLAB\R2015b\runtime\win64;C:\Program Files\MATLAB\R2015b\bin;C:\Program Files\MATLAB\R2015b\polyspace\bin;C:\msys64\usr\bin;C:\Users\dell\Downloads\Programs\bazel-3.4.1-windows-x86_64_2.exe;</span>
</span></span><span style="display:flex;"><span>sentences <span style="color:#f92672">=</span> parse_document(text)
</span></span><span style="display:flex;"><span>tokenized_sentences <span style="color:#f92672">=</span> [nltk<span style="color:#f92672">.</span>word_tokenize(sentence) <span style="color:#66d9ef">for</span> sentence <span style="color:#f92672">in</span> sentences]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># set java path in environment variables</span>
</span></span><span style="display:flex;"><span>java_path <span style="color:#f92672">=</span> <span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;C:\Program Files (x86)\Common Files\Oracle\Java\javapath\java.exe&#39;</span>
</span></span><span style="display:flex;"><span>os<span style="color:#f92672">.</span>environ[<span style="color:#e6db74">&#39;JAVAHOME&#39;</span>] <span style="color:#f92672">=</span> java_path
</span></span><span style="display:flex;"><span><span style="color:#75715e"># load stanford NER</span>
</span></span><span style="display:flex;"><span>sn <span style="color:#f92672">=</span> StanfordNERTagger(<span style="color:#e6db74">&#39;./stanford-ner/classifiers/english.muc.7class.distsim.crf.ser.gz&#39;</span>,
</span></span><span style="display:flex;"><span>                       path_to_jar<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;./stanford-ner/stanford-ner.jar&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># tag sentences</span>
</span></span><span style="display:flex;"><span>ne_annotated_sentences <span style="color:#f92672">=</span> [sn<span style="color:#f92672">.</span>tag(sent) <span style="color:#66d9ef">for</span> sent <span style="color:#f92672">in</span> tokenized_sentences]
</span></span><span style="display:flex;"><span><span style="color:#75715e"># extract named entities</span>
</span></span><span style="display:flex;"><span>named_entities <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> sentence <span style="color:#f92672">in</span> ne_annotated_sentences:
</span></span><span style="display:flex;"><span>   temp_entity_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span>
</span></span><span style="display:flex;"><span>   temp_named_entity <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>
</span></span><span style="display:flex;"><span>   <span style="color:#66d9ef">for</span> term, tag <span style="color:#f92672">in</span> sentence:
</span></span><span style="display:flex;"><span>       <span style="color:#75715e"># get terms with NE tags</span>
</span></span><span style="display:flex;"><span>       <span style="color:#66d9ef">if</span> tag <span style="color:#f92672">!=</span> <span style="color:#e6db74">&#39;O&#39;</span>:
</span></span><span style="display:flex;"><span>           temp_entity_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39; &#39;</span><span style="color:#f92672">.</span>join([temp_entity_name, term])<span style="color:#f92672">.</span>strip() <span style="color:#75715e">#get NE name</span>
</span></span><span style="display:flex;"><span>           temp_named_entity <span style="color:#f92672">=</span> (temp_entity_name, tag) <span style="color:#75715e"># get NE and its category</span>
</span></span><span style="display:flex;"><span>       <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>           <span style="color:#66d9ef">if</span> temp_named_entity:
</span></span><span style="display:flex;"><span>               named_entities<span style="color:#f92672">.</span>append(temp_named_entity)
</span></span><span style="display:flex;"><span>               temp_entity_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span>
</span></span><span style="display:flex;"><span>               temp_named_entity <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># get unique named entities</span>
</span></span><span style="display:flex;"><span>named_entities <span style="color:#f92672">=</span> list(set(named_entities))
</span></span><span style="display:flex;"><span><span style="color:#75715e"># store named entities in a data frame</span>
</span></span><span style="display:flex;"><span>entity_frame <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(named_entities, columns<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;Entity Name&#39;</span>, <span style="color:#e6db74">&#39;Entity Type&#39;</span>])
</span></span><span style="display:flex;"><span><span style="color:#75715e"># display results</span>
</span></span><span style="display:flex;"><span>print(entity_frame)
</span></span></code></pre></div><h4 id="1110-文本分类">1.1.10. 文本分类</h4>
<h4 id="1111-情感分类">1.1.11. 情感分类</h4>
<ul>
<li><a href="http://ir.dlut.edu.cn/EmotionOntologyDownload"target="_blank" rel="external nofollow noopener noreferrer">http://ir.dlut.edu.cn/EmotionOntologyDownload<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
</ul>
<h4 id="1112-事件抽取">1.1.12. 事件抽取</h4>
<ul>
<li><a href="https://github.com/twjiang/fact_triple_extraction"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/twjiang/fact_triple_extraction<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
</ul>
<h2 id="2stanfordnlp">2.StanfordNlp</h2>
<blockquote>
<p>斯坦福 NER 标记器的一大优势是，为我们提供了几种不同的模型来提取命名实体。我们可以使用以下任何一个：</p>
<ul>
<li>三类模型，用于识别位置，人员和组织</li>
<li>四类模型，用于识别位置，人员，组织和杂项实体</li>
<li>七类模型，识别位置，人员，组织，时间，金钱，百分比和日期</li>
</ul>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#!/usr/bin/env python</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> __future__ <span style="color:#f92672">import</span> print_function
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pickle
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> argparse <span style="color:#f92672">import</span> ArgumentParser
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> platform <span style="color:#f92672">import</span> system
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> subprocess <span style="color:#f92672">import</span> Popen
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sys <span style="color:#f92672">import</span> argv
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sys <span style="color:#f92672">import</span> stderr
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#IS_WINDOWS = True if system() == &#39;Windows&#39; else False</span>
</span></span><span style="display:flex;"><span>JAVA_BIN_PATH <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;java.exe&#39;</span> <span style="color:#66d9ef">if</span> IS_WINDOWS <span style="color:#66d9ef">else</span> <span style="color:#e6db74">&#39;java&#39;</span>
</span></span><span style="display:flex;"><span>STANFORD_NER_FOLDER <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;stanford-ner&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">arg_parse</span>():
</span></span><span style="display:flex;"><span>    arg_p <span style="color:#f92672">=</span> ArgumentParser(<span style="color:#e6db74">&#39;Stanford NER Python Wrapper&#39;</span>)
</span></span><span style="display:flex;"><span>    arg_p<span style="color:#f92672">.</span>add_argument(<span style="color:#e6db74">&#39;-f&#39;</span>, <span style="color:#e6db74">&#39;--filename&#39;</span>, type<span style="color:#f92672">=</span>str, default<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>)
</span></span><span style="display:flex;"><span>    arg_p<span style="color:#f92672">.</span>add_argument(<span style="color:#e6db74">&#39;-v&#39;</span>, <span style="color:#e6db74">&#39;--verbose&#39;</span>, action<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;store_true&#39;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> arg_p
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">debug_print</span>(log, verbose):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> verbose:
</span></span><span style="display:flex;"><span>        print(log)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">process_entity_relations</span>(entity_relations_str, verbose<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># format is ollie.</span>
</span></span><span style="display:flex;"><span>    entity_relations <span style="color:#f92672">=</span> list()
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> s <span style="color:#f92672">in</span> entity_relations_str:
</span></span><span style="display:flex;"><span>        entity_relations<span style="color:#f92672">.</span>append(s[s<span style="color:#f92672">.</span>find(<span style="color:#e6db74">&#34;(&#34;</span>) <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>:s<span style="color:#f92672">.</span>find(<span style="color:#e6db74">&#34;)&#34;</span>)]<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;;&#39;</span>))
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> entity_relations
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">stanford_ner</span>(filename, verbose<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, absolute_path<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>    out <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;out.txt&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    command <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> absolute_path <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>        command <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;cd </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">;&#39;</span><span style="color:#f92672">.</span>format(absolute_path)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>        filename <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;../</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>format(filename)
</span></span><span style="display:flex;"><span><span style="color:#75715e">#java -mx1g -cp &#34;*:lib/*&#34; edu.stanford.nlp.ie.NERClassifierCombiner -textFile sample.txt -ner.model classifiers/english.all.3class.distsim.crf.ser.gz,classifiers/english.conll.4class.distsim.crf.ser.gz,classifiers/english.muc.7class.distsim.crf.ser.gz</span>
</span></span><span style="display:flex;"><span>    command <span style="color:#f92672">+=</span> <span style="color:#e6db74">&#39;cd </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">; </span><span style="color:#e6db74">{}</span><span style="color:#e6db74"> -mx1g -cp &#34;*:lib/*&#34; edu.stanford.nlp.ie.NERClassifierCombiner &#39;</span> \
</span></span><span style="display:flex;"><span>               <span style="color:#e6db74">&#39;-ner.model classifiers/english.all.3class.distsim.crf.ser.gz &#39;</span> \
</span></span><span style="display:flex;"><span>               <span style="color:#e6db74">&#39;-outputFormat tabbedEntities -textFile </span><span style="color:#e6db74">{}</span><span style="color:#e6db74"> &gt; ../</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#39;</span> \
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">.</span>format(STANFORD_NER_FOLDER, JAVA_BIN_PATH, filename, out)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> verbose:
</span></span><span style="display:flex;"><span>        debug_print(<span style="color:#e6db74">&#39;Executing command = </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>format(command), verbose)
</span></span><span style="display:flex;"><span>        java_process <span style="color:#f92672">=</span> Popen(command, stdout<span style="color:#f92672">=</span>stderr, shell<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>        java_process <span style="color:#f92672">=</span> Popen(command, stdout<span style="color:#f92672">=</span>stderr, stderr<span style="color:#f92672">=</span>open(os<span style="color:#f92672">.</span>devnull, <span style="color:#e6db74">&#39;w&#39;</span>), shell<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>    java_process<span style="color:#f92672">.</span>wait()
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">assert</span> <span style="color:#f92672">not</span> java_process<span style="color:#f92672">.</span>returncode, <span style="color:#e6db74">&#39;ERROR: Call to stanford_ner exited with a non-zero code status.&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> absolute_path <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> absolute_path <span style="color:#f92672">+</span> out
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> open(out, <span style="color:#e6db74">&#39;r&#39;</span>) <span style="color:#66d9ef">as</span> output_file:
</span></span><span style="display:flex;"><span>        results_str <span style="color:#f92672">=</span> output_file<span style="color:#f92672">.</span>readlines()
</span></span><span style="display:flex;"><span>    os<span style="color:#f92672">.</span>remove(out)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    results <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> res <span style="color:#f92672">in</span> results_str:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> len(res<span style="color:#f92672">.</span>strip()) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>            split_res <span style="color:#f92672">=</span> res<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>            entity_name <span style="color:#f92672">=</span> split_res[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>            entity_type <span style="color:#f92672">=</span> split_res[<span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> len(entity_name) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">and</span> len(entity_type) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>                results<span style="color:#f92672">.</span>append([entity_name<span style="color:#f92672">.</span>strip(), entity_type<span style="color:#f92672">.</span>strip()])
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> verbose:
</span></span><span style="display:flex;"><span>        pickle<span style="color:#f92672">.</span>dump(results_str, open(<span style="color:#e6db74">&#39;out.pkl&#39;</span>, <span style="color:#e6db74">&#39;wb&#39;</span>))
</span></span><span style="display:flex;"><span>        debug_print(<span style="color:#e6db74">&#39;wrote to out.pkl&#39;</span>, verbose)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> results
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">main</span>(args):
</span></span><span style="display:flex;"><span>    arg_p <span style="color:#f92672">=</span> arg_parse()<span style="color:#f92672">.</span>parse_args(args[<span style="color:#ae81ff">1</span>:])
</span></span><span style="display:flex;"><span>    filename <span style="color:#f92672">=</span> arg_p<span style="color:#f92672">.</span>filename
</span></span><span style="display:flex;"><span>    verbose <span style="color:#f92672">=</span> arg_p<span style="color:#f92672">.</span>verbose
</span></span><span style="display:flex;"><span>    debug_print(arg_p, verbose)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> filename <span style="color:#f92672">is</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#39;please provide a text file containing your input. Program will exit.&#39;</span>)
</span></span><span style="display:flex;"><span>        exit(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> verbose:
</span></span><span style="display:flex;"><span>        debug_print(<span style="color:#e6db74">&#39;filename = </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>format(filename), verbose)
</span></span><span style="display:flex;"><span>    entities <span style="color:#f92672">=</span> stanford_ner(filename, verbose)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>join([entity[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>ljust(<span style="color:#ae81ff">20</span>) <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">+</span> entity[<span style="color:#ae81ff">1</span>] <span style="color:#66d9ef">for</span> entity <span style="color:#f92672">in</span> entities]))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;__main__&#39;</span>:
</span></span><span style="display:flex;"><span>    exit(main(argv))
</span></span></code></pre></div><h2 id="3-jieba-分词">3. jieba 分词</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>pip3 install jieba
</span></span><span style="display:flex;"><span>import jieba
</span></span></code></pre></div><h3 id="31-分词">3.1. 分词</h3>
<blockquote>
<h5 id="jiebacut-和jiebalcut--lcut-将返回的对象转化为list对象返回">jieba.cut 和jieba.lcut；  <code>lcut</code> 将返回的对象转化为<code>list对象</code>返回·</h5>
</blockquote>
<pre tabindex="0"><code>def cut(self, sentence, cut_all=False, HMM=True, use_paddle=False):
# sentence: 需要分词的字符串;
# cut_all: 参数用来控制是否采用全模式；
# HMM: 参数用来控制是否使用 HMM 模型;
# use_paddle: 参数用来控制是否使用paddle模式下的分词模式，paddle模式采用延迟加载方式，通过enable_paddle接口安装paddlepaddle-tiny
</code></pre><h6 id="1精准模式默认">1）精准模式（默认）:</h6>
<blockquote>
<p>试图将句子最精确地切开，适合文本分析</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>seg_list <span style="color:#f92672">=</span> jieba<span style="color:#f92672">.</span>cut(<span style="color:#e6db74">&#34;我来到北京清华大学&#34;</span>, cut_all<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;精准模式: &#34;</span> <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;/ &#34;</span><span style="color:#f92672">.</span>join(seg_list))  <span style="color:#75715e"># 精确模式</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># -----output-----</span>
</span></span><span style="display:flex;"><span>精准模式: 我<span style="color:#f92672">/</span> 来到<span style="color:#f92672">/</span> 北京<span style="color:#f92672">/</span> 清华大学
</span></span></code></pre></div><h6 id="2全模式">2）全模式:</h6>
<blockquote>
<p>把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义；</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>seg_list <span style="color:#f92672">=</span> jieba<span style="color:#f92672">.</span>cut(<span style="color:#e6db74">&#34;我来到北京清华大学&#34;</span>, cut_all<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;全模式: &#34;</span> <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;/ &#34;</span><span style="color:#f92672">.</span>join(seg_list))  <span style="color:#75715e"># 全模式</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># -----output-----</span>
</span></span><span style="display:flex;"><span>全模式: 我<span style="color:#f92672">/</span> 来到<span style="color:#f92672">/</span> 北京<span style="color:#f92672">/</span> 清华<span style="color:#f92672">/</span> 清华大学<span style="color:#f92672">/</span> 华大<span style="color:#f92672">/</span> 大学
</span></span></code></pre></div><h6 id="3paddle模式">3）paddle模式</h6>
<blockquote>
<p>利用PaddlePaddle深度学习框架，训练序列标注（双向GRU）网络模型实现分词。同时支持词性标注。
paddle模式使用需安装paddlepaddle-tiny，pip install paddlepaddle-tiny==1.6.1。
目前paddle模式支持jieba v0.40及以上版本。
jieba v0.40以下版本，请升级jieba，pip installjieba &ndash;upgrade。 <a href="https://www.paddlepaddle.org.cn/"target="_blank" rel="external nofollow noopener noreferrer">PaddlePaddle官网<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> jieba
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 通过enable_paddle接口安装paddlepaddle-tiny，并且import相关代码；</span>
</span></span><span style="display:flex;"><span>jieba<span style="color:#f92672">.</span>enable_paddle()  <span style="color:#75715e"># 初次使用可以自动安装并导入代码</span>
</span></span><span style="display:flex;"><span>seg_list <span style="color:#f92672">=</span> jieba<span style="color:#f92672">.</span>cut(str, use_paddle<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;Paddle模式: &#39;</span> <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;/&#39;</span><span style="color:#f92672">.</span>join(list(seg_list)))
</span></span><span style="display:flex;"><span><span style="color:#75715e"># -----output-----</span>
</span></span><span style="display:flex;"><span>Paddle模式: 我<span style="color:#f92672">/</span>来到<span style="color:#f92672">/</span>北京清华大学
</span></span></code></pre></div><h3 id="32-搜索引擎模式">3.2. 搜索引擎模式</h3>
<blockquote>
<p>在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>seg_list <span style="color:#f92672">=</span> jieba<span style="color:#f92672">.</span>cut_for_search(<span style="color:#e6db74">&#34;小明硕士毕业于中国科学院计算所，后在日本京都大学深造&#34;</span>)  <span style="color:#75715e"># 搜索引擎模式</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;, &#34;</span><span style="color:#f92672">.</span>join(seg_list))
</span></span><span style="display:flex;"><span><span style="color:#75715e"># -----output-----</span>
</span></span><span style="display:flex;"><span>小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, <span style="color:#960050;background-color:#1e0010">，</span>, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造
</span></span></code></pre></div><h5 id="1-jiebatokenizerdictionarydefault_dict">1) jieba.Tokenizer(dictionary=DEFAULT_DICT)</h5>
<blockquote>
<p>新建自定义分词器，可用于同时使用不同词典。jieba.dt 为默认分词器，所有全局分词相关函数都是该分词器的映射。</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> jieba
</span></span><span style="display:flex;"><span>test_sent <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;永和服装饰品有限公司&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># jieba.load_userdict(dict_path)    # dict_path为文件类对象或自定义词典的路径。</span>
</span></span><span style="display:flex;"><span>result <span style="color:#f92672">=</span> jieba<span style="color:#f92672">.</span>tokenize(test_sent) <span style="color:#75715e">##Tokenize：返回词语在原文的起始位置</span>
</span></span><span style="display:flex;"><span>print(result)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> tk <span style="color:#f92672">in</span> result:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># print (&#34;word %s\t\t start: %d \t\t end:%d&#34; % (tk[0],tk[1],tk[2])    )</span>
</span></span><span style="display:flex;"><span>    print (tk)
</span></span><span style="display:flex;"><span>   
</span></span><span style="display:flex;"><span><span style="color:#75715e"># -----output-----</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">&lt;</span>generator object Tokenizer<span style="color:#f92672">.</span>tokenize at <span style="color:#ae81ff">0x7f6b68a69d58</span><span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>(<span style="color:#e6db74">&#39;永和&#39;</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">2</span>)  <span style="color:#75715e">#词语、词频（可省略）、词性（可省略）</span>
</span></span><span style="display:flex;"><span>(<span style="color:#e6db74">&#39;服装&#39;</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>(<span style="color:#e6db74">&#39;饰品&#39;</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">6</span>)
</span></span><span style="display:flex;"><span>(<span style="color:#e6db74">&#39;有限公司&#39;</span>, <span style="color:#ae81ff">6</span>, <span style="color:#ae81ff">10</span>)    
</span></span></code></pre></div><h6 id="2使用自定义词典文件">2）使用自定义词典文件</h6>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> jieba
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>test_sent <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;中信建投投资公司投资了一款游戏,中信也投资了一个游戏公司&#34;</span>
</span></span><span style="display:flex;"><span>jieba<span style="color:#f92672">.</span>load_userdict(<span style="color:#e6db74">&#34;userdict.txt&#34;</span>)
</span></span><span style="display:flex;"><span>words <span style="color:#f92672">=</span> jieba<span style="color:#f92672">.</span>cut(test_sent)
</span></span><span style="display:flex;"><span>print(list(words))
</span></span><span style="display:flex;"><span><span style="color:#75715e">#-----output------</span>
</span></span><span style="display:flex;"><span>[<span style="color:#e6db74">&#39;中信建投&#39;</span>, <span style="color:#e6db74">&#39;投资公司&#39;</span>, <span style="color:#e6db74">&#39;投资&#39;</span>, <span style="color:#e6db74">&#39;了&#39;</span>, <span style="color:#e6db74">&#39;一款&#39;</span>, <span style="color:#e6db74">&#39;游戏&#39;</span>, <span style="color:#e6db74">&#39;,&#39;</span>, <span style="color:#e6db74">&#39;中信&#39;</span>, <span style="color:#e6db74">&#39;也&#39;</span>, <span style="color:#e6db74">&#39;投资&#39;</span>, <span style="color:#e6db74">&#39;了&#39;</span>, <span style="color:#e6db74">&#39;一个&#39;</span>, <span style="color:#e6db74">&#39;游戏&#39;</span>, <span style="color:#e6db74">&#39;公司&#39;</span>]
</span></span></code></pre></div><h6 id="3使用-jieba-在程序中动态修改词典">3）使用 jieba 在程序中动态修改词典</h6>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> jieba
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 定义示例句子</span>
</span></span><span style="display:flex;"><span>test_sent <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;中信建投投资公司投资了一款游戏,中信也投资了一个游戏公司&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#添加词</span>
</span></span><span style="display:flex;"><span>jieba<span style="color:#f92672">.</span>add_word(<span style="color:#e6db74">&#39;中信建投&#39;</span>)
</span></span><span style="display:flex;"><span>jieba<span style="color:#f92672">.</span>add_word(<span style="color:#e6db74">&#39;投资公司&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 删除词</span>
</span></span><span style="display:flex;"><span>jieba<span style="color:#f92672">.</span>del_word(<span style="color:#e6db74">&#39;中信建投&#39;</span>)
</span></span><span style="display:flex;"><span>words <span style="color:#f92672">=</span> jieba<span style="color:#f92672">.</span>cut(test_sent)
</span></span><span style="display:flex;"><span>print(list(words))
</span></span><span style="display:flex;"><span><span style="color:#75715e">#-----output------</span>
</span></span><span style="display:flex;"><span>[<span style="color:#e6db74">&#39;中信&#39;</span>, <span style="color:#e6db74">&#39;建投&#39;</span>, <span style="color:#e6db74">&#39;投资公司&#39;</span>, <span style="color:#e6db74">&#39;投资&#39;</span>, <span style="color:#e6db74">&#39;了&#39;</span>, <span style="color:#e6db74">&#39;一款&#39;</span>, <span style="color:#e6db74">&#39;游戏&#39;</span>, <span style="color:#e6db74">&#39;,&#39;</span>, <span style="color:#e6db74">&#39;中信&#39;</span>, <span style="color:#e6db74">&#39;也&#39;</span>, <span style="color:#e6db74">&#39;投资&#39;</span>, <span style="color:#e6db74">&#39;了&#39;</span>, <span style="color:#e6db74">&#39;一个&#39;</span>, <span style="color:#e6db74">&#39;游戏&#39;</span>, <span style="color:#e6db74">&#39;公司&#39;</span>]
</span></span></code></pre></div><h3 id="33-关键词提取">3.3. 关键词提取</h3>
<h6 id="1tf-idf接口和示例">1）TF-IDF接口和示例</h6>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> jieba.analyse
</span></span></code></pre></div><ul>
<li>
<p>jieba.analyse.extract_tags(sentence, topK=20, withWeight=False,allowPOS=())</p>
<p>其中需要说明的是：</p>
<ul>
<li>1.sentence 为待提取的文本</li>
<li>2.topK 为返回几个 TF/IDF 权重最大的关键词，默认值为 20</li>
<li>3.withWeight 为是否一并返回关键词权重值，默认值为 False</li>
<li>4.allowPOS 仅包括指定词性的词，默认值为空，即不筛选</li>
</ul>
</li>
<li>
<p>jieba.analyse.TFIDF(idf_path=None) 新建 TFIDF 实例，idf_path 为 IDF 频率文件</p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> jieba
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> jieba.analyse
</span></span><span style="display:flex;"><span><span style="color:#75715e">#读取文件,返回一个字符串，使用utf-8编码方式读取，该文档位于此python同以及目录下</span>
</span></span><span style="display:flex;"><span>content  <span style="color:#f92672">=</span> open(<span style="color:#e6db74">&#39;data.txt&#39;</span>,<span style="color:#e6db74">&#39;r&#39;</span>,encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;utf-8&#39;</span>)<span style="color:#f92672">.</span>read()
</span></span><span style="display:flex;"><span>tags <span style="color:#f92672">=</span> jieba<span style="color:#f92672">.</span>analyse<span style="color:#f92672">.</span>extract_tags(content,topK<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>,withWeight<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,allowPOS<span style="color:#f92672">=</span>(<span style="color:#e6db74">&#34;nr&#34;</span>)) 
</span></span><span style="display:flex;"><span>print(tags)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ----output-------</span>
</span></span><span style="display:flex;"><span>[(<span style="color:#e6db74">&#39;虚竹&#39;</span>, <span style="color:#ae81ff">0.20382572423643955</span>), (<span style="color:#e6db74">&#39;丐帮&#39;</span>, <span style="color:#ae81ff">0.07839419568792882</span>), (<span style="color:#e6db74">&#39;什么&#39;</span>, <span style="color:#ae81ff">0.07287469641815765</span>), (<span style="color:#e6db74">&#39;自己&#39;</span>, <span style="color:#ae81ff">0.05838617200768695</span>), (<span style="color:#e6db74">&#39;师父&#39;</span>, <span style="color:#ae81ff">0.05459680087740782</span>), (<span style="color:#e6db74">&#39;内力&#39;</span>, <span style="color:#ae81ff">0.05353758008018405</span>), (<span style="color:#e6db74">&#39;大理&#39;</span>, <span style="color:#ae81ff">0.04885277765801372</span>), (<span style="color:#e6db74">&#39;咱们&#39;</span>, <span style="color:#ae81ff">0.04458784837687502</span>), (<span style="color:#e6db74">&#39;星宿&#39;</span>, <span style="color:#ae81ff">0.04412126568280158</span>), (<span style="color:#e6db74">&#39;少林&#39;</span>, <span style="color:#ae81ff">0.04207588649463058</span>)]
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">123456789</span>
</span></span></code></pre></div><h6 id="2stop-words">2）Stop Words</h6>
<ul>
<li>用法： jieba.analyse.set_stop_words(file_name) # file_name为自定义语料库的路径</li>
<li>自定义语料库示例：</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> jieba
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> jieba.analyse
</span></span><span style="display:flex;"><span><span style="color:#75715e">#读取文件,返回一个字符串，使用utf-8编码方式读取，该文档位于此python同以及目录下</span>
</span></span><span style="display:flex;"><span>content  <span style="color:#f92672">=</span> open(<span style="color:#e6db74">u</span><span style="color:#e6db74">&#39;data.txt&#39;</span>,<span style="color:#e6db74">&#39;r&#39;</span>,encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;utf-8&#39;</span>)<span style="color:#f92672">.</span>read()
</span></span><span style="display:flex;"><span>jieba<span style="color:#f92672">.</span>analyse<span style="color:#f92672">.</span>set_stop_words(<span style="color:#e6db74">&#34;stopwords.txt&#34;</span>)
</span></span><span style="display:flex;"><span>tags <span style="color:#f92672">=</span> jieba<span style="color:#f92672">.</span>analyse<span style="color:#f92672">.</span>extract_tags(content, topK<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;,&#34;</span><span style="color:#f92672">.</span>join(tags))
</span></span></code></pre></div><h3 id="34-词性标注">3.4. 词性标注</h3>
<ul>
<li>jieba.posseg.POSTokenizer(tokenizer=None) 新建自定义分词器，tokenizer参数可指定内部使用的 jieba.Tokenizer 分词器。 jieba.posseg.dt 为默认词性标注分词器。</li>
<li>标注句子分词后每个词的词性，采用和 ictclas 兼容的标记法。</li>
<li>用法示例</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> jieba.posseg <span style="color:#66d9ef">as</span> pseg
</span></span><span style="display:flex;"><span>words <span style="color:#f92672">=</span> pseg<span style="color:#f92672">.</span>cut(<span style="color:#e6db74">&#34;我爱北京天安门&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> word, flag <span style="color:#f92672">in</span> words:
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#39;</span><span style="color:#e6db74">%s</span><span style="color:#e6db74"> </span><span style="color:#e6db74">%s</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">%</span> (word, flag))
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ----output--------</span>
</span></span><span style="display:flex;"><span>我 r
</span></span><span style="display:flex;"><span>爱 v
</span></span><span style="display:flex;"><span>北京 ns
</span></span><span style="display:flex;"><span>天安门 ns
</span></span></code></pre></div><p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201116165024512.png"
    data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201116165024512.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201116165024512.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201116165024512.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201116165024512.png"
    title="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201116165024512.png"/></p>
<h2 id="4-nlp-pyltp">4. nlp-pyltp</h2>
<blockquote>
<p>LTP 是哈工大社会计算与信息检索研究中心历时十年开发的一整套中文语言处理系统。LTP 制定了基于 XML 的语言处理结果表示，并在此基础上提供了一整套自底向上的丰富而且高效的中文语言处理模块 （包括词法、句法、语义等6项中文处理核心技术），以及基于动态链接库（Dynamic Link Library, DLL）的应用程序接口，可视化工具，并且能够以网络服务（Web Service）的形式进行使用。</p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116214442582.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116214442582.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116214442582.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116214442582.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116214442582.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116214442582.png"/></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 分句子</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> pyltp <span style="color:#f92672">import</span> SentenceSplitter
</span></span><span style="display:flex;"><span>sents <span style="color:#f92672">=</span> SentenceSplitter<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;元芳你怎么看？我就趴窗口上看呗！&#39;</span>)  <span style="color:#75715e"># 分句</span>
</span></span><span style="display:flex;"><span>print (<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>join(sents))
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#---- 分词</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> pyltp <span style="color:#f92672">import</span> Segmentor
</span></span><span style="display:flex;"><span>LTP_DATA_DIR <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;./ltp_data_v3.4.0&#39;</span>  <span style="color:#75715e"># ltp模型目录的路径</span>
</span></span><span style="display:flex;"><span>cws_model_path <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(LTP_DATA_DIR, <span style="color:#e6db74">&#39;cws.model&#39;</span>)  <span style="color:#75715e"># 分词模型路径，模型名称为`cws.model`</span>
</span></span><span style="display:flex;"><span>segmentor <span style="color:#f92672">=</span> Segmentor()  <span style="color:#75715e"># 初始化实例</span>
</span></span><span style="display:flex;"><span>segmentor<span style="color:#f92672">.</span>load(cws_model_path)  <span style="color:#75715e"># 加载模型</span>
</span></span><span style="display:flex;"><span>word1 <span style="color:#f92672">=</span> segmentor<span style="color:#f92672">.</span>segment(<span style="color:#e6db74">&#39;中信建投证券投资有限公司&#39;</span>)  <span style="color:#75715e"># 分词</span>
</span></span><span style="display:flex;"><span>word2 <span style="color:#f92672">=</span> segmentor<span style="color:#f92672">.</span>segment(<span style="color:#e6db74">&#39;中信今天投资了一款游戏&#39;</span>)  <span style="color:#75715e"># 分词</span>
</span></span><span style="display:flex;"><span>print(type(word1))
</span></span><span style="display:flex;"><span>print (<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>join(word1))
</span></span><span style="display:flex;"><span>print (<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>join(word2))
</span></span><span style="display:flex;"><span>segmentor<span style="color:#f92672">.</span>release()  <span style="color:#75715e"># 释放模型</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 词性标注</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span>LTP_DATA_DIR <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;./ltp_data_v3.4.0&#39;</span>  <span style="color:#75715e"># ltp模型目录的路径</span>
</span></span><span style="display:flex;"><span>pos_model_path <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(LTP_DATA_DIR, <span style="color:#e6db74">&#39;pos.model&#39;</span>)  <span style="color:#75715e"># 词性标注模型路径，模型名称为`pos.model`</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> pyltp <span style="color:#f92672">import</span> Postagger
</span></span><span style="display:flex;"><span>postagger <span style="color:#f92672">=</span> Postagger() <span style="color:#75715e"># 初始化实例</span>
</span></span><span style="display:flex;"><span>postagger<span style="color:#f92672">.</span>load(pos_model_path)  <span style="color:#75715e"># 加载模型</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>word1 <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;中信建投&#34;</span>,<span style="color:#e6db74">&#34;证券&#34;</span>,<span style="color:#e6db74">&#34;投资&#34;</span>,<span style="color:#e6db74">&#34;有限公司&#34;</span>]
</span></span><span style="display:flex;"><span>word2 <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;中信&#34;</span>,<span style="color:#e6db74">&#34;	今天&#34;</span>,<span style="color:#e6db74">&#34;投资&#34;</span>,<span style="color:#e6db74">&#34;了&#34;</span>,<span style="color:#e6db74">&#34;一款&#34;</span>,<span style="color:#e6db74">&#34;游戏&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>postags1 <span style="color:#f92672">=</span> postagger<span style="color:#f92672">.</span>postag(word1)  <span style="color:#75715e"># 词性标注</span>
</span></span><span style="display:flex;"><span>postags2 <span style="color:#f92672">=</span> postagger<span style="color:#f92672">.</span>postag(word2)  <span style="color:#75715e"># 词性标注</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print (<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>join(postags1))
</span></span><span style="display:flex;"><span>print (<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>join(postags2))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>postagger<span style="color:#f92672">.</span>release()  <span style="color:#75715e"># 释放模型</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#--   命名实体识别</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span>LTP_DATA_DIR <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;./ltp_data_v3.4.0&#39;</span>  <span style="color:#75715e"># ltp模型目录的路径</span>
</span></span><span style="display:flex;"><span>ner_model_path <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(LTP_DATA_DIR, <span style="color:#e6db74">&#39;ner.model&#39;</span>)  <span style="color:#75715e"># 命名实体识别模型路径，模型名称为`pos.model`</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> pyltp <span style="color:#f92672">import</span> NamedEntityRecognizer
</span></span><span style="display:flex;"><span>recognizer <span style="color:#f92672">=</span> NamedEntityRecognizer() <span style="color:#75715e"># 初始化实例</span>
</span></span><span style="display:flex;"><span>recognizer<span style="color:#f92672">.</span>load(ner_model_path)  <span style="color:#75715e"># 加载模型</span>
</span></span><span style="display:flex;"><span>word1 <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;中信建投&#34;</span>,<span style="color:#e6db74">&#34;证券&#34;</span>,<span style="color:#e6db74">&#34;投资&#34;</span>,<span style="color:#e6db74">&#34;有限公司&#34;</span>]
</span></span><span style="display:flex;"><span>word2 <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;中信&#34;</span>,<span style="color:#e6db74">&#34;今天&#34;</span>,<span style="color:#e6db74">&#34;投资&#34;</span>,<span style="color:#e6db74">&#34;了&#34;</span>,<span style="color:#e6db74">&#34;一款&#34;</span>,<span style="color:#e6db74">&#34;游戏&#34;</span>]
</span></span><span style="display:flex;"><span>postags1  <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;j&#34;</span>,<span style="color:#e6db74">&#34;n&#34;</span>,<span style="color:#e6db74">&#34;v&#34;</span>,<span style="color:#e6db74">&#34;n&#34;</span>]
</span></span><span style="display:flex;"><span>postags2 <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;j&#34;</span>,<span style="color:#e6db74">&#34;nt&#34;</span>,<span style="color:#e6db74">&#34;v&#34;</span>,<span style="color:#e6db74">&#34;u&#34;</span>,<span style="color:#e6db74">&#34;m&#34;</span>,<span style="color:#e6db74">&#34;n&#34;</span>]
</span></span><span style="display:flex;"><span>netags1 <span style="color:#f92672">=</span> recognizer<span style="color:#f92672">.</span>recognize(word1, postags1)  <span style="color:#75715e"># 命名实体识别</span>
</span></span><span style="display:flex;"><span>netags2 <span style="color:#f92672">=</span> recognizer<span style="color:#f92672">.</span>recognize(word2, postags2)  <span style="color:#75715e"># 命名实体识别</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>join(netags1))
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>join(netags2))
</span></span><span style="display:flex;"><span>recognizer<span style="color:#f92672">.</span>release()  <span style="color:#75715e"># 释放模型</span>
</span></span></code></pre></div><blockquote>
<p><code>依存句法</code> (Dependency Parsing, DP) 通过分析语言单位内成分之间的依存关系揭示其句法结构。 直观来讲，依存句法分析识别句子中的<code>“主谓宾”、“定状补”</code>这些语法成分，并分析<code>各成分之间的关 系</code>。</p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116215205218.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116215205218.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116215205218.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116215205218.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116215205218.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116215205218.png"/></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 1）依存句法分析</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span>LTP_DATA_DIR <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;./ltp_data_v3.4.0&#39;</span>  <span style="color:#75715e"># ltp模型目录的路径</span>
</span></span><span style="display:flex;"><span>par_model_path <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(LTP_DATA_DIR, <span style="color:#e6db74">&#39;parser.model&#39;</span>)  <span style="color:#75715e"># 依存句法分析模型路径，模型名称为`parser.model`</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> pyltp <span style="color:#f92672">import</span> Parser
</span></span><span style="display:flex;"><span>parser <span style="color:#f92672">=</span> Parser() <span style="color:#75715e"># 初始化实例</span>
</span></span><span style="display:flex;"><span>parser<span style="color:#f92672">.</span>load(par_model_path)  <span style="color:#75715e"># 加载模型</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>words <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;中信建投&#39;</span>, <span style="color:#e6db74">&#39;证券&#39;</span>, <span style="color:#e6db74">&#39;投资&#39;</span>, <span style="color:#e6db74">&#39;有限公司&#39;</span>,<span style="color:#e6db74">&#34;今天&#34;</span>,<span style="color:#e6db74">&#34;投资&#34;</span>,<span style="color:#e6db74">&#34;了&#34;</span>,<span style="color:#e6db74">&#34;一款&#34;</span>,<span style="color:#e6db74">&#34;雷人&#34;</span>,<span style="color:#e6db74">&#34;游戏&#34;</span>]
</span></span><span style="display:flex;"><span>postags <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;j&#34;</span>,<span style="color:#e6db74">&#34;n&#34;</span>,<span style="color:#e6db74">&#34;v&#34;</span>,<span style="color:#e6db74">&#34;n&#34;</span>,<span style="color:#e6db74">&#34;nt&#34;</span>,<span style="color:#e6db74">&#34;v&#34;</span>,<span style="color:#e6db74">&#34;u&#34;</span>,<span style="color:#e6db74">&#34;m&#34;</span>,<span style="color:#e6db74">&#34;n&#34;</span>,<span style="color:#e6db74">&#34;n&#34;</span>]
</span></span><span style="display:flex;"><span>arcs <span style="color:#f92672">=</span> parser<span style="color:#f92672">.</span>parse(words, postags)  <span style="color:#75715e"># 句法分析</span>
</span></span><span style="display:flex;"><span>print (<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>join(<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">%d</span><span style="color:#e6db74">:</span><span style="color:#e6db74">%s</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> (arc<span style="color:#f92672">.</span>head, arc<span style="color:#f92672">.</span>relation) <span style="color:#66d9ef">for</span> arc <span style="color:#f92672">in</span> arcs))
</span></span><span style="display:flex;"><span>parser<span style="color:#f92672">.</span>release()  <span style="color:#75715e"># 释放模型</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 2）语义角色标注</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span>LTP_DATA_DIR <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;./ltp_data_v3.4.0&#39;</span>  <span style="color:#75715e"># ltp模型目录的路径</span>
</span></span><span style="display:flex;"><span>srl_model_path <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(LTP_DATA_DIR, <span style="color:#e6db74">&#39;pisrl.model&#39;</span>)  <span style="color:#75715e"># 语义角色标注模型目录路径，模型目录为`srl`。注意该模型路径是一个目录，而不是一个文件。</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> pyltp <span style="color:#f92672">import</span> SementicRoleLabeller
</span></span><span style="display:flex;"><span>labeller <span style="color:#f92672">=</span> SementicRoleLabeller() <span style="color:#75715e"># 初始化实例</span>
</span></span><span style="display:flex;"><span>labeller<span style="color:#f92672">.</span>load(srl_model_path)  <span style="color:#75715e"># 加载模型</span>
</span></span><span style="display:flex;"><span>words <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;中信建投&#39;</span>, <span style="color:#e6db74">&#39;证券&#39;</span>, <span style="color:#e6db74">&#39;投资&#39;</span>, <span style="color:#e6db74">&#39;有限公司&#39;</span>,<span style="color:#e6db74">&#34;今天&#34;</span>,<span style="color:#e6db74">&#34;投资&#34;</span>,<span style="color:#e6db74">&#34;了&#34;</span>,<span style="color:#e6db74">&#34;一款&#34;</span>,<span style="color:#e6db74">&#34;雷人&#34;</span>,<span style="color:#e6db74">&#34;游戏&#34;</span>]
</span></span><span style="display:flex;"><span>postags <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;j&#34;</span>,<span style="color:#e6db74">&#34;n&#34;</span>,<span style="color:#e6db74">&#34;v&#34;</span>,<span style="color:#e6db74">&#34;n&#34;</span>,<span style="color:#e6db74">&#34;nt&#34;</span>,<span style="color:#e6db74">&#34;v&#34;</span>,<span style="color:#e6db74">&#34;u&#34;</span>,<span style="color:#e6db74">&#34;m&#34;</span>,<span style="color:#e6db74">&#34;n&#34;</span>,<span style="color:#e6db74">&#34;n&#34;</span>]
</span></span><span style="display:flex;"><span><span style="color:#75715e"># arcs 使用依存句法分析的结果</span>
</span></span><span style="display:flex;"><span>roles <span style="color:#f92672">=</span> labeller<span style="color:#f92672">.</span>label(words, postags, arcs)  <span style="color:#75715e"># 语义角色标注</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 打印结果</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> role <span style="color:#f92672">in</span> roles:
</span></span><span style="display:flex;"><span>    print (role<span style="color:#f92672">.</span>index, <span style="color:#e6db74">&#34;&#34;</span><span style="color:#f92672">.</span>join([<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">%s</span><span style="color:#e6db74">:(</span><span style="color:#e6db74">%d</span><span style="color:#e6db74">,</span><span style="color:#e6db74">%d</span><span style="color:#e6db74">)&#34;</span> <span style="color:#f92672">%</span> (arg<span style="color:#f92672">.</span>name, arg<span style="color:#f92672">.</span>range<span style="color:#f92672">.</span>start, arg<span style="color:#f92672">.</span>range<span style="color:#f92672">.</span>end) <span style="color:#66d9ef">for</span> arg <span style="color:#f92672">in</span> role<span style="color:#f92672">.</span>arguments]))
</span></span><span style="display:flex;"><span>labeller<span style="color:#f92672">.</span>release()  <span style="color:#75715e"># 释放模型</span>
</span></span></code></pre></div><blockquote>
<p><code>语义角色标注 (Semantic Role Labeling, SRL) </code>是一种浅层的语义分析技术，标注句子中某些短语为给定谓词的论元 (语义角色) ，如施事、受事、时间和地点等。其能够对问答系统、信息抽取和机器翻译等应用产生推动作用。</p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116215730714.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116215730714.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116215730714.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116215730714.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116215730714.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116215730714.png"/></p>
<blockquote>
<p><code>语义依存分析 (Semantic Dependency Parsing, SDP)</code>，分析句子各个语言单位之间的语义关联，并将语义关联以依存结构呈现。 使用语义依存刻画句子语义，好处在于不需要去抽象词汇本身，而是通过词汇所承受的语义框架来描述该词汇，而论元的数目相对词汇来说数量总是少了很多的。语义依存分析目标是跨越句子表层句法结构的束缚，直接获取深层的语义信息。</p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116220050224.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116220050224.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116220050224.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116220050224.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116220050224.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116220050224.png"/></p>
<h2 id="5-学习链接">5. 学习链接</h2>
<ul>
<li>
<p><a href="http://www.ltp-cloud.com/intro#dp_how"target="_blank" rel="external nofollow noopener noreferrer">http://www.ltp-cloud.com/intro#dp_how<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</li>
<li>
<p><a href="http://www.ltp-cloud.com/document2#api2_python_interface"target="_blank" rel="external nofollow noopener noreferrer">http://www.ltp-cloud.com/document2#api2_python_interface<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</li>
<li>
<p><a href="http://www.ltp-cloud.com/blog/"target="_blank" rel="external nofollow noopener noreferrer">技术博客<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</li>
<li>
<p><a href="http://nlp.stanford.edu:8080/ner/process"target="_blank" rel="external nofollow noopener noreferrer">Stanfordnlp<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</li>
</ul>
</div>
<div class="post-footer" id="post-footer">
  <div class="post-info">
    <div class="post-info-line">
      <div class="post-info-mod">
        <span title=2023-09-28&#32;23:29:20>更新于 2023-09-28&nbsp;</span>
      </div><div class="post-info-license">
          <span><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span>
        </div></div>
    <div class="post-info-line">
      <div class="post-info-md"><span><a href="liudongdong1.github.io/stanfordnlp_record/index.md" title="阅读原始文档" class="link-to-markdown">阅读原始文档</a></span><span><a href="https://liudongdong1.github.io/edit/master/content/posts%5c%e8%87%aa%e7%84%b6%e8%af%ad%e8%a8%80%5cFramework%5cStanfordnlp_record.md" title="编辑此页"target="_blank" rel="external nofollow noopener noreferrer" class="link-to-edit">编辑此页</a></span></div>
      <div class="post-info-share">
        <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="liudongdong1.github.io/stanfordnlp_record/" data-title="Standfordnlp" data-hashtags="NLP"><i class="fa-brands fa-twitter fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="liudongdong1.github.io/stanfordnlp_record/" data-hashtag="NLP"><i class="fa-brands fa-facebook-square fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="liudongdong1.github.io/stanfordnlp_record/" data-title="Standfordnlp" data-image="https://gitee.com/github-25970295/blogImage/raw/master/img/82.jpeg"><i class="fa-brands fa-weibo fa-fw" aria-hidden="true"></i></a>
  </span>
      </div>
    </div>
  </div>

  <div class="post-info-more">
    <section class="post-tags"><i class="fa-solid fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="liudongdong1.github.io/tags/nlp/">NLP</a></section>
    <section>
      <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="liudongdong1.github.io/">主页</a></span>
    </section>
  </div>

  <div class="post-nav"><a href="liudongdong1.github.io/picturecompress/" class="prev" rel="prev" title="PictureCompress"><i class="fa-solid fa-angle-left fa-fw" aria-hidden="true"></i>PictureCompress</a>
      <a href="liudongdong1.github.io/nlprelative/" class="next" rel="next" title="NLPRelative">NLPRelative<i class="fa-solid fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article></main><footer class="footer">
    <div class="footer-container"><div class="footer-line powered">由 <a href="https://gohugo.io/" target="_blank" rel="external nofollow noopener noreferrer" title="Hugo 0.118.2">Hugo</a> 强力驱动 | 主题 - <a href="https://github.com/hugo-fixit/FixIt" target="_blank" rel="external" title="FixIt v0.2.17-RC"><img class="fixit-icon" src="/liudongdong1.github.io/fixit.min.svg" alt="FixIt logo" />&nbsp;FixIt</a>
        </div><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">2020 - 2023</span><span class="author" itemprop="copyrightHolder">
              <a href="https://liudongdong1.github.io/"target="_blank" rel="external nofollow noopener noreferrer">LiuDongdong</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div><div class="footer-line statistics"><span class="site-time" title='网站运行中 ...'><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden="true"></i>&nbsp;<span class="run-times">网站运行中 ...</span></span></div><div class="footer-line ibruce">
          <span id="busuanzi_container_site_uv" title='总访客数'><i class="fa-regular fa-user fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span><span id="busuanzi_container_site_pv" class="footer-divider" title='总访问量'><i class="fa-regular fa-eye fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span>
        </div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="回到顶部"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric">0%</span>
        </div></div><a href="https://liudongdong1.github.io/" title="在 GitHub 上查看源代码"target="_blank" rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><div id="mask"></div><div class="reading-progress-bar" style="left: 0;top: 0;--bg-progress: #0076ff;--bg-progress-dark: #fff;"></div><noscript>
    <div class="noscript-warning">FixIt 主题在启用 JavaScript 的情况下效果最佳。</div>
  </noscript>
</div><link rel="stylesheet" href="/liudongdong1.github.io/lib/katex/katex.min.css"><link rel="stylesheet" href="/liudongdong1.github.io/lib/cookieconsent/cookieconsent.min.css"><script src="/liudongdong1.github.io/lib/autocomplete/autocomplete.min.js" defer></script><script src="/liudongdong1.github.io/lib/algoliasearch/algoliasearch-lite.umd.min.js" defer></script><script src="/liudongdong1.github.io/lib/lazysizes/lazysizes.min.js" async defer></script><script src="/liudongdong1.github.io/lib/sharer/sharer.min.js" async defer></script><script src="/liudongdong1.github.io/lib/typeit/index.umd.js" defer></script><script src="/liudongdong1.github.io/lib/katex/katex.min.js" defer></script><script src="/liudongdong1.github.io/lib/katex/auto-render.min.js" defer></script><script src="/liudongdong1.github.io/lib/katex/copy-tex.min.js" defer></script><script src="/liudongdong1.github.io/lib/katex/mhchem.min.js" defer></script><script src="/liudongdong1.github.io/lib/cookieconsent/cookieconsent.min.js" defer></script><script src="/liudongdong1.github.io/lib/pangu/pangu.min.js" defer></script><script src="/liudongdong1.github.io/lib/cell-watermark/watermark.min.js" defer></script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async defer></script><script>window.config={"code":{"copyTitle":"复制到剪贴板","editLockTitle":"锁定可编辑代码块","editUnLockTitle":"解锁可编辑代码块","editable":true,"maxShownLines":10},"comment":{"enable":false},"cookieconsent":{"content":{"dismiss":"同意","link":"了解更多","message":"本网站使用 Cookies 来改善您的浏览体验。"},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"data":{"typeit-header-subtitle-desktop":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e","typeit-header-subtitle-mobile":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e"},"enablePWA":true,"enablePangu":true,"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"2R1K9SKLQZ","algoliaIndex":"index.zh-cn","algoliaSearchKey":"4a226aa1c5c98d6859e4d1386adb2bc7","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"},"siteTime":"2020-12-18T16:15:22+08:00","typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"typeit-header-subtitle-desktop":["typeit-header-subtitle-desktop"],"typeit-header-subtitle-mobile":["typeit-header-subtitle-mobile"]},"duration":-1,"speed":100},"watermark":{"appendto":".wrapper\u003emain","colspacing":30,"content":"\u003cimg class=\"fixit-icon\" src=\"/fixit.min.svg\" alt=\"FixIt logo\" /\u003e FixIt 主题","enable":true,"fontfamily":"inherit","fontsize":0.85,"height":21,"opacity":0.0125,"rotate":15,"rowspacing":60,"width":150}};</script><script src="/liudongdong1.github.io/js/theme.min.js" defer></script><script src="/liudongdong1.github.io/js/custom.min.js" defer></script></body>
</html>
