<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>math - 标签 - DAY By DAY</title>
    <link>https://liudongdong1.github.io/tags/math/</link>
    <description>math - 标签 - DAY By DAY</description>
    <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>3463264078@qq.cn (LiuDongdong)</managingEditor>
      <webMaster>3463264078@qq.cn (LiuDongdong)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Mon, 18 Oct 2021 17:00:57 &#43;0000</lastBuildDate><atom:link href="https://liudongdong1.github.io/tags/math/" rel="self" type="application/rss+xml" /><item>
  <title>HighDimensionClassify</title>
  <link>https://liudongdong1.github.io/highdimensionclassify/</link>
  <pubDate>Mon, 18 Oct 2021 17:00:57 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/highdimensionclassify/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.stocksnap.io/img-thumbs/280h/2P4CSFCJYF.jpg" referrerpolicy="no-referrer">
      </div>Zhu Q, Deng W, Zheng Z, et al. A Spectral-Spatial-Dependent Global Learning Framework for Insufficient and Imbalanced Hyperspectral Image Classification[J]. IEEE Transactions on Cybernetics, 2021. code [pdf]
Paper: Summary a spectral-spatial dependent global learning (SSDGL) framework based on global convolutional long short-term memory (GCL) and global joint attention mechanism (GJAM) is proposed for insufficient and imbalanced HSI classification. in SSDGL, the hierarchically balanced(H-B) sampling strategy and the weighted softmax loss are proposed to address the imbalanced sample problem.]]></description>
</item>
<item>
  <title>SkLearn Evaluation</title>
  <link>https://liudongdong1.github.io/sklearn-evaluation/</link>
  <pubDate>Wed, 14 Apr 2021 21:38:11 &#43;0000</pubDate>
  <author>LiuDongdong</author>
  <guid>https://liudongdong1.github.io/sklearn-evaluation/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210501113504.png" referrerpolicy="no-referrer">
      </div>1. Cross-validation cross_val_score from sklearn.model_selection import cross_val_score clf = svm.SVC(kernel=&#39;linear&#39;, C=1, random_state=42) scores = cross_val_score(clf, X, y, cv=5，scoring=&#39;f1_macro&#39;) print(&#34;%0.2f accuracy with a standard deviation of %0.2f&#34; % (scores.mean(), scores.std())) from sklearn import preprocessing X_train, X_test, y_train, y_test = train_test_split(]]></description>
</item>
<item>
  <title>SkLearn Record</title>
  <link>https://liudongdong1.github.io/sklearn-record/</link>
  <pubDate>Wed, 14 Apr 2021 21:38:11 &#43;0000</pubDate>
  <author>LiuDongdong</author>
  <guid>https://liudongdong1.github.io/sklearn-record/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210414084511.png" referrerpolicy="no-referrer">
      </div>Supervised learning 1.1. Linear Models 1.2. Linear and Quadratic Discriminant Analysis 1.3. Kernel ridge regression 1.4. Support Vector Machines 1.5. Stochastic Gradient Descent 1.6. Nearest Neighbors 1.7. Gaussian Processes 1.8. Cross decomposition 1.9. Naive Bayes 1.10. Decision Trees 1.11. Ensemble methods 1.12. Multiclass and multioutput algorithms 1.13. Feature selection 1.14. Semi-supervised learning 1.15. Isotonic regression 1.16. Probability calibration 1.17. Neural network models (supervised) Unsupervised learning 2.1. Gaussian mixture models 2.2.]]></description>
</item>
<item>
  <title>SkLearnVisualization</title>
  <link>https://liudongdong1.github.io/sklearnvisualization/</link>
  <pubDate>Wed, 14 Apr 2021 21:38:11 &#43;0000</pubDate>
  <author>LiuDongdong</author>
  <guid>https://liudongdong1.github.io/sklearnvisualization/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210522212757.png" referrerpolicy="no-referrer">
      </div>1. cross-validation（ROC) print(__doc__) import numpy as np import matplotlib.pyplot as plt from sklearn import svm, datasets from sklearn.metrics import auc from sklearn.metrics import plot_roc_curve from sklearn.model_selection import StratifiedKFold # ############################################################################# # Data IO and generation # Import some data to play with iris = datasets.load_iris() X = iris.data y = iris.target X, y = X[y != 2], y[y != 2] n_samples, n_features = X.shape # Add noisy features random_state = np.]]></description>
</item>
<item>
  <title>SkLearn Optimize</title>
  <link>https://liudongdong1.github.io/sklearn-optimize/</link>
  <pubDate>Wed, 14 Apr 2021 08:38:11 &#43;0000</pubDate>
  <author>LiuDongdong</author>
  <guid>https://liudongdong1.github.io/sklearn-optimize/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210501113542.png" referrerpolicy="no-referrer">
      </div>使用scikit-learn时提高速度的三种主要方法是：使用joblib和Ray并行化或分发培训，使用不同的超参数优化技术（网格搜索，随机搜]]></description>
</item>
<item>
  <title>FitFunction</title>
  <link>https://liudongdong1.github.io/fitfunction/</link>
  <pubDate>Thu, 18 Mar 2021 07:00:57 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/fitfunction/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210501113433.png" referrerpolicy="no-referrer">
      </div>1. 多项式拟合 import numpy as np import matplotlib.pyplot as plt # 模拟生成一组实验数据 x = np.arange(0,10,0.2) y = -(x-3.5)**2+4.7 noise = np.random.uniform(-3,3,len(x)) y += noise fig, ax = plt.subplots() ax.plot(x, y, &#39;b--&#39;) ax.set_xlabel(&#39;x&#39;) ax.set_ylabel(&#39;y&#39;) # 二次拟合 coef = np.polyfit(x, y, 2) y_fit = np.polyval(coef, x) ax.plot(x, y_fit, &#39;g&#39;) # 找出其中的峰]]></description>
</item>
<item>
  <title>FitFunction</title>
  <link>https://liudongdong1.github.io/t-sne/</link>
  <pubDate>Thu, 18 Mar 2021 07:00:57 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/t-sne/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.stocksnap.io/img-thumbs/280h/NHFG4FDXGH.jpg" referrerpolicy="no-referrer">
      </div>1. SNE 基本原理 2. 目标函数求解 3. 对称 SNE 4. t-SNE 在对称 的改进是，首先通过在高维空间中使用高斯分布将距离转换为概率分布，然后在低维空间中，使用更加偏重长]]></description>
</item>
<item>
  <title>Pdf&amp;Cdf&amp;Pmf</title>
  <link>https://liudongdong1.github.io/pdfcdfpmf/</link>
  <pubDate>Fri, 04 Dec 2020 09:56:09 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/pdfcdfpmf/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/79.jpeg" referrerpolicy="no-referrer">
      </div>1. PDF&amp;CDF&amp;PMF 2. code import numpy as np import matplotlib.pyplot as plt import os from scipy import stats import seaborn as sns def readTxt(path): f = open(path,&#39;r&#39;, encoding=&#39;UTF-8&#39;) dataList = [] dataList=[line.split(&#34;:&#34;)[-1].split(&#34;\n&#34;)[0] for line in f.readlines()] dataList=[float(i) for i in dataList] return dataList data=[&#39;52.20153254455275&#39;, &#39;48.421227186748&#39;, &#39;50.95434359918541&#39;] data=[float(i) for i in data] fs_xk = np.sort(data) hist, bin_edges = np.histogram(fs_xk) width = (bin_edges[1] - bin_edges[0]) * 0.95 plt.bar(bin_edges[1:], hist/sum(hist), width=width, color=&#39;#5B9BD5&#39;) cdf = np.]]></description>
</item>
<item>
  <title>Mathbasic</title>
  <link>https://liudongdong1.github.io/mathbasic/</link>
  <pubDate>Sat, 17 Oct 2020 15:56:09 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/mathbasic/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/tennis-racke-and-ball-on-court.jpg" referrerpolicy="no-referrer">
      </div>每一个概念，被定义就是为了去解决一个实际问题（问Why&amp;What），接着寻找解决问题的方法（问How），这个“方法”在计算机领域被称]]></description>
</item>
<item>
  <title>SentenceDistance</title>
  <link>https://liudongdong1.github.io/sentencedistance/</link>
  <pubDate>Thu, 15 Oct 2020 07:56:09 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/sentencedistance/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.stocksnap.io/img-thumbs/280h/FZ5NYSFTLG.jpg" referrerpolicy="no-referrer">
      </div>0. Relative API CountVectorizer() 词频统计 &gt;&gt;&gt; from sklearn.feature_extraction.text import CountVectorizer &gt;&gt;&gt; corpus = [ ... &#39;This is the first document.&#39;, ... &#39;This document is the second document.&#39;, ... &#39;And this is the third one.&#39;, ... &#39;Is this the first document?&#39;, ... ] &gt;&gt;&gt; vectorizer = CountVectorizer() &gt;&gt;&gt; X = vectorizer.fit_transform(corpus) &gt;&gt;&gt; print(vectorizer.get_feature_names()) [&#39;and&#39;, &#39;document&#39;, &#39;first&#39;, &#39;is&#39;, &#39;one&#39;, &#39;second&#39;, &#39;the&#39;, &#39;third&#39;, &#39;this&#39;] &gt;&gt;&gt; print(X.toarray()) [[0 1 1 1]]></description>
</item>
</channel>
</rss>
