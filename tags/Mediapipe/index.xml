<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Mediapipe - 标签 - DAY By DAY</title>
    <link>https://liudongdong1.github.io/tags/mediapipe/</link>
    <description>Mediapipe - 标签 - DAY By DAY</description>
    <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>3463264078@qq.cn (LiuDongdong)</managingEditor>
      <webMaster>3463264078@qq.cn (LiuDongdong)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Thu, 14 Jan 2021 21:59:57 &#43;0000</lastBuildDate><atom:link href="https://liudongdong1.github.io/tags/mediapipe/" rel="self" type="application/rss+xml" /><item>
  <title>MediaPipePose</title>
  <link>https://liudongdong1.github.io/mediapipepose/</link>
  <pubDate>Thu, 14 Jan 2021 21:59:57 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/mediapipepose/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.stocksnap.io/img-thumbs/280h/ULHEMNJ457.jpg" referrerpolicy="no-referrer">
      </div>Human pose estimation from video plays a critical role in various applications such as quantifying physical exercises, sign language recognition, and full-body gesture control. For example, it can form the basis for yoga, dance, and fitness applications. It can also enable the overlay of digital content and information on top of the physical world in augmented reality. MediaPipe Pose is a ML solution for high-fidelity body pose tracking, inferring 33]]></description>
</item>
<item>
  <title>MediaPipe_Usage</title>
  <link>https://liudongdong1.github.io/mediapipe_usage/</link>
  <pubDate>Mon, 14 Sep 2020 21:59:57 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/mediapipe_usage/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200715085515063.png" referrerpolicy="no-referrer">
      </div>1. Installation $ git clone https://github.com/google/mediapipe.git # Change directory into MediaPipe root directory $ cd mediapipe #install Bazel #link https://blog.csdn.net/liudongdong19 #install opencv and ffmpeg sudo apt-get install libopencv-core-dev libopencv-highgui-dev \libopencv-calib3d-dev libopencv-features2d-dev \libopencv-imgproc-dev libopencv-video-dev # Requires a GPU with EGL driver support. # Can use mesa GPU libraries for desktop, (or Nvidia/AMD equivalent). sudo apt-get install mesa-common-dev libegl1-mesa-dev libgles2-mesa-dev # To compile with GPU support, replace --define MEDIAPIPE_DISABLE_GPU=1 # with --copt -DMESA_EGL_NO_X11_HEADERS --copt -DEGL_NO_X11 $ export GLOG_logtostderr=1 # if you are running on Linux desktop with CPU only $ bazel run --define MEDIAPIPE_DISABLE_GPU=1 \ mediapipe/examples/desktop/hello_world:hello_world # If you are running on Linux desktop with GPU support enabled (via mesa drivers) $ bazel run --copt -DMESA_EGL_NO_X11_HEADERS --copt -DEGL_NO_X11 \ mediapipe/examples/desktop/hello_world:hello_world 2.]]></description>
</item>
<item>
  <title>MediaPipe</title>
  <link>https://liudongdong1.github.io/mediapipe/</link>
  <pubDate>Mon, 24 Aug 2020 21:59:57 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/mediapipe/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200715085515063.png" referrerpolicy="no-referrer">
      </div>MediaPipe is the simplest way for researchers and developers to build world-class ML solutions and applications for mobile, desktop/cloud, web and IoT devices. 1. Introduce End-to-End acceleration: built-in fast ML inference and processing accelerated even on common hardware Build one, deploy anywhere: Unified solution works across Android, iOS, desktop/cloud, web and IoT Ready-to-use solutions: cutting-edge ML solutions demonstrating full power of the framework Free and Open Source 2.PaperReading level: CCF_A]]></description>
</item>
</channel>
</rss>
