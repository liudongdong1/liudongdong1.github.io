<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>AIOT - 标签 - DAY By DAY</title><link>liudongdong1.github.io/tags/aiot/</link><description>AIOT - 标签 - DAY By DAY</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>3463264078@qq.cn (LiuDongdong)</managingEditor><webMaster>3463264078@qq.cn (LiuDongdong)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Wed, 10 Nov 2021 16:00:04 +0000</lastBuildDate><atom:link href="liudongdong1.github.io/tags/aiot/" rel="self" type="application/rss+xml"/><item><title>ThingsBoard_FileStructure</title><link>liudongdong1.github.io/thingsboard_filestructure/</link><pubDate>Wed, 10 Nov 2021 16:00:04 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/thingsboard_filestructure/</guid><description>1. 文件目录</description></item><item><title>gps</title><link>liudongdong1.github.io/gps/</link><pubDate>Tue, 25 May 2021 16:00:04 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/gps/</guid><description><![CDATA[<div class="featured-image">
        <img src="https://cdn.pixabay.com/photo/2018/05/26/21/21/blueberries-3432295__340.jpg" referrerpolicy="no-referrer">
      </div># WARNING: you are on the master branch, please refer to the examples on the branch that matches your `cortex version` import serial, pynmea2, time, threading as td import logging logger = logging.getLogger(__name__) class ReadGPSData(td.Thread): &#34;&#34;&#34; Class to read the data off of the EC25-E&#39;s GPS module. Can be easily adapted to work with any other GPS module. &#34;&#34;&#34; def __init__(self, write_port, read_port, baudrate, name=&#34;GPS&#34;): &#34;&#34;&#34; write_port - The serial]]></description></item><item><title>image</title><link>liudongdong1.github.io/image/</link><pubDate>Sun, 25 Apr 2021 16:00:04 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/image/</guid><description>&lt;div class="featured-image">
&lt;img src="https://cdn.pixabay.com/photo/2021/06/15/03/35/chrysanthemum-6337374__340.jpg" referrerpolicy="no-referrer">
&lt;/div>1. imageHangle # WARNING: you are on the master branch, please refer to the examples on the branch that matches your `cortex version` import cv2 import numpy as np def resize_image(image, desired_width): current_width = image.shape[1] scale_percent = desired_width / current_width width = int(image.shape[1] * scale_percent) height = int(image.shape[0] * scale_percent) resized = cv2.resize(image, (width, height), interpolation=cv2.INTER_AREA) return resized def compress_image(image, grayscale=True, desired_width=416, top_crop_percent=0.45): if grayscale: image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) image</description></item><item><title>HandRecognition</title><link>liudongdong1.github.io/handrecognition/</link><pubDate>Sat, 24 Oct 2020 16:00:04 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/handrecognition/</guid><description><![CDATA[<div class="featured-image">
        <img src="https://gitee.com/github-25970295/blogImage/raw/master/img/30.jpeg" referrerpolicy="no-referrer">
      </div>1. IMU，肌电信号 1.1. Serendipity Wen, Hongyi, Julian Ramos Rojas, and Anind K. Dey. &ldquo;Serendipity: Finger gesture recognition using an off-the-shelf smartwatch.&rdquo; Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. 2016. 107 1.1.1. Relative Expanding interaction space: SkinWatch [9] provides gesture input by sensing deformation of skin. Abracadabra [4] enables off-the-screen fine motor control by placing a magnet on the]]></description></item><item><title>SmartWatchRelative</title><link>liudongdong1.github.io/smartwatchrelative/</link><pubDate>Sat, 24 Oct 2020 16:00:04 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/smartwatchrelative/</guid><description><![CDATA[<div class="featured-image">
        <img src="https://gitee.com/github-25970295/blogImage/raw/master/img/30.jpeg" referrerpolicy="no-referrer">
      </div>level: author: Gutao date: 2018
Zhang, Yu, et al. &ldquo;Findroidhr: Smartwatch gesture input with optical heartrate monitor.&rdquo; Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 2.1 (2018): 1-42.
Paper: Findroidhr ]]></description></item><item><title>ObjectCenteredSensing</title><link>liudongdong1.github.io/objectcenteredsensing/</link><pubDate>Wed, 19 Aug 2020 07:56:09 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/objectcenteredsensing/</guid><description><![CDATA[<div class="featured-image">
        <img src="https://cdn.pixabay.com/photo/2017/10/12/22/17/business-2846221__340.jpg" referrerpolicy="no-referrer">
      </div>1. 物体检测 .1. 流体 D. V. Q. Rodrigues, D. Rodriguez and C. Li, &ldquo;Liquid Aerosol Detection Based on Sub-THz Portable Doppler Radars,&rdquo; 2020 IEEE Asia-Pacific Microwave Conference (APMC), 2020, pp. 504-506, doi: 10.1109/APMC47863.2020.9331483. [pdf] Bala B S, Swetha M, Tamilarasi M, et al. Survey on women safety using IOT[J]. International Journal of Computer Engineering in Research Trends, 2018, 5(2): 16-24. [pdf] .2. 材质分类]]></description></item><item><title>BandWatchSurvey</title><link>liudongdong1.github.io/bandwatchsurvey/</link><pubDate>Sat, 11 Jul 2020 21:59:57 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/bandwatchsurvey/</guid><description>&lt;div class="featured-image">
&lt;img src="https://gitee.com/github-25970295/blogImage/raw/master/img/59.jpeg" referrerpolicy="no-referrer">
&lt;/div>MetaSensors, comes in a small package that includes motion and environmental sensors. Our Sensors communicate to Devices including Smartphone, Tablets, Computers, Gateway Hubs and RaspberryPis using Bluetooth Low Energy. 1. Fitbit Sense手表 EDA(即皮肤电活动)传感器基本上可以跟踪皮肤汗液中的电变化,可</description></item><item><title>IoT比赛项目</title><link>liudongdong1.github.io/iot%E6%AF%94%E8%B5%9B%E9%A1%B9%E7%9B%AE/</link><pubDate>Sat, 11 Jul 2020 16:00:04 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/iot%E6%AF%94%E8%B5%9B%E9%A1%B9%E7%9B%AE/</guid><description>&lt;div class="featured-image">
&lt;img src="https://cdn.stocksnap.io/img-thumbs/280h/smartphone-camera_TBGNSSQV6B.jpg" referrerpolicy="no-referrer">
&lt;/div>1. 基于颜色的产品分拣系统 控制器电路由一个连接在它上面的摄像头组成，它可以检测前面小物体的颜色。电动机用来将物体送入摄像室。一旦检测到颜色，一</description></item><item><title>Multi-Sense</title><link>liudongdong1.github.io/multi-sense/</link><pubDate>Wed, 24 Jun 2020 19:30:32 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/multi-sense/</guid><description><![CDATA[<div class="featured-image">
        <img src="https://gitee.com/github-25970295/blogImage/raw/master/img/apple-iphone-smartphone-technology-1.jpg" referrerpolicy="no-referrer">
      </div>level: IEEE Robotics and automation letters date: &lsquo;2019,10&rsquo; keyword: Deep learning in robotics and automation,action segmentation,ergonomic safety. Paper: Ergonomic Risk predition we present a first of its kind end-to-end deep learning system for ergonomic risk assessment during indoor object manipulation using camera videos. Our learning system is based on action segmentation*, where an action class (with a corresponding risk label) is predicted for every video frame. The REBA model assigns]]></description></item><item><title>CameraOpencv</title><link>liudongdong1.github.io/cameraopencv/</link><pubDate>Mon, 25 May 2020 16:00:04 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/cameraopencv/</guid><description>&lt;div class="featured-image">
&lt;img src="https://cdn.pixabay.com/photo/2021/06/15/14/52/strawberries-6338813__340.jpg" referrerpolicy="no-referrer">
&lt;/div>import cv2 from PyQt5.QtCore import QTimer class Camera(object): def __init__(self,timesInterval): self.device = 0 self.timesInterval =timesInterval #ms self.cap = cv2.VideoCapture() self.timer = QTimer() #A single-shot timer fires only once, non-single-shot timers fire every interval milliseconds. def stop(self): self.timer.stop() self.cap.release() return True def pause(self): self.timer.stop() def begin(self): self.timer.start(self.timesInterval) def start(self, device): if self.cap.isOpened(): self.cap.release() self.timer.start(self.timesInterval) self.cap.open(device) self.device = device return True def restart(self): self.start(self.device) @property def is_pause(self): return self.cap.isOpened() and not self.timer.isActive()</description></item></channel></rss>