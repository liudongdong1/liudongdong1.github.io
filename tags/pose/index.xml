<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Pose - 标签 - DAY By DAY</title>
    <link>https://liudongdong1.github.io/tags/pose/</link>
    <description>Pose - 标签 - DAY By DAY</description>
    <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>3463264078@qq.cn (LiuDongdong)</managingEditor>
      <webMaster>3463264078@qq.cn (LiuDongdong)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Tue, 02 Nov 2021 10:30:29 &#43;0000</lastBuildDate><atom:link href="https://liudongdong1.github.io/tags/pose/" rel="self" type="application/rss+xml" /><item>
  <title>HumanPosePaper</title>
  <link>https://liudongdong1.github.io/humanposepaper/</link>
  <pubDate>Tue, 02 Nov 2021 10:30:29 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/humanposepaper/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.stocksnap.io/img-thumbs/280h/9YZ9JQIHRH.jpg" referrerpolicy="no-referrer">
      </div>Zhang S, Zhang Y, Bogo F, et al. Learning motion priors for 4d human body capture in 3d scenes[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021: 11343-11353. [pdf] [code] Paper: LEMO Summary a marker-based motion smoothness prior and a contact-aware motion infillter wihcih is fine-tuned per-instance in a self-supervised fashion. a novel marker-based moiton smoothness prior that encodes the whole-body motion in a learned latent space, which can]]></description>
</item>
<item>
  <title>Vicon动捕</title>
  <link>https://liudongdong1.github.io/vicon%E5%8A%A8%E6%8D%95/</link>
  <pubDate>Mon, 13 Sep 2021 10:30:29 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/vicon%E5%8A%A8%E6%8D%95/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.stocksnap.io/img-thumbs/280h/8THWMOJNHY.jpg" referrerpolicy="no-referrer">
      </div>Vicon 光学动作捕捉系统系统是一组网络连接的 Vicon 运动捕捉摄像机和其它设备以提 供实时光学数据，这些数据可以被应用于实时在线或者离线的运动捕捉、分析，应]]></description>
</item>
<item>
  <title>HumanPoseProject</title>
  <link>https://liudongdong1.github.io/humanposeproject/</link>
  <pubDate>Fri, 13 Aug 2021 10:30:29 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/humanposeproject/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://images.unsplash.com/photo-1624788998865-126ccbb55e40?ixid=MnwxMjA3fDB8MHx0b3BpYy1mZWVkfDJ8NnNNVmpUTFNrZVF8fGVufDB8fHx8&amp;ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=500&amp;q=60" referrerpolicy="no-referrer">
      </div>1. residual_pose Hourglass model for multi-person 2D pose estimation from depth images. Our regressor NN architecture for 3D human pose estimation. 3D pose prior for recovering from 2D missed detections. Tranined models for 2D and 3D pose estimation. Code for obtaining 2D and 3D pose from a depth image. 11 months ago. star12 2. depth_human_synthesis We have created a collection of 24 human characters, 12 men and 12 women, with]]></description>
</item>
<item>
  <title>3DPoseRelative</title>
  <link>https://liudongdong1.github.io/3dposerelative/</link>
  <pubDate>Sun, 06 Jun 2021 09:33:10 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/3dposerelative/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.stocksnap.io/img-thumbs/280h/flower-background_1CPDPEZCIM.jpg" referrerpolicy="no-referrer">
      </div>1. Mediapipe 3D detection 使用移动增强现实(AR)会话数据(session data)，开发了新的数据pipeline。大部分智能手机现在都具备了增强现实的功能]]></description>
</item>
<item>
  <title>IMU Trajectory</title>
  <link>https://liudongdong1.github.io/imu-trajectory/</link>
  <pubDate>Thu, 25 Jun 2020 10:09:10 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/imu-trajectory/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/armature-4103639__340.webp" referrerpolicy="no-referrer">
      </div>Advantages of IMU : (1) energy-efficient, capable of running 24h a day without draining a battery; (2) works any where even inside a bag or a pocket(get device acc); Disadvantage: small sensor errors or biases explode quickly in the double integration process. In Augmented Reality applications(eg., apple ARKit, Google ARCore, Microsoft HoloLens), IMU augments Slam by resolving scale ambiguities and providing motion cues in the absence of visual features. UAVs,]]></description>
</item>
</channel>
</rss>
