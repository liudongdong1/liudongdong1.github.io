<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Model - 标签 - DAY By DAY</title>
    <link>https://liudongdong1.github.io/tags/model/</link>
    <description>Model - 标签 - DAY By DAY</description>
    <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>3463264078@qq.cn (LiuDongdong)</managingEditor>
      <webMaster>3463264078@qq.cn (LiuDongdong)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sat, 20 Nov 2021 22:45:45 &#43;0000</lastBuildDate><atom:link href="https://liudongdong1.github.io/tags/model/" rel="self" type="application/rss+xml" /><item>
  <title>CircleGan</title>
  <link>https://liudongdong1.github.io/circlegan/</link>
  <pubDate>Sat, 20 Nov 2021 22:45:45 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/circlegan/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.stocksnap.io/img-thumbs/280h/TDAU1ERCD4.jpg" referrerpolicy="no-referrer">
      </div>Zhu, Jun-Yan, et al. &ldquo;Unpaired image-to-image translation using cycle-consistent adversarial networks.&rdquo; Proceedings of the IEEE international conference on computer vision. 2017. cite 10600 [pdf] [code] Paper: CircleGAN Summary present a method that can learn to do the same, capturing special characteristics of one image collection and figureing out how these characteristics could be translated into the other image collection. Research Objective Application Area: Collection style transfer: learns to mimic the]]></description>
</item>
<item>
  <title>Pytorch3D</title>
  <link>https://liudongdong1.github.io/pytorch3d/</link>
  <pubDate>Mon, 14 Jun 2021 21:59:57 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/pytorch3d/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.pixabay.com/photo/2021/03/19/04/49/kid-6106557__340.jpg" referrerpolicy="no-referrer">
      </div>Chaton, Thomas, et al. &ldquo;Torch-Points3D: A Modular Multi-Task Frameworkfor Reproducible Deep Learning on 3D Point Clouds.&rdquo; arXiv preprint arXiv:2010.04642 (2020). [pdf] [code]]]></description>
</item>
<item>
  <title>PytorchGNN</title>
  <link>https://liudongdong1.github.io/pytorchgnn/</link>
  <pubDate>Mon, 14 Jun 2021 21:59:57 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/pytorchgnn/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.pixabay.com/photo/2021/05/19/14/31/dandelion-6266230__340.jpg" referrerpolicy="no-referrer">
      </div>论文对GNN模型分类如下： 图卷积网络(Graph convolutional networks)和图注意力网络(graph attention networks)，因为涉及到传播步骤(pr]]></description>
</item>
<item>
  <title>GraphPaper</title>
  <link>https://liudongdong1.github.io/graphpaper/</link>
  <pubDate>Tue, 06 Apr 2021 17:23:49 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/graphpaper/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.pixabay.com/photo/2021/06/15/03/35/chrysanthemum-6337374__340.jpg" referrerpolicy="no-referrer">
      </div>1. DDGK Al-Rfou R, Perozzi B, Zelle D. Ddgk: Learning graph representations for deep divergence graph kernels[C]//The World Wide Web Conference. 2019: 37-48. end-to-end supervised graph classification: learn a intermediate representation of an entire graph as precondition in order to solve the classification task; graph representation learning: feature engineering: graph&rsquo;s clustering coefficient, its motif distribution,its spectral decomposition , limited to composing only known graph encode algorithmic heuristics from graph isomorphism]]></description>
</item>
<item>
  <title>layerIntroduce</title>
  <link>https://liudongdong1.github.io/layerintroduce/</link>
  <pubDate>Tue, 06 Apr 2021 17:23:49 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/layerintroduce/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.pixabay.com/photo/2016/11/23/14/37/apple-1853259__340.jpg" referrerpolicy="no-referrer">
      </div>1. 卷积层 卷积运算：卷积核在输入图像上滑动，相应位置上进行相加。卷积过程类似于用一个模板去图像上寻找与他相似的区域，与卷积核模式越相似，激活值]]></description>
</item>
<item>
  <title>softmax</title>
  <link>https://liudongdong1.github.io/softmax/</link>
  <pubDate>Wed, 24 Mar 2021 21:31:56 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/softmax/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://gitee.com/github-25970295/blogImage/raw/master/img/20210501113610.png" referrerpolicy="no-referrer">
      </div>1. softmax函数 softmax用于多分类过程中，它将多个神经元的输出，映射到（0,1）区间内。假设我们有一个数组，V，Vi表示V中的第i]]></description>
</item>
<item>
  <title>Ghost</title>
  <link>https://liudongdong1.github.io/ghostnetpaper/</link>
  <pubDate>Tue, 26 Jan 2021 23:00:04 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/ghostnetpaper/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.pixabay.com/photo/2015/07/17/22/43/student-849824__340.jpg" referrerpolicy="no-referrer">
      </div> Han, Kai, et al. &ldquo;Ghostnet: More features from cheap operations.&rdquo; Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.
Paper: Ghost Summary apply a series of linear transformations with cheap cost to generate many ghost feature maps that could fully reveal information undelying intrinsic features; source code:https://github.com/huawei-noah/ghostnet ]]></description>
</item>
<item>
  <title>CrossDomain</title>
  <link>https://liudongdong1.github.io/crossdomain/</link>
  <pubDate>Thu, 03 Dec 2020 18:45:45 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/crossdomain/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.stocksnap.io/img-thumbs/280h/fall-leaf_VUPSHHDWZB.jpg" referrerpolicy="no-referrer">
      </div>UDA refers to a set of transfer learning methods for transferring knowledge learned from th source domain to the target domain under the assumption of domain discrepancy. Domain adaptation generally assumes that the two domains have the same conditional distributions, but different marginal distributions. 1. Resource Paper List: https://github.com/zhaoxin94/awesome-domain-adaptation Project List: https://github.com/jindongwang/transferlearning Na J, Jung H, Chang H J, et al. FixBi: Bridging Domain Spaces for Unsupervised Domain Adaptation[C] //Proceedings]]></description>
</item>
<item>
  <title>MetaLearning</title>
  <link>https://liudongdong1.github.io/metalearning/</link>
  <pubDate>Thu, 03 Dec 2020 18:45:45 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/metalearning/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.pixabay.com/photo/2016/01/19/16/49/laptop-1149412__340.jpg" referrerpolicy="no-referrer">
      </div>Few-shot classification aims to learn a classifier to recognize unseen classes during training with limited labeled examples. meta-learning paradigm: transferable knowledge is extracted and propagated from a collection of tasks to prevent over fitting and improve generalization. model initialization based methods; metric learning methods hallucination based methods directly predicting the weighs of the classifiers for novel classes Relative Work
Initialization based methods: good model initialization: to learn to fine-tune, learn with limited number of labeled examples and small number of gradient update steps; learning an optimizer: LSTM-based meta-learner for replacing the stochastic gradient decent optimizer.]]></description>
</item>
<item>
  <title>AllenNLPIntroduce</title>
  <link>https://liudongdong1.github.io/allennlpintroduce/</link>
  <pubDate>Tue, 20 Oct 2020 07:56:09 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/allennlpintroduce/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://gitee.com/github-25970295/blogImage/raw/master/img/20210501113113.png" referrerpolicy="no-referrer">
      </div>you can write your own script to construct the dataset reader and model and run the training loop, or you can write a configuration file and use the allennlp train command 1. Text Classification Spam filtering Detect and filter spam emails Email Spam / Not spam Sentiment analysis Detect the polarity of text Tweet, review Positive / Negative Topic detection Detect the topic of text News article, blog post Business]]></description>
</item>
</channel>
</rss>
