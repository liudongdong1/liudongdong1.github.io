<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Kinect - 标签 - DAY By DAY</title>
    <link>https://liudongdong1.github.io/tags/kinect/</link>
    <description>Kinect - 标签 - DAY By DAY</description>
    <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>3463264078@qq.cn (LiuDongdong)</managingEditor>
      <webMaster>3463264078@qq.cn (LiuDongdong)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Tue, 03 Aug 2021 11:00:04 &#43;0000</lastBuildDate><atom:link href="https://liudongdong1.github.io/tags/kinect/" rel="self" type="application/rss+xml" /><item>
  <title>红外_paper</title>
  <link>https://liudongdong1.github.io/%E7%BA%A2%E5%A4%96_paper/</link>
  <pubDate>Tue, 03 Aug 2021 11:00:04 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/%E7%BA%A2%E5%A4%96_paper/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.stocksnap.io/img-thumbs/280h/flowers-garden_5ZAZEO70PJ.jpg" referrerpolicy="no-referrer">
      </div>Chen, Tuochao, et al. &ldquo;NeckFace: Continuously Tracking Full Facial Expressions on Neck-mounted Wearables.&rdquo; Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 5.2 (2021): 1-31. Paper: NeckFace Summary AdminLTE：github上的一个开源项目，基于Boostrap3的后台管理]]></description>
</item>
<item>
  <title>KinetRelativeProject</title>
  <link>https://liudongdong1.github.io/kinectrelativeproject/</link>
  <pubDate>Wed, 28 Apr 2021 16:00:04 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/kinectrelativeproject/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210501111446.png" referrerpolicy="no-referrer">
      </div>1. Azure-Kinect-Sensor-SDK Azure Kinect SDK is a cross platform (Linux and Windows) user mode SDK to read data from your Azure Kinect device. Depth camera access RGB camera access and control (e.g. exposure and white balance) Motion sensor (gyroscope and accelerometer) access Synchronized Depth-RGB camera streaming with configurable delay between cameras External device synchronization control with configurable delay offset between devices Camera frame meta-data access for image resolution, timestamp and]]></description>
</item>
<item>
  <title>kinect2project</title>
  <link>https://liudongdong1.github.io/kinect2project/</link>
  <pubDate>Tue, 30 Mar 2021 16:00:04 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/kinect2project/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.stocksnap.io/img-thumbs/280h/DTL0R2W7UJ.jpg" referrerpolicy="no-referrer">
      </div>In the depth image, the value of a pixels relates to the distance from the camera as measured by time-of-flight. For the active infrared image, the value of a pixel is determined by the amount of infrared light reflected back to the camera. The Kinect uses the reflected IR to calculate time of flight but then also makes it available as an IR image. 1. OpenDepthSensor kine]]></description>
</item>
<item>
  <title>kinect2Relative</title>
  <link>https://liudongdong1.github.io/kinect2relative/</link>
  <pubDate>Fri, 19 Mar 2021 16:00:04 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/kinect2relative/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://cdn.pixabay.com/photo/2016/02/19/10/00/laptop-1209008__340.jpg" referrerpolicy="no-referrer">
      </div>红外图像，像素值由反射回相机的红外光量确定。 深度图像也叫距离影像，是指将从图像采集器到场景中各点的距离（深度）值作为像素值的图像。获取方法有]]></description>
</item>
</channel>
</rss>
