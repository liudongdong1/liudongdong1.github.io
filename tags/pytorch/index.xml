<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Pytorch - 标签 - DAY By DAY</title><link>liudongdong1.github.io/tags/pytorch/</link><description>Pytorch - 标签 - DAY By DAY</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>3463264078@qq.cn (LiuDongdong)</managingEditor><webMaster>3463264078@qq.cn (LiuDongdong)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Mon, 14 Jun 2021 21:59:57 +0000</lastBuildDate><atom:link href="liudongdong1.github.io/tags/pytorch/" rel="self" type="application/rss+xml"/><item><title>Pytorch3D</title><link>liudongdong1.github.io/pytorch3d/</link><pubDate>Mon, 14 Jun 2021 21:59:57 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/pytorch3d/</guid><description><![CDATA[<div class="featured-image">
        <img src="https://cdn.pixabay.com/photo/2021/03/19/04/49/kid-6106557__340.jpg" referrerpolicy="no-referrer">
      </div>Chaton, Thomas, et al. &ldquo;Torch-Points3D: A Modular Multi-Task Frameworkfor Reproducible Deep Learning on 3D Point Clouds.&rdquo; arXiv preprint arXiv:2010.04642 (2020). [pdf] [code]]]></description></item><item><title>PytorchGNN</title><link>liudongdong1.github.io/pytorchgnn/</link><pubDate>Mon, 14 Jun 2021 21:59:57 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/pytorchgnn/</guid><description>&lt;div class="featured-image">
&lt;img src="https://cdn.pixabay.com/photo/2021/05/19/14/31/dandelion-6266230__340.jpg" referrerpolicy="no-referrer">
&lt;/div>论文对GNN模型分类如下： 图卷积网络(Graph convolutional networks)和图注意力网络(graph attention networks)，因为涉及到传播步骤(pr</description></item><item><title>AndroidPytorch</title><link>liudongdong1.github.io/androidpytorch/</link><pubDate>Fri, 21 May 2021 22:02:27 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/androidpytorch/</guid><description><![CDATA[<div class="featured-image">
        <img src="https://cdn.pixabay.com/photo/2021/11/19/05/12/maple-6808150__340.jpg" referrerpolicy="no-referrer">
      </div>1. 模型转化 import torch import torchvision from torch.utils.mobile_optimizer import optimize_for_mobile model = torchvision.models.mobilenet_v3_small(pretrained=True) #model.load_state_dict(torch.load(model_pth)) # 加载参数 model.eval() example = torch.rand(1, 3, 224, 224) traced_script_module = torch.jit.trace(model, example) # 模型转化 optimized_traced_model = optimize_for_mobile(traced_script_module) optimized_traced_model.save(&#34;model.pt&#34;) # 保存文件 optimized_traced_model._save_for_lite_interpreter(&#34;app/src/main/assets/model.pt&#34;) 2. Gradle 依赖 implementation &#39;org.pytorch:pytorch_android_lite:1.9.0&#39; implementation &#39;org.pytorch:pytorch_android_torchvision:1.9.0&#39; 3. 封装函数 public class MainActivity extends AppCompatActivity { @Override protected void]]></description></item><item><title>GraphPaper</title><link>liudongdong1.github.io/graphpaper/</link><pubDate>Tue, 06 Apr 2021 17:23:49 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/graphpaper/</guid><description><![CDATA[<div class="featured-image">
        <img src="https://cdn.pixabay.com/photo/2021/06/15/03/35/chrysanthemum-6337374__340.jpg" referrerpolicy="no-referrer">
      </div>1. DDGK Al-Rfou R, Perozzi B, Zelle D. Ddgk: Learning graph representations for deep divergence graph kernels[C]//The World Wide Web Conference. 2019: 37-48. end-to-end supervised graph classification: learn a intermediate representation of an entire graph as precondition in order to solve the classification task; graph representation learning: feature engineering: graph&rsquo;s clustering coefficient, its motif distribution,its spectral decomposition , limited to composing only known graph encode algorithmic heuristics from graph isomorphism]]></description></item><item><title>CharDataSimulation</title><link>liudongdong1.github.io/chardatasimulation/</link><pubDate>Sat, 23 Jan 2021 08:56:09 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/chardatasimulation/</guid><description>&lt;div class="featured-image">
&lt;img src="https://gitee.com/github-25970295/blogImage/raw/master/img/20210501131735.png" referrerpolicy="no-referrer">
&lt;/div>1. 图片生成 利用电脑中字体文件生成a-z 字符图片数据。 # 测试文件 from PIL import Image, ImageDraw, ImageFont, ImageFilter import random import matplotlib.pyplot as plt import numpy as np import os # 随机字母: def rndChar(): return chr(random.randint(65, 90)) # 随机颜色1: def rndColor():</description></item><item><title>Torchtext</title><link>liudongdong1.github.io/torchtext_vocab/</link><pubDate>Tue, 27 Oct 2020 08:56:09 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/torchtext_vocab/</guid><description>&lt;div class="featured-image">
&lt;img src="https://gitee.com/github-25970295/blogImage/raw/master/img/32.jpeg" referrerpolicy="no-referrer">
&lt;/div>torchtext.data.Example : 用来表示一个样本，数据+标签 torchtext.vocab.Vocab: 词汇表相关 torchtext.data.Datasets: 数据集类，getitem 返回 Example实例 torchtext.data.Field : 用来定义字段的处理方法（文本字段，标签字段）</description></item><item><title>PytorchSegmentCode</title><link>liudongdong1.github.io/pytorchsegmentcode/</link><pubDate>Tue, 20 Oct 2020 08:56:09 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/pytorchsegmentcode/</guid><description><![CDATA[<div class="featured-image">
        <img src="https://gitee.com/github-25970295/blogImage/raw/master/img/tourists-in-sea.jpg" referrerpolicy="no-referrer">
      </div>0. 基础配置 0.1. 设置随机种子 def set_seeds(seed, cuda): &#34;&#34;&#34; Set Numpy and PyTorch seeds. &#34;&#34;&#34; np.random.seed(seed) torch.manual_seed(seed) if cuda: torch.cuda.manual_seed_all(seed) print (&#34;==&gt; Set NumPy and PyTorch seeds.&#34;) 0.2. 张量处理与转化 tensor.type() # Data type tensor.size() # Shape of the tensor. It is a subclass of Python tuple tensor.dim() # Number of dimensions. # Type convertions. tensor = tensor.cuda()]]></description></item><item><title>TorchVision_Transforms</title><link>liudongdong1.github.io/torchvision_transforms/</link><pubDate>Sat, 17 Oct 2020 15:56:09 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/torchvision_transforms/</guid><description><![CDATA[<div class="featured-image">
        <img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201017144214641.png" referrerpolicy="no-referrer">
      </div>Offering transformation pipeline;
transforms.Compose([ transforms.CenterCrop(10), transforms.ToTensor(), ]) 1. PIL Image Op CenterCrop(size) # Crops the given PIL Image at the center. ColorJitter(brightness=0, contrast=0, saturation=0, hue=0)#Randomly change the brightness, contrast and saturation of an image. FiveCrop(size) #Crop the given PIL Image into four corners and the central crop Grayscale(num_output_channels=1) # convert image to grayscale RandomAffine(degrees, translate=None, scale=None, shear=None, resample=False, fillcolor=0)#Random affine transformation of the image keeping center invariant RandomCrop(size, padding=None, pad_if_needed=False, fill=0, padding_mode=&#39;constant&#39;)#Crop the given PIL Image at a random location.]]></description></item><item><title>TorchVision_DataLoad</title><link>liudongdong1.github.io/torchvision_dataload/</link><pubDate>Sat, 17 Oct 2020 08:56:09 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/torchvision_dataload/</guid><description>&lt;div class="featured-image">
&lt;img src="https://gitee.com/github-25970295/blogImage/raw/master/img/39.jpeg" referrerpolicy="no-referrer">
&lt;/div>All datasets are subclasses of torch.utils.data.Dataset i.e, they have __getitem__ and __len__ methods implemented. Hence, they can all be passed to a torch.utils.data.DataLoader which can load multiple samples parallelly using torch.multiprocessing workers. Dataloader： offer a way to parallelly load data, batch load, and offer shuffle policy. Dataset: the dataset entry, offer getitem function., Transformer function 在这里执行</description></item><item><title>TorchVision_Models</title><link>liudongdong1.github.io/torchvision_models/</link><pubDate>Fri, 16 Oct 2020 08:56:09 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/torchvision_models/</guid><description>&lt;div class="featured-image">
&lt;img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201129141709288.png" referrerpolicy="no-referrer">
&lt;/div>Torchvision.Models contain different models like: image classification, pixelwise semantic segmentation, object detection, instance segmentation, person keypoint detection and video classification. 1. Classification Models AlexNet VGGResNetSqueezeNetDenseNetInception v3GoogLeNetShuffleNet v2MobileNet v2ResNeXtWide ResNetMNASNet 1.1. Random weights import torchvision.models as models resnet18 = models.resnet18() alexnet = models.alexnet() vgg16 = models.vgg16() squeezenet = models.squeezenet1_0() densenet = models.densenet161() inception = models.inception_v3() googlenet = models.googlenet() shufflenet = models.shufflenet_v2_x1_0() mobilenet = models.mobilenet_v2() resnext50_32x4d = models.resnext50_32x4d() wide_resnet50_2 = models.wide_resnet50_2() mnasnet</description></item></channel></rss>