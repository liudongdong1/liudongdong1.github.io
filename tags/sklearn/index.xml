<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>sklearn - 标签 - DAY By DAY</title>
    <link>https://liudongdong1.github.io/tags/sklearn/</link>
    <description>sklearn - 标签 - DAY By DAY</description>
    <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>3463264078@qq.cn (LiuDongdong)</managingEditor>
      <webMaster>3463264078@qq.cn (LiuDongdong)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sat, 01 May 2021 21:38:11 &#43;0000</lastBuildDate><atom:link href="https://liudongdong1.github.io/tags/sklearn/" rel="self" type="application/rss+xml" /><item>
  <title>Classify_face</title>
  <link>https://liudongdong1.github.io/classify_face/</link>
  <pubDate>Sat, 01 May 2021 21:38:11 &#43;0000</pubDate>
  <author>LiuDongdong</author>
  <guid>https://liudongdong1.github.io/classify_face/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210522212703.png" referrerpolicy="no-referrer">
      </div>from time import time import logging import matplotlib.pyplot as plt from sklearn.model_selection import train_test_split from sklearn.model_selection import GridSearchCV from sklearn.datasets import fetch_lfw_people from sklearn.metrics import classification_report from sklearn.metrics import confusion_matrix from sklearn.decomposition import PCA from sklearn.svm import SVC print(__doc__) # Display progress logs on stdout logging.basicConfig(level=logging.INFO, format=&#39;%(asctime)s %(message)s&#39;) # ############################################################################# # Download the data, if not already on disk and load it as numpy arrays lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4) # introspect the images arrays to find the shapes (for plotting) n_samples, h, w = lfw_people.]]></description>
</item>
<item>
  <title>Classify_digit</title>
  <link>https://liudongdong1.github.io/classify_digit/</link>
  <pubDate>Wed, 14 Apr 2021 21:38:11 &#43;0000</pubDate>
  <author>LiuDongdong</author>
  <guid>https://liudongdong1.github.io/classify_digit/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210522212643.png" referrerpolicy="no-referrer">
      </div>To apply a classifier on this data, we need to flatten the images, turning each 2-D array of grayscale values from shape (8, 8) into shape (64,). Subsequently, the entire dataset will be of shape (n_samples, n_features), where n_samples is the number of images and n_features is the total number of pixels in each image. label没有用onehot编]]></description>
</item>
<item>
  <title>SkLearn Evaluation</title>
  <link>https://liudongdong1.github.io/sklearn-evaluation/</link>
  <pubDate>Wed, 14 Apr 2021 21:38:11 &#43;0000</pubDate>
  <author>LiuDongdong</author>
  <guid>https://liudongdong1.github.io/sklearn-evaluation/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210501113504.png" referrerpolicy="no-referrer">
      </div>1. Cross-validation cross_val_score from sklearn.model_selection import cross_val_score clf = svm.SVC(kernel=&#39;linear&#39;, C=1, random_state=42) scores = cross_val_score(clf, X, y, cv=5，scoring=&#39;f1_macro&#39;) print(&#34;%0.2f accuracy with a standard deviation of %0.2f&#34; % (scores.mean(), scores.std())) from sklearn import preprocessing X_train, X_test, y_train, y_test = train_test_split(]]></description>
</item>
<item>
  <title>SkLearn Record</title>
  <link>https://liudongdong1.github.io/sklearn-record/</link>
  <pubDate>Wed, 14 Apr 2021 21:38:11 &#43;0000</pubDate>
  <author>LiuDongdong</author>
  <guid>https://liudongdong1.github.io/sklearn-record/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210414084511.png" referrerpolicy="no-referrer">
      </div>Supervised learning 1.1. Linear Models 1.2. Linear and Quadratic Discriminant Analysis 1.3. Kernel ridge regression 1.4. Support Vector Machines 1.5. Stochastic Gradient Descent 1.6. Nearest Neighbors 1.7. Gaussian Processes 1.8. Cross decomposition 1.9. Naive Bayes 1.10. Decision Trees 1.11. Ensemble methods 1.12. Multiclass and multioutput algorithms 1.13. Feature selection 1.14. Semi-supervised learning 1.15. Isotonic regression 1.16. Probability calibration 1.17. Neural network models (supervised) Unsupervised learning 2.1. Gaussian mixture models 2.2.]]></description>
</item>
<item>
  <title>SkLearnVisualization</title>
  <link>https://liudongdong1.github.io/sklearnvisualization/</link>
  <pubDate>Wed, 14 Apr 2021 21:38:11 &#43;0000</pubDate>
  <author>LiuDongdong</author>
  <guid>https://liudongdong1.github.io/sklearnvisualization/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210522212757.png" referrerpolicy="no-referrer">
      </div>1. cross-validation（ROC) print(__doc__) import numpy as np import matplotlib.pyplot as plt from sklearn import svm, datasets from sklearn.metrics import auc from sklearn.metrics import plot_roc_curve from sklearn.model_selection import StratifiedKFold # ############################################################################# # Data IO and generation # Import some data to play with iris = datasets.load_iris() X = iris.data y = iris.target X, y = X[y != 2], y[y != 2] n_samples, n_features = X.shape # Add noisy features random_state = np.]]></description>
</item>
<item>
  <title>SkLearn Optimize</title>
  <link>https://liudongdong1.github.io/sklearn-optimize/</link>
  <pubDate>Wed, 14 Apr 2021 08:38:11 &#43;0000</pubDate>
  <author>LiuDongdong</author>
  <guid>https://liudongdong1.github.io/sklearn-optimize/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210501113542.png" referrerpolicy="no-referrer">
      </div>使用scikit-learn时提高速度的三种主要方法是：使用joblib和Ray并行化或分发培训，使用不同的超参数优化技术（网格搜索，随机搜]]></description>
</item>
<item>
  <title>DataPreprocessing</title>
  <link>https://liudongdong1.github.io/datapreprocessing/</link>
  <pubDate>Wed, 24 Feb 2021 08:56:09 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/datapreprocessing/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210522212626.png" referrerpolicy="no-referrer">
      </div>0. Preprocessing preprocessing.Binarizer(*[, threshold, copy]) Binarize data (set feature values to 0 or 1) according to a threshold. preprocessing.FunctionTransformer([func, …]) Constructs a transformer from an arbitrary callable. preprocessing.KBinsDiscretizer([n_bins, …]) Bin continuous data into intervals. preprocessing.KernelCenterer() Center a kernel matrix. preprocessing.LabelBinarizer(*[, neg_label, …]) Binarize labels in a one-vs-all fashion. preprocessing.LabelEncoder() Encode target labels with value between 0 and n_classes-1. preprocessing.MultiLabelBinarizer(*[, …]) Transform between]]></description>
</item>
<item>
  <title>SkLearnDataFlow</title>
  <link>https://liudongdong1.github.io/sklearndataflow/</link>
  <pubDate>Wed, 24 Feb 2021 08:56:09 &#43;0000</pubDate>
  <author>liudongdong1</author>
  <guid>https://liudongdong1.github.io/sklearndataflow/</guid>
  <description><![CDATA[<div class="featured-image">
        <img src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210522212739.png" referrerpolicy="no-referrer">
      </div>Scikit-learn is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection and evaluation, and many other utilities. 1. Fit&amp;Predict The samples matrix (or design matrix) (https://scikit-learn.org/stable/glossary.html#term-X). The size of X is typically (n_samples, n_features), which means that samples are represented as rows and features are represented as columns. The target values y which are real]]></description>
</item>
</channel>
</rss>
