<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>CV - 标签 - DAY By DAY</title><link>liudongdong1.github.io/tags/cv/</link><description>CV - 标签 - DAY By DAY</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>3463264078@qq.cn (LiuDongdong)</managingEditor><webMaster>3463264078@qq.cn (LiuDongdong)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sat, 23 Oct 2021 21:45:45 +0000</lastBuildDate><atom:link href="liudongdong1.github.io/tags/cv/" rel="self" type="application/rss+xml"/><item><title>Frame_BasicSR</title><link>liudongdong1.github.io/frame_basicsr/</link><pubDate>Sat, 23 Oct 2021 21:45:45 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/frame_basicsr/</guid><description>&lt;div class="featured-image">
&lt;img src="https://cdn.stocksnap.io/img-thumbs/280h/5U2FV0UNXF.jpg" referrerpolicy="no-referrer">
&lt;/div>BasicSR (Basic Super Restoration) 是一个基于 PyTorch 的开源图像视频复原工具箱, 比如 超分辨率, 去噪, 去模糊, 去 JPEG 压缩噪声等. Real-ESRGAN: 通用图像复原的实用算法 GFPGAN: 真实场景人脸复原的实用算</description></item><item><title>Rendering</title><link>liudongdong1.github.io/rendering/</link><pubDate>Mon, 11 Oct 2021 21:45:45 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/rendering/</guid><description>&lt;div class="featured-image">
&lt;img src="https://cdn.stocksnap.io/img-thumbs/280h/IQ2LORUXQB.jpg" referrerpolicy="no-referrer">
&lt;/div>Rückert D, Franke L, Stamminger M. ADOP: Approximate Differentiable One-Pixel Point Rendering[J]. arXiv preprint arXiv:2110.06635, 2021. pdf code star 538
Paper: ADOP Summary present a novel point-based, differentiable neural rendering pipeline for scene refinement and novel view synthesis. the point cloud rendering is performed by a differentiable renderer using multi-resolution one-pixel point rasterization. after rendering , the neural image pyramid is passed through a deep neural network for shading calculations and hole-filling.</description></item><item><title>SuperResolution</title><link>liudongdong1.github.io/superresolution/</link><pubDate>Thu, 23 Sep 2021 21:45:45 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/superresolution/</guid><description>&lt;div class="featured-image">
&lt;img src="https://cdn.stocksnap.io/img-thumbs/280h/QSCRVBUU2G.jpg" referrerpolicy="no-referrer">
&lt;/div>Tian Y, Zhang Y, Fu Y, et al. Tdan: Temporally-deformable alignment network for video super-resolution[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 3360-3369. Paper: Tdan Summary propose a temporally-deformable alignment network(TDAN) to adaptively align the reference frame and each supporting frame a the feature level without computing optical flow. use features from both the reference frame and each supporting frame to dynamically predict offsets of sampling</description></item><item><title>Vicon动捕</title><link>liudongdong1.github.io/vicon%E5%8A%A8%E6%8D%95/</link><pubDate>Mon, 13 Sep 2021 10:30:29 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/vicon%E5%8A%A8%E6%8D%95/</guid><description>&lt;div class="featured-image">
&lt;img src="https://cdn.stocksnap.io/img-thumbs/280h/8THWMOJNHY.jpg" referrerpolicy="no-referrer">
&lt;/div>Vicon 光学动作捕捉系统系统是一组网络连接的 Vicon 运动捕捉摄像机和其它设备以提 供实时光学数据，这些数据可以被应用于实时在线或者离线的运动捕捉、分析，应</description></item><item><title>HumanPoseProject</title><link>liudongdong1.github.io/humanposeproject/</link><pubDate>Fri, 13 Aug 2021 10:30:29 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/humanposeproject/</guid><description><![CDATA[<div class="featured-image">
        <img src="https://images.unsplash.com/photo-1624788998865-126ccbb55e40?ixid=MnwxMjA3fDB8MHx0b3BpYy1mZWVkfDJ8NnNNVmpUTFNrZVF8fGVufDB8fHx8&amp;ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=500&amp;q=60" referrerpolicy="no-referrer">
      </div>1. residual_pose Hourglass model for multi-person 2D pose estimation from depth images. Our regressor NN architecture for 3D human pose estimation. 3D pose prior for recovering from 2D missed detections. Tranined models for 2D and 3D pose estimation. Code for obtaining 2D and 3D pose from a depth image. 11 months ago. star12 2. depth_human_synthesis We have created a collection of 24 human characters, 12 men and 12 women, with]]></description></item><item><title>YoloRelative</title><link>liudongdong1.github.io/yolorelative/</link><pubDate>Mon, 26 Jul 2021 18:04:14 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/yolorelative/</guid><description>&lt;div class="featured-image">
&lt;img src="https://cdn.stocksnap.io/img-thumbs/280h/bird-egret_54R1KQELFW.jpg" referrerpolicy="no-referrer">
&lt;/div>1 Yolox相关基础知识点 1.1 Yolox的论文及代码 Yolox论文名：《YOLOX: Exceeding YOLO Series in 2021》 Yolox论文地址：https://ar</description></item><item><title>LightestDetection</title><link>liudongdong1.github.io/lightestdetection/</link><pubDate>Sun, 13 Jun 2021 16:00:04 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/lightestdetection/</guid><description><![CDATA[<div class="featured-image">
        <img src="https://cdn.pixabay.com/photo/2016/05/16/15/40/texture-1395982__340.jpg" referrerpolicy="no-referrer">
      </div>minMaxLoc寻找矩阵(一维数组当作向量,用Mat定义) 中最小值和最大值的位置. 1. BrightArea import numpy as np import argparse import cv2 # construct the argument parse and parse the arguments ap = argparse.ArgumentParser() ap.add_argument(&#34;-i&#34;, &#34;--image&#34;, help = &#34;path to]]></description></item><item><title>3DPoseRelative</title><link>liudongdong1.github.io/3dposerelative/</link><pubDate>Sun, 06 Jun 2021 09:33:10 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/3dposerelative/</guid><description>&lt;div class="featured-image">
&lt;img src="https://cdn.stocksnap.io/img-thumbs/280h/flower-background_1CPDPEZCIM.jpg" referrerpolicy="no-referrer">
&lt;/div>1. Mediapipe 3D detection 使用移动增强现实(AR)会话数据(session data)，开发了新的数据pipeline。大部分智能手机现在都具备了增强现实的功能</description></item><item><title>CharDataSimulation</title><link>liudongdong1.github.io/chardatasimulation/</link><pubDate>Sat, 23 Jan 2021 08:56:09 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/chardatasimulation/</guid><description>&lt;div class="featured-image">
&lt;img src="https://gitee.com/github-25970295/blogImage/raw/master/img/20210501131735.png" referrerpolicy="no-referrer">
&lt;/div>1. 图片生成 利用电脑中字体文件生成a-z 字符图片数据。 # 测试文件 from PIL import Image, ImageDraw, ImageFont, ImageFilter import random import matplotlib.pyplot as plt import numpy as np import os # 随机字母: def rndChar(): return chr(random.randint(65, 90)) # 随机颜色1: def rndColor():</description></item><item><title>PaperRecord</title><link>liudongdong1.github.io/paperrecord/</link><pubDate>Wed, 13 Jan 2021 10:30:29 +0000</pubDate><author>liudongdong1</author><guid>liudongdong1.github.io/paperrecord/</guid><description><![CDATA[<div class="featured-image">
        <img src="https://gitee.com/github-25970295/blogImage/raw/master/img/20210501133441.png" referrerpolicy="no-referrer">
      </div>clothes classification, attribute prediction, clothing item retrieval. clothes have large variations in style, texture, and cutting. clothing items are frequently subject to deformation and occlusion. clothes images often exhibit serous variations when they are taken under different scenarios. Liu, Ziwei, et al. &ldquo;Deepfashion: Powering robust clothes recognition and retrieval with rich annotations.&rdquo; Proceedings of the IEEE conference on computer vision and pattern recognition. 2016. Paper: Deepfashion Summary introduce DeepFashion, a]]></description></item></channel></rss>