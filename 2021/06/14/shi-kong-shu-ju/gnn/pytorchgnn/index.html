<!DOCTYPE HTML>
<html lang="en">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="PytorchGNN, AIOT,Space&amp;Temporal Sequence Analysis,SpringBoot,liudongdong1,cloud">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>PytorchGNN | DaybyDay</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="DaybyDay" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">DaybyDay</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>Tags</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">

      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/about">
          
          <i class="fas fa-user-circle" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>about</span>
        </a>
      </li>
      
      <li>
        <a href="/resume">
          
          <i class="fa fa-user-secret" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>resume</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>Friends</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/gallery" class="waves-effect waves-light">
      
      <i class="fas fa-camera" style="zoom: 0.6;"></i>
      
      <span>Galleries</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">DaybyDay</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			Tags
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-user-circle"></i>
			
			About
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/about " style="margin-left:75px">
				  
				   <i class="fa fas fa-user-circle" style="position: absolute;left:50px" ></i>
			      
		          <span>about</span>
                  </a>
                </li>
              
                <li>

                  <a href="/resume " style="margin-left:75px">
				  
				   <i class="fa fa fa-user-secret" style="position: absolute;left:50px" ></i>
			      
		          <span>resume</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			Friends
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/gallery" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-camera"></i>
			
			Galleries
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/liudongdong1" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/liudongdong1" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://cdn.pixabay.com/photo/2021/05/19/14/31/dandelion-6266230__340.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">PytorchGNN</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    .toc-fixed .toc-link::before{
        position: fixed!important;/*当toc的位置改为fixed时，.toc-link::before也要改为fixed*/
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/pytorch/">
                                <span class="chip bg-color">pytorch</span>
                            </a>
                        
                            <a href="/tags/GNN/">
                                <span class="chip bg-color">GNN</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E6%97%B6%E7%A9%BA%E6%95%B0%E6%8D%AE/" class="post-category">
                                时空数据
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2021-06-14
                </div>
                

                <!-- 
                    <i class="fa fa-pencil"></i> Author: liudongdong1
                  -->

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>Update Date:&nbsp;&nbsp;
                    2021-09-06
                </div>
                

                <!-- 
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>Word Count:&nbsp;&nbsp;
                    10.3k
                </div>
                 -->

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>Read Times:&nbsp;&nbsp;
                    59 Min
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>Read Count:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>论文对GNN模型分类如下：</p>
<ul>
<li><code>图卷积网络(Graph convolutional networks)</code>和<code>图注意力网络(graph attention networks)</code>，因为涉及到传播步骤(propagation step)。</li>
<li><code>图的空域网络(spatial-temporal networks)</code>，因为该模型通常用在动态图(dynamic graph)上。</li>
<li>图的自编码(auto-encoder)，因为该模型通常使用无监督学习(unsupervised)的方式。</li>
<li><code>图生成网络(generative networks)</code>，因为是生成式网络。</li>
</ul>
</blockquote>
<p>$$<br>\mathbf{h}<em>{v}=f\left(\mathbf{x}</em>{v}, \mathbf{x}<em>{c o[v]}, \mathbf{h}</em>{n e[v]}, \mathbf{x}_{n e[v]}\right)\label{eq:1}<br>$$</p>
<p>$$<br>\mathbf{o}<em>{v}=g\left(\mathbf{h}</em>{v}, \mathbf{x}_{v}\right)<br>$$</p>
<p>其中，$\mathbf{x}<em>{v}$，$\mathbf{x}</em>{c o[v]}$，$\mathbf{h}<em>{n e[v]}$，$\mathbf{x}</em>{n e[v]}$分别表示节点$v$的特征向量，节点$v$边的特征向量，节点$v$邻居节点的状态向量和节点$v$邻居节点特征向量。</p>
<p>假设将所有的状态向量，所有的输出向量，所有的特征向量叠加起来分别使用矩阵$\mathbf{H}$，$\mathbf{O}$，$ \mathbf{X}$和 $\mathbf{X}_{N}$来表示，那么可以得到更加紧凑的表示：<br>$$<br>\mathbf{H}=F(\mathbf{H}, \mathbf{X})\label{eq:3}<br>$$</p>
<p>$$<br>\mathbf{O}=G\left(\mathbf{H}, \mathbf{X}_{N}\right)<br>$$</p>
<p>其中，$F$表示全局转化函数(global transition function)，$G$表示全局输出函数(global output function)，分别是所有节点$f$和$g$的叠加形式</p>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/graph_type.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/propa_step.png" alt=""></p>
<p>不同类别模型的Aggregator计算方法和Updater计算方法如下表</p>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/gnn_table.png" alt=""></p>
<blockquote>
<p>Fey M, Lenssen J E. Fast graph representation learning with PyTorch Geometric[J]. arXiv preprint arXiv:1903.02428, 2019. [<a href="https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/1903.02428&amp;hl=zh-CN&amp;sa=T&amp;oi=gsb-gga&amp;ct=res&amp;cd=0&amp;d=8986807541681358909&amp;ei=M1LMYND3EsSsywSBmKRw&amp;scisig=AAGBfm2Raynm1DnoD_UxQ8L7vr2Nf8M3xQ" target="_blank" rel="noopener">pdf</a>]</p>
<p>Rozemberczki B, Scherer P, He Y, et al. PyTorch Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models[J]. arXiv preprint arXiv:2104.07788, 2021. <a href="https://github.com/benedekrozemberczki/pytorch_geometric_temporal" target="_blank" rel="noopener">geometrictemporal</a></p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/table.png" alt=""></p>
<h3 id="1-Structure"><a href="#1-Structure" class="headerlink" title="1. Structure"></a>1. Structure</h3><blockquote>
<p>provide easy to use data iterators which are parametrized with spatiotemporal data. These iterators can serve snapshots which are formed by a single graph or multiple graphs which are batched together with the block diagonal batching trick.</p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210617111513969.png" alt=""></p>
<ul>
<li><p><strong>Temporal signal iterators</strong></p>
<ul>
<li><code>StaticGraphTemporalSignal</code> - Is designed for <strong>temporal signals</strong> defined on a <strong>static</strong> graph.</li>
<li><code>DynamicGraphTemporalSignal</code> - Is designed for <strong>temporal signals</strong> defined on a <strong>dynamic</strong> graph.</li>
<li><code>DynamicGraphStaticSignal</code> - Is designed for <strong>static signals</strong> defined on a <strong>dynamic</strong> graph.</li>
</ul>
</li>
<li><p><strong>Temporal Data Snapshots</strong></p>
<ul>
<li><code>data.x</code>: Node feature matrix with shape <code>[num_nodes, num_node_features]</code></li>
<li><code>data.edge_index</code>: Graph connectivity in COO format with shape <code>[2, num_edges]</code> and type <code>torch.long</code></li>
<li><code>data.edge_attr</code>: Edge feature matrix with shape <code>[num_edges, num_edge_features]</code></li>
<li><code>data.y</code>: Target to train against (may have arbitrary shape), <em>e.g.</em>, node-level targets of shape <code>[num_nodes, *]</code> or graph-level targets of shape <code>[1, *]</code></li>
<li><code>data.pos</code>: Node position matrix with shape <code>[num_nodes, num_dimensions]</code></li>
</ul>
</li>
</ul>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210618090628020.png" alt=""></p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#创建了一个新的Data</span>
<span class="token comment" spellcheck="true">#方式一</span>
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>data <span class="token keyword">import</span> Data
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>long<span class="token punctuation">)</span>
edge_index <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                          <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">,</span>long<span class="token punctuation">)</span>
data <span class="token operator">=</span> Data<span class="token punctuation">(</span>x<span class="token operator">=</span>x<span class="token punctuation">,</span>y<span class="token operator">=</span>y<span class="token punctuation">,</span>edge_index<span class="token operator">=</span>edge_index<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#方式二：</span>
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>data <span class="token keyword">import</span> Data
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>long<span class="token punctuation">)</span>
edge_index <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                           <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                           <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                           <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>
                           <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>long<span class="token punctuation">)</span>
data <span class="token operator">=</span> Data<span class="token punctuation">(</span>x<span class="token operator">=</span>x<span class="token punctuation">,</span>y<span class="token operator">=</span>y<span class="token punctuation">,</span>edge_index<span class="token operator">=</span>edge_index<span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
Batch<span class="token punctuation">(</span>x<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">]</span><span class="token punctuation">,</span> edge_index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1568</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">,</span> batch<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<ul>
<li><strong>Train-Test Splitting</strong> &amp;&amp; <strong>Integrated Benchmark Dataset Loaders</strong></li>
</ul>
<h3 id="2-Dataset"><a href="#2-Dataset" class="headerlink" title="2. Dataset"></a>2. <a href="https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html" target="_blank" rel="noopener">Dataset</a></h3><h4 id="1-offered-dataset"><a href="#1-offered-dataset" class="headerlink" title=".1. offered dataset"></a>.1. offered dataset</h4><ul>
<li><a href="https://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/dataset.html#torch_geometric_temporal.data.dataset.chickenpox.ChickenpoxDatasetLoader" target="_blank" rel="noopener">Hungarian Chickenpox Dataset.</a></li>
<li><a href="https://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/dataset.html#torch_geometric_temporal.data.dataset.pedalme.PedalMeDatasetLoader" target="_blank" rel="noopener">PedalMe London Dataset.</a></li>
<li><a href="https://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/dataset.html#torch_geometric_temporal.data.dataset.wikimath.WikiMathsDatasetLoader" target="_blank" rel="noopener">Wikipedia Vital Math Dataset.</a></li>
<li><a href="https://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/dataset.html#torch_geometric_temporal.data.dataset.windmill.WindmillOutputDatasetLoader" target="_blank" rel="noopener">Windmill Output Dataset.</a></li>
<li><a href="https://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/dataset.html#torch_geometric_temporal.data.dataset.pems_bay.PemsBayDatasetLoader" target="_blank" rel="noopener">Pems Bay Dataset.</a></li>
<li><a href="https://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/dataset.html#torch_geometric_temporal.data.dataset.metr_la.METRLADatasetLoader" target="_blank" rel="noopener">Metr LA Dataset.</a></li>
<li><a href="https://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/dataset.html#torch_geometric_temporal.data.dataset.encovid.EnglandCovidDatasetLoader" target="_blank" rel="noopener">England COVID 19.</a></li>
<li><a href="https://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/dataset.html#torch_geometric_temporal.data.dataset.twitter_tennis.TwitterTennisDatasetLoader" target="_blank" rel="noopener">Twitter Tennis.</a></li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> TUDataset
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
dataset <span class="token operator">=</span> TUDataset<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'/tmp/ENZYMES'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'ENZYMES'</span><span class="token punctuation">,</span> use_node_attr<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> batch <span class="token keyword">in</span> loader<span class="token punctuation">:</span>
    batch
<span class="token operator">>></span><span class="token operator">></span> Batch<span class="token punctuation">(</span>batch<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1082</span><span class="token punctuation">]</span><span class="token punctuation">,</span> edge_index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4066</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1082</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    batch<span class="token punctuation">.</span>num_graphs
<span class="token operator">>></span><span class="token operator">></span> <span class="token number">32</span></code></pre>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#dataset split</span>
<span class="token keyword">from</span> torch_geometric_temporal<span class="token punctuation">.</span>dataset <span class="token keyword">import</span> ChickenpoxDatasetLoader
<span class="token keyword">from</span> torch_geometric_temporal<span class="token punctuation">.</span>signal <span class="token keyword">import</span> temporal_signal_split
loader <span class="token operator">=</span> ChickenpoxDatasetLoader<span class="token punctuation">(</span><span class="token punctuation">)</span>
dataset <span class="token operator">=</span> loader<span class="token punctuation">.</span>get_dataset<span class="token punctuation">(</span><span class="token punctuation">)</span>
dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#shuffle dataset</span>
train_dataset<span class="token punctuation">,</span> test_dataset <span class="token operator">=</span> temporal_signal_split<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> train_ratio<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">)</span></code></pre>
<ul>
<li><strong>Mini-Batch</strong></li>
</ul>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210618092943939.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210618093025169.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210618160343566.png" alt=""></p>
<h5 id="1-Planetoid-类实例化流程"><a href="#1-Planetoid-类实例化流程" class="headerlink" title="1. Planetoid 类实例化流程"></a>1. Planetoid 类实例化流程</h5><pre class=" language-python"><code class="language-python">dataset <span class="token operator">=</span> Planetoid<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'dataset/PlanetoidPubMed'</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>NormalizeFeatures<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
data <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#这一步才执行transform的函数</span></code></pre>
<ol>
<li><p>首先，检查数据原始文件是否已下载：</p>
<ul>
<li>检查<code>self.raw_dir</code>目录下是否存在<code>raw_file_names()</code>属性方法返回的每个文件，</li>
<li>如有文件不存在，则调用<code>download()</code>方法执行原始文件下载。</li>
</ul>
</li>
<li><p>其次，检查数据是否经过处理：</p>
<ul>
<li><p>首先，检查之前对数据做变换的方法：检查</p>
<pre><code>self.processed_dir</code></pre><p>目录下是否存在</p>
<pre><code>pre_transform.pt</code></pre><p>文件：</p>
<ul>
<li><p>如果存在，意味着之前进行过数据变换，接着需要加载该文件，以获取之前所用的数据变换的方法，并检查它与当前</p>
<pre><code>pre_transform</code></pre><p>参数指定的方法是否相同，</p>
<ul>
<li>如果不相同则会报出一个警告，“The pre_transform argument differs from the one used in ……”。</li>
</ul>
</li>
</ul>
</li>
<li><p>其次，检查之前的样本过滤的方法：检查</p>
<pre><code>self.processed_dir</code></pre><p>目录下是否存在</p>
<pre><code>pre_filter.pt</code></pre><p>文件：</p>
<ul>
<li><p>如果存在，则加载该文件并获取之前所用的样本过滤的方法，并检查它与当前</p>
<pre><code>pre_filter</code></pre><p>参数指定的方法是否相同，</p>
<ul>
<li>如果不相同则会报出一个警告，“The pre_filter argument differs from the one used in ……”。</li>
</ul>
</li>
</ul>
</li>
<li><p>接着，检查是否存在处理好的数据：检查</p>
<pre><code>self.processed_dir</code></pre><p>目录下是否存在</p>
<pre><code>self.processed_file_names</code></pre><p>属性方法返回的所有文件，如有文件不存在，则需要执行以下的操作：</p>
<ul>
<li><p>调用<code>process()</code>方法，进行数据处理。</p>
</li>
<li><p>如果<code>pre_transform</code>参数不为<code>None</code>，则调用<code>pre_transform()</code>函数进行数据处理。</p>
</li>
<li><p>如果<code>pre_filter</code>参数不为<code>None</code>，则进行样本过滤（此例子中不需要进行样本过滤，<code>pre_filter</code>参数为<code>None</code>）。</p>
</li>
<li><p>保存处理好的数据到文件，文件存储在</p>
<p>processed_paths()</p>
<p>属性方法返回的文件路径。如果将数据保存到多个文件中，则返回的路径有多个。</p>
<ul>
<li><strong><code>processed_paths()</code>属性方法是在基类（<a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html?highlight=dataset#torch_geometric.data.Dataset" target="_blank" rel="noopener">DataSet</a>）中定义的</strong>，它对<code>self.processed_dir</code>文件夹与<code>processed_file_names()</code>属性方法的返回每一个文件名做拼接，然后返回。</li>
</ul>
</li>
<li><p>最后保存新的<code>pre_transform.pt</code>文件和<code>pre_filter.pt</code>文件，它们分别存储当前使用的数据处理方法和样本过滤方法。</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>保证有预处理的文件后，在<code>self.data, self.slices = torch.load(self.processed_paths[0])</code>时从预处理文件路径中加载预处理后的数据。</p>
</li>
<li><p>在执行<code>data = dataset[0]</code>时才调用选择的<code>transform</code>函数。</p>
</li>
</ol>
<h4 id="2-customed-dataset"><a href="#2-customed-dataset" class="headerlink" title=".2. customed dataset"></a>.2. customed dataset</h4><blockquote>
<p>PyG提供两种不同的数据集类：Dataset,InMemoryDataset ,InMemoryDataset继承Dataset, 如果要继承InMemoryDataset 需要实现以下几个类</p>
<ul>
<li><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.InMemoryDataset.raw_file_names" target="_blank" rel="noopener"><code>torch_geometric.data.InMemoryDataset.raw_file_names()</code></a>: A list of files in the <code>raw_dir</code> which needs to be found in order to skip the download.</li>
<li><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.InMemoryDataset.processed_file_names" target="_blank" rel="noopener"><code>torch_geometric.data.InMemoryDataset.processed_file_names()</code></a>: A list of files in the <code>processed_dir</code> which needs to be found in order to skip the processing.</li>
<li><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.InMemoryDataset.download" target="_blank" rel="noopener"><code>torch_geometric.data.InMemoryDataset.download()</code></a>: Downloads raw data into <code>raw_dir</code>.</li>
<li><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.InMemoryDataset.process" target="_blank" rel="noopener"><code>torch_geometric.data.InMemoryDataset.process()</code></a>: Processes raw data and saves it into the <code>processed_dir</code>.</li>
</ul>
</blockquote>
<ul>
<li><code>root</code>：字符串类型，存储数据集的文件夹的路径下。该文件夹下有两个文件夹：<ul>
<li>一个文件夹为记录在<strong><code>raw_dir</code></strong>，它用于存储未处理的文件，从网络上下载的<strong>数据集原始文件</strong>会被存放到这里；</li>
<li>另一个文件夹记录在<strong><code>processed_dir</code></strong>，<strong>处理后的数据</strong>被保存到这里，以后从此文件夹下加载文件即可获得<code>Data</code>对象。</li>
<li>注：<code>raw_dir</code>和<code>processed_dir</code>是属性方法，我们可以自定义要使用的文件夹。</li>
</ul>
</li>
<li><code>transform</code>：函数类型，一个数据转换函数，它接收一个<code>Data</code>对象并返回一个转换后的<code>Data</code>对象。<strong>此函数在每一次数据获取过程中都会被执行</strong>。获取数据的函数首先使用此函数对<code>Data</code>对象做转换，然后才返回数据。此函数应该用于数据增广（Data Augmentation）。该参数默认值为<code>None</code>，表示不对数据做转换。</li>
<li><code>pre_transform</code>：函数类型，一个数据转换函数，它接收一个<code>Data</code>对象并返回一个转换后的<code>Data</code>对象。<strong>此函数在<code>Data</code>对象被保存到文件前调用</strong>。因此它应该用于只执行一次的数据预处理。该参数默认值为<code>None</code>，表示不做数据预处理。</li>
<li><code>pre_filter</code>：函数类型，<strong>一个检查数据是否要保留的函数</strong>，它接收一个<code>Data</code>对象，返回此<code>Data</code>对象是否应该被包含在最终的数据集中。此函数也在<a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data" target="_blank" rel="noopener"><code>Data</code></a>对象被保存到文件前调用。该参数默认值为<code>None</code>，表示不做数据检查，保留所有的数据。</li>
<li>raw_file_names(): 属性方法，返回一个<strong>数据集原始文件</strong>的文件名列表，<strong>数据集原始文件应该能在<code>raw_dir</code>文件夹中找到</strong>，否则调用<code>download()</code>函数下载文件到<code>raw_dir</code>文件夹。</li>
<li>processed_file_names: 属性方法，返回一个存储<strong>处理过的数据的文件</strong>的文件名列表，存储处理过的数据的文件应该能在<code>processed_dir</code>文件夹中找到，否则调用<code>process()</code>函数对样本做处理，然后保存处理过的数据到<code>processed_dir</code>文件夹下的文件里。</li>
<li>download: 根据定义的<code>url</code>属性<strong>下载数据集原始文件</strong>到<code>raw_dir</code>文件夹。</li>
<li>processed: <strong>调用读取数据函数，将数据包装成Data</strong>，然后<strong>处理数据</strong>，保存处理好的数据到<code>processed_dir</code>文件夹下的文件。</li>
<li>raw_dir: 属性方法，原始数据存储的文件夹路径，我们可以自定义要使用的文件夹。</li>
<li>processed_dir: 属性方法，处理后数据存储的文件夹路径，我们可以自定义要使用的文件夹。</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>data <span class="token keyword">import</span> InMemoryDataset

<span class="token keyword">class</span> <span class="token class-name">MyOwnDataset</span><span class="token punctuation">(</span>InMemoryDataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> root<span class="token punctuation">,</span> transform<span class="token operator">=</span>None<span class="token punctuation">,</span> pre_transform<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>MyOwnDataset<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>root<span class="token punctuation">,</span> transform<span class="token punctuation">,</span> pre_transform<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>data<span class="token punctuation">,</span> self<span class="token punctuation">.</span>slices <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>self<span class="token punctuation">.</span>processed_paths<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#它返回一个包含没有处理的数据的名字的list。如果你只有一个文件，那么它返回的list将只包含一个元素。事实上，你可以返回一个空list，然后确定你的文件在后面的函数process()中。</span>
    @property
    <span class="token keyword">def</span> <span class="token function">raw_file_names</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token string">'some_file_1'</span><span class="token punctuation">,</span> <span class="token string">'some_file_2'</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>

    <span class="token comment" spellcheck="true">#它返回一个包含所有处理过的数据的list。在调用process()这个函数后，通常返回的list只有一个元素，它只保存已经处理过的数据的名字。</span>
    @property
    <span class="token keyword">def</span> <span class="token function">processed_file_names</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token string">'data.pt'</span><span class="token punctuation">]</span>

    <span class="token comment" spellcheck="true">#下载数据到你正在工作的目录中，你可以在self.raw_dir中指定。</span>
    <span class="token keyword">def</span> <span class="token function">download</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># Download to `self.raw_dir`.</span>

    <span class="token keyword">def</span> <span class="token function">process</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># Read data into huge `Data` list.</span>
        data_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>pre_filter <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>
            data_list <span class="token punctuation">[</span>data <span class="token keyword">for</span> data <span class="token keyword">in</span> data_list <span class="token keyword">if</span> self<span class="token punctuation">.</span>pre_filter<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">]</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>pre_transform <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>
            data_list <span class="token operator">=</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>pre_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span> <span class="token keyword">for</span> data <span class="token keyword">in</span> data_list<span class="token punctuation">]</span>

        data<span class="token punctuation">,</span> slices <span class="token operator">=</span> self<span class="token punctuation">.</span>collate<span class="token punctuation">(</span>data_list<span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> slices<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>processed_paths<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<blockquote>
<ul>
<li><code>torch_geometric.data.Dataset.len()</code>: Returns the number of examples in your dataset.</li>
<li><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Dataset.get" target="_blank" rel="noopener"><code>torch_geometric.data.Dataset.get()</code></a>: Implements the logic to load a single graph.</li>
</ul>
</blockquote>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> os<span class="token punctuation">.</span>path <span class="token keyword">as</span> osp

<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> download_url


<span class="token keyword">class</span> <span class="token class-name">MyOwnDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> root<span class="token punctuation">,</span> transform<span class="token operator">=</span>None<span class="token punctuation">,</span> pre_transform<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>MyOwnDataset<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>root<span class="token punctuation">,</span> transform<span class="token punctuation">,</span> pre_transform<span class="token punctuation">)</span>

    @property
    <span class="token keyword">def</span> <span class="token function">raw_file_names</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token string">'some_file_1'</span><span class="token punctuation">,</span> <span class="token string">'some_file_2'</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>

    @property
    <span class="token keyword">def</span> <span class="token function">processed_file_names</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token string">'data_1.pt'</span><span class="token punctuation">,</span> <span class="token string">'data_2.pt'</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">download</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># Download to `self.raw_dir`.</span>
        path <span class="token operator">=</span> download_url<span class="token punctuation">(</span>url<span class="token punctuation">,</span> self<span class="token punctuation">.</span>raw_dir<span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

    <span class="token keyword">def</span> <span class="token function">process</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        i <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">for</span> raw_path <span class="token keyword">in</span> self<span class="token punctuation">.</span>raw_paths<span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># Read data from `raw_path`.</span>
            data <span class="token operator">=</span> Data<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>

            <span class="token keyword">if</span> self<span class="token punctuation">.</span>pre_filter <span class="token keyword">is</span> <span class="token operator">not</span> None <span class="token operator">and</span> <span class="token operator">not</span> self<span class="token punctuation">.</span>pre_filter<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">continue</span>

            <span class="token keyword">if</span> self<span class="token punctuation">.</span>pre_transform <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>
                data <span class="token operator">=</span> self<span class="token punctuation">.</span>pre_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>data<span class="token punctuation">,</span> osp<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>processed_dir<span class="token punctuation">,</span> <span class="token string">'data_{}.pt'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            i <span class="token operator">+=</span> <span class="token number">1</span>

    <span class="token keyword">def</span> <span class="token function">len</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>processed_file_names<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">get</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        data <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>osp<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>processed_dir<span class="token punctuation">,</span> <span class="token string">'data_{}.pt'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> data</code></pre>
<h4 id="3-Transformer"><a href="#3-Transformer" class="headerlink" title=".3. Transformer"></a>.3. <a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html" target="_blank" rel="noopener">Transformer</a></h4><blockquote>
<p>Transforms can be chained together using <a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.Compose" target="_blank" rel="noopener"><code>torch_geometric. transforms. Compose</code></a> and are applied before saving a processed dataset on disk (<code>pre_transform</code>) or before accessing a graph in a dataset (<code>transform</code>).</p>
</blockquote>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#convert the point cloud dataset into a graph dataset by generating nearest neighbor graphs from the point clouds via transform</span>
<span class="token keyword">import</span> torch_geometric<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> T
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> ShapeNet

dataset <span class="token operator">=</span> ShapeNet<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'/tmp/ShapeNet'</span><span class="token punctuation">,</span> categories<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Airplane'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    pre_transform<span class="token operator">=</span>T<span class="token punctuation">.</span>KNNGraph<span class="token punctuation">(</span>k<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token operator">>></span><span class="token operator">></span> Data<span class="token punctuation">(</span>edge_index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">15108</span><span class="token punctuation">]</span><span class="token punctuation">,</span> pos<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2518</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2518</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<table>
<thead>
<tr>
<th><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.Compose" target="_blank" rel="noopener"><code>Compose</code></a></th>
<th>Composes several transforms together.</th>
</tr>
</thead>
<tbody><tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.ToSparseTensor" target="_blank" rel="noopener"><code>ToSparseTensor</code></a></td>
<td>Converts the <code>edge_index</code> attribute of a data object into a (transposed) <code>torch_sparse.SparseTensor</code> type with key <code>adj_.t</code>.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.ToUndirected" target="_blank" rel="noopener"><code>ToUndirected</code></a></td>
<td>Converts the graph to an undirected graph, so that (j,i)∈E(j,i)∈E for every edge (i,j)∈E(i,j)∈E.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.Constant" target="_blank" rel="noopener"><code>Constant</code></a></td>
<td>Adds a constant value to each node feature.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.Distance" target="_blank" rel="noopener"><code>Distance</code></a></td>
<td>Saves the Euclidean distance of linked nodes in its edge attributes.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.Cartesian" target="_blank" rel="noopener"><code>Cartesian</code></a></td>
<td>Saves the relative Cartesian coordinates of linked nodes in its edge attributes.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.LocalCartesian" target="_blank" rel="noopener"><code>LocalCartesian</code></a></td>
<td>Saves the relative Cartesian coordinates of linked nodes in its edge attributes.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.Polar" target="_blank" rel="noopener"><code>Polar</code></a></td>
<td>Saves the <code>polar coordinates</code> of linked nodes in its edge attributes.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.Spherical" target="_blank" rel="noopener"><code>Spherical</code></a></td>
<td>Saves the spherical coordinates of linked nodes in its edge attributes.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.PointPairFeatures" target="_blank" rel="noopener"><code>PointPairFeatures</code></a></td>
<td>Computes the rotation-invariant Point Pair Features</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.OneHotDegree" target="_blank" rel="noopener"><code>OneHotDegree</code></a></td>
<td>Adds the node degree as one hot encodings to the node features.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.TargetIndegree" target="_blank" rel="noopener"><code>TargetIndegree</code></a></td>
<td>Saves the globally normalized degree of target nodes</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.LocalDegreeProfile" target="_blank" rel="noopener"><code>LocalDegreeProfile</code></a></td>
<td>Appends the Local Degree Profile (LDP) from the <a href="https://arxiv.org/abs/1811.03508" target="_blank" rel="noopener">“A Simple yet Effective Baseline for Non-attribute Graph Classification”</a> paper</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.Center" target="_blank" rel="noopener"><code>Center</code></a></td>
<td>Centers node positions around the origin.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.NormalizeRotation" target="_blank" rel="noopener"><code>NormalizeRotation</code></a></td>
<td><code>Rotates all points according to the eigenvectors of the point cloud.</code></td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.NormalizeScale" target="_blank" rel="noopener"><code>NormalizeScale</code></a></td>
<td>Centers and normalizes node positions to the interval (−1,1)(−1,1).</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.RandomTranslate" target="_blank" rel="noopener"><code>RandomTranslate</code></a></td>
<td>Translates node positions by randomly sampled translation values within a given interval.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.RandomFlip" target="_blank" rel="noopener"><code>RandomFlip</code></a></td>
<td>Flips node positions along a given axis randomly with a given probability.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.LinearTransformation" target="_blank" rel="noopener"><code>LinearTransformation</code></a></td>
<td>Transforms node positions with a square transformation matrix computed offline.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.RandomScale" target="_blank" rel="noopener"><code>RandomScale</code></a></td>
<td>Scales node positions by a randomly sampled factor ss within a given interval, <em>e.g.</em>, resulting in the transformation matrix</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.RandomRotate" target="_blank" rel="noopener"><code>RandomRotate</code></a></td>
<td><code>Rotates node positions around a specific axis by a randomly sampled factor within a given interval.</code></td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.RandomShear" target="_blank" rel="noopener"><code>RandomShear</code></a></td>
<td>Shears node positions by randomly sampled factors ss within a given interval, <em>e.g.</em>, resulting in the transformation matrix</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.NormalizeFeatures" target="_blank" rel="noopener"><code>NormalizeFeatures</code></a></td>
<td>Row-normalizes node features to sum-up to one.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.AddSelfLoops" target="_blank" rel="noopener"><code>AddSelfLoops</code></a></td>
<td>Adds self-loops to edge indices.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.RemoveIsolatedNodes" target="_blank" rel="noopener"><code>RemoveIsolatedNodes</code></a></td>
<td>Removes isolated nodes from the graph.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.KNNGraph" target="_blank" rel="noopener"><code>KNNGraph</code></a></td>
<td>Creates a<code>k-NN graph</code> based on node positions <code>pos</code>.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.RadiusGraph" target="_blank" rel="noopener"><code>RadiusGraph</code></a></td>
<td>Creates edges based on node positions <code>pos</code> to all points within a given distance.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.FaceToEdge" target="_blank" rel="noopener"><code>FaceToEdge</code></a></td>
<td>Converts<code>mesh faces</code> <code>[3, num_faces]</code> to edge indices <code>[2, num_edges]</code>.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.SamplePoints" target="_blank" rel="noopener"><code>SamplePoints</code></a></td>
<td>Uniformly samples <code>num</code> points on the mesh faces according to their face area.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.FixedPoints" target="_blank" rel="noopener"><code>FixedPoints</code></a></td>
<td>Samples a fixed number of <code>num</code> points and features from a point cloud.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.ToDense" target="_blank" rel="noopener"><code>ToDense</code></a></td>
<td>Converts a sparse adjacency matrix to a dense adjacency matrix with shape <code>[num_nodes, num_nodes, *]</code>.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.TwoHop" target="_blank" rel="noopener"><code>TwoHop</code></a></td>
<td>Adds the two hop edges to the edge indices.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.LineGraph" target="_blank" rel="noopener"><code>LineGraph</code></a></td>
<td>Converts a graph to its corresponding line-graph:</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.LaplacianLambdaMax" target="_blank" rel="noopener"><code>LaplacianLambdaMax</code></a></td>
<td>Computes the highest eigenvalue of the graph Laplacian given by <a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.get_laplacian" target="_blank" rel="noopener"><code>torch_geometric.utils.get_laplacian()</code></a>.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.GenerateMeshNormals" target="_blank" rel="noopener"><code>GenerateMeshNormals</code></a></td>
<td>Generate normal vectors for each mesh node based on neighboring faces.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.Delaunay" target="_blank" rel="noopener"><code>Delaunay</code></a></td>
<td>Computes the delaunay triangulation of a set of points.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.ToSLIC" target="_blank" rel="noopener"><code>ToSLIC</code></a></td>
<td>Converts an image to a superpixel representation using the <code>skimage.segmentation.slic()</code> algorithm, resulting in a <a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data" target="_blank" rel="noopener"><code>torch_geometric.data.Data</code></a> object holding the centroids of superpixels in <code>pos</code> and their mean color in <code>x</code>.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.GDC" target="_blank" rel="noopener"><code>GDC</code></a></td>
<td>Processes the graph via Graph Diffusion Convolution (GDC) from the <a href="https://www.kdd.in.tum.de/gdc" target="_blank" rel="noopener">“Diffusion Improves Graph Learning”</a> paper.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.SIGN" target="_blank" rel="noopener"><code>SIGN</code></a></td>
<td>The Scalable Inception Graph Neural Network module (SIGN) from the <a href="https://arxiv.org/abs/2004.11198" target="_blank" rel="noopener">“SIGN: Scalable Inception Graph Neural Networks”</a> paper, which precomputes the fixed representations</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.GridSampling" target="_blank" rel="noopener"><code>GridSampling</code></a></td>
<td>Clusters points into voxels with size <code>size</code>.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.GCNNorm" target="_blank" rel="noopener"><code>GCNNorm</code></a></td>
<td>Applies the GCN normalization from the <a href="https://arxiv.org/abs/1609.02907" target="_blank" rel="noopener">“Semi-supervised Classification with Graph Convolutional Networks”</a> paper.</td>
</tr>
<tr>
<td><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.AddTrainValTestMask" target="_blank" rel="noopener"><code>AddTrainValTestMask</code></a></td>
<td>Adds a node-level random split via <code>train_mask</code>, <code>val_mask</code> and <code>test_mask</code> attributes to the <code>data</code> object.</td>
</tr>
</tbody></table>
<h3 id="3-Models"><a href="#3-Models" class="headerlink" title="3. Models"></a>3. Models</h3><h4 id="1-MLs"><a href="#1-MLs" class="headerlink" title=".1. MLs"></a>.1. MLs</h4><ul>
<li><strong>Temporal Deep learning:</strong> <ul>
<li><code>LSTM or GRU</code> generates in-memory representations of data points which are iteratively updated as it learns by new snapshots;</li>
<li><code>attention mechanism</code>: to learn representation of the data points which are adaptively recontextualized based on the temporal history.</li>
</ul>
</li>
<li>*<em>Static Graph Representation Learning: *</em> <ul>
<li><code>message passing formalism</code>: learning representations of vertices, edges, and whole graphs with GNN.</li>
<li>models are differentiated by assumptions about the input graph ( eg. node heterogeneity, multiplexity, presence of edge attributes ), message compression function, propagation scheme, message aggregation function.</li>
</ul>
</li>
<li><strong>Spatio-temporal Deep Learning:</strong>  combine temporal deep learning technique and graph representation learning.</li>
<li><strong>Predictive Perfromance:</strong> <ul>
<li><code>Incremental:</code> the loss is back-propagated and model wights are updated after each temporal snapshot;</li>
<li><code>Cumulative:</code> aggregated loss from every temporal snapshot and update weights with optimizer per epoch.</li>
</ul>
</li>
</ul>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210617112633539.png" alt=""></p>
<ul>
<li><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#convolutional-layers" target="_blank" rel="noopener">Convolutional Layers</a></li>
<li><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#dense-convolutional-layers" target="_blank" rel="noopener">Dense Convolutional Layers</a></li>
<li><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#normalization-layers" target="_blank" rel="noopener">Normalization Layers</a></li>
<li><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#global-pooling-layers" target="_blank" rel="noopener">Global Pooling Layers</a></li>
<li><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#pooling-layers" target="_blank" rel="noopener">Pooling Layers</a></li>
<li><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#dense-pooling-layers" target="_blank" rel="noopener">Dense Pooling Layers</a></li>
<li><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#unpooling-layers" target="_blank" rel="noopener">Unpooling Layers</a></li>
<li><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#models" target="_blank" rel="noopener">Models</a></li>
<li><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#functional" target="_blank" rel="noopener">Functional</a></li>
<li><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#module-torch_geometric.nn.data_parallel" target="_blank" rel="noopener">DataParallel Layers</a></li>
</ul>
<h4 id="2-MessagePassing-amp-neighborhood-aggregation"><a href="#2-MessagePassing-amp-neighborhood-aggregation" class="headerlink" title=".2. MessagePassing&amp;neighborhood aggregation"></a>.2. MessagePassing&amp;neighborhood aggregation</h4><p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210618160144302.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210618095312400.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210618155312167.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210618095445424.png" alt="image-20210618095445424"></p>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210618160311559.png" alt=""></p>
<ul>
<li><code>MessagePassing(aggr="add", flow="source_to_target", node_dim=-2)</code>: Defines the aggregation scheme to use (<code>"add"</code>, <code>"mean"</code> or <code>"max"</code>) and the flow direction of message passing (either <code>"source_to_target"</code> or <code>"target_to_source"</code>). Furthermore, the <code>node_dim</code> attribute indicates along which axis to propagate.</li>
<li><code>MessagePassing.propagate(edge_index, size=None, **kwargs)</code>: The initial call to start propagating messages. Takes in the edge indices and all additional data which is needed to construct messages and to update node embeddings. Note that <a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.message_passing.MessagePassing.propagate" target="_blank" rel="noopener"><code>propagate()</code></a> is not limited to exchange messages in symmetric adjacency matrices of shape <code>[N, N]</code> only, but can also exchange messages in general sparse assignment matrices, <em>.e.g.</em>, bipartite graphs, of shape <code>[N, M]</code> by passing <code>size=(N, M)</code> as an additional argument. If set to <a href="https://docs.python.org/3/library/constants.html#None" target="_blank" rel="noopener"><code>None</code></a>, the assignment matrix is assumed to be symmetric. For bipartite graphs with two independent sets of nodes and indices, and each set holding its own information, this split can be marked by passing the information as a tuple, <em>e.g.</em> <code>x=(x_N, x_M)</code>.</li>
<li><code>MessagePassing.message(...)</code>: Constructs messages to node i in analogy to ϕϕfor each edge in (j,i)∈E(j,i)∈E if <code>flow="source_to_target"</code> and (i,j)∈E(i,j)∈E if <code>flow="target_to_source"</code>. Can take any argument which was initially passed to <code>propagate()</code>. In addition, tensors passed to <code>propagate()</code> can be mapped to the respective nodes ii and jj by appending <code>_i</code> or <code>_j</code> to the variable name, <em>.e.g.</em> <code>x_i</code> and <code>x_j</code>. Note that we generally refer to ii as the central nodes that aggregates information, and refer to jj as the neighboring nodes, since this is the most common notation.</li>
<li><code>MessagePassing.update(aggr_out, ...)</code>: Updates node embeddings in analogy to γγ for each node i∈Vi∈V. Takes in the output of aggregation as first argument and any argument which was initially passed to <a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.message_passing.MessagePassing.propagate" target="_blank" rel="noopener"><code>propagate()</code></a>.</li>
</ul>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210618104838632.png" alt=""></p>
<h5 id="1-GCN-Layer"><a href="#1-GCN-Layer" class="headerlink" title=".1. GCN Layer"></a>.1. <a href="https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html#id2" target="_blank" rel="noopener">GCN Layer</a></h5><p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210618095657408.png" alt=""></p>
<blockquote>
<ol>
<li>Add self-loops to the adjacency matrix.</li>
<li>Linearly transform node feature matrix.</li>
<li>Compute normalization coefficients.</li>
<li>Normalize node features in ϕϕ.</li>
<li>Sum up neighboring node features (<code>"add"</code> aggregation).</li>
</ol>
</blockquote>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> MessagePassing
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>utils <span class="token keyword">import</span> add_self_loops<span class="token punctuation">,</span> degree

<span class="token keyword">class</span> <span class="token class-name">GCNConv</span><span class="token punctuation">(</span>MessagePassing<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>GCNConv<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>aggr<span class="token operator">=</span><span class="token string">'add'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># "Add" aggregation (Step 5).</span>
        self<span class="token punctuation">.</span>lin <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># x has shape [N, in_channels]</span>
        <span class="token comment" spellcheck="true"># edge_index has shape [2, E]</span>

        <span class="token comment" spellcheck="true"># Step 1: Add self-loops to the adjacency matrix.</span>
        edge_index<span class="token punctuation">,</span> _ <span class="token operator">=</span> add_self_loops<span class="token punctuation">(</span>edge_index<span class="token punctuation">,</span> num_nodes<span class="token operator">=</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Step 2: Linearly transform node feature matrix.</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>lin<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Step 3: Compute normalization.</span>
        row<span class="token punctuation">,</span> col <span class="token operator">=</span> edge_index
        deg <span class="token operator">=</span> degree<span class="token punctuation">(</span>col<span class="token punctuation">,</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>x<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
        deg_inv_sqrt <span class="token operator">=</span> deg<span class="token punctuation">.</span>pow<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">)</span>
        deg_inv_sqrt<span class="token punctuation">[</span>deg_inv_sqrt <span class="token operator">==</span> float<span class="token punctuation">(</span><span class="token string">'inf'</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
        norm <span class="token operator">=</span> deg_inv_sqrt<span class="token punctuation">[</span>row<span class="token punctuation">]</span> <span class="token operator">*</span> deg_inv_sqrt<span class="token punctuation">[</span>col<span class="token punctuation">]</span>

        <span class="token comment" spellcheck="true"># Step 4-5: Start propagating messages.</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>propagate<span class="token punctuation">(</span>edge_index<span class="token punctuation">,</span> x<span class="token operator">=</span>x<span class="token punctuation">,</span> norm<span class="token operator">=</span>norm<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#当我们调用 propagate() 的时候，内部会自动的调用 message() 和 update() 函数，传递的参数是 x 。</span>

    <span class="token keyword">def</span> <span class="token function">message</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x_j<span class="token punctuation">,</span> norm<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># x_j has shape [E, out_channels]</span>

        <span class="token comment" spellcheck="true"># Step 4: Normalize node features.</span>
        <span class="token keyword">return</span> norm<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> x_j</code></pre>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210618103522520.png" alt=""></p>
<h5 id="2-Edge-Convolution"><a href="#2-Edge-Convolution" class="headerlink" title=".2.Edge Convolution"></a>.2.<a href="https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html#id3" target="_blank" rel="noopener">Edge Convolution</a></h5><p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210618100719167.png" alt=""></p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Sequential <span class="token keyword">as</span> Seq<span class="token punctuation">,</span> Linear<span class="token punctuation">,</span> ReLU
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> MessagePassing

<span class="token keyword">class</span> <span class="token class-name">EdgeConv</span><span class="token punctuation">(</span>MessagePassing<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>EdgeConv<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>aggr<span class="token operator">=</span><span class="token string">'max'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#  "Max" aggregation.</span>
        self<span class="token punctuation">.</span>mlp <span class="token operator">=</span> Seq<span class="token punctuation">(</span>Linear<span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>
                       ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                       Linear<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># x has shape [N, in_channels]</span>
        <span class="token comment" spellcheck="true"># edge_index has shape [2, E]</span>

        <span class="token keyword">return</span> self<span class="token punctuation">.</span>propagate<span class="token punctuation">(</span>edge_index<span class="token punctuation">,</span> x<span class="token operator">=</span>x<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">message</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x_i<span class="token punctuation">,</span> x_j<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># x_i has shape [E, in_channels]</span>
        <span class="token comment" spellcheck="true"># x_j has shape [E, in_channels]</span>

        tmp <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x_i<span class="token punctuation">,</span> x_j <span class="token operator">-</span> x_i<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># tmp has shape [E, 2 * in_channels]</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>mlp<span class="token punctuation">(</span>tmp<span class="token punctuation">)</span>


<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> knn_graph

<span class="token keyword">class</span> <span class="token class-name">DynamicEdgeConv</span><span class="token punctuation">(</span>EdgeConv<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>DynamicEdgeConv<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>k <span class="token operator">=</span> k

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> batch<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
        edge_index <span class="token operator">=</span> knn_graph<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>k<span class="token punctuation">,</span> batch<span class="token punctuation">,</span> loop<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> flow<span class="token operator">=</span>self<span class="token punctuation">.</span>flow<span class="token punctuation">)</span>
        <span class="token keyword">return</span> super<span class="token punctuation">(</span>DynamicEdgeConv<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>forward<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span></code></pre>
<h5 id="3-Global-Pooling"><a href="#3-Global-Pooling" class="headerlink" title=".3. Global Pooling"></a>.3. Global Pooling</h5><blockquote>
<p>PyG also supports <code>graph-level outputs</code>as opposed to node-level outputs by providing a variety of <code>readout functions such as global add, mean or max pooling</code>. We additionaly offer more sophisticated methods such as set-to-set (Vinyals et al., 2016), sort pooling (Zhang et al., 2018) or the global soft attention layer from Li et al. (2016).</p>
</blockquote>
<h5 id="4-Hierarchical-Pooling"><a href="#4-Hierarchical-Pooling" class="headerlink" title=".4. Hierarchical Pooling"></a>.4. Hierarchical Pooling</h5><blockquote>
<p>To further <code>extract hierarchical information</code> and to allow deeper GNN models, various<code>pooling approaches can be applied in a spatial or data-dependent manner.</code> We currently provide implementation examples for <code>Graclus</code> (Dhillon et al., 2007; Fagginger Auer &amp; Bisseling, 2011) and <code>voxel grid pooling</code> (Simonovsky &amp; Komodakis, 2017), the <code>iterative farthest point sampling algorithm</code> (Qi et al., 2017) followed by <code>k-NN or query ball graph generation</code> (Qi et al., 2017; Wang et al., 2018b), and differentiable pooling mechanisms such as <code>DiffPool</code> (Ying et al., 2018) and<code>topk pooling</code> (Gao &amp; Ji, 2018; Cangea et al., 2018)</p>
</blockquote>
<h3 id="4-Application"><a href="#4-Application" class="headerlink" title="4.  Application"></a>4.  Application</h3><blockquote>
<p>epidemiological forecasting, ride-hail demand prediction, web-traffic management, document labeling, fraud detection, traffic forecasting, chem-informatics systems</p>
</blockquote>
<h4 id="1-Epidemiological-Forecasting"><a href="#1-Epidemiological-Forecasting" class="headerlink" title=".1. Epidemiological Forecasting"></a>.1. Epidemiological Forecasting</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> torch_geometric_temporal<span class="token punctuation">.</span>dataset <span class="token keyword">import</span> ChickenpoxDatasetLoader
<span class="token keyword">from</span> torch_geometric_temporal<span class="token punctuation">.</span>signal <span class="token keyword">import</span> temporal_signal_split
loader <span class="token operator">=</span> ChickenpoxDatasetLoader<span class="token punctuation">(</span><span class="token punctuation">)</span>
dataset <span class="token operator">=</span> loader<span class="token punctuation">.</span>get_dataset<span class="token punctuation">(</span><span class="token punctuation">)</span>
train_dataset<span class="token punctuation">,</span> test_dataset <span class="token operator">=</span> temporal_signal_split<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> train_ratio<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>

<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> torch_geometric_temporal<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>recurrent <span class="token keyword">import</span> DCRNN

<span class="token keyword">class</span> <span class="token class-name">RecurrentGCN</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> node_features<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>RecurrentGCN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>recurrent <span class="token operator">=</span> DCRNN<span class="token punctuation">(</span>node_features<span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> edge_index<span class="token punctuation">,</span> edge_weight<span class="token punctuation">)</span><span class="token punctuation">:</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>recurrent<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">,</span> edge_weight<span class="token punctuation">)</span>
        h <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>h<span class="token punctuation">)</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>h<span class="token punctuation">)</span>
        <span class="token keyword">return</span> h

<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm
model <span class="token operator">=</span> RecurrentGCN<span class="token punctuation">(</span>node_features <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    cost <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> time<span class="token punctuation">,</span> snapshot <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
        y_hat <span class="token operator">=</span> model<span class="token punctuation">(</span>snapshot<span class="token punctuation">.</span>x<span class="token punctuation">,</span> snapshot<span class="token punctuation">.</span>edge_index<span class="token punctuation">,</span> snapshot<span class="token punctuation">.</span>edge_attr<span class="token punctuation">)</span>
        cost <span class="token operator">=</span> cost <span class="token operator">+</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">(</span>y_hat<span class="token operator">-</span>snapshot<span class="token punctuation">.</span>y<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span>
    cost <span class="token operator">=</span> cost <span class="token operator">/</span> <span class="token punctuation">(</span>time<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>
    cost<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
cost <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> time<span class="token punctuation">,</span> snapshot <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>test_dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    y_hat <span class="token operator">=</span> model<span class="token punctuation">(</span>snapshot<span class="token punctuation">.</span>x<span class="token punctuation">,</span> snapshot<span class="token punctuation">.</span>edge_index<span class="token punctuation">,</span> snapshot<span class="token punctuation">.</span>edge_attr<span class="token punctuation">)</span>
    cost <span class="token operator">=</span> cost <span class="token operator">+</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">(</span>y_hat<span class="token operator">-</span>snapshot<span class="token punctuation">.</span>y<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span>
cost <span class="token operator">=</span> cost <span class="token operator">/</span> <span class="token punctuation">(</span>time<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>
cost <span class="token operator">=</span> cost<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"MSE: {:.4f}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>cost<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> MSE<span class="token punctuation">:</span> <span class="token number">0.6866</span></code></pre>
<h4 id="2-Web-Traffic-Prediction"><a href="#2-Web-Traffic-Prediction" class="headerlink" title=".2. Web Traffic Prediction"></a>.2. Web Traffic Prediction</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> torch_geometric_temporal<span class="token punctuation">.</span>dataset <span class="token keyword">import</span> WikiMathsDatasetLoader
<span class="token keyword">from</span> torch_geometric_temporal<span class="token punctuation">.</span>signal <span class="token keyword">import</span> temporal_signal_split
loader <span class="token operator">=</span> WikiMathsDatasetLoader<span class="token punctuation">(</span><span class="token punctuation">)</span>
dataset <span class="token operator">=</span> loader<span class="token punctuation">.</span>get_dataset<span class="token punctuation">(</span>lags<span class="token operator">=</span><span class="token number">14</span><span class="token punctuation">)</span>
train_dataset<span class="token punctuation">,</span> test_dataset <span class="token operator">=</span> temporal_signal_split<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> train_ratio<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>

<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> torch_geometric_temporal<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>recurrent <span class="token keyword">import</span> GConvGRU

<span class="token keyword">class</span> <span class="token class-name">RecurrentGCN</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> node_features<span class="token punctuation">,</span> filters<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>RecurrentGCN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>recurrent <span class="token operator">=</span> GConvGRU<span class="token punctuation">(</span>node_features<span class="token punctuation">,</span> filters<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>filters<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> edge_index<span class="token punctuation">,</span> edge_weight<span class="token punctuation">)</span><span class="token punctuation">:</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>recurrent<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">,</span> edge_weight<span class="token punctuation">)</span>
        h <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>h<span class="token punctuation">)</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>h<span class="token punctuation">)</span>
        <span class="token keyword">return</span> h

<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm
model <span class="token operator">=</span> RecurrentGCN<span class="token punctuation">(</span>node_features<span class="token operator">=</span><span class="token number">14</span><span class="token punctuation">,</span> filters<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> time<span class="token punctuation">,</span> snapshot <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
        y_hat <span class="token operator">=</span> model<span class="token punctuation">(</span>snapshot<span class="token punctuation">.</span>x<span class="token punctuation">,</span> snapshot<span class="token punctuation">.</span>edge_index<span class="token punctuation">,</span> snapshot<span class="token punctuation">.</span>edge_attr<span class="token punctuation">)</span>
        cost <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">(</span>y_hat<span class="token operator">-</span>snapshot<span class="token punctuation">.</span>y<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span>
        cost<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
cost <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> time<span class="token punctuation">,</span> snapshot <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>test_dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    y_hat <span class="token operator">=</span> model<span class="token punctuation">(</span>snapshot<span class="token punctuation">.</span>x<span class="token punctuation">,</span> snapshot<span class="token punctuation">.</span>edge_index<span class="token punctuation">,</span> snapshot<span class="token punctuation">.</span>edge_attr<span class="token punctuation">)</span>
    cost <span class="token operator">=</span> cost <span class="token operator">+</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">(</span>y_hat<span class="token operator">-</span>snapshot<span class="token punctuation">.</span>y<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span>
cost <span class="token operator">=</span> cost <span class="token operator">/</span> <span class="token punctuation">(</span>time<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>
cost <span class="token operator">=</span> cost<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"MSE: {:.4f}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>cost<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> MSE<span class="token punctuation">:</span> <span class="token number">0.7760</span></code></pre>
<h4 id="3-Cora-2layerGCN"><a href="#3-Cora-2layerGCN" class="headerlink" title=".3. Cora 2layerGCN"></a>.3. Cora 2layerGCN</h4><blockquote>
<p>一个epoch中的一个data包含一个完整的数据集</p>
</blockquote>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> Planetoid
dataset <span class="token operator">=</span> Planetoid<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'/tmp/Cora'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'Cora'</span><span class="token punctuation">)</span>

<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> GCNConv

<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> GCNConv<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>num_node_features<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> GCNConv<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> dataset<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x<span class="token punctuation">,</span> edge_index <span class="token operator">=</span> data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index

        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span>

        <span class="token keyword">return</span> F<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
data <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">5e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    out <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> F<span class="token punctuation">.</span>nll_loss<span class="token punctuation">(</span>out<span class="token punctuation">[</span>data<span class="token punctuation">.</span>train_mask<span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>y<span class="token punctuation">[</span>data<span class="token punctuation">.</span>train_mask<span class="token punctuation">]</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
_<span class="token punctuation">,</span> pred <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
correct <span class="token operator">=</span> int<span class="token punctuation">(</span>pred<span class="token punctuation">[</span>data<span class="token punctuation">.</span>test_mask<span class="token punctuation">]</span><span class="token punctuation">.</span>eq<span class="token punctuation">(</span>data<span class="token punctuation">.</span>y<span class="token punctuation">[</span>data<span class="token punctuation">.</span>test_mask<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
acc <span class="token operator">=</span> correct <span class="token operator">/</span> int<span class="token punctuation">(</span>data<span class="token punctuation">.</span>test_mask<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Accuracy: {:.4f}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>acc<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> Accuracy<span class="token punctuation">:</span> <span class="token number">0.8150</span></code></pre>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> GCNConv
<span class="token keyword">import</span> torch_geometric<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> T
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> Planetoid

dataset <span class="token operator">=</span> Planetoid<span class="token punctuation">(</span><span class="token string">"Planetoid"</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"Cora"</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>T<span class="token punctuation">.</span>ToSparseTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
data <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token operator">>></span><span class="token operator">></span> Data<span class="token punctuation">(</span>adj_t<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2708</span><span class="token punctuation">,</span> <span class="token number">2708</span><span class="token punctuation">,</span> nnz<span class="token operator">=</span><span class="token number">10556</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2708</span><span class="token punctuation">,</span> <span class="token number">1433</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2708</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> GCNConv<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>num_features<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> cached<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> GCNConv<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> dataset<span class="token punctuation">.</span>num_classes<span class="token punctuation">,</span> cached<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> adj_t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">,</span> adj_t<span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">,</span> adj_t<span class="token punctuation">)</span>
        <span class="token keyword">return</span> F<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

model <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    out <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> data<span class="token punctuation">.</span>adj_t<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> F<span class="token punctuation">.</span>nll_loss<span class="token punctuation">(</span>out<span class="token punctuation">,</span> data<span class="token punctuation">.</span>y<span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> float<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">201</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    loss <span class="token operator">=</span> train<span class="token punctuation">(</span>data<span class="token punctuation">)</span></code></pre>
<h4 id="4-karate-club"><a href="#4-karate-club" class="headerlink" title=".4. karate club"></a>.4. karate club</h4><blockquote>
<p><strong>Zachary’s karate club</strong> is a social network of a university karate club, described in the paper “An Information Flow Model for Conflict and Fission in Small Groups” by Wayne W. Zachary. The network became a popular example of <a href="https://en.wikipedia.org/wiki/Community_structure" target="_blank" rel="noopener">community structure</a> in networks after its use by <a href="https://en.wikipedia.org/wiki/Michelle_Girvan" target="_blank" rel="noopener">Michelle Girvan</a> and <a href="https://en.wikipedia.org/wiki/Mark_Newman" target="_blank" rel="noopener">Mark Newman</a> in 2002.<a href="https://en.wikipedia.org/wiki/Zachary' target=" _blank"="" rel="noopener" s_karate_club#cite_note-gn-1"="">[1]</a>   </p>
</blockquote>
<ul>
<li><strong>Node Classification</strong></li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> KarateClub
dataset <span class="token operator">=</span> KarateClub<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#1 graph, number of features: 34, classes:4, which represent the community each node belongs to.</span>
<span class="token comment" spellcheck="true">#Data(edge_index=[2, 156], train_mask=[34], x=[34, 34], y=[34])</span>


<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Linear
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> GCNConv
<span class="token keyword">class</span> <span class="token class-name">GCN</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>GCN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">12345</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> GCNConv<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>num_features<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> GCNConv<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv3 <span class="token operator">=</span> GCNConv<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> Linear<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> dataset<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span>
        h <span class="token operator">=</span> h<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>h<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span>
        h <span class="token operator">=</span> h<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3<span class="token punctuation">(</span>h<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span>
        h <span class="token operator">=</span> h<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Final GNN embedding space.</span>

        <span class="token comment" spellcheck="true"># Apply a final (linear) classifier.</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>h<span class="token punctuation">)</span>
        <span class="token keyword">return</span> out<span class="token punctuation">,</span> h

model <span class="token operator">=</span> GCN<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#34→4→4→2->num_classes, 每一个row表示一个节点，对每一个节点进行分类</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>

model <span class="token operator">=</span> GCN<span class="token punctuation">(</span><span class="token punctuation">)</span>
_<span class="token punctuation">,</span> h <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Embedding shape: {list(h.shape)}'</span><span class="token punctuation">)</span>
visualize<span class="token punctuation">(</span>h<span class="token punctuation">,</span> color<span class="token operator">=</span>data<span class="token punctuation">.</span>y<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#h:&lt;class 'torch.Tensor'>, grad_fn=&lt;TanhBackward>) torch.Size([34, 2]</span>


<span class="token keyword">import</span> time
<span class="token keyword">from</span> IPython<span class="token punctuation">.</span>display <span class="token keyword">import</span> Javascript  <span class="token comment" spellcheck="true"># Restrict height of output cell.</span>
display<span class="token punctuation">(</span>Javascript<span class="token punctuation">(</span><span class="token triple-quoted-string string">'''google.colab.output.setIframeHeight(0, true, {maxHeight: 430})'''</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

model <span class="token operator">=</span> GCN<span class="token punctuation">(</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Define loss criterion.</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Define optimizer.</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Clear gradients.</span>
    out<span class="token punctuation">,</span> h <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Perform a single forward pass.</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>out<span class="token punctuation">[</span>data<span class="token punctuation">.</span>train_mask<span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>y<span class="token punctuation">[</span>data<span class="token punctuation">.</span>train_mask<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Compute the loss solely based on the training nodes.</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Derive gradients.</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Update parameters based on gradients.</span>
    <span class="token keyword">return</span> loss<span class="token punctuation">,</span> h

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">401</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    loss<span class="token punctuation">,</span> h <span class="token operator">=</span> train<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token keyword">if</span> epoch <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        visualize<span class="token punctuation">(</span>h<span class="token punctuation">,</span> color<span class="token operator">=</span>data<span class="token punctuation">.</span>y<span class="token punctuation">,</span> epoch<span class="token operator">=</span>epoch<span class="token punctuation">,</span> loss<span class="token operator">=</span>loss<span class="token punctuation">)</span>
        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">0.3</span><span class="token punctuation">)</span></code></pre>
<h4 id="5-Planetoid"><a href="#5-Planetoid" class="headerlink" title=".5. Planetoid"></a>.5. <a href="https://colab.research.google.com/drive/14OvFnAXggxB8vM4e8vSURUp1TaKnovzX?usp=sharing#scrollTo=9r_VmGMukf5R" target="_blank" rel="noopener">Planetoid</a></h4><ul>
<li><strong>Node Classification</strong></li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> Planetoid
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>transforms <span class="token keyword">import</span> NormalizeFeatures

dataset <span class="token operator">=</span> Planetoid<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'data/Planetoid'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'Cora'</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>NormalizeFeatures<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])</span>
<span class="token comment" spellcheck="true">#Number of classes: 7</span></code></pre>
<ul>
<li><strong>MLP</strong></li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Linear
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token keyword">class</span> <span class="token class-name">MLP</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hidden_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>MLP<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">12345</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>lin1 <span class="token operator">=</span> Linear<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>num_features<span class="token punctuation">,</span> hidden_channels<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>lin2 <span class="token operator">=</span> Linear<span class="token punctuation">(</span>hidden_channels<span class="token punctuation">,</span> dataset<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>lin1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>relu<span class="token punctuation">(</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>lin2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

model <span class="token operator">=</span> MLP<span class="token punctuation">(</span>hidden_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>

<span class="token keyword">from</span> IPython<span class="token punctuation">.</span>display <span class="token keyword">import</span> Javascript  <span class="token comment" spellcheck="true"># Restrict height of output cell.</span>
display<span class="token punctuation">(</span>Javascript<span class="token punctuation">(</span><span class="token triple-quoted-string string">'''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

model <span class="token operator">=</span> MLP<span class="token punctuation">(</span>hidden_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Define loss criterion.</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">5e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Define optimizer.</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
      model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
      optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Clear gradients.</span>
      out <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Perform a single forward pass.</span>
      loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>out<span class="token punctuation">[</span>data<span class="token punctuation">.</span>train_mask<span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>y<span class="token punctuation">[</span>data<span class="token punctuation">.</span>train_mask<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Compute the loss solely based on the training nodes.</span>
      loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Derive gradients.</span>
      optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Update parameters based on gradients.</span>
      <span class="token keyword">return</span> loss

<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
      model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
      out <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x<span class="token punctuation">)</span>
      pred <span class="token operator">=</span> out<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Use the class with highest probability.</span>
      test_correct <span class="token operator">=</span> pred<span class="token punctuation">[</span>data<span class="token punctuation">.</span>test_mask<span class="token punctuation">]</span> <span class="token operator">==</span> data<span class="token punctuation">.</span>y<span class="token punctuation">[</span>data<span class="token punctuation">.</span>test_mask<span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># Check against ground-truth labels.</span>
      test_acc <span class="token operator">=</span> int<span class="token punctuation">(</span>test_correct<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> int<span class="token punctuation">(</span>data<span class="token punctuation">.</span>test_mask<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Derive ratio of correct predictions.</span>
      <span class="token keyword">return</span> test_acc

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">201</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    loss <span class="token operator">=</span> train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Epoch: {epoch:03d}, Loss: {loss:.4f}'</span><span class="token punctuation">)</span></code></pre>
<ul>
<li><strong>GCN</strong></li>
</ul>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210618121248908.png" alt=""></p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> GCNConv
<span class="token keyword">class</span> <span class="token class-name">GCN</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hidden_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>GCN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">12345</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> GCNConv<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>num_features<span class="token punctuation">,</span> hidden_channels<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> GCNConv<span class="token punctuation">(</span>hidden_channels<span class="token punctuation">,</span> dataset<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>relu<span class="token punctuation">(</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

model <span class="token operator">=</span> GCN<span class="token punctuation">(</span>hidden_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>


<span class="token keyword">from</span> IPython<span class="token punctuation">.</span>display <span class="token keyword">import</span> Javascript  <span class="token comment" spellcheck="true"># Restrict height of output cell.</span>
display<span class="token punctuation">(</span>Javascript<span class="token punctuation">(</span><span class="token triple-quoted-string string">'''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

model <span class="token operator">=</span> GCN<span class="token punctuation">(</span>hidden_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">5e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
      model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
      optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Clear gradients.</span>
      out <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Perform a single forward pass.</span>
      loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>out<span class="token punctuation">[</span>data<span class="token punctuation">.</span>train_mask<span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>y<span class="token punctuation">[</span>data<span class="token punctuation">.</span>train_mask<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Compute the loss solely based on the training nodes.</span>
      loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Derive gradients.</span>
      optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Update parameters based on gradients.</span>
      <span class="token keyword">return</span> loss

<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
      model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
      out <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index<span class="token punctuation">)</span>
      pred <span class="token operator">=</span> out<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Use the class with highest probability.</span>
      test_correct <span class="token operator">=</span> pred<span class="token punctuation">[</span>data<span class="token punctuation">.</span>test_mask<span class="token punctuation">]</span> <span class="token operator">==</span> data<span class="token punctuation">.</span>y<span class="token punctuation">[</span>data<span class="token punctuation">.</span>test_mask<span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># Check against ground-truth labels.</span>
      test_acc <span class="token operator">=</span> int<span class="token punctuation">(</span>test_correct<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> int<span class="token punctuation">(</span>data<span class="token punctuation">.</span>test_mask<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Derive ratio of correct predictions.</span>
      <span class="token keyword">return</span> test_acc


<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">201</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    loss <span class="token operator">=</span> train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Epoch: {epoch:03d}, Loss: {loss:.4f}'</span><span class="token punctuation">)</span></code></pre>
<h4 id="6-TUDdataset"><a href="#6-TUDdataset" class="headerlink" title=".6. TUDdataset"></a>.6. TUDdataset</h4><ul>
<li><strong>Graph classification</strong></li>
</ul>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210618131022161.png" alt=""></p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> TUDataset

dataset <span class="token operator">=</span> TUDataset<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'data/TUDataset'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'MUTAG'</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#Data(edge_attr=[38, 4], edge_index=[2, 38], x=[17, 7], y=[1])</span>
<span class="token comment" spellcheck="true">#Number of graphs: 188</span>
<span class="token comment" spellcheck="true">#Number of features: 7</span>
<span class="token comment" spellcheck="true">#Number of classes: 2</span>
torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">12345</span><span class="token punctuation">)</span>
dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span><span class="token punctuation">)</span>

train_dataset <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">150</span><span class="token punctuation">]</span>
test_dataset <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token number">150</span><span class="token punctuation">:</span><span class="token punctuation">]</span>

<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> step<span class="token punctuation">,</span> data <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Step {step + 1}:'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'======='</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Number of graphs in the current batch: {data.num_graphs}'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#Batch(batch=[1169], edge_attr=[2592, 4], edge_index=[2, 2592], x=[1169, 7], y=[64])</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Linear
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> GCNConv
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> global_mean_pool

<span class="token keyword">class</span> <span class="token class-name">GCN</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hidden_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>GCN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">12345</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> GCNConv<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>num_node_features<span class="token punctuation">,</span> hidden_channels<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> GCNConv<span class="token punctuation">(</span>hidden_channels<span class="token punctuation">,</span> hidden_channels<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv3 <span class="token operator">=</span> GCNConv<span class="token punctuation">(</span>hidden_channels<span class="token punctuation">,</span> hidden_channels<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>lin <span class="token operator">=</span> Linear<span class="token punctuation">(</span>hidden_channels<span class="token punctuation">,</span> dataset<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> edge_index<span class="token punctuation">,</span> batch<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 1. Obtain node embeddings </span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>relu<span class="token punctuation">(</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>relu<span class="token punctuation">(</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 2. Readout layer</span>
        x <span class="token operator">=</span> global_mean_pool<span class="token punctuation">(</span>x<span class="token punctuation">,</span> batch<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># [batch_size, hidden_channels]</span>

        <span class="token comment" spellcheck="true"># 3. Apply a final classifier</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>lin<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token keyword">return</span> x

model <span class="token operator">=</span> GCN<span class="token punctuation">(</span>hidden_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#GCN(</span>
<span class="token comment" spellcheck="true">#  (conv1): GCNConv(7, 64)</span>
<span class="token comment" spellcheck="true">#  (conv2): GCNConv(64, 64)</span>
<span class="token comment" spellcheck="true">#  (conv3): GCNConv(64, 64)</span>
<span class="token comment" spellcheck="true">#  (lin): Linear(in_features=64, out_features=2, bias=True)</span>
<span class="token comment" spellcheck="true">#)</span>

<span class="token keyword">from</span> IPython<span class="token punctuation">.</span>display <span class="token keyword">import</span> Javascript
display<span class="token punctuation">(</span>Javascript<span class="token punctuation">(</span><span class="token triple-quoted-string string">'''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

model <span class="token operator">=</span> GCN<span class="token punctuation">(</span>hidden_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">for</span> data <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># Iterate in batches over the training dataset.</span>
         out <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index<span class="token punctuation">,</span> data<span class="token punctuation">.</span>batch<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Perform a single forward pass.</span>
         loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>out<span class="token punctuation">,</span> data<span class="token punctuation">.</span>y<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Compute the loss.</span>
         loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Derive gradients.</span>
         optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Update parameters based on gradients.</span>
         optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Clear gradients.</span>

<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
     model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>

     correct <span class="token operator">=</span> <span class="token number">0</span>
     <span class="token keyword">for</span> data <span class="token keyword">in</span> loader<span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># Iterate in batches over the training/test dataset.</span>
         out <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index<span class="token punctuation">,</span> data<span class="token punctuation">.</span>batch<span class="token punctuation">)</span>  
         pred <span class="token operator">=</span> out<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Use the class with highest probability.</span>
         correct <span class="token operator">+=</span> int<span class="token punctuation">(</span><span class="token punctuation">(</span>pred <span class="token operator">==</span> data<span class="token punctuation">.</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Check against ground-truth labels.</span>
     <span class="token keyword">return</span> correct <span class="token operator">/</span> len<span class="token punctuation">(</span>loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Derive ratio of correct predictions.</span>


<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">201</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    train_acc <span class="token operator">=</span> test<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span>
    test_acc <span class="token operator">=</span> test<span class="token punctuation">(</span>test_loader<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}'</span><span class="token punctuation">)</span></code></pre>
<h4 id="7-PointCloudClassification"><a href="#7-PointCloudClassification" class="headerlink" title=".7. PointCloudClassification"></a>.7. PointCloudClassification</h4><ul>
<li>GeometricShapes</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Install required packages.</span>
!pip install <span class="token operator">-</span>q torch<span class="token operator">-</span>scatter <span class="token operator">-</span>f https<span class="token punctuation">:</span><span class="token operator">//</span>pytorch<span class="token operator">-</span>geometric<span class="token punctuation">.</span>com<span class="token operator">/</span>whl<span class="token operator">/</span>torch<span class="token number">-1.8</span><span class="token punctuation">.</span><span class="token number">0</span><span class="token operator">+</span>cu101<span class="token punctuation">.</span>html
!pip install <span class="token operator">-</span>q torch<span class="token operator">-</span>sparse <span class="token operator">-</span>f https<span class="token punctuation">:</span><span class="token operator">//</span>pytorch<span class="token operator">-</span>geometric<span class="token punctuation">.</span>com<span class="token operator">/</span>whl<span class="token operator">/</span>torch<span class="token number">-1.8</span><span class="token punctuation">.</span><span class="token number">0</span><span class="token operator">+</span>cu101<span class="token punctuation">.</span>html
!pip install <span class="token operator">-</span>q torch<span class="token operator">-</span>cluster <span class="token operator">-</span>f https<span class="token punctuation">:</span><span class="token operator">//</span>pytorch<span class="token operator">-</span>geometric<span class="token punctuation">.</span>com<span class="token operator">/</span>whl<span class="token operator">/</span>torch<span class="token number">-1.8</span><span class="token punctuation">.</span><span class="token number">0</span><span class="token operator">+</span>cu101<span class="token punctuation">.</span>html
!pip install <span class="token operator">-</span>q torch<span class="token operator">-</span>geometric

<span class="token comment" spellcheck="true"># Helper functions for visualization.</span>
<span class="token operator">%</span>matplotlib inline
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> mpl_toolkits<span class="token punctuation">.</span>mplot3d <span class="token keyword">import</span> Axes3D

<span class="token keyword">def</span> <span class="token function">visualize_mesh</span><span class="token punctuation">(</span>pos<span class="token punctuation">,</span> face<span class="token punctuation">)</span><span class="token punctuation">:</span>
    fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ax <span class="token operator">=</span> fig<span class="token punctuation">.</span>gca<span class="token punctuation">(</span>projection<span class="token operator">=</span><span class="token string">'3d'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>axes<span class="token punctuation">.</span>xaxis<span class="token punctuation">.</span>set_ticklabels<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>axes<span class="token punctuation">.</span>yaxis<span class="token punctuation">.</span>set_ticklabels<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>axes<span class="token punctuation">.</span>zaxis<span class="token punctuation">.</span>set_ticklabels<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>plot_trisurf<span class="token punctuation">(</span>pos<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> pos<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> pos<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> triangles<span class="token operator">=</span>data<span class="token punctuation">.</span>face<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> antialiased<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">visualize_points</span><span class="token punctuation">(</span>pos<span class="token punctuation">,</span> edge_index<span class="token operator">=</span>None<span class="token punctuation">,</span> index<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
    fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> edge_index <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span>src<span class="token punctuation">,</span> dst<span class="token punctuation">)</span> <span class="token keyword">in</span> edge_index<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
             src <span class="token operator">=</span> pos<span class="token punctuation">[</span>src<span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
             dst <span class="token operator">=</span> pos<span class="token punctuation">[</span>dst<span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
             plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span>src<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dst<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>src<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dst<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> linewidth<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'black'</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> index <span class="token keyword">is</span> None<span class="token punctuation">:</span>
        plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>pos<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> pos<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> zorder<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
       mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>pos<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span>
       mask<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">True</span>
       plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>pos<span class="token punctuation">[</span><span class="token operator">~</span>mask<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> pos<span class="token punctuation">[</span><span class="token operator">~</span>mask<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'lightgray'</span><span class="token punctuation">,</span> zorder<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>
       plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>pos<span class="token punctuation">[</span>mask<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> pos<span class="token punctuation">[</span>mask<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> zorder<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#load dataset</span>
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> GeometricShapes
dataset <span class="token operator">=</span> GeometricShapes<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'data/GeometricShapes'</span><span class="token punctuation">)</span></code></pre>
<blockquote>
<p>transform our meshes into points via the usage of “transforms”. Here, PyTorch Geometric provides the <a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.SamplePoints" target="_blank" rel="noopener"><code>torch_geometric.transforms.SamplePoints</code></a> transformation, which will uniformly sample a fixed number of points on the mesh faces according to their face area.</p>
</blockquote>
<ul>
<li><strong>RandomRotate</strong></li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>transforms <span class="token keyword">import</span> Compose<span class="token punctuation">,</span> RandomRotate

torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>

random_rotate <span class="token operator">=</span> Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    RandomRotate<span class="token punctuation">(</span>degrees<span class="token operator">=</span><span class="token number">180</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    RandomRotate<span class="token punctuation">(</span>degrees<span class="token operator">=</span><span class="token number">180</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    RandomRotate<span class="token punctuation">(</span>degrees<span class="token operator">=</span><span class="token number">180</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

dataset <span class="token operator">=</span> GeometricShapes<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'data/GeometricShapes'</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>random_rotate<span class="token punctuation">)</span>

data <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
visualize_mesh<span class="token punctuation">(</span>data<span class="token punctuation">.</span>pos<span class="token punctuation">,</span> data<span class="token punctuation">.</span>face<span class="token punctuation">)</span>

data <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
visualize_mesh<span class="token punctuation">(</span>data<span class="token punctuation">.</span>pos<span class="token punctuation">,</span> data<span class="token punctuation">.</span>face<span class="token punctuation">)</span></code></pre>
<ul>
<li><strong>SamplePoints</strong></li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>transforms <span class="token keyword">import</span> SamplePoints

torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">42</span><span class="token punctuation">)</span>

dataset<span class="token punctuation">.</span>transform <span class="token operator">=</span> SamplePoints<span class="token punctuation">(</span>num<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">)</span>

data <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#Data(face=[3, 30], pos=[32, 3], y=[1]) =>Data(pos=[256, 3], y=[1])</span>
visualize_points<span class="token punctuation">(</span>data<span class="token punctuation">.</span>pos<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index<span class="token punctuation">)</span>

data <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#Data(face=[3, 2], pos=[4, 3], y=[1])=>Data(pos=[256, 3], y=[1])</span>
visualize_points<span class="token punctuation">(</span>data<span class="token punctuation">.</span>pos<span class="token punctuation">)</span></code></pre>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210618133509868.png" alt=""></p>
<blockquote>
<p><code>PointNet++</code> processes <code>point clouds iteratively</code> by following a <code>simple grouping, neighborhood aggregation and downsampling scheme:</code></p>
<ol>
<li>The <strong>grouping phase</strong> constructs a graph in which <code>nearby points are connected</code>. Typically, this is either done via <code>k-nearest neighbor search</code> or via <code>ball queries (which connects all points that are within a radius to the query point).</code></li>
<li>The <strong>neighborhood aggregation phase</strong> executes a Graph Neural Network layer that, for each point,<code>aggregates information from its direct neighbors</code>(given by the graph constructed in the previous phase). This allows PointNet++ to capture local context at different scales.</li>
<li>The <strong>downsampling phase</strong> implements a pooling scheme suitable for point clouds with potentially different sizes. We will ignore this phase for now and will come back later to it.</li>
</ol>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210618132211963.png" alt=""></p>
<ul>
<li><strong>knn_graph</strong></li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> torch_cluster <span class="token keyword">import</span> knn_graph

data <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
data<span class="token punctuation">.</span>edge_index <span class="token operator">=</span> knn_graph<span class="token punctuation">(</span>data<span class="token punctuation">.</span>pos<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span>edge_index<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
visualize_points<span class="token punctuation">(</span>data<span class="token punctuation">.</span>pos<span class="token punctuation">,</span> edge_index<span class="token operator">=</span>data<span class="token punctuation">.</span>edge_index<span class="token punctuation">)</span>

data <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span>
data<span class="token punctuation">.</span>edge_index <span class="token operator">=</span> knn_graph<span class="token punctuation">(</span>data<span class="token punctuation">.</span>pos<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span>edge_index<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
visualize_points<span class="token punctuation">(</span>data<span class="token punctuation">.</span>pos<span class="token punctuation">,</span> edge_index<span class="token operator">=</span>data<span class="token punctuation">.</span>edge_index<span class="token punctuation">)</span></code></pre>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210618132356302.png" alt=""></p>
<ul>
<li><strong>Neighborhood Aggregation</strong></li>
</ul>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210618132502775.png" alt=""></p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Sequential<span class="token punctuation">,</span> Linear<span class="token punctuation">,</span> ReLU
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> MessagePassing


<span class="token keyword">class</span> <span class="token class-name">PointNetLayer</span><span class="token punctuation">(</span>MessagePassing<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># Message passing with "max" aggregation.</span>
        super<span class="token punctuation">(</span>PointNetLayer<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token string">'max'</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Initialization of the MLP:</span>
        <span class="token comment" spellcheck="true"># Here, the number of input features correspond to the hidden node</span>
        <span class="token comment" spellcheck="true"># dimensionality plus point dimensionality (=3).</span>
        self<span class="token punctuation">.</span>mlp <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>Linear<span class="token punctuation">(</span>in_channels <span class="token operator">+</span> <span class="token number">3</span><span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>
                              ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                              Linear<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> h<span class="token punctuation">,</span> pos<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># Start propagating messages.</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>propagate<span class="token punctuation">(</span>edge_index<span class="token punctuation">,</span> h<span class="token operator">=</span>h<span class="token punctuation">,</span> pos<span class="token operator">=</span>pos<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">message</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> h_j<span class="token punctuation">,</span> pos_j<span class="token punctuation">,</span> pos_i<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># h_j defines the features of neighboring nodes as shape [num_edges, in_channels]</span>
        <span class="token comment" spellcheck="true"># pos_j defines the position of neighboring nodes as shape [num_edges, 3]</span>
        <span class="token comment" spellcheck="true"># pos_i defines the position of central nodes as shape [num_edges, 3]</span>

        input <span class="token operator">=</span> pos_j <span class="token operator">-</span> pos_i  <span class="token comment" spellcheck="true"># Compute spatial relation.</span>

        <span class="token keyword">if</span> h_j <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># In the first layer, we may not have any hidden node features,</span>
            <span class="token comment" spellcheck="true"># so we only combine them in case they are present.</span>
            input <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>h_j<span class="token punctuation">,</span> input<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> self<span class="token punctuation">.</span>mlp<span class="token punctuation">(</span>input<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Apply our final MLP.</span></code></pre>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> torch_cluster <span class="token keyword">import</span> knn_graph
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> global_max_pool


<span class="token keyword">class</span> <span class="token class-name">PointNet</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>PointNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">12345</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> PointNetLayer<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> PointNetLayer<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> dataset<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pos<span class="token punctuation">,</span> batch<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># Compute the kNN graph:</span>
        <span class="token comment" spellcheck="true"># Here, we need to pass the batch vector to the function call in order</span>
        <span class="token comment" spellcheck="true"># to prevent creating edges between points of different examples.</span>
        <span class="token comment" spellcheck="true"># We also add `loop=True` which will add self-loops to the graph in</span>
        <span class="token comment" spellcheck="true"># order to preserve central point information.</span>
        edge_index <span class="token operator">=</span> knn_graph<span class="token punctuation">(</span>pos<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span> batch<span class="token operator">=</span>batch<span class="token punctuation">,</span> loop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 3. Start bipartite message passing.</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>h<span class="token operator">=</span>pos<span class="token punctuation">,</span> pos<span class="token operator">=</span>pos<span class="token punctuation">,</span> edge_index<span class="token operator">=</span>edge_index<span class="token punctuation">)</span>
        h <span class="token operator">=</span> h<span class="token punctuation">.</span>relu<span class="token punctuation">(</span><span class="token punctuation">)</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>h<span class="token operator">=</span>h<span class="token punctuation">,</span> pos<span class="token operator">=</span>pos<span class="token punctuation">,</span> edge_index<span class="token operator">=</span>edge_index<span class="token punctuation">)</span>
        h <span class="token operator">=</span> h<span class="token punctuation">.</span>relu<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 4. Global Pooling.</span>
        h <span class="token operator">=</span> global_max_pool<span class="token punctuation">(</span>h<span class="token punctuation">,</span> batch<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># [num_examples, hidden_channels]</span>

        <span class="token comment" spellcheck="true"># 5. Classifier.</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>h<span class="token punctuation">)</span>


model <span class="token operator">=</span> PointNet<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span></code></pre>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> IPython<span class="token punctuation">.</span>display <span class="token keyword">import</span> Javascript  <span class="token comment" spellcheck="true"># Restrict height of output cell.</span>
display<span class="token punctuation">(</span>Javascript<span class="token punctuation">(</span><span class="token triple-quoted-string string">'''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

train_dataset <span class="token operator">=</span> GeometricShapes<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'data/GeometricShapes'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                                transform<span class="token operator">=</span>SamplePoints<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_dataset <span class="token operator">=</span> GeometricShapes<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'data/GeometricShapes'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                               transform<span class="token operator">=</span>SamplePoints<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>

model <span class="token operator">=</span> PointNet<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Define loss criterion.</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

    total_loss <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> loader<span class="token punctuation">:</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Clear gradients.</span>
        <span class="token comment" spellcheck="true">#batch(batch=[1280], pos=[1280, 3], ptr=[11], y=[10])</span>
        logits <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>pos<span class="token punctuation">,</span> data<span class="token punctuation">.</span>batch<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Forward pass.</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> data<span class="token punctuation">.</span>y<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Loss computation.</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Backward pass.</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Update model parameters.</span>
        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> data<span class="token punctuation">.</span>num_graphs

    <span class="token keyword">return</span> total_loss <span class="token operator">/</span> len<span class="token punctuation">(</span>train_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>


@torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>

    total_correct <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> loader<span class="token punctuation">:</span>
        logits <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>pos<span class="token punctuation">,</span> data<span class="token punctuation">.</span>batch<span class="token punctuation">)</span>
        pred <span class="token operator">=</span> logits<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        total_correct <span class="token operator">+=</span> int<span class="token punctuation">(</span><span class="token punctuation">(</span>pred <span class="token operator">==</span> data<span class="token punctuation">.</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> total_correct <span class="token operator">/</span> len<span class="token punctuation">(</span>loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">51</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    loss <span class="token operator">=</span> train<span class="token punctuation">(</span>model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> train_loader<span class="token punctuation">)</span>
    test_acc <span class="token operator">=</span> test<span class="token punctuation">(</span>model<span class="token punctuation">,</span> test_loader<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Epoch: {epoch:02d}, Loss: {loss:.4f}, Test Accuracy: {test_acc:.4f}'</span><span class="token punctuation">)</span></code></pre>
<h4 id="8-BigGraph"><a href="#8-BigGraph" class="headerlink" title=".8. BigGraph"></a>.8. BigGraph</h4><blockquote>
<p><strong>Cluster-GCN</strong> (<a href="https://arxiv.org/abs/1905.07953" target="_blank" rel="noopener">Chiang et al. (2019)</a>, which is based on<code>pre-partitioning the graph into subgraphs on which one can operate in a mini-batch fashion</code>.</p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210618134507044.png" alt="image-20210618134507044"></p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> Planetoid
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>transforms <span class="token keyword">import</span> NormalizeFeatures

dataset <span class="token operator">=</span> Planetoid<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'data/Planetoid'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'PubMed'</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>NormalizeFeatures<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#Data(edge_index=[2, 88648], test_mask=[19717], train_mask=[19717], val_mask=[19717], x=[19717, 500], y=[19717])</span>

<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>data <span class="token keyword">import</span> ClusterData<span class="token punctuation">,</span> ClusterLoader
torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">12345</span><span class="token punctuation">)</span>
cluster_data <span class="token operator">=</span> ClusterData<span class="token punctuation">(</span>data<span class="token punctuation">,</span> num_parts<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 1. Create subgraphs.</span>
train_loader <span class="token operator">=</span> ClusterLoader<span class="token punctuation">(</span>cluster_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 2. Stochastic partioning scheme.</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
total_num_nodes <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> step<span class="token punctuation">,</span> sub_data <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Step {step + 1}:'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'======='</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Number of nodes in the current batch: {sub_data.num_nodes}'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sub_data<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Data(edge_index=[2, 15230], test_mask=[4946], train_mask=[4946], val_mask=[4946], x=[4946, 500], y=[4946])</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    total_num_nodes <span class="token operator">+=</span> sub_data<span class="token punctuation">.</span>num_nodes
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Iterated over {total_num_nodes} of {data.num_nodes} nodes!'</span><span class="token punctuation">)</span>


<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> GCNConv
<span class="token keyword">class</span> <span class="token class-name">GCN</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hidden_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>GCN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">12345</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> GCNConv<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>num_node_features<span class="token punctuation">,</span> hidden_channels<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> GCNConv<span class="token punctuation">(</span>hidden_channels<span class="token punctuation">,</span> dataset<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>relu<span class="token punctuation">(</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

model <span class="token operator">=</span> GCN<span class="token punctuation">(</span>hidden_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>



<span class="token keyword">from</span> IPython<span class="token punctuation">.</span>display <span class="token keyword">import</span> Javascript
display<span class="token punctuation">(</span>Javascript<span class="token punctuation">(</span><span class="token triple-quoted-string string">'''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> GCN<span class="token punctuation">(</span>hidden_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">5e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
      model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token keyword">for</span> sub_data <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># Iterate over each mini-batch.</span>
          out <span class="token operator">=</span> model<span class="token punctuation">(</span>sub_data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> sub_data<span class="token punctuation">.</span>edge_index<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Perform a single forward pass.</span>
          loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>out<span class="token punctuation">[</span>sub_data<span class="token punctuation">.</span>train_mask<span class="token punctuation">]</span><span class="token punctuation">,</span> sub_data<span class="token punctuation">.</span>y<span class="token punctuation">[</span>sub_data<span class="token punctuation">.</span>train_mask<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Compute the loss solely based on the training nodes.</span>
          loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Derive gradients.</span>
          optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Update parameters based on gradients.</span>
          optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Clear gradients.</span>
<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
      model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
      out <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index<span class="token punctuation">)</span>
      pred <span class="token operator">=</span> out<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Use the class with highest probability.</span>

      accs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
      <span class="token keyword">for</span> mask <span class="token keyword">in</span> <span class="token punctuation">[</span>data<span class="token punctuation">.</span>train_mask<span class="token punctuation">,</span> data<span class="token punctuation">.</span>val_mask<span class="token punctuation">,</span> data<span class="token punctuation">.</span>test_mask<span class="token punctuation">]</span><span class="token punctuation">:</span>
          correct <span class="token operator">=</span> pred<span class="token punctuation">[</span>mask<span class="token punctuation">]</span> <span class="token operator">==</span> data<span class="token punctuation">.</span>y<span class="token punctuation">[</span>mask<span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># Check against ground-truth labels.</span>
          accs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>int<span class="token punctuation">(</span>correct<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> int<span class="token punctuation">(</span>mask<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Derive ratio of correct predictions.</span>
      <span class="token keyword">return</span> accs
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">51</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    loss <span class="token operator">=</span> train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    train_acc<span class="token punctuation">,</span> val_acc<span class="token punctuation">,</span> test_acc <span class="token operator">=</span> test<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Epoch: {epoch:03d}, Train: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}'</span><span class="token punctuation">)</span></code></pre>
<h4 id="9-GNNModelExplain"><a href="#9-GNNModelExplain" class="headerlink" title=".9. GNNModelExplain"></a>.9. GNNModelExplain</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> TUDataset
path <span class="token operator">=</span> <span class="token string">'.'</span>
dataset <span class="token operator">=</span> TUDataset<span class="token punctuation">(</span>path<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'Mutagenicity'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span><span class="token punctuation">)</span>
test_dataset <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token punctuation">:</span>len<span class="token punctuation">(</span>dataset<span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">10</span><span class="token punctuation">]</span>
train_dataset <span class="token operator">=</span> dataset<span class="token punctuation">[</span>len<span class="token punctuation">(</span>dataset<span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">10</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">)</span>
train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#model define</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Linear
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> global_add_pool<span class="token punctuation">,</span> GraphConv
<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dim<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        num_features <span class="token operator">=</span> dataset<span class="token punctuation">.</span>num_features
        self<span class="token punctuation">.</span>dim <span class="token operator">=</span> dim

        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> GraphConv<span class="token punctuation">(</span>num_features<span class="token punctuation">,</span> dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> GraphConv<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv3 <span class="token operator">=</span> GraphConv<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv4 <span class="token operator">=</span> GraphConv<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv5 <span class="token operator">=</span> GraphConv<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> Linear<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> Linear<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dataset<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> edge_index<span class="token punctuation">,</span> batch<span class="token punctuation">,</span> edge_weight<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">,</span> edge_weight<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">,</span> edge_weight<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv3<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">,</span> edge_weight<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv4<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">,</span> edge_weight<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv5<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">,</span> edge_weight<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> global_add_pool<span class="token punctuation">(</span>x<span class="token punctuation">,</span> batch<span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> F<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># train&amp;test function</span>
<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> epoch <span class="token operator">==</span> <span class="token number">51</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> param_group <span class="token keyword">in</span> optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">:</span>
            param_group<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.5</span> <span class="token operator">*</span> param_group<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span>

    loss_all <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>
        data <span class="token operator">=</span> data<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true">#Batch(batch=[3977], edge_attr=[7906, 3], edge_index=[2, 7906], ptr=[129], x=[3977, 14], y=[128])</span>
        output <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index<span class="token punctuation">,</span> data<span class="token punctuation">.</span>batch<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> F<span class="token punctuation">.</span>nll_loss<span class="token punctuation">(</span>output<span class="token punctuation">,</span> data<span class="token punctuation">.</span>y<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss_all <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> data<span class="token punctuation">.</span>num_graphs
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> loss_all <span class="token operator">/</span> len<span class="token punctuation">(</span>train_dataset<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>

    correct <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> loader<span class="token punctuation">:</span>
        data <span class="token operator">=</span> data<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        output <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index<span class="token punctuation">,</span> data<span class="token punctuation">.</span>batch<span class="token punctuation">)</span>
        pred <span class="token operator">=</span> output<span class="token punctuation">.</span>max<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        correct <span class="token operator">+=</span> pred<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>data<span class="token punctuation">.</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> correct <span class="token operator">/</span> len<span class="token punctuation">(</span>loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>


device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> Net<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    train_loss <span class="token operator">=</span> train<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>
    train_acc <span class="token operator">=</span> test<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span>
    test_acc <span class="token operator">=</span> test<span class="token punctuation">(</span>test_loader<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch: {:03d}, Train Loss: {:.7f}, '</span>
          <span class="token string">'Train Acc: {:.7f}, Test Acc: {:.7f}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> train_loss<span class="token punctuation">,</span>
                                                       train_acc<span class="token punctuation">,</span> test_acc<span class="token punctuation">)</span><span class="token punctuation">)</span>



<span class="token keyword">from</span> captum<span class="token punctuation">.</span>attr <span class="token keyword">import</span> Saliency<span class="token punctuation">,</span> IntegratedGradients
<span class="token keyword">def</span> <span class="token function">model_forward</span><span class="token punctuation">(</span>edge_mask<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    batch <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    out <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index<span class="token punctuation">,</span> batch<span class="token punctuation">,</span> edge_mask<span class="token punctuation">)</span>
    <span class="token keyword">return</span> out


<span class="token keyword">def</span> <span class="token function">explain</span><span class="token punctuation">(</span>method<span class="token punctuation">,</span> data<span class="token punctuation">,</span> target<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    input_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>data<span class="token punctuation">.</span>edge_index<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    <span class="token keyword">if</span> method <span class="token operator">==</span> <span class="token string">'ig'</span><span class="token punctuation">:</span>
        ig <span class="token operator">=</span> IntegratedGradients<span class="token punctuation">(</span>model_forward<span class="token punctuation">)</span>
        mask <span class="token operator">=</span> ig<span class="token punctuation">.</span>attribute<span class="token punctuation">(</span>input_mask<span class="token punctuation">,</span> target<span class="token operator">=</span>target<span class="token punctuation">,</span>
                            additional_forward_args<span class="token operator">=</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                            internal_batch_size<span class="token operator">=</span>data<span class="token punctuation">.</span>edge_index<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">elif</span> method <span class="token operator">==</span> <span class="token string">'saliency'</span><span class="token punctuation">:</span>
        saliency <span class="token operator">=</span> Saliency<span class="token punctuation">(</span>model_forward<span class="token punctuation">)</span>
        mask <span class="token operator">=</span> saliency<span class="token punctuation">.</span>attribute<span class="token punctuation">(</span>input_mask<span class="token punctuation">,</span> target<span class="token operator">=</span>target<span class="token punctuation">,</span>
                                  additional_forward_args<span class="token operator">=</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">raise</span> Exception<span class="token punctuation">(</span><span class="token string">'Unknown explanation method'</span><span class="token punctuation">)</span>

    edge_mask <span class="token operator">=</span> np<span class="token punctuation">.</span>abs<span class="token punctuation">(</span>mask<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> edge_mask<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># avoid division by zero</span>
        edge_mask <span class="token operator">=</span> edge_mask <span class="token operator">/</span> edge_mask<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> edge_mask



<span class="token keyword">import</span> random
<span class="token keyword">from</span> collections <span class="token keyword">import</span> defaultdict
<span class="token keyword">def</span> <span class="token function">aggregate_edge_directions</span><span class="token punctuation">(</span>edge_mask<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    edge_mask_dict <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span>float<span class="token punctuation">)</span>
    <span class="token keyword">for</span> val<span class="token punctuation">,</span> u<span class="token punctuation">,</span> v <span class="token keyword">in</span> list<span class="token punctuation">(</span>zip<span class="token punctuation">(</span>edge_mask<span class="token punctuation">,</span> <span class="token operator">*</span>data<span class="token punctuation">.</span>edge_index<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        u<span class="token punctuation">,</span> v <span class="token operator">=</span> u<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> v<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> u <span class="token operator">></span> v<span class="token punctuation">:</span>
            u<span class="token punctuation">,</span> v <span class="token operator">=</span> v<span class="token punctuation">,</span> u
        edge_mask_dict<span class="token punctuation">[</span><span class="token punctuation">(</span>u<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">+=</span> val
    <span class="token keyword">return</span> edge_mask_dict

data <span class="token operator">=</span> random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span><span class="token punctuation">[</span>t <span class="token keyword">for</span> t <span class="token keyword">in</span> test_dataset <span class="token keyword">if</span> <span class="token operator">not</span> t<span class="token punctuation">.</span>y<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
mol <span class="token operator">=</span> to_molecule<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
<span class="token keyword">for</span> title<span class="token punctuation">,</span> method <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'Integrated Gradients'</span><span class="token punctuation">,</span> <span class="token string">'ig'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'Saliency'</span><span class="token punctuation">,</span> <span class="token string">'saliency'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    edge_mask <span class="token operator">=</span> explain<span class="token punctuation">(</span>method<span class="token punctuation">,</span> data<span class="token punctuation">,</span> target<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    edge_mask_dict <span class="token operator">=</span> aggregate_edge_directions<span class="token punctuation">(</span>edge_mask<span class="token punctuation">,</span> data<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>title<span class="token punctuation">)</span>
    draw_molecule<span class="token punctuation">(</span>mol<span class="token punctuation">,</span> edge_mask_dict<span class="token punctuation">)</span></code></pre>
<h3 id="5-Visualization"><a href="#5-Visualization" class="headerlink" title="5. Visualization"></a>5. Visualization</h3><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>utils <span class="token keyword">import</span> to_networkx
<span class="token operator">%</span>matplotlib inline
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> networkx <span class="token keyword">as</span> nx
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt


<span class="token keyword">def</span> <span class="token function">visualize</span><span class="token punctuation">(</span>h<span class="token punctuation">,</span> color<span class="token punctuation">,</span> epoch<span class="token operator">=</span>None<span class="token punctuation">,</span> loss<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>yticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> torch<span class="token punctuation">.</span>is_tensor<span class="token punctuation">(</span>h<span class="token punctuation">)</span><span class="token punctuation">:</span>
        h <span class="token operator">=</span> h<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>h<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> h<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">140</span><span class="token punctuation">,</span> c<span class="token operator">=</span>color<span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">"Set2"</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> epoch <span class="token keyword">is</span> <span class="token operator">not</span> None <span class="token operator">and</span> loss <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>
            plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span>f<span class="token string">'Epoch: {epoch}, Loss: {loss.item():.4f}'</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        nx<span class="token punctuation">.</span>draw_networkx<span class="token punctuation">(</span>G<span class="token punctuation">,</span> pos<span class="token operator">=</span>nx<span class="token punctuation">.</span>spring_layout<span class="token punctuation">(</span>G<span class="token punctuation">,</span> seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token punctuation">,</span> with_labels<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                         node_color<span class="token operator">=</span>color<span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">"Set2"</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#data: Data(edge_index=[2, 156], train_mask=[34], x=[34, 34], y=[34])    </span>
G <span class="token operator">=</span> to_networkx<span class="token punctuation">(</span>data<span class="token punctuation">,</span> to_undirected<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#G &lt;class 'networkx.classes.graph.Graph'></span>
visualize<span class="token punctuation">(</span>G<span class="token punctuation">,</span> color<span class="token operator">=</span>data<span class="token punctuation">.</span>y<span class="token punctuation">)</span></code></pre>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> networkx <span class="token keyword">as</span> nx
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>utils <span class="token keyword">import</span> to_networkx


<span class="token keyword">def</span> <span class="token function">draw_molecule</span><span class="token punctuation">(</span>g<span class="token punctuation">,</span> edge_mask<span class="token operator">=</span>None<span class="token punctuation">,</span> draw_edge_labels<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    g <span class="token operator">=</span> g<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to_undirected<span class="token punctuation">(</span><span class="token punctuation">)</span>
    node_labels <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
    <span class="token keyword">for</span> u<span class="token punctuation">,</span> data <span class="token keyword">in</span> g<span class="token punctuation">.</span>nodes<span class="token punctuation">(</span>data<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        node_labels<span class="token punctuation">[</span>u<span class="token punctuation">]</span> <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span>
    pos <span class="token operator">=</span> nx<span class="token punctuation">.</span>planar_layout<span class="token punctuation">(</span>g<span class="token punctuation">)</span>
    pos <span class="token operator">=</span> nx<span class="token punctuation">.</span>spring_layout<span class="token punctuation">(</span>g<span class="token punctuation">,</span> pos<span class="token operator">=</span>pos<span class="token punctuation">)</span>
    <span class="token keyword">if</span> edge_mask <span class="token keyword">is</span> None<span class="token punctuation">:</span>
        edge_color <span class="token operator">=</span> <span class="token string">'black'</span>
        widths <span class="token operator">=</span> None
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        edge_color <span class="token operator">=</span> <span class="token punctuation">[</span>edge_mask<span class="token punctuation">[</span><span class="token punctuation">(</span>u<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> u<span class="token punctuation">,</span> v <span class="token keyword">in</span> g<span class="token punctuation">.</span>edges<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        widths <span class="token operator">=</span> <span class="token punctuation">[</span>x <span class="token operator">*</span> <span class="token number">10</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> edge_color<span class="token punctuation">]</span>
    nx<span class="token punctuation">.</span>draw<span class="token punctuation">(</span>g<span class="token punctuation">,</span> pos<span class="token operator">=</span>pos<span class="token punctuation">,</span> labels<span class="token operator">=</span>node_labels<span class="token punctuation">,</span> width<span class="token operator">=</span>widths<span class="token punctuation">,</span>
            edge_color<span class="token operator">=</span>edge_color<span class="token punctuation">,</span> edge_cmap<span class="token operator">=</span>plt<span class="token punctuation">.</span>cm<span class="token punctuation">.</span>Blues<span class="token punctuation">,</span>
            node_color<span class="token operator">=</span><span class="token string">'azure'</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> draw_edge_labels <span class="token operator">and</span> edge_mask <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>
        edge_labels <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token string">'%.2f'</span> <span class="token operator">%</span> v<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> edge_mask<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>    
        nx<span class="token punctuation">.</span>draw_networkx_edge_labels<span class="token punctuation">(</span>g<span class="token punctuation">,</span> pos<span class="token punctuation">,</span> edge_labels<span class="token operator">=</span>edge_labels<span class="token punctuation">,</span>
                                    font_color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">to_molecule</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    ATOM_MAP <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'C'</span><span class="token punctuation">,</span> <span class="token string">'O'</span><span class="token punctuation">,</span> <span class="token string">'Cl'</span><span class="token punctuation">,</span> <span class="token string">'H'</span><span class="token punctuation">,</span> <span class="token string">'N'</span><span class="token punctuation">,</span> <span class="token string">'F'</span><span class="token punctuation">,</span>
                <span class="token string">'Br'</span><span class="token punctuation">,</span> <span class="token string">'S'</span><span class="token punctuation">,</span> <span class="token string">'P'</span><span class="token punctuation">,</span> <span class="token string">'I'</span><span class="token punctuation">,</span> <span class="token string">'Na'</span><span class="token punctuation">,</span> <span class="token string">'K'</span><span class="token punctuation">,</span> <span class="token string">'Li'</span><span class="token punctuation">,</span> <span class="token string">'Ca'</span><span class="token punctuation">]</span>
    g <span class="token operator">=</span> to_networkx<span class="token punctuation">(</span>data<span class="token punctuation">,</span> node_attrs<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'x'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> u<span class="token punctuation">,</span> data <span class="token keyword">in</span> g<span class="token punctuation">.</span>nodes<span class="token punctuation">(</span>data<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        data<span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span> <span class="token operator">=</span> ATOM_MAP<span class="token punctuation">[</span>data<span class="token punctuation">[</span><span class="token string">'x'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>index<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token keyword">del</span> data<span class="token punctuation">[</span><span class="token string">'x'</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> g

<span class="token keyword">import</span> random
data <span class="token operator">=</span> random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span><span class="token punctuation">[</span>t <span class="token keyword">for</span> t <span class="token keyword">in</span> train_dataset<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span>data<span class="token punctuation">)</span>
mol <span class="token operator">=</span> to_molecule<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>mol<span class="token punctuation">)</span><span class="token punctuation">)</span>
draw_molecule<span class="token punctuation">(</span>mol<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#&lt;class 'torch_geometric.data.data.Data'> Data(edge_attr=[76, 3], edge_index=[2, 76], x=[34, 14], y=[1])</span>
<span class="token comment" spellcheck="true">#&lt;class 'networkx.classes.digraph.DiGraph'></span></code></pre>
<h3 id="6-Demo"><a href="#6-Demo" class="headerlink" title="6. Demo"></a>6. Demo</h3><h4 id="1-Customed-dataset"><a href="#1-Customed-dataset" class="headerlink" title=".1. Customed dataset"></a>.1. Customed dataset</h4><ul>
<li>dataset generate</li>
</ul>
<blockquote>
<ul>
<li><p>10 graphs and 30 nodes per graph with random edges connections</p>
</li>
<li><p>number of node feature = 3</p>
</li>
<li><p>number of edge feature = 1</p>
</li>
<li><p>node’s classification and graph classification</p>
<p>  Adj [num_graph, num_node, num_node] be the adjacent matrices (sparse)<br>  node_feature [num_graph, num_node, num_node_feature]<br>  edge_feature [num_graph, num_node, num_node] (sparse)</p>
</li>
</ul>
</blockquote>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> os
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>data <span class="token keyword">import</span> InMemoryDataset
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>data <span class="token keyword">import</span> Data
<span class="token keyword">import</span> torch_geometric<span class="token punctuation">.</span>utils <span class="token keyword">as</span> ut
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">42</span><span class="token punctuation">)</span>

num_graph <span class="token operator">=</span> <span class="token number">10</span>
num_node <span class="token operator">=</span> <span class="token number">50</span>
num_node_features <span class="token operator">=</span> <span class="token number">3</span>
num_edge_features <span class="token operator">=</span> <span class="token number">1</span>

Adj <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>num_graph<span class="token punctuation">,</span> num_node<span class="token punctuation">,</span> num_node<span class="token punctuation">)</span>
Adj<span class="token punctuation">[</span>Adj <span class="token operator">>=</span> <span class="token number">0.8</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">True</span>
Adj<span class="token punctuation">[</span>Adj <span class="token operator">&lt;=</span> <span class="token number">0.8</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span>
node_feature <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>num_graph<span class="token punctuation">,</span> num_node<span class="token punctuation">,</span> num_node_features<span class="token punctuation">)</span>
edge_feature <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>num_graph<span class="token punctuation">,</span> num_node<span class="token punctuation">,</span> num_node<span class="token punctuation">)</span> <span class="token operator">*</span> Adj

graph_label <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>num_graph<span class="token punctuation">)</span>
graph_label<span class="token punctuation">[</span>graph_label<span class="token operator">></span><span class="token number">0.5</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
graph_label<span class="token punctuation">[</span>graph_label<span class="token operator">&lt;</span><span class="token number">0.5</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
graph_label <span class="token operator">=</span> graph_label<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>int<span class="token punctuation">)</span>

node_label <span class="token operator">=</span> np<span class="token punctuation">.</span> random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>num_graph<span class="token punctuation">,</span> num_node<span class="token punctuation">)</span>
node_label<span class="token punctuation">[</span>node_label<span class="token operator">></span><span class="token number">0.5</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
node_label<span class="token punctuation">[</span>node_label<span class="token operator">&lt;</span><span class="token number">0.5</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
node_label <span class="token operator">=</span> node_label<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>int<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>Adj<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> edge_feature<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> node_feature<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p><img src="../../../../picture/image-20210621114008066.png" alt="image-20210621114008066"></p>
<h4 id="2-Graph-Classification"><a href="#2-Graph-Classification" class="headerlink" title=".2. Graph Classification"></a>.2. Graph Classification</h4><blockquote>
<p>一个graph数据对应一个Data， 可以将多个graph存储到一个data文件里面，也可以将每个graph存在对应单独的data文件里面。</p>
</blockquote>
<ul>
<li>multi-graph&amp;one data</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GraphDatasetInMem</span><span class="token punctuation">(</span>InMemoryDataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Graph classification 
    """</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> root<span class="token punctuation">,</span> transform<span class="token operator">=</span>None<span class="token punctuation">,</span> pre_transform<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>GraphDatasetInMem<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>root<span class="token punctuation">,</span>transform<span class="token punctuation">,</span> pre_transform<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>data<span class="token punctuation">,</span> self<span class="token punctuation">.</span>slices <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>self<span class="token punctuation">.</span>processed_paths<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    @property
    <span class="token keyword">def</span> <span class="token function">raw_file_names</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    @property
    <span class="token keyword">def</span> <span class="token function">processed_file_names</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span>r<span class="token string">'.\GraphDatasetInMem.dataset'</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">download</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>

    <span class="token keyword">def</span> <span class="token function">process</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        data_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true"># graph classification need to define data_list for multiple graph</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_graph<span class="token punctuation">)</span><span class="token punctuation">:</span>
            source_nodes<span class="token punctuation">,</span> target_nodes <span class="token operator">=</span> np<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>Adj<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            source_nodes <span class="token operator">=</span> source_nodes<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            target_nodes <span class="token operator">=</span> target_nodes<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

            edge_index <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>source_nodes<span class="token punctuation">,</span> target_nodes<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>long<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># edge_index should be long type</span>

            edge_weight <span class="token operator">=</span> edge_feature<span class="token punctuation">[</span>i<span class="token punctuation">,</span> source_nodes<span class="token punctuation">,</span> target_nodes<span class="token punctuation">]</span>
            edge_weight <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>edge_weight<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> num_edge_features<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># edge_index should be float</span>
            type

            x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>node_feature<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span> 

            <span class="token comment" spellcheck="true"># y should be long type, graph label should not be a 0-dimesion tensor</span>
            <span class="token comment" spellcheck="true"># use [graph_label[i]] ranther than graph_label[i]</span>
            y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>graph_label<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>long<span class="token punctuation">)</span> 

            data <span class="token operator">=</span> Data<span class="token punctuation">(</span>x<span class="token operator">=</span>x<span class="token punctuation">,</span> edge_index<span class="token operator">=</span>edge_index<span class="token punctuation">,</span> y<span class="token operator">=</span>y<span class="token punctuation">,</span> edge_attr<span class="token operator">=</span>edge_weight<span class="token punctuation">)</span>
            data_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

        data<span class="token punctuation">,</span> slices <span class="token operator">=</span> self<span class="token punctuation">.</span>collate<span class="token punctuation">(</span>data_list<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># Here used to be [data] for one graph</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> slices<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>processed_paths<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#usage</span>
dataset_graph_InMem <span class="token operator">=</span> GraphDatasetInMem<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>dataset_graph_InMem<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>dataset_graph_InMem<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#output</span>
<span class="token comment" spellcheck="true">#Data(edge_attr=[504, 1], edge_index=[2, 504], x=[50, 3], y=[1])</span>
<span class="token comment" spellcheck="true">#Data(edge_attr=[495, 1], edge_index=[2, 495], x=[50, 3], y=[1])</span></code></pre>
<ul>
<li>one graph one pt file</li>
</ul>
<blockquote>
<p>区别在于：没有data, slices = self.collate(data_list) # Here used to be [data] for one graph，但是有以下函数：</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        data <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>osp<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>processed_dir<span class="token punctuation">,</span> <span class="token string">'graphDataset1_{}.pt'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> data</code></pre>
</blockquote>
<pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GraphDataset_1</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Graph classification 
    """</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> root<span class="token punctuation">,</span> transform<span class="token operator">=</span>None<span class="token punctuation">,</span> pre_transform<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>GraphDataset_1<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>root<span class="token punctuation">,</span>transform<span class="token punctuation">,</span> pre_transform<span class="token punctuation">)</span>

    @property
    <span class="token keyword">def</span> <span class="token function">raw_file_names</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    @property
    <span class="token keyword">def</span> <span class="token function">processed_file_names</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span>r<span class="token string">'.\GraphDataset1_0.pt'</span><span class="token punctuation">,</span> r<span class="token string">'.\GraphDataset1_1.pt'</span><span class="token punctuation">,</span> r<span class="token string">'.\GraphDataset1_2.pt'</span><span class="token punctuation">,</span> r<span class="token string">'.\GraphDataset1_3.pt'</span><span class="token punctuation">,</span> r<span class="token string">'.\GraphDataset1_4.pt'</span><span class="token punctuation">,</span> r<span class="token string">'.\GraphDataset1_5.pt'</span><span class="token punctuation">,</span> r<span class="token string">'.\GraphDataset1_6.pt'</span><span class="token punctuation">,</span> r<span class="token string">'.\GraphDataset1_7.pt'</span><span class="token punctuation">,</span> r<span class="token string">'.\GraphDataset1_8.pt'</span><span class="token punctuation">,</span> r<span class="token string">'.\GraphDataset1_9.pt'</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">download</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>

    <span class="token keyword">def</span> <span class="token function">process</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true">#data_list = [] # graph classification need to define data_list for multiple graph</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_graph<span class="token punctuation">)</span><span class="token punctuation">:</span>
            source_nodes<span class="token punctuation">,</span> target_nodes <span class="token operator">=</span> np<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>Adj<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            source_nodes <span class="token operator">=</span> source_nodes<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            target_nodes <span class="token operator">=</span> target_nodes<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

            edge_index <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>source_nodes<span class="token punctuation">,</span> target_nodes<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>long<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># edge_index should be long type</span>

            edge_weight <span class="token operator">=</span> edge_feature<span class="token punctuation">[</span>i<span class="token punctuation">,</span> source_nodes<span class="token punctuation">,</span> target_nodes<span class="token punctuation">]</span>
            edge_weight <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>edge_weight<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> num_edge_features<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># edge_index should be float</span>
            type

            x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>node_feature<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span> 

            <span class="token comment" spellcheck="true"># y should be long type, graph label should not be a 0-dimesion tensor</span>
            <span class="token comment" spellcheck="true"># use [graph_label[i]] ranther than graph_label[i]</span>
            y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>graph_label<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>long<span class="token punctuation">)</span> 

            data <span class="token operator">=</span> Data<span class="token punctuation">(</span>x<span class="token operator">=</span>x<span class="token punctuation">,</span> edge_index<span class="token operator">=</span>edge_index<span class="token punctuation">,</span> y<span class="token operator">=</span>y<span class="token punctuation">,</span> edge_attr<span class="token operator">=</span>edge_weight<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true">#data_list.append(data)</span>
            <span class="token comment" spellcheck="true"># save one graph per time</span>
            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>data<span class="token punctuation">,</span> osp<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>processed_dir<span class="token punctuation">,</span> <span class="token string">'graphDataset1_{}.pt'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">len</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>processed_file_names<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">get</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        data <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>osp<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>processed_dir<span class="token punctuation">,</span> <span class="token string">'graphDataset1_{}.pt'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> data

<span class="token comment" spellcheck="true"># usage</span>
dataset_graph_1 <span class="token operator">=</span> GraphDataset_1<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>dataset_graph_1<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>dataset_graph_1<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#Data(edge_attr=[504, 1], edge_index=[2, 504], x=[50, 3], y=[1])</span>
<span class="token comment" spellcheck="true">#Data(edge_attr=[495, 1], edge_index=[2, 495], x=[50, 3], y=[1])</span></code></pre>
<h4 id="3-Node-Classification"><a href="#3-Node-Classification" class="headerlink" title=".3. Node Classification"></a>.3. Node Classification</h4><ul>
<li>in on graph</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> os<span class="token punctuation">.</span>path <span class="token keyword">as</span> osp
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset
<span class="token keyword">class</span> <span class="token class-name">NodeDatasetInMem</span><span class="token punctuation">(</span>InMemoryDataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    node classification in one graph
    Should define the mask for training, validation and test
    """</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> root<span class="token punctuation">,</span> num_train_per_class<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">,</span> num_val<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> num_test<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>None<span class="token punctuation">,</span> pre_transform<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>num_train_per_class <span class="token operator">=</span> num_train_per_class
        self<span class="token punctuation">.</span>num_val <span class="token operator">=</span> num_val
        self<span class="token punctuation">.</span>num_test <span class="token operator">=</span> num_test
        super<span class="token punctuation">(</span>NodeDatasetInMem<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>root<span class="token punctuation">,</span>transform<span class="token punctuation">,</span> pre_transform<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>data<span class="token punctuation">,</span> self<span class="token punctuation">.</span>slices <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>self<span class="token punctuation">.</span>processed_paths<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    @property
    <span class="token keyword">def</span> <span class="token function">raw_file_names</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    @property
    <span class="token keyword">def</span> <span class="token function">processed_file_names</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span>r<span class="token string">'.\NodeDatasetInMem.dataset'</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">download</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>

    <span class="token keyword">def</span> <span class="token function">process</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        num_train_per_class <span class="token operator">=</span> self<span class="token punctuation">.</span>num_train_per_class
        num_val <span class="token operator">=</span> self<span class="token punctuation">.</span>num_val
        num_test <span class="token operator">=</span> self<span class="token punctuation">.</span>num_test
        <span class="token comment" spellcheck="true">#data_list = []  # node classification do not neet to define data_list just data (one graph)</span>
        i<span class="token operator">=</span><span class="token number">0</span>
        source_nodes<span class="token punctuation">,</span> target_nodes <span class="token operator">=</span> np<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>Adj<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        source_nodes <span class="token operator">=</span> source_nodes<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        target_nodes <span class="token operator">=</span> target_nodes<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        edge_index <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>source_nodes<span class="token punctuation">,</span> target_nodes<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>long<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># edge_index should be long type</span>

        edge_weight <span class="token operator">=</span> edge_feature<span class="token punctuation">[</span>i<span class="token punctuation">,</span> source_nodes<span class="token punctuation">,</span> target_nodes<span class="token punctuation">]</span>
        edge_weight <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>edge_weight<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> num_edge_features<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># edge_index should be float</span>
        type
        train_mask <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>num_node<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>bool<span class="token punctuation">)</span>
        val_mask <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>num_node<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>bool<span class="token punctuation">)</span>
        test_mask <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>num_node<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>bool<span class="token punctuation">)</span>

        label <span class="token operator">=</span> node_label<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
        <span class="token punctuation">[</span>org_class_0_ind<span class="token punctuation">]</span> <span class="token operator">=</span>  np<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>label <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> 
        org_class_0_ind <span class="token operator">=</span> org_class_0_ind<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        perm_class_0_ind <span class="token operator">=</span> org_class_0_ind<span class="token punctuation">[</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>permutation<span class="token punctuation">(</span>org_class_0_ind<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

        <span class="token punctuation">[</span>org_class_1_ind<span class="token punctuation">]</span> <span class="token operator">=</span>  np<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>label <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span> 
        org_class_1_ind <span class="token operator">=</span> org_class_1_ind<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        perm_class_1_ind <span class="token operator">=</span> org_class_1_ind<span class="token punctuation">[</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>permutation<span class="token punctuation">(</span>org_class_1_ind<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>


        train_ind <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>perm_class_0_ind<span class="token punctuation">[</span><span class="token punctuation">:</span>num_train_per_class<span class="token punctuation">]</span><span class="token punctuation">,</span> perm_class_1_ind<span class="token punctuation">[</span><span class="token punctuation">:</span>num_train_per_class<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        train_mask<span class="token punctuation">[</span>train_ind<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">True</span>

        <span class="token punctuation">[</span>remaining<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span><span class="token operator">~</span>train_mask<span class="token punctuation">)</span>
        remaining <span class="token operator">=</span> remaining<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

        val_mask<span class="token punctuation">[</span>remaining<span class="token punctuation">[</span><span class="token punctuation">:</span>num_val<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">True</span>
        test_mask<span class="token punctuation">[</span>remaining<span class="token punctuation">[</span>num_val<span class="token punctuation">:</span>num_val<span class="token operator">+</span>num_test<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">True</span>

        train_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>train_mask<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># mask should be long type</span>
        val_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>val_mask<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span>
        test_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>test_mask<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span>

        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>node_feature<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span> 
        y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>node_label<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>long<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># y should be long type</span>

        data <span class="token operator">=</span> Data<span class="token punctuation">(</span>x<span class="token operator">=</span>x<span class="token punctuation">,</span> edge_index<span class="token operator">=</span>edge_index<span class="token punctuation">,</span> y<span class="token operator">=</span>y<span class="token punctuation">,</span> edge_attr<span class="token operator">=</span>edge_weight<span class="token punctuation">,</span> train_mask <span class="token operator">=</span> train_mask<span class="token punctuation">,</span> val_mask <span class="token operator">=</span> val_mask<span class="token punctuation">,</span> test_mask <span class="token operator">=</span> test_mask<span class="token punctuation">)</span>

        data<span class="token punctuation">,</span> slices <span class="token operator">=</span> self<span class="token punctuation">.</span>collate<span class="token punctuation">(</span><span class="token punctuation">[</span>data<span class="token punctuation">]</span><span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> slices<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>processed_paths<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

 <span class="token comment" spellcheck="true">#output</span>
dataset_node_InMem <span class="token operator">=</span> NodeDatasetInMem<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>dataset_node_InMem<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>dataset_node_InMem<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#tensor([1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1,1, 1])</span>
<span class="token comment" spellcheck="true">#torch.Size([50])</span></code></pre>
<pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">NodeDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    node classification in one graph
    Should define the mask for training, validation and test
    """</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> root<span class="token punctuation">,</span> num_train_per_class<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">,</span> num_val<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> num_test<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>None<span class="token punctuation">,</span> pre_transform<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>num_train_per_class <span class="token operator">=</span> num_train_per_class
        self<span class="token punctuation">.</span>num_val <span class="token operator">=</span> num_val
        self<span class="token punctuation">.</span>num_test <span class="token operator">=</span> num_test
        super<span class="token punctuation">(</span>NodeDataset<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>root<span class="token punctuation">,</span>transform<span class="token punctuation">,</span> pre_transform<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># Do not load the data and slices here</span>
        <span class="token comment" spellcheck="true">#self.data, self.slices = torch.load(self.processed_paths[0])</span>

    @property
    <span class="token keyword">def</span> <span class="token function">raw_file_names</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    @property
    <span class="token keyword">def</span> <span class="token function">processed_file_names</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span>r<span class="token string">'./NodeDataset_0.pt'</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">download</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>

    <span class="token keyword">def</span> <span class="token function">process</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        num_train_per_class <span class="token operator">=</span> self<span class="token punctuation">.</span>num_train_per_class
        num_val <span class="token operator">=</span> self<span class="token punctuation">.</span>num_val
        num_test <span class="token operator">=</span> self<span class="token punctuation">.</span>num_test
        <span class="token comment" spellcheck="true">#data_list = []  # node classification do not neet to define data_list just data (one graph)</span>
        i<span class="token operator">=</span><span class="token number">0</span>
        source_nodes<span class="token punctuation">,</span> target_nodes <span class="token operator">=</span> np<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>Adj<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        source_nodes <span class="token operator">=</span> source_nodes<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        target_nodes <span class="token operator">=</span> target_nodes<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        edge_index <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>source_nodes<span class="token punctuation">,</span> target_nodes<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>long<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># edge_index should be long type</span>

        edge_weight <span class="token operator">=</span> edge_feature<span class="token punctuation">[</span>i<span class="token punctuation">,</span> source_nodes<span class="token punctuation">,</span> target_nodes<span class="token punctuation">]</span>
        edge_weight <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>edge_weight<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> num_edge_features<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># edge_index should be float</span>
        type
        train_mask <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>num_node<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>bool<span class="token punctuation">)</span>
        val_mask <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>num_node<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>bool<span class="token punctuation">)</span>
        test_mask <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>num_node<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>bool<span class="token punctuation">)</span>

        label <span class="token operator">=</span> node_label<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
        <span class="token punctuation">[</span>org_class_0_ind<span class="token punctuation">]</span> <span class="token operator">=</span>  np<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>label <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> 
        org_class_0_ind <span class="token operator">=</span> org_class_0_ind<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        perm_class_0_ind <span class="token operator">=</span> org_class_0_ind<span class="token punctuation">[</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>permutation<span class="token punctuation">(</span>org_class_0_ind<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

        <span class="token punctuation">[</span>org_class_1_ind<span class="token punctuation">]</span> <span class="token operator">=</span>  np<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>label <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span> 
        org_class_1_ind <span class="token operator">=</span> org_class_1_ind<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        perm_class_1_ind <span class="token operator">=</span> org_class_1_ind<span class="token punctuation">[</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>permutation<span class="token punctuation">(</span>org_class_1_ind<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>


        train_ind <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>perm_class_0_ind<span class="token punctuation">[</span><span class="token punctuation">:</span>num_train_per_class<span class="token punctuation">]</span><span class="token punctuation">,</span> perm_class_1_ind<span class="token punctuation">[</span><span class="token punctuation">:</span>num_train_per_class<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        train_mask<span class="token punctuation">[</span>train_ind<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">True</span>

        <span class="token punctuation">[</span>remaining<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span><span class="token operator">~</span>train_mask<span class="token punctuation">)</span>
        remaining <span class="token operator">=</span> remaining<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

        val_mask<span class="token punctuation">[</span>remaining<span class="token punctuation">[</span><span class="token punctuation">:</span>num_val<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">True</span>
        test_mask<span class="token punctuation">[</span>remaining<span class="token punctuation">[</span>num_val<span class="token punctuation">:</span>num_val<span class="token operator">+</span>num_test<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">True</span>

        train_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>train_mask<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># mask should be long type</span>
        val_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>val_mask<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span>
        test_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>test_mask<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span>

        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>node_feature<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span> 
        y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>node_label<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>long<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># y should be long type</span>

        data <span class="token operator">=</span> Data<span class="token punctuation">(</span>x<span class="token operator">=</span>x<span class="token punctuation">,</span> edge_index<span class="token operator">=</span>edge_index<span class="token punctuation">,</span> y<span class="token operator">=</span>y<span class="token punctuation">,</span> edge_attr<span class="token operator">=</span>edge_weight<span class="token punctuation">,</span> train_mask <span class="token operator">=</span> train_mask<span class="token punctuation">,</span> val_mask <span class="token operator">=</span> val_mask<span class="token punctuation">,</span> test_mask <span class="token operator">=</span> test_mask<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># Directly save the data in order as .pt form</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>data<span class="token punctuation">,</span> osp<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>processed_dir<span class="token punctuation">,</span> <span class="token string">'NodeDataset_{}.pt'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">len</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>processed_file_names<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">get</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        data <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>osp<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>processed_dir<span class="token punctuation">,</span> <span class="token string">'NodeDataset_{}.pt'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> data
   <span class="token comment" spellcheck="true">#</span>
dataset_node <span class="token operator">=</span> NodeDataset<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./'</span><span class="token punctuation">)</span>
dataset_node<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token comment" spellcheck="true">#Data(edge_attr=[504, 1], edge_index=[2, 504], test_mask=[50], train_mask=[50], val_mask=[50], x=[50, 3], y=[50])</span></code></pre>
<h3 id="Resouce"><a href="#Resouce" class="headerlink" title="Resouce"></a>Resouce</h3><ul>
<li><a href="https://github.com/rusty1s/pytorch_geometric" target="_blank" rel="noopener">pytorch_geometric11.3k </a> <a href="https://pytorch-geometric.readthedocs.io/en/latest/notes/colabs.html" target="_blank" rel="noopener">pytorch_geometric11.3k_demo</a></li>
<li><a href="https://github.com/benedekrozemberczki/pytorch_geometric_temporal" target="_blank" rel="noopener">pytorch_geometric_temporal</a>  : A Temporal Extension Library for PyTorch Geometric</li>
<li><a href="https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html" target="_blank" rel="noopener">https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html</a></li>
<li><a href="https://colab.research.google.com/drive/1h3-vJGRVloF5zStxL5I0rSy4ZUPNsjy8?usp=sharing" target="_blank" rel="noopener">Introduction: Hands-on Graph Neural Networks</a></li>
<li><a href="https://colab.research.google.com/drive/14OvFnAXggxB8vM4e8vSURUp1TaKnovzX?usp=sharing" target="_blank" rel="noopener">Node Classification with Graph Neural Networks</a></li>
<li><a href="https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing" target="_blank" rel="noopener">Graph Classification with Graph Neural Networks</a></li>
<li><a href="https://colab.research.google.com/drive/1XAjcjRHrSR_ypCk_feIWFbcBKyT4Lirs?usp=sharing" target="_blank" rel="noopener">Scaling Graph Neural Networks</a></li>
<li><a href="https://colab.research.google.com/drive/1D45E5bUK3gQ40YpZo65ozs7hg5l-eo_U?usp=sharing" target="_blank" rel="noopener">Point Cloud Classification with Graph Neural Networks</a></li>
<li><a href="https://colab.research.google.com/drive/1fLJbFPz0yMCQg81DdCP5I8jXw9LoggKO?usp=sharing" target="_blank" rel="noopener">Explaining GNN Model Predictions using Captum</a></li>
<li><a href="http://htmlpreview.github.io/?https://github.com/rusty1s/rusty1s.github.io/blob/master/pyg_notebook.html" target="_blank" rel="noopener">Fast Graph Representation</a></li>
<li><a href="https://github.com/GQ93/Pytorch-geometric-notes/blob/master/costumed_graph_datasets.ipynb" target="_blank" rel="noopener">custom dataset</a> </li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://liudongdong1.github.io" rel="external nofollow noreferrer">liudongdong1</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://liudongdong1.github.io/2021/06/14/shi-kong-shu-ju/gnn/pytorchgnn/">https://liudongdong1.github.io/2021/06/14/shi-kong-shu-ju/gnn/pytorchgnn/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint polocy. If reproduced, please indicate source
                    <a href="https://liudongdong1.github.io" target="_blank">liudongdong1</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/pytorch/">
                                    <span class="chip bg-color">pytorch</span>
                                </a>
                            
                                <a href="/tags/GNN/">
                                    <span class="chip bg-color">GNN</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="qq,qzone,wechat,weibo,douban" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/2021/06/14/shi-kong-shu-ju/gnn/pytorch3d/">
                    <div class="card-image">
                        
                        <img src="https://cdn.pixabay.com/photo/2021/03/19/04/49/kid-6106557__340.jpg" class="responsive-img" alt="Pytorch3D">
                        
                        <span class="card-title">Pytorch3D</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
Chaton, Thomas, et al. “Torch-Points3D: A Modular Multi-Task Frameworkfor Reproducible Deep Learning on 3D Point Clouds
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2021-06-14
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E6%97%B6%E7%A9%BA%E6%95%B0%E6%8D%AE/" class="post-category">
                                    时空数据
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/pytorch/">
                        <span class="chip bg-color">pytorch</span>
                    </a>
                    
                    <a href="/tags/GNN/">
                        <span class="chip bg-color">GNN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2021/06/14/bian-cheng-yu-yan/ke-shi-hua/frfntptn/">
                    <div class="card-image">
                        
                        <img src="https://cdn.stocksnap.io/img-thumbs/280h/UELPTNOKP4.jpg" class="responsive-img" alt="FRFNTPTN">
                        
                        <span class="card-title">FRFNTPTN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            0. python统计函数import numpy as np
layerData = np.loadtxt(open('./data/layer_test_acc.csv', "r"), delimiter=",", skiprows=1
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-06-14
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E8%AF%AD%E8%A8%80%E6%A1%86%E6%9E%B6/" class="post-category">
                                    语言框架
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/visual/">
                        <span class="chip bg-color">visual</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <!-- <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="463294659"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2019</span>
            <a href="https://liudongdong1.github.io" target="_blank">liudongdong</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">1413.4k</span>&nbsp;字
            
            
            
            
            
            
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/liudongdong1/" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:3463264078@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>














    <a href="https://blog.csdn.net/liudongdong19/" class="tooltipped" target="_blank" data-tooltip="关注我的CSDN: https://blog.csdn.net/liudongdong19/" data-position="top" data-delay="50">
        <i class="fab fa-csdn">C</i>
    </a>





</div>
    </div>
</footer>

<div class="progress-bar"></div>
 -->

    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/search.xml", 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script type="text/javascript" src="/js/CFS.Snow.min.js"></script>
    <!-- 点击爆灯效果 -->
    <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas> 
    <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script> 
    <script type="text/javascript" src="/js/fireworks.js"></script>
    <!--动态线条背景-->
    <script type="text/javascript"
        color="122 103 238" opacity='0.7' zIndex="-2" count="200" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js">
    </script>
    <!-- 天气 -->
    <!-- weather -->
    <!-- weather -->
    <script type="text/javascript">
         WIDGET = {FID: 'knAMQaFanP'}
    </script>
    <script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"></script>
    <script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"></script>
    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    

    
    
    <script type="text/javascript" size="150" alpha='0.6'
        zIndex="-1" src="/libs/background/ribbon-refresh.min.js" async="async"></script>
    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    
    <!-- {% include '_custom/custom.swig' %} -->

</body>

</html>
