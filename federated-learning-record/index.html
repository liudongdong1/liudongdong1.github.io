<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <head>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>Federated Learning Record - DAY By DAY</title><meta name="author" content="LiuDongdong">
<meta name="author-link" content="https://liudongdong1.github.io/">
<meta name="description" content="level: author: , Anit Kumar Sahu(Bosch Center for AI) date: 2019 Paper: Federated Learning Summary discuss the unique characteristics and challenges of federated learning, providing a broad overview of current approaches, and outline several directions of future work that are relevant to a wide range of research communities. Research Objective Application Area: learning sentiment, semantic location, activities of mobile phone users, adapting to pedestrian behavior in autonomous vehicles, predicting health" /><meta name="keywords" content='Federated Learning, Data Privacy' /><meta itemprop="name" content="Federated Learning Record">
<meta itemprop="description" content="level: author: , Anit Kumar Sahu(Bosch Center for AI) date: 2019 Paper: Federated Learning Summary discuss the unique characteristics and challenges of federated learning, providing a broad overview of current approaches, and outline several directions of future work that are relevant to a wide range of research communities. Research Objective Application Area: learning sentiment, semantic location, activities of mobile phone users, adapting to pedestrian behavior in autonomous vehicles, predicting health"><meta itemprop="datePublished" content="2022-04-29T18:51:16+00:00" />
<meta itemprop="dateModified" content="2023-12-31T16:31:43+08:00" />
<meta itemprop="wordCount" content="3985"><meta itemprop="image" content="https://liudongdong1.github.io/logo.png"/>
<meta itemprop="keywords" content="Federated Learning,Data Privacy," /><meta property="og:title" content="Federated Learning Record" />
<meta property="og:description" content="level: author: , Anit Kumar Sahu(Bosch Center for AI) date: 2019 Paper: Federated Learning Summary discuss the unique characteristics and challenges of federated learning, providing a broad overview of current approaches, and outline several directions of future work that are relevant to a wide range of research communities. Research Objective Application Area: learning sentiment, semantic location, activities of mobile phone users, adapting to pedestrian behavior in autonomous vehicles, predicting health" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://liudongdong1.github.io/federated-learning-record/" /><meta property="og:image" content="https://liudongdong1.github.io/logo.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-29T18:51:16+00:00" />
<meta property="article:modified_time" content="2023-12-31T16:31:43+08:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://liudongdong1.github.io/logo.png"/>

<meta name="twitter:title" content="Federated Learning Record"/>
<meta name="twitter:description" content="level: author: , Anit Kumar Sahu(Bosch Center for AI) date: 2019 Paper: Federated Learning Summary discuss the unique characteristics and challenges of federated learning, providing a broad overview of current approaches, and outline several directions of future work that are relevant to a wide range of research communities. Research Objective Application Area: learning sentiment, semantic location, activities of mobile phone users, adapting to pedestrian behavior in autonomous vehicles, predicting health"/>
<meta name="application-name" content="DAY By DAY">
<meta name="apple-mobile-web-app-title" content="DAY By DAY"><meta name="theme-color" data-light="#f8f8f8" data-dark="#252627" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://liudongdong1.github.io/federated-learning-record/" /><link rel="prev" href="https://liudongdong1.github.io/%E5%AD%98%E5%82%A8%E5%8D%8F%E8%AE%AE-nvme%E4%BB%8B%E7%BB%8D/" /><link rel="next" href="https://liudongdong1.github.io/virtio/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "Federated Learning Record",
    "inLanguage": "zh-CN",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https:\/\/liudongdong1.github.io\/federated-learning-record\/"
    },"genre": "posts","keywords": "Federated Learning, Data Privacy","wordcount":  3985 ,
    "url": "https:\/\/liudongdong1.github.io\/federated-learning-record\/","datePublished": "2022-04-29T18:51:16+00:00","dateModified": "2023-12-31T16:31:43+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
      "@type": "Organization",
      "name": "LiuDongdong","logo": "https:\/\/liudongdong1.github.io\/images\/person.png"},"author": {
        "@type": "Person",
        "name": "liudongdong1"
      },"description": ""
  }
  </script></head>
  <body data-header-desktop="auto" data-header-mobile="auto"><script>(window.localStorage?.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('data-theme', 'dark');</script><div class="wrapper"><script type="text/javascript"
        async
        src="https://cdnjs.cloudflare.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>
<header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper" data-github-corner="right">
    <div class="header-title">
      <a href="/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="DAY By DAY"
    title="DAY By DAY"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-desktop" class="typeit header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a
                class="menu-link"
                href="/posts/"
                
                
              ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/categories/"
                
                
              ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/tags/"
                
                
              ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/friends/"
                title="友情链接"
                
              ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/about/"
                
                
              ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li class="menu-item delimiter"></li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <ul class="sub-menu"><li class="menu-item">没有更多翻译</li></ul>
          </li><li class="menu-item search" id="search-desktop">
            <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-desktop">
            <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
              <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
            </a>
            <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
              <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
            </a>
            <span class="search-button search-loading" id="search-loading-desktop">
              <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
            </span>
          </li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li>
      </ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="/fixit.min.svg"
    title="/fixit.min.svg"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-mobile" class="typeit header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li class="search-wrapper">
            <div class="search mobile" id="search-mobile">
              <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-mobile">
              <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
              </a>
              <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
              </a>
              <span class="search-button search-loading" id="search-loading-mobile">
                <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
              </span>
            </div>
            <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
              取消
            </a>
          </li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/posts/"
                  
                  
                ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/categories/"
                  
                  
                ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/tags/"
                  
                  
                ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/friends/"
                  title="友情链接"
                  
                ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/about/"
                  
                  
                ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li
              class="menu-item text-center"
            ><a
                  class="menu-link"
                  href="/"
                  title="GitHub"
                  
                ><i class='fa-brands fa-github fa-fw' aria-hidden='true'></i> </a></li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <select class="language-select" onchange="location = this.value;"><option disabled>没有更多翻译</option></select>
          </li></ul>
    </nav>
  </div>
</header><div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
  </div>
  <div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
  </div><main class="container" data-page-style="normal"><aside class="toc" id="toc-auto"><h2 class="toc-title">目录 <i class="toc-icon fa-solid fa-angle-down fa-fw"></i></h2>
      <div class="toc-content" id="toc-content-auto"></div></aside>

  <aside class="aside-custom" id="aside-sakana">
    

<div class="sakana-widget">
  <div class="sakana-item" id="takina-widget"></div>
  <div class="sakana-item" id="chisato-widget"></div>
</div>
<script>
  function initSakanaWidget() {
    const takina = SakanaWidget.getCharacter('takina')
    SakanaWidget.registerCharacter('takina-slow', takina);
    new SakanaWidget({
      character: 'takina-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#takina-widget');

    const chisato = SakanaWidget.getCharacter('chisato')
    SakanaWidget.registerCharacter('chisato-slow', chisato);
    new SakanaWidget({
      character: 'chisato-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#chisato-widget');
  }
</script>
<script async onload="initSakanaWidget()" src="https://cdn.jsdelivr.net/npm/sakana-widget@2.3.0/lib/sakana.min.js">
</script></aside>

  <article class="page single">
    <div class="header"><h1 class="single-title animate__animated animate__flipInX">
        <span>Federated Learning Record</span>
      </h1></div><div class="post-meta">
      <div class="post-meta-line"><span class="post-author"><span class="author"><i class="fa-solid fa-user-circle" aria-hidden="true"></i>
      liudongdong1</span></span>
          <span class="post-category">收录于 <a href="/categories/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;Categories</a>&ensp;<a href="/categories/aiot/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;AIOT</a></span></div>
      <div class="post-meta-line"><span title=2022-04-29&#32;18:51:16>
            <i class="fa-regular fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2022-04-29" >2022-04-29</time>
          </span>&nbsp;<i class="fa-solid fa-pencil-alt fa-fw"></i>&nbsp;约 3985 字&nbsp;
        <i class="fa-regular fa-clock fa-fw"></i>&nbsp;预计阅读 8 分钟&nbsp;<span id="busuanzi_container_page_pv" class="busuanzi_visitors comment-visitors" data-flag-title="Federated Learning Record">
            <i class="fa-regular fa-eye fa-fw"></i>&nbsp;<span id="busuanzi_value_page_pv">-</span>&nbsp;次阅读
          </span>&nbsp;</div>
    </div><div class="featured-image"><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/fdlearning.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/fdlearning.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/fdlearning.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/fdlearning.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/fdlearning.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/fdlearning.png"/></div><div class="details toc" id="toc-static" kept="true">
        <div class="details-summary toc-title">
          <span>目录</span>
          <span><i class="details-icon fa-solid fa-angle-right"></i></span>
        </div>
        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li></li>
      </ul>
    </li>
    <li><a href="#paper-communication-efficient">Paper: Communication-Efficient</a>
      <ul>
        <li></li>
      </ul>
    </li>
    <li><a href="#paper-fl-system-design">Paper: FL System Design</a>
      <ul>
        <li></li>
      </ul>
    </li>
    <li><a href="#paper-mobile-key-prediction">Paper: Mobile Key Prediction</a>
      <ul>
        <li></li>
      </ul>
    </li>
    <li><a href="#paper-fed-vision">Paper: Fed-Vision</a>
      <ul>
        <li></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li></li>
      </ul>
    </li>
  </ul>
</nav></div>
      </div><div
      class="content"
      id="content"
      
      
    ><p><strong>level</strong>:
<strong>author</strong>: 	, Anit Kumar Sahu(Bosch Center for AI)
<strong>date</strong>: 2019</p>
<hr>
<h1 id="paper-federated-learning">Paper: Federated Learning</h1>
<!-- raw HTML omitted -->
<h4 id="summary">Summary</h4>
<ol>
<li>discuss the unique characteristics and challenges of federated learning, providing a broad overview of current approaches, and outline several directions of future work that are relevant to a wide range of research communities.</li>
</ol>
<h4 id="research-objective">Research Objective</h4>
<ul>
<li><strong>Application Area</strong>: learning sentiment, semantic location, activities of mobile phone users, adapting to pedestrian behavior in autonomous vehicles, predicting health events like heart attack risk from wearable devices;
<ul>
<li><strong>Smart phones:</strong> next-word prediction; voice recognition; while protect their personal privacy or to save the limited bandwidth/battery power of their phone;</li>
<li><strong>Organizations:</strong> reduce strain on the network and enable private learning between divices/organizations;</li>
<li><strong>Internet of things:</strong> Modern IoT networks, such as wearable devices, autonomous vehicles, or smart homes containing numerous sensors.</li>
</ul>
</li>
</ul>
<h4 id="proble-statement">Proble Statement</h4>
<ul>
<li>aim to learn the model under the constraint that device-generated data is stored and processed locally, with only intermediate updates being communicated periodically with a central server.
<ul>
<li>m: the total number of devices;</li>
<li>$p_k&gt;0 $  and $\sum_kp_k=1$, and $F_k$ is the local objective function for the kth device;</li>
<li>$p_k$: the relative impact of each device, like $p_k=1/n$ or $p_k=n_k/n$;</li>
<li>$n=\sum_kn_k$:  is the total number of samples;</li>
</ul>
</li>
</ul>
<p>$$
min_wF(w), where F(w):=\sum_{k=1}^{m}p_kF_k(w)\
F_k(w)=1/n_k\sum_{j_k=1}^{n_k}f_{j_k}(w;x_{j_k};y_{j_k})
$$</p>
<h4 id="core-problem-">Core Problem :</h4>
<ul>
<li><strong>Expensive Communications:</strong> to develop communication-efficient methods that iteratively send small messages or model updates as part of the training process, as for reducing communication:
<ul>
<li>reducing the total number of communication rounds;</li>
<li>reducing the size of transmitted message at each round;</li>
</ul>
</li>
<li><strong>Systems Heterogeneity:</strong>  the storage, computational and communication capabilities of each device in FL may differ due to variability in hardware, network connectivity, and power.
<ul>
<li>anticipate a low amount of participation;</li>
<li>tolerate heterogeneous hardware;</li>
<li>be robust to dropped devices in the network;</li>
</ul>
</li>
<li><strong>Statistical Heterogeneity:</strong> devices frequently generate and collect data in a non-identically distributed manner across the netwok;
<ul>
<li>multi-task and meta-learning perspectives enable personalized or device-specific modeling;</li>
</ul>
</li>
<li><strong>Privacy Concerns:</strong> tools like secure multiparty computation or differential privacy, which provide privacy at the cost of reduced model performance or system efficiency which should be understand and balance the trade-off;</li>
</ul>
<h4 id="previous-work">Previous work:</h4>
<p><strong>【Communication-efficiency】</strong></p>
<ul>
<li><strong>Local Updating methods</strong></li>
</ul>
<blockquote>
<ul>
<li>
<p>Mini-batch optimization methods to process multiple data points at a time;</p>
</li>
<li>
<p>distributed  approaches like ADMM[4] in real-word data center environments;</p>
</li>
<li>
<p>variable number of local updates to be applied on each machine in parallel at each communication round,</p>
</li>
</ul>
</blockquote>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200831230510.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200831230510.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200831230510.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200831230510.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200831230510.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200831230510.png"/></p>
<ul>
<li><strong>Compression schemes</strong></li>
</ul>
<blockquote>
<ul>
<li>model compression such as sparsification, subsampling, and quantization; [119], [135] for detail;</li>
<li>the low participation of devices, non-identically distributed local data, and local updating schemes pose noval challenges to these model compression approaches;
<ul>
<li>errors accumulated locally may be stale if the devices are not frequently sampled;</li>
<li>forcing the updating models to be sparse and low-rank;</li>
<li>performing quantization with structured random rotations;</li>
<li>using lossy compression and dropout to reduce server-device communication;</li>
<li>applying Golomb lossless encoding;</li>
</ul>
</li>
</ul>
</blockquote>
<ul>
<li><strong>Decentralized training</strong></li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200831231146.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200831231146.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200831231146.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200831231146.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200831231146.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200831231146.png"/></p>
<p><strong>【Systems Heterogeneity】</strong></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200901083436.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200901083436.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200901083436.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200901083436.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200901083436.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200901083436.png"/></p>
<ul>
<li><strong>Asynchronous Communication</strong>:</li>
</ul>
<blockquote>
<p>bounded-delay assumptions can be unrealistic in federated settings, where the delay may be on the order of hour to days, or completely unbounded.</p>
</blockquote>
<ul>
<li><strong>Active Sampling</strong></li>
</ul>
<blockquote>
<ul>
<li>activately selecting participating devices at each round;
<ul>
<li>based on systems resources, with the aim being for the server to aggregate as many device updates within pre-defined time window.</li>
<li>based on the data quality.</li>
<li><!-- raw HTML omitted -->how to extend these approaches to handle real-time, device-specific fluctuations in computation and communication delays<!-- raw HTML omitted --></li>
<li><!-- raw HTML omitted -->how to actively sampling a set of small but sufficiently representative devices based on the underlying statistical structure<!-- raw HTML omitted --></li>
</ul>
</li>
</ul>
</blockquote>
<ul>
<li><strong>Fault Tolerance</strong></li>
</ul>
<blockquote>
<ul>
<li>ignore such device failure, which may introduce bias;</li>
<li>code computation by introducing algorithmic redundancy:
<ul>
<li>using gradient coding and its variants</li>
</ul>
</li>
</ul>
</blockquote>
<p><strong>【Statistical Heterogeneity】</strong></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200901090728.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200901090728.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200901090728.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200901090728.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200901090728.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200901090728.png"/></p>
<blockquote>
<p>the data is not identically distributed across devices, both in terms of modeling the data and in analyzing the convergence behavior of associated training procedures.</p>
</blockquote>
<ul>
<li><strong>Modeling Heterogeneous Data</strong>  统计异质性</li>
</ul>
<blockquote>
<p>using meta-learning and multi-task learning.</p>
<p>MOCHA[106], an optimization framework designed for the federated setting, allow for personalization by learning separate but relate models for each device while leveraging a shared representation via multi-task learning;</p>
<p>[26] models the star topology and perform variational inference;</p>
</blockquote>
<ul>
<li><strong>Convergence Guarantees for Non-IID Data</strong></li>
</ul>
<blockquote>
<p>FedProx makes a small modification to the FedAvg method to help ensure convergence, both theoretically and in practice. FedProx can also be interpreted as a generalized, reparameterized version of FedAvg that has practical ramifications in the context of accounting for systems heterogeneity across devices.</p>
</blockquote>
<p><strong>【Privacy】</strong></p>
<blockquote>
<p>sharing other information such as model updates can also leak sensitive user information;</p>
</blockquote>
<ul>
<li><strong>Privacy in Machine Learning</strong></li>
</ul>
<blockquote>
<ul>
<li>differential privacy to communicate noisy data sketches;</li>
<li>homomorphic encryption to operate on encrypted data;</li>
<li>secure function evaluation or multi-party computation;</li>
</ul>
</blockquote>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200901091216.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200901091216.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200901091216.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200901091216.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200901091216.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200901091216.png"/></p>
<ul>
<li><strong>Privacy in FL</strong></li>
</ul>
<blockquote>
<p>develop methods that are computationally cheap, commucation-efficient and tolerant to dropped devices, all without overly compromising accuracy.</p>
<ul>
<li>SMC is a lossless method, retain the original accuracy with a very high privacy guarantee, incuring significant extra communication cost;</li>
<li>differential privacy: using hyperparameters that affect communication and accuracy that must be carefully chosen.</li>
</ul>
</blockquote>
<h4 id="future-directions">Future Directions</h4>
<ul>
<li><strong>Extreme communication schemes:</strong></li>
<li><strong>Communication reduction and the Pareto frontier</strong></li>
<li><strong>Novel medels of asynchrony</strong></li>
<li><strong>Heterogeneity diagnostics</strong></li>
<li><strong>Granular privacy constraints</strong></li>
<li><strong>Beyond supervised learning</strong></li>
<li><strong>Productionizing federated learning</strong>
<ul>
<li>concept drift(the underlying data-generation model changes over time)</li>
<li>diurnal variations( the devices exhibit different behavior at different times of the day or week)</li>
<li>cold start problems(new devices enter the network)</li>
</ul>
</li>
<li><strong>Benchmarks</strong></li>
</ul>
<h4 id="notes-font-colororange去加强了解font">Notes <!-- raw HTML omitted -->去加强了解<!-- raw HTML omitted --></h4>
<ul>
<li>non-convex problems</li>
<li>[114]</li>
<li>differential privacy[32, 33, 34]
<ul>
<li>. A firm foundation for private data analysis</li>
<li>The algorithmic foundations of differential privacy</li>
<li>Calibrating noise to sensitivity in private data analysis</li>
</ul>
</li>
</ul>
<p><strong>level:</strong>  cited by 750
<strong>author</strong>: H.Brendan McMahan  ,Google Inc</p>
<p><strong>date</strong>: 2017,2,28
<strong>keyword</strong>:</p>
<ul>
<li>federal learning, distributed optimization and estimation, communication efficiency</li>
</ul>
<hr>
<h2 id="paper-communication-efficient">Paper: Communication-Efficient</h2>
<!-- raw HTML omitted -->
<h4 id="summary-1">Summary</h4>
<ol>
<li><!-- raw HTML omitted -->introduce the FederatedAveraging algorithm, which combines local SGD on each client with a server that performs model averaging.<!-- raw HTML omitted --></li>
<li>learned the base concept of Federated learning.  learned the code but don&rsquo;t run it successfully.</li>
</ol>
<h4 id="research-objective-1">Research Objective</h4>
<ul>
<li><strong>Application Area</strong>: Modern mobile devices (phones,tablets) have access to a wealth of data suitable for learning models, which in turn improve the user experience on the devices.
<ul>
<li><!-- raw HTML omitted -->Language models:<!-- raw HTML omitted --> improve speech recognition and text entry on touch-screen keyboards by improving decoding,next-word-prediction,even the whole replies.</li>
<li><!-- raw HTML omitted -->Image modes: <!-- raw HTML omitted --> automatically select good photos</li>
</ul>
</li>
<li><strong>Purpose</strong>:  advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates.</li>
</ul>
<h4 id="proble-statement-1">Proble Statement</h4>
<p><strong>Opportunities:</strong></p>
<ul>
<li>the device we carried contained many <!-- raw HTML omitted -->sensors<!-- raw HTML omitted -->, create much private data.</li>
<li>the data driven many  <!-- raw HTML omitted -->intelligent applications<!-- raw HTML omitted --> to improve usability.</li>
<li><!-- raw HTML omitted -->centrally store these data cost a lot<!-- raw HTML omitted -->, eg: memory, communicating.</li>
<li>decouple the model training from the need for direct access to the raw data,  <!-- raw HTML omitted -->reduce privacy and security risks by limiting the attack surface to only the device.<!-- raw HTML omitted --></li>
</ul>
<p><strong>Previous work:</strong></p>
<ul>
<li><strong>Federated Learning:</strong>
<ul>
<li>training on real-world data from mobile devices provides a distinct advantage over training on proxy data that is generally available in the data center.</li>
<li>data is privacy sensitive or large in size</li>
<li><!-- raw HTML omitted -->for supervised tasks, labels on the data can be inferred naturally from user interaction.<!-- raw HTML omitted --></li>
</ul>
</li>
<li><strong>Privacy:</strong>  the information transmitted for federated learning is the minimal update necessary to improve a particular model.   (有本书是关于数据隐私的，以及各种保护隐私算法)</li>
<li><strong>Federated Optimization:</strong> several key properties that differentiate it from typical distributed optimization problem.
<ul>
<li><!-- raw HTML omitted -->Non-IID: <!-- raw HTML omitted -->the data based on the usage of particular user will not presentative of the population distribution</li>
<li><!-- raw HTML omitted -->Unbalanced: <!-- raw HTML omitted -->the usage of device is different, leading to different amount of data.</li>
<li><!-- raw HTML omitted -->Massively distributed:<!-- raw HTML omitted --> the number of clients participating in an optimization is much larger than average number of examples per client.</li>
<li><!-- raw HTML omitted -->Limited communication:<!-- raw HTML omitted --> mobile devices are frequently offline or on slow or expensive connections.</li>
</ul>
</li>
<li>previous work don&rsquo;t consider unbalanced and non-IID data and the empirical evaluation is limited, we focus on the noe-IID and unbalanced properties of optimization, communication constraints.</li>
</ul>
<h4 id="methods">Methods</h4>
<ul>
<li><strong>system overview</strong>:</li>
</ul>
<!-- raw HTML omitted -->
<p>【<strong>Challenge</strong> 1】<!-- raw HTML omitted -->client availability and unbalanced and non-IID data<!-- raw HTML omitted --></p>
<ul>
<li>
<p>assume a synchronous update scheme that proceeds in rounds of communication.</p>
</li>
<li>
<p>propose Federated Averaging algorithm</p>
<ul>
<li>
<!-- raw HTML omitted -->
</li>
<li>
<p>Federated SGD &amp;&amp;Federated AVG</p>
<!-- raw HTML omitted -->
</li>
</ul>
<p>【<strong>Challenge</strong> 2】<!-- raw HTML omitted -->while in data center optimization, communication costs are relatively small, and computation costs dominate with GPU to low down, in federated optimization, communication costs dominate.<!-- raw HTML omitted --></p>
<ul>
<li>the clients will only volunteer to participate in the optimization when they are charged, plugged-in, and on an unmetered wifi connection.</li>
<li>use additional computation to decrease the number of rounds of communication
<ul>
<li>increase parallelism</li>
<li>increase computation on each client: client perform more complex computation between each communication round.</li>
</ul>
</li>
</ul>
<p>【<strong>Challenge</strong> 3】Non-Convex的问题，会得到任意坏的结果 <strong>每一轮</strong>的<strong>各个客户端</strong>的<strong>起始参数值相同</strong>（也就是<strong>前一轮的全局参数值</strong>）</p>
<!-- raw HTML omitted -->
</li>
</ul>
<h4 id="evaluation">Evaluation</h4>
<ul>
<li>
<p>Accuracy&amp;&amp;Communication rounds</p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409174338562.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409174338562.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409174338562.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409174338562.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409174338562.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409174338562.png"/></p>
</li>
<li>
<p>local epoch test:</p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409174644230.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409174644230.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409174644230.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409174644230.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409174644230.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409174644230.png"/></p>
</li>
<li>
<p>CIFAR experiments:</p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409173229481.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409173229481.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409173229481.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409173229481.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409173229481.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409173229481.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409173127571.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409173127571.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409173127571.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409173127571.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409173127571.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409173127571.png"/></p>
</li>
<li>
<p>Large-scaleLSTMexperiments</p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409173430010.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409173430010.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409173430010.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409173430010.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409173430010.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409173430010.png"/></p>
</li>
</ul>
<h4 id="conclusion">Conclusion</h4>
<ul>
<li>the identification of the problem of training on decentralized data from mobile devices as an important research direction</li>
<li>the selection of straightforward and practical algorithm that can be applied to this setting</li>
<li>an extensive empirical evaluation of the proposed approach.</li>
</ul>
<h4 id="notes">Notes</h4>
<ul>
<li><i class="fa-regular fa-check-square fa-fw" aria-hidden="true"></i> 传统的分布式优化问题的独立同分布假设
<img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409184415543.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409184415543.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409184415543.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409184415543.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409184415543.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200409184415543.png"/></li>
</ul>
<p><strong>level</strong>:  SysML Conference
<strong>author</strong>: Keith Bonawitz
<strong>date</strong>: 2019, 5, 22
<strong>keyword</strong>:</p>
<ul>
<li>Federated Learning, System Design</li>
</ul>
<hr>
<h2 id="paper-fl-system-design">Paper: FL System Design</h2>
<!-- raw HTML omitted -->
<h4 id="summary-2">Summary</h4>
<ol>
<li>谷歌<!-- raw HTML omitted -->基于TensorFlow构建了全球首个产品级可扩展的大规模移动端联合学习系统，目前已在数千万台手机上运行<!-- raw HTML omitted -->。这些手机能协同学习一个共享模型，所有的训练数据都留在设备端，确保了个人数据安全，手机端智能应用也能更快更低能耗更新。</li>
<li><strong>Federated Learning progress:</strong><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://inews.gtimg.com/newsapp_bt/0/7635343934/1000"
    data-srcset="https://inews.gtimg.com/newsapp_bt/0/7635343934/1000, https://inews.gtimg.com/newsapp_bt/0/7635343934/1000 1.5x, https://inews.gtimg.com/newsapp_bt/0/7635343934/1000 2x"
    data-sizes="auto"
    alt="https://inews.gtimg.com/newsapp_bt/0/7635343934/1000"
    title="https://inews.gtimg.com/newsapp_bt/0/7635343934/1000"/></li>
<li><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://inews.gtimg.com/newsapp_bt/0/7635343935/1000"
    data-srcset="https://inews.gtimg.com/newsapp_bt/0/7635343935/1000, https://inews.gtimg.com/newsapp_bt/0/7635343935/1000 1.5x, https://inews.gtimg.com/newsapp_bt/0/7635343935/1000 2x"
    data-sizes="auto"
    alt="https://inews.gtimg.com/newsapp_bt/0/7635343935/1000"
    title="https://inews.gtimg.com/newsapp_bt/0/7635343935/1000"/></li>
<li><strong>Server elements:</strong><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://inews.gtimg.com/newsapp_bt/0/7635343937/1000"
    data-srcset="https://inews.gtimg.com/newsapp_bt/0/7635343937/1000, https://inews.gtimg.com/newsapp_bt/0/7635343937/1000 1.5x, https://inews.gtimg.com/newsapp_bt/0/7635343937/1000 2x"
    data-sizes="auto"
    alt="https://inews.gtimg.com/newsapp_bt/0/7635343937/1000"
    title="https://inews.gtimg.com/newsapp_bt/0/7635343937/1000"/></li>
</ol>
<p><strong>level</strong>:
<strong>author</strong>: AndrewHard,    GoogleLLC
<strong>date</strong>: 2019, 2,28
<strong>keyword</strong>:</p>
<ul>
<li>Federated Learning, language modeling, CIFG, NLP， next word prediction</li>
</ul>
<hr>
<h2 id="paper-mobile-key-prediction">Paper: Mobile Key Prediction</h2>
<!-- raw HTML omitted -->
<h4 id="summary-3">Summary</h4>
<ol>
<li>Gboard provides auto-correction, word completion, and next-word prediction features.</li>
</ol>
<h4 id="methods-1">Methods</h4>
<ul>
<li><strong>system overview</strong>:</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200327114728675.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200327114728675.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200327114728675.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200327114728675.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200327114728675.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200327114728675.png"/></p>
<ul>
<li>clients process their local data and share model updates with the server, weights from a large population of clients are aggregated by the server and combined to create an improved global model.
<ul>
<li>for every client: learnign rate $\epsilon $,the local client update $w_{t+1}^k=w_t-\epsilon g_k$ , $g_k$ is the average gradient.</li>
<li>for server: $w_{t+1}=\sum_{k=1}^K(n_k/N)w_{t+1}^k$</li>
</ul>
</li>
<li>updates are processed in memory and are immediately discarded after accumulation in a weight vector.</li>
</ul>
<h4 id="notes-font-colororange去加强了解font-1">Notes <!-- raw HTML omitted -->去加强了解<!-- raw HTML omitted --></h4>
<ul>
<li><i class="fa-regular fa-check-square fa-fw" aria-hidden="true"></i> FSA是一个FSM(有限状态机)的一种，特性如下:
<ul>
<li>确定：意味着指定任何一个状态，只可能最多有一个转移可以访问到。</li>
<li>无环： 不可能重复遍历同一个状态</li>
<li>接收机：有限状态机只“接受”特定的输入序列，并终止于final状态。</li>
<li>查找这个key是否在集合内的时间复杂度，取决于key的长度，而不是集合的大小。</li>
<li>构建上： TRIE只共享前缀，而FSA不仅共享前缀还共享后缀。</li>
</ul>
</li>
<li><i class="fa-regular fa-check-square fa-fw" aria-hidden="true"></i> FST是也一个有限状态机（FSM）,具有这样的特性：
<ul>
<li>确定：意味着指定任何一个状态，只可能最多有一个转移可以遍历到。</li>
<li>无环： 不可能重复遍历同一个状态</li>
<li>transducer：接收特定的序列，终止于final状态，同时会<strong>输出一个值</strong>。</li>
<li>不但能<strong>共享前缀</strong>还能<strong>共享后缀</strong>。不但能判断查找的key是否存在，还能给出响应的输入output</li>
<li>构建： 在FSA上，多了转移上<strong>放置和共享outputs</strong></li>
</ul>
</li>
<li><i class="fa-regular fa-square fa-fw" aria-hidden="true"></i> paper 2, “Finite-state transducers in language and speech processing</li>
<li><i class="fa-regular fa-square fa-fw" aria-hidden="true"></i> 3 “Mobile keyboard input decoding with ﬁnite-state transducers</li>
<li><i class="fa-regular fa-square fa-fw" aria-hidden="true"></i> CIFG for next-word prediction</li>
<li><i class="fa-regular fa-square fa-fw" aria-hidden="true"></i> Character-aware neural language models</li>
</ul>
<p><strong>level</strong>: CCF_A     AAAI
<strong>author</strong>: Yang Liu, Anbu Huang, Yun Luo, He Huang, Youzhi Liu, Yuanyuan Chen
<strong>date</strong>: 2020, 1,17
<strong>keyword</strong>:</p>
<ul>
<li>Federated Learning, Object Detection</li>
</ul>
<hr>
<h2 id="paper-fed-vision">Paper: Fed-Vision</h2>
<!-- raw HTML omitted -->
<h4 id="research-objective-2">Research Objective</h4>
<ul>
<li><strong>Application Area</strong>: federated learning in Computer Vision</li>
<li><strong>Purpose</strong>:  use federated learning to solve the problem in computor vision.</li>
</ul>
<h4 id="proble-statement-2">Proble Statement</h4>
<ul>
<li>
<p>Computer vision: privacy concerns, high cost of transmitting video data</p>
</li>
<li>
<p>traditional typical workflow for centralized training of an object detector.</p>
<ul>
<li>
<p>difficult to share data across organizations due to liability concerns</p>
</li>
<li>
<p>the whole process takes a long time and depends on when the next round of off-line training occurs, new data must wait for next round of training.</p>
</li>
<li>
<p>communication cost in transmitting data.</p>
<!-- raw HTML omitted -->
</li>
</ul>
</li>
</ul>
<h4 id="methods-2">Methods</h4>
<ul>
<li><strong>system overview</strong>: HFL （horizontal federated learning)</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410171127248.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410171127248.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410171127248.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410171127248.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410171127248.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410171127248.png"/></p>
<p><strong>【Module 1】 Crowdsourced Image Annotation</strong></p>
<ul>
<li>use annotate the picture with { label, x, y, w, h}</li>
</ul>
<!-- raw HTML omitted -->
<p><strong>【Module 2】Federated ModelTraining</strong></p>
<!-- raw HTML omitted -->
<ul>
<li>Configuration： configure training information, eg. number of iterations, reconnections, the server URL for uploading&hellip;</li>
<li>Task Scheduler: global dispatch scheduling, coordinate communications between the server and clients to balance the utilization of local computational resources.</li>
<li>Task Manager: coordinates the concurrent federated model training processes.</li>
<li>Explorer: monitors the resource utilization situation on the client side, eg: CPU usage, memory usage, network load, etc. to inform the task scheduler on its load-balancing decisions.</li>
<li>FL_SERVER: responsible for model parameter uploading, model aggregation, and model dispatch</li>
<li>FL_CLIENT: hosts the task manager and explorer components and performs local model training.</li>
</ul>
<p><strong>【Module 2】Federated Model Update</strong></p>
<ul>
<li>
<p>the number of model parameter files, and thus the storage size required, increases with the rounds of training operations</p>
</li>
<li>
<p>Using Cloud Object Storage(COS) to store practically limitless amounts of data easily and at an affordable cost</p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410172540671.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410172540671.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410172540671.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410172540671.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410172540671.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410172540671.png"/></p>
</li>
</ul>
<p><strong>【Module 3】Computer Vision Object Detect FedYOLOv3</strong></p>
<ul>
<li>in general two-stage approaches produce more accurate object detecion results(r-cnn), while one-stage approaches are more efficient,YOLOv3</li>
<li>process of YOLOv3:
<ul>
<li>Predicting the positions of B bounding boxes&lt;x,y,w,h&gt;</li>
<li>Estimating the confidence score for the B predicted bounding boxes, whether a bounding box contains the target object $p(obj)=1$ meaning contain object else 0; how precise the boundary of box is. $\theta=p(obj)*IOU$, IOU meaning the intersection-over-union.</li>
<li>computing the class conditional probability,$p(c_i|obj)\epsilon[0,1]$ for each of the C classes.</li>
<li>The loss function:<img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410173637335.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410173637335.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410173637335.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410173637335.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410173637335.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410173637335.png"/></li>
</ul>
</li>
</ul>
<p><strong>【Module 4】Model Compression</strong></p>
<ul>
<li>$M^{i,k}$ define the i-th user after the k-th iteration of FL training, $M_j^{i,k}$ define the j-th layer of $M^{i,k}$, $|\sum M_j^{i,k}|$  the sum of the absolute values of parameters in the j-th layer, the j-th layer to the overall model perfomance: $v(j)=|\sum M_j^{i,k}-\sum M_j^{i,k-1}|$, the larger the value of $v(j)$ , the greater the impact of layer j on the model, FL_CLIENT ranks the $v(j) values of ally layers in the model in descending order and selects only the parameters of  first n layers to upload for aggregation.</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410173826315.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410173826315.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410173826315.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410173826315.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410173826315.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200410173826315.png"/></p>
<h4 id="evaluation-1">Evaluation</h4>
<ul>
<li>Experiment company introduce:
<ul>
<li>CRC has business interests in consumer products, health-care, energy services, urban construction and operation, technology and ﬁnance. <!-- raw HTML omitted --> detect multiple types of safety hazards via cameras in more than 100 factories<!-- raw HTML omitted -->.</li>
<li>GRG Banking has more than 300,000 equipment deployed in over 80 countries. <!-- raw HTML omitted -->monitor suspicious transaction behaviours via cameras on the equipment<!-- raw HTML omitted --></li>
<li>SPIC the world&rsquo;s largest photovoltaic power generation company. <!-- raw HTML omitted -->monitor the safety of more than 10,000 square meters of photovoltaic panels<!-- raw HTML omitted --></li>
</ul>
</li>
<li>get good performance in Efficiency, data privacy, cost.</li>
</ul>
<h4 id="conclusion-1">Conclusion</h4>
<ul>
<li>report FedVision&ndash; a machine learning engineering platform to support the development of federated learning powered computer vision applications.</li>
<li>the first industrial application platform in computer vision-based tasks developed by webank and Extreme Vision to help customers develop computer vision based safety monitoring solutions in smart city applications.</li>
<li>the platform help improve their operational efficiency and reduce their costs, while eliminating the need to transmit sensitive data around.</li>
</ul>
<p><strong>level</strong>: ICLR 2020
<strong>author</strong>: Hongyi Wang*(Wisconsin-Madison), Mikhail Yurochkin(MIT-IBM Watson AI lab), Yuekai Sun(Michigan University)
<strong>date</strong>: 2020
<strong>keyword</strong>:</p>
<ul>
<li>data privacy, federated learning</li>
</ul>
<hr>
<h1 id="paper-fedmatchedavg">Paper: FedMatchedAvg</h1>
<!-- raw HTML omitted -->
<h4 id="summary-4">Summary</h4>
<ol>
<li>FedMA constructs the shared global model in a layer-wise manner by matching and averaging hidden elements(i.e. channels for convolutional layers; hidden states for LSTM; neurons for fully connected layers) with similar feature extraction signatures.</li>
<li>demostrate how PFNM can be applied to CNNs and LSTMs, but find it only gives very minor improvements over weight averging.</li>
<li>propose FedMA(Federated Matched Averaging) a new layer-wise federated learning algorithm for modern CNNs and LSTMs that appeal to Bayesian nonparametric methods to adapt to heterogeniety in the data.</li>
</ol>
<h4 id="proble-statement-3">Proble Statement</h4>
<ul>
<li>coordinate-wise averaging of weights may have drastic detrimental effects on the performance of the averaged model and adds significantly to the communication burden.(<!-- raw HTML omitted -->permutation invariance of NN parameters<!-- raw HTML omitted -->)</li>
</ul>
<p>previous work:</p>
<ul>
<li>FedAvg(MCMahan et al.2017): the parameters of local models are averaged element-wise with weights proportional to sizes of the client datasets.</li>
<li>FedProx(Sahu et al.) adds a proximal term to the client cost functions, limiting the impact of local updates by keeping them close to the global model.</li>
<li>Agnostic Federated Learning(Mohri et al.): optimizes a centralized distribution that is a mixture of the client distributions.</li>
<li>Probabilistic Federated Neural Matching(Yurochkin et al.2019): matching the neurons of client NNs before averaging them,using Bayesian non-parametric methods to adapt to global model size and to heterogeneity in the data. <!-- raw HTML omitted --> only work with simple architectures<!-- raw HTML omitted --></li>
</ul>
<h4 id="methods-3">Methods</h4>
<ul>
<li><strong>Problem Formulation</strong>:  <!-- raw HTML omitted -->这里不懂，先记录着<!-- raw HTML omitted --></li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705163648667.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705163648667.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705163648667.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705163648667.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705163648667.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705163648667.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705164501351.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705164501351.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705164501351.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705164501351.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705164501351.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705164501351.png"/></p>
<ul>
<li><strong>system overview</strong>:</li>
</ul>
<blockquote>
<p>First, data center gathers only the weights of the first layers from the clients and performs one-layer matching described previously to obtain the first layer weights of the federeated model. Data center then broadcasts these weights to the clients, which proceed to train all consecutive layers on their datasets, keeping the matched federated layers frozen. And repeated up to the last layer for which we conduct a weighted averaging based on the class proportions of data points per client.</p>
<p>FedMA with communication, where local clients receive the matched global model at the beginning of a new round and reconstruct their local models with the size equal to the original local models based on the matching results of the previous round.</p>
</blockquote>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165047111.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165047111.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165047111.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165047111.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165047111.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165047111.png"/></p>
<h4 id="evaluation-2">Evaluation</h4>
<ul>
<li><strong>Environment</strong>:
<ul>
<li>Dataset:</li>
</ul>
</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165157271.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165157271.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165157271.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165157271.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165157271.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165157271.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165215850.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165215850.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165215850.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165215850.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165215850.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165215850.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165252982.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165252982.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165252982.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165252982.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165252982.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165252982.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165314632.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165314632.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165314632.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165314632.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165314632.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705165314632.png"/></p>
<h4 id="conclusion-2">Conclusion</h4>
<ul>
<li><!-- raw HTML omitted -->present Federated Matched Averaging(FedMA), a layer-wise federated learning algorithm designed for modern CNNs and LSTMs architectures that accounts for permutation invariance of the neurons and permits global model size adaptation.<!-- raw HTML omitted --></li>
</ul>
<h4 id="notes-font-colororange去加强了解font-2">Notes <!-- raw HTML omitted -->去加强了解<!-- raw HTML omitted --></h4>
<ul>
<li><a href="https://github.com/cheind/py-lapsolver"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/cheind/py-lapsolver<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
</ul>
<p><strong>level</strong>:
<strong>author</strong>: Wei Chen(Carnegie Mellon Univertity)  Radu Mar
<strong>date</strong>: 2020
<strong>keyword</strong>:</p>
<ul>
<li>Federated Learning; activation-divergence issue;  Maximum Entropy; Non-IID;</li>
</ul>
<blockquote>
<p>Chen, Wei, Kartikeya Bhardwaj, and Radu Marculescu. &ldquo;FedMAX: Mitigating Activation Divergence for Accurate and Communication-Efficient Federated Learning.&rdquo; <em>arXiv preprint arXiv:2004.03657</em> (2020).</p>
</blockquote>
<hr>
<h1 id="paper--fedmax">Paper:  FedMax</h1>
<!-- raw HTML omitted -->
<h4 id="summary-5">Summary</h4>
<ol>
<li>introduce a prior based on the principle of maximum entropy, which assumes minimal information about the per-device activation vectors and aims at making the activation vectors of same classes as similar as possible across multiple devices.</li>
<li>makes activation vector across multiple devices more similar(for same classes); improving the accuracy;</li>
<li>significantly reduces the number of total communication rounds needed to save energy when training on edge devices.</li>
</ol>
<h4 id="proble-statement-4">Proble Statement</h4>
<ul>
<li>the activation vectors in FL can diverge, even if subsets of users share a few common classes with data residing on different devices.</li>
</ul>
<p>previous work:</p>
<ul>
<li><strong>FedAvg:</strong>  not designed to handle the statistical heterogeneity in federated settings, when data is not independent and identically distributed across diferent devices.</li>
<li><strong>Data-sharing strategy:</strong> distributes global data across the local devices, but obtaining this common global data is problematic in practice.</li>
<li><strong>FedProx[4]:</strong> targets the weight-divergence problem, the local-weights diverge from the global model due to non-IID data at local devices; by introducing a new loss function which constrains the local models to stay close to the global model.</li>
</ul>
<h4 id="methods-4">Methods</h4>
<ul>
<li><strong>Problem Formulation</strong>:
<ul>
<li>$g_k(w_k)$: local objective which is typically the loss function of the prediction made with model parameters w;</li>
<li>m: the number of devices selected at any given communication round; m=C*M</li>
<li>C: the proportion of selected devices;</li>
<li>$\sum_{k=1}^Mp_k=1,p_k=n_k/n$,;</li>
<li>$n_k$: is the number of samples available at the device k;</li>
<li>$n=\sum_{k=1}^Mn_k$: total number of samples;</li>
</ul>
</li>
</ul>
<p>$$
min_w g(w)=\sum_{k=1}^m P_k*g_k(w_k)
$$</p>
<ul>
<li>
<p><strong>system overview</strong>:</p>
<ul>
<li>
<p>$L^2$ <strong>Norm regularization:</strong> reduce the activation-divergence across different devices by preventing the activation vectors from taking large values;</p>
<ul>
<li>$F_k(w_k)$: the cross entropy loss on local data;</li>
<li>$\alpha_i^k$: the activation vectors at the input of the last fully-connected layer.</li>
</ul>
<p>$$
min_wg_k(w_k)=F_k(w_k)+\beta ||a_i^k||_2\
$$</p>
</li>
<li>
<p><strong>Maximum Entropy Regularization:</strong>  for we don&rsquo;t know which users have data from which classes, in other words, we don&rsquo;t have any prior information about how the activation vectors at different user should be distributed.</p>
<ul>
<li>N: the min-batch size of local training data;</li>
<li>$H$: the entropy of activation vectors;</li>
<li>U: the uniform distribution over the activation vectors;</li>
<li>KL(.||.): the KL divergence;</li>
</ul>
<p>$$
min_w g_k(w_k)=F_k(w_k)-\beta 1/N \sum_{i=1}^NH(\alpha_i^k)\
using Kullback-Leibler: min_w g_k(w_k)=F_k(w_k)+\beta 1/N \sum_{i=1}^N KL(\alpha_i^k||U)
$$</p>
</li>
</ul>
</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913184242778.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913184242778.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913184242778.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913184242778.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913184242778.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913184242778.png"/></p>
<ul>
<li>$w^0$: the initial model and weights generated on a remote server;</li>
<li>$E$: local epochs;</li>
<li>$B$: the local training batch size;</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200913185949.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200913185949.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200913185949.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200913185949.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200913185949.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200913185949.png"/></p>
<h4 id="evaluation-3">Evaluation</h4>
<ul>
<li><strong>Effects of maximum entropy regularization with different distribution of synthetic data</strong></li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200913190823.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200913190823.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200913190823.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200913190823.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200913190823.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200913190823.png"/></p>
<ul>
<li><strong>Comparison of $L^2$-norm against Maximum Entropy</strong></li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191102135.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191102135.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191102135.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191102135.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191102135.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191102135.png"/></p>
<ul>
<li><strong>Different Dataset Comparison</strong></li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200913191304.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200913191304.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200913191304.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20200913191304.png 2x"
    data-sizes="auto"
    alt="3000 rounds"
    title="3000 rounds"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191408146.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191408146.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191408146.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191408146.png 2x"
    data-sizes="auto"
    alt="600 round"
    title="600 round"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191609259.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191609259.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191609259.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191609259.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191609259.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191609259.png"/></p>
<ul>
<li><strong>Medical data experiment-</strong></li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191758843.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191758843.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191758843.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191758843.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191758843.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191758843.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191829604.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191829604.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191829604.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191829604.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191829604.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913191829604.png"/></p>
<ul>
<li><strong>Mitigating Activation Divergence</strong></li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913192202686.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913192202686.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913192202686.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913192202686.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913192202686.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913192202686.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913192226909.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913192226909.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913192226909.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913192226909.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913192226909.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913192226909.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913192251229.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913192251229.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913192251229.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913192251229.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913192251229.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200913192251229.png"/></p>
<h4 id="notes-font-colororange去加强了解font-3">Notes <!-- raw HTML omitted -->去加强了解<!-- raw HTML omitted --></h4>
<ul>
<li><i class="fa-regular fa-square fa-fw" aria-hidden="true"></i> differential privacy [15]</li>
<li><i class="fa-regular fa-square fa-fw" aria-hidden="true"></i> KL divergence</li>
</ul>
<p><strong>level</strong>: ICLR2020, CCF_A
<strong>author</strong>: Sean Augenstein(Google Inc), H.Brendan McMahan(Google Inc)
<strong>date</strong>: 2020
<strong>keyword</strong>:</p>
<ul>
<li>federated learning</li>
</ul>
<hr>
<h1 id="paper-effectiveml-on-private">Paper: EffectiveML on Private</h1>
<!-- raw HTML omitted -->
<h4 id="summary-6">Summary</h4>
<ol>
<li>demostrates that generative models-trained using federated methods and with formal differential privacy guarantees&ndash;can be used effectively to debug many commonly occurring data issues even when the data cannot be directly inspected.</li>
<li>Identifying key challenges in implementing end-to-end workflows with non-inspectable data, e.g. for debugging a &ldquo;primary&rdquo; ML model used in a mobile application.</li>
<li>Proposing a methodology that allows auxiliary generative models to resolve these challenges.</li>
<li>demonstrating how privacy preserving federated generative models-RNNs for text and GANs for images-can be trained to high enough fidelity to discover introduced data errors matching those encountered in real world scenarios.</li>
</ol>
<h4 id="proble-statement-5">Proble Statement</h4>
<ul>
<li>challenges in model development and debugging.</li>
</ul>
<p>previous work:</p>
<ul>
<li>manual data inspection is problematic for privacy-sensitive datasets:
<ul>
<li>identifying and fixing problems in the data</li>
<li>generating new modeling hypotheses</li>
<li>assigning or refining human-provided labels</li>
</ul>
</li>
</ul>
<h4 id="methods-5">Methods</h4>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705204644162.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705204644162.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705204644162.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705204644162.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705204644162.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20200705204644162.png"/></p>
<ul>
<li><!-- raw HTML omitted -->没有看懂<!-- raw HTML omitted --></li>
</ul>
</div>
<div class="post-footer" id="post-footer">
  <div class="post-info">
    <div class="post-info-line">
      <div class="post-info-mod">
        <span title=2023-12-31&#32;16:31:43>更新于 2023-12-31&nbsp;</span>
      </div><div class="post-info-license">
          <span><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span>
        </div></div>
    <div class="post-info-line">
      <div class="post-info-md"><span><a href="/federated-learning-record/index.md" title="阅读原始文档" class="link-to-markdown">阅读原始文档</a></span><span><a href="https://liudongdong1.github.io/edit/master/content/posts%5c%e6%97%b6%e7%a9%ba%e6%95%b0%e6%8d%ae%5cFederatedLearning%5cFederated-Learning-Record.md" title="编辑此页"target="_blank" rel="external nofollow noopener noreferrer" class="link-to-edit">编辑此页</a></span></div>
      <div class="post-info-share">
        <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="https://liudongdong1.github.io/federated-learning-record/" data-title="Federated Learning Record" data-hashtags="Federated Learning,Data Privacy"><i class="fa-brands fa-twitter fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="https://liudongdong1.github.io/federated-learning-record/" data-hashtag="Federated Learning"><i class="fa-brands fa-facebook-square fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="https://liudongdong1.github.io/federated-learning-record/" data-title="Federated Learning Record" data-image="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/fdlearning.png"><i class="fa-brands fa-weibo fa-fw" aria-hidden="true"></i></a>
  </span>
      </div>
    </div>
  </div>

  <div class="post-info-more">
    <section class="post-tags"><i class="fa-solid fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/federated-learning/">Federated Learning</a>,&nbsp;<a href="/tags/data-privacy/">Data Privacy</a></section>
    <section>
      <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
    </section>
  </div>

  <div class="post-nav"><a href="/%E5%AD%98%E5%82%A8%E5%8D%8F%E8%AE%AE-nvme%E4%BB%8B%E7%BB%8D/" class="prev" rel="prev" title="NEMe介绍"><i class="fa-solid fa-angle-left fa-fw" aria-hidden="true"></i>NEMe介绍</a>
      <a href="/virtio/" class="next" rel="next" title="virtio介绍">virtio介绍<i class="fa-solid fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article></main><footer class="footer">
    <div class="footer-container"><div class="footer-line powered">由 <a href="https://gohugo.io/" target="_blank" rel="external nofollow noopener noreferrer" title="Hugo 0.118.2">Hugo</a> 强力驱动 | 主题 - <a href="https://github.com/hugo-fixit/FixIt" target="_blank" rel="external" title="FixIt v0.2.17-RC"><img class="fixit-icon" src="/fixit.min.svg" alt="FixIt logo" />&nbsp;FixIt</a>
        </div><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">2020 - 2024</span><span class="author" itemprop="copyrightHolder">
              <a href="https://liudongdong1.github.io/"target="_blank" rel="external nofollow noopener noreferrer">LiuDongdong</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div><div class="footer-line statistics"><span class="site-time" title='网站运行中 ...'><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden="true"></i>&nbsp;<span class="run-times">网站运行中 ...</span></span></div><div class="footer-line ibruce">
          <span id="busuanzi_container_site_uv" title='总访客数'><i class="fa-regular fa-user fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span><span id="busuanzi_container_site_pv" class="footer-divider" title='总访问量'><i class="fa-regular fa-eye fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span>
        </div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="回到顶部"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric">0%</span>
        </div></div><a href="https://liudongdong1.github.io/" title="在 GitHub 上查看源代码"target="_blank" rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><div id="mask"></div><div class="reading-progress-bar" style="left: 0;top: 0;--bg-progress: #0076ff;--bg-progress-dark: #fff;"></div><noscript>
    <div class="noscript-warning">FixIt 主题在启用 JavaScript 的情况下效果最佳。</div>
  </noscript>
</div><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script src="/lib/autocomplete/autocomplete.min.js" defer></script><script src="/lib/algoliasearch/algoliasearch-lite.umd.min.js" defer></script><script src="/lib/lazysizes/lazysizes.min.js" async defer></script><script src="/lib/sharer/sharer.min.js" async defer></script><script src="/lib/typeit/index.umd.js" defer></script><script src="/lib/katex/katex.min.js" defer></script><script src="/lib/katex/auto-render.min.js" defer></script><script src="/lib/katex/copy-tex.min.js" defer></script><script src="/lib/katex/mhchem.min.js" defer></script><script src="/lib/cookieconsent/cookieconsent.min.js" defer></script><script src="/lib/pangu/pangu.min.js" defer></script><script src="/lib/cell-watermark/watermark.min.js" defer></script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async defer></script><script>window.config={"code":{"copyTitle":"复制到剪贴板","editLockTitle":"锁定可编辑代码块","editUnLockTitle":"解锁可编辑代码块","editable":true,"maxShownLines":10},"comment":{"enable":false},"cookieconsent":{"content":{"dismiss":"同意","link":"了解更多","message":"本网站使用 Cookies 来改善您的浏览体验。"},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"data":{"typeit-header-subtitle-desktop":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e","typeit-header-subtitle-mobile":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e"},"enablePWA":true,"enablePangu":true,"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"2R1K9SKLQZ","algoliaIndex":"index.zh-cn","algoliaSearchKey":"4a226aa1c5c98d6859e4d1386adb2bc7","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"},"siteTime":"2020-12-18T16:15:22+08:00","typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"typeit-header-subtitle-desktop":["typeit-header-subtitle-desktop"],"typeit-header-subtitle-mobile":["typeit-header-subtitle-mobile"]},"duration":-1,"speed":100},"watermark":{"appendto":".wrapper\u003emain","colspacing":30,"content":"\u003cimg class=\"fixit-icon\" src=\"/fixit.min.svg\" alt=\"FixIt logo\" /\u003e FixIt 主题","enable":true,"fontfamily":"inherit","fontsize":0.85,"height":21,"opacity":0.0125,"rotate":15,"rowspacing":60,"width":150}};</script><script src="/js/theme.min.js" defer></script><script src="/js/custom.min.js" defer></script></body>
</html>
