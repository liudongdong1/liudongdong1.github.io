<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>SkLearn Optimize - DAY By DAY</title><meta name=author content="LiuDongdong"><meta name=author-link content="https://liudongdong1.github.io/"><meta name=description content="使用scikit-learn时提高速度的三种主要方法是：使用joblib和Ray并行化或分发培训，使用不同的超参数优化技术（网格搜索，随机搜"><meta name=keywords content="Sklearn,Math"><meta itemprop=name content="SkLearn Optimize"><meta itemprop=description content="使用scikit-learn时提高速度的三种主要方法是：使用joblib和Ray并行化或分发培训，使用不同的超参数优化技术（网格搜索，随机搜"><meta itemprop=datePublished content="2021-04-14T08:38:11+00:00"><meta itemprop=dateModified content="2023-09-29T00:12:27+08:00"><meta itemprop=wordCount content="5774"><meta itemprop=image content="/logo.png"><meta itemprop=keywords content="Sklearn,Math,"><meta property="og:title" content="SkLearn Optimize"><meta property="og:description" content="使用scikit-learn时提高速度的三种主要方法是：使用joblib和Ray并行化或分发培训，使用不同的超参数优化技术（网格搜索，随机搜"><meta property="og:type" content="article"><meta property="og:url" content="liudongdong1.github.io/sklearn-optimize/"><meta property="og:image" content="/logo.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-04-14T08:38:11+00:00"><meta property="article:modified_time" content="2023-09-29T00:12:27+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="/logo.png"><meta name=twitter:title content="SkLearn Optimize"><meta name=twitter:description content="使用scikit-learn时提高速度的三种主要方法是：使用joblib和Ray并行化或分发培训，使用不同的超参数优化技术（网格搜索，随机搜"><meta name=application-name content="DAY By DAY"><meta name=apple-mobile-web-app-title content="DAY By DAY"><meta name=theme-color data-light=#f8f8f8 data-dark=#252627 content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=liudongdong1.github.io/sklearn-optimize/><link rel=prev href=liudongdong1.github.io/pptsegment/><link rel=next href=liudongdong1.github.io/sklearnvisualization/><link rel=stylesheet href=/liudongdong1.github.io/css/style.min.css><link rel=stylesheet href=/liudongdong1.github.io/lib/fontawesome-free/all.min.css><link rel=stylesheet href=/liudongdong1.github.io/lib/animate/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"SkLearn Optimize","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"liudongdong1.github.io\/sklearn-optimize\/"},"genre":"posts","keywords":"Sklearn, Math","wordcount":5774,"url":"liudongdong1.github.io\/sklearn-optimize\/","datePublished":"2021-04-14T08:38:11+00:00","dateModified":"2023-09-29T00:12:27+08:00","license":"This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher":{"@type":"Organization","name":"LiuDongdong","logo":"\/images\/person.png"},"author":{"@type":"Person","name":"LiuDongdong"},"description":""}</script></head><body data-header-desktop=auto data-header-mobile=auto><script>(window.localStorage?.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("data-theme","dark")</script><div class=wrapper><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper data-github-corner=right><div class=header-title><a href=liudongdong1.github.io/ title="DAY By DAY"><img class="lazyload logo" src=/liudongdong1.github.io/svg/loading.min.svg data-src=/fixit.min.svg data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x" data-sizes=auto alt="DAY By DAY" title="DAY By DAY"><span class=header-title-text></span></a><span id=typeit-header-subtitle-desktop class="typeit header-subtitle"></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 所有文章</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/friends/ title=友情链接><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden=true></i> 友链</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/about/><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden=true></i> 关于</a></li><li class="menu-item delimiter"></li><li class="menu-item language"><span role=button aria-label=选择语言 title=选择语言>简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden=true></i></span><ul class=sub-menu><li class=menu-item>没有更多翻译</li></ul></li><li class="menu-item search" id=search-desktop><input type=text placeholder="搜索文章标题或内容 ..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i></a>
<span class="search-button search-loading" id=search-loading-desktop><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></li><li class="menu-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=liudongdong1.github.io/ title="DAY By DAY"><img class="lazyload logo" src=/liudongdong1.github.io/svg/loading.min.svg data-src=/fixit.min.svg data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x" data-sizes=auto alt=/fixit.min.svg title=/fixit.min.svg><span class=header-title-text></span></a><span id=typeit-header-subtitle-mobile class="typeit header-subtitle"></span></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder="搜索文章标题或内容 ..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i></a>
<span class="search-button search-loading" id=search-loading-mobile><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 所有文章</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/friends/ title=友情链接><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden=true></i> 友链</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/about/><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden=true></i> 关于</a></li><li class="menu-item text-center"><a class=menu-link href=https://liudongdong1.github.io/ title=GitHub rel="noopener noreferrer" target=_blank><i class='fa-brands fa-github fa-fw' aria-hidden=true></i></a></li><li class="menu-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li><li class="menu-item language"><span role=button aria-label=选择语言 title=选择语言>简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden=true></i></span>
<select class=language-select onchange="location=this.value"><option disabled>没有更多翻译</option></select></li></ul></nav></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=container data-page-style=normal><aside class=toc id=toc-auto><h2 class=toc-title>目录 <i class="toc-icon fa-solid fa-angle-down fa-fw"></i></h2><div class=toc-content id=toc-content-auto></div></aside><aside class=aside-custom id=aside-sakana><div class=sakana-widget><div class=sakana-item id=takina-widget></div><div class=sakana-item id=chisato-widget></div></div><script>function initSakanaWidget(){const e=SakanaWidget.getCharacter("takina");SakanaWidget.registerCharacter("takina-slow",e),new SakanaWidget({character:"takina-slow",controls:!1,autoFit:!0,stroke:{color:"#b4b4b4",width:2}}).mount("#takina-widget");const t=SakanaWidget.getCharacter("chisato");SakanaWidget.registerCharacter("chisato-slow",t),new SakanaWidget({character:"chisato-slow",controls:!1,autoFit:!0,stroke:{color:"#b4b4b4",width:2}}).mount("#chisato-widget")}</script><script async onload=initSakanaWidget() src=https://cdn.jsdelivr.net/npm/sakana-widget@2.3.0/lib/sakana.min.js></script></aside><article class="page single"><div class=header><h1 class="single-title animate__animated animate__flipInX"><span>SkLearn Optimize</span></h1></div><div class=post-meta><div class=post-meta-line><span class=post-author><a href=https://liudongdong1.github.io/ title=作者 target=_blank rel="external nofollow noopener noreferrer author" class=author><img class="lazyload avatar" src=/liudongdong1.github.io/svg/loading.min.svg data-src=/liudongdong1.github.io/images/study-avatar.png data-srcset="/liudongdong1.github.io/images/study-avatar.png, /liudongdong1.github.io/images/study-avatar.png 1.5x, /liudongdong1.github.io/images/study-avatar.png 2x" data-sizes=auto alt=LiuDongdong title=LiuDongdong width=1024 height=1024>&nbsp;LiuDongdong</a></span></div><div class=post-meta-line><span title="2021-04-14 08:38:11"><i class="fa-regular fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2021-04-14>2021-04-14</time>
</span>&nbsp;<i class="fa-solid fa-pencil-alt fa-fw"></i>&nbsp;约 5774 字&nbsp;
<i class="fa-regular fa-clock fa-fw"></i>&nbsp;预计阅读 12 分钟&nbsp;<span id=busuanzi_container_page_pv class="busuanzi_visitors comment-visitors" data-flag-title="SkLearn Optimize">
<i class="fa-regular fa-eye fa-fw"></i>&nbsp;<span id=busuanzi_value_page_pv>-</span>&nbsp;次阅读
</span>&nbsp;</div></div><div class=featured-image><img class=lazyload src=/liudongdong1.github.io/svg/loading.min.svg data-src=https://gitee.com/github-25970295/blogImage/raw/master/img/20210501113542.png data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/20210501113542.png, https://gitee.com/github-25970295/blogImage/raw/master/img/20210501113542.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/20210501113542.png 2x" data-sizes=auto alt=https://gitee.com/github-25970295/blogImage/raw/master/img/20210501113542.png title=https://gitee.com/github-25970295/blogImage/raw/master/img/20210501113542.png></div><div class="details toc" id=toc-static kept=true><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fa-solid fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><ul><li><a href=#1-gridsearchcvhttpsscikit-learnorgstablemodulesgeneratedsklearnmodel_selectiongridsearchcvhtmlhighlightgrid20searchsklearnmodel_selectiongridsearchcv>1. <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=grid%20search#sklearn.model_selection.GridSearchCV">GridSearchCV</a></a></li><li><a href=#2-halvinggridsearchcvhttpsscikit-learnorgstablemodulesgeneratedsklearnmodel_selectionhalvinggridsearchcvhtmlsklearnmodel_selectionhalvinggridsearchcv--halvingrandomsearchcvhttpsscikit-learnorgstablemodulesgeneratedsklearnmodel_selectionhalvingrandomsearchcvhtmlsklearnmodel_selectionhalvingrandomsearchcv>2. <a href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV>HalvingGridSearchCV</a> & <a href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html#sklearn.model_selection.HalvingRandomSearchCV>HalvingRandomSearchCV</a></a></li><li><a href=#3-randomizedsearchcvhttpsscikit-learnorgstablemodulesgeneratedsklearnmodel_selectionrandomizedsearchcvhtmlsklearnmodel_selectionrandomizedsearchcv>3. <a href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV>RandomizedSearchCV</a></a></li><li><a href=#4-跨框架调参>4. 跨框架调参</a></li><li><a href=#学习资源>学习资源</a></li></ul></li></ul></nav></div></div><div class=content id=content><blockquote><p>使用scikit-learn时提高速度的三种主要方法是：使用<strong>joblib和Ray并行化或分发培训</strong>，<strong>使用不同的超参数优化技术</strong>（网格搜索，随机搜索，提前停止），以及<strong>更改优化功能</strong>（求解器）。</p><p>1.<strong>随机参数选择模型（RandomizedSearchCV）可以帮助我们快速的确定参数的范围。</strong></p><p>2.<strong>对于随机参数选择模型而言，初始的特征空间选择特别重要。如果初始的特征空间选择不对，则后面的调参工作都可能是徒劳。我们可参考一些经验值或者做一些对比试验，来确定模型的参数空间。</strong></p><p>3.**RandomizedSearchCV 和 GridSearchCV 搭配使用，<code>先找大致范围，再精确搜索**</code>。</p><p>4.通过优化模型参数，虽然每次的提升幅度不是很大，但是通过多次的优化，这些小的提升累加在一起就是很大的提升。</p><p>5.<strong>遇到不懂的问题，多查看sklearn官方文档，这是一个逐渐积累和提升的过程</strong>。</p></blockquote><p><img class=lazyload src=/liudongdong1.github.io/svg/loading.min.svg data-src=https://gitee.com/github-25970295/blogImage/raw/master/img/20210414094200.png data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/20210414094200.png, https://gitee.com/github-25970295/blogImage/raw/master/img/20210414094200.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/20210414094200.png 2x" data-sizes=auto alt=https://gitee.com/github-25970295/blogImage/raw/master/img/20210414094200.png title=https://gitee.com/github-25970295/blogImage/raw/master/img/20210414094200.png></p><h3 id=1-gridsearchcvhttpsscikit-learnorgstablemodulesgeneratedsklearnmodel_selectiongridsearchcvhtmlhighlightgrid20searchsklearnmodel_selectiongridsearchcv>1. <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=grid%20search#sklearn.model_selection.GridSearchCV" target=_blank rel="external nofollow noopener noreferrer">GridSearchCV<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></h3><h4 id=11-函数介绍>1.1. 函数介绍</h4><p><em>class</em> <code>sklearn.model_selection.``GridSearchCV</code>(<em>estimator</em>, <em>param_grid</em>, ***, <em>scoring=None</em>, <em>n_jobs=None</em>, <em>refit=True</em>, <em>cv=None</em>, <em>verbose=0</em>, <em>pre_dispatch=&lsquo;2*n_jobs&rsquo;</em>, <em>error_score=nan</em>, <em>return_train_score=False</em>)[<a href=https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/model_selection/_search.py#L971 target=_blank rel="external nofollow noopener noreferrer">source]<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></p><ul><li>estimator ：估计器对象，例如要找随机森林模型的最佳参数，就传随机森林模型。</li><li>parameters：要选择的参数集合。</li><li>cv: 用来指定交叉验证数据集的生成规则。假设=5表示每次计算都把数据集分成5份，拿其中一份作为交叉验证数据集，其他作为训练集。</li></ul><blockquote><p>GridSearchCV implements a “fit” and a “score” method. It also implements “score_samples”, “predict”, “predict_proba”, “decision_function”, “transform” and “inverse_transform” if they are implemented in the estimator used.</p></blockquote><blockquote><p>GridSearch和CV，即网格搜索和交叉验证。网格搜索，搜索的是参数，即在指定的参数范围内，按步长依次调整参数，利用调整的参数训练学习器，从所有的参数中找到在验证集上精度最高的参数，这其实是一个训练和比较的过程,非常耗时。</p><p>网格搜索适用于三四个（或者更少）的超参数（<code>当超参数的数量增长时，网格搜索的计算复杂度会呈现指数增长，这时候则使用随机搜索</code>），用户列出一个较小的超参数值域，这些超参数至于的笛卡尔积（排列组合）为一组组超参数。网格搜索算法使用每组超参数训练模型并挑选验证集误差最小的超参数组合。</p></blockquote><h4 id=12-使用案例>1.2. 使用案例</h4><h5 id=1-decisiontreeclassifier-调参数>.1. <strong>DecisionTreeClassifier 调参数</strong></h5><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 数据分为训练集和测试集</span>
</span></span><span style=display:flex><span>x_train,x_test,y_train,y_test <span style=color:#f92672>=</span> train_test_split(x,y,test_size<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>,random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 用GridSearchCV寻找最优参数（字典）  参数具体看API种 estimator 函数有哪些参数</span>
</span></span><span style=display:flex><span>param <span style=color:#f92672>=</span> [{<span style=color:#e6db74>&#39;criterion&#39;</span>:[<span style=color:#e6db74>&#39;gini&#39;</span>],<span style=color:#e6db74>&#39;max_depth&#39;</span>:[<span style=color:#ae81ff>30</span>,<span style=color:#ae81ff>50</span>,<span style=color:#ae81ff>60</span>,<span style=color:#ae81ff>100</span>],<span style=color:#e6db74>&#39;min_samples_leaf&#39;</span>:[<span style=color:#ae81ff>2</span>,<span style=color:#ae81ff>3</span>,<span style=color:#ae81ff>5</span>,<span style=color:#ae81ff>10</span>],<span style=color:#e6db74>&#39;min_impurity_decrease&#39;</span>:[<span style=color:#ae81ff>0.1</span>,<span style=color:#ae81ff>0.2</span>,<span style=color:#ae81ff>0.5</span>]},
</span></span><span style=display:flex><span>         {<span style=color:#e6db74>&#39;criterion&#39;</span>:[<span style=color:#e6db74>&#39;gini&#39;</span>,<span style=color:#e6db74>&#39;entropy&#39;</span>]},
</span></span><span style=display:flex><span>         {<span style=color:#e6db74>&#39;max_depth&#39;</span>: [<span style=color:#ae81ff>30</span>,<span style=color:#ae81ff>60</span>,<span style=color:#ae81ff>100</span>], <span style=color:#e6db74>&#39;min_impurity_decrease&#39;</span>:[<span style=color:#ae81ff>0.1</span>,<span style=color:#ae81ff>0.2</span>,<span style=color:#ae81ff>0.5</span>]}]
</span></span><span style=display:flex><span>clf <span style=color:#f92672>=</span> GridSearchCV(DecisionTreeClassifier(),param_grid<span style=color:#f92672>=</span>param,cv<span style=color:#f92672>=</span><span style=color:#ae81ff>6</span>)
</span></span><span style=display:flex><span>clf<span style=color:#f92672>.</span>fit(x_train,y_train)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;最优分类器:&#39;</span>,grid<span style=color:#f92672>.</span>best_params_,<span style=color:#e6db74>&#39;最优分数:&#39;</span>, grid<span style=color:#f92672>.</span>best_score_)  <span style=color:#75715e># 得到最优的参数和分值</span>
</span></span></code></pre></div><ul><li>调参过程可视化</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>clf<span style=color:#f92672>.</span>fit(x_train,y_train)
</span></span><span style=display:flex><span>fig <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>figure()
</span></span><span style=display:flex><span>ax <span style=color:#f92672>=</span> fig<span style=color:#f92672>.</span>add_subplot(<span style=color:#ae81ff>111</span>)
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>fill_between(min_samples_leaf,clf<span style=color:#f92672>.</span>cv_results_[<span style=color:#e6db74>&#39;mean_train_score&#39;</span>]<span style=color:#f92672>+</span>clf<span style=color:#f92672>.</span>cv_results_[<span style=color:#e6db74>&#39;std_train_score&#39;</span>],
</span></span><span style=display:flex><span>                 clf<span style=color:#f92672>.</span>cv_results_[<span style=color:#e6db74>&#39;mean_train_score&#39;</span>]<span style=color:#f92672>-</span>clf<span style=color:#f92672>.</span>cv_results_[<span style=color:#e6db74>&#39;std_train_score&#39;</span>],color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;b&#39;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>fill_between(min_samples_leaf,clf<span style=color:#f92672>.</span>cv_results_[<span style=color:#e6db74>&#39;mean_test_score&#39;</span>]<span style=color:#f92672>+</span>clf<span style=color:#f92672>.</span>cv_results_[<span style=color:#e6db74>&#39;std_test_score&#39;</span>],
</span></span><span style=display:flex><span>                 clf<span style=color:#f92672>.</span>cv_results_[<span style=color:#e6db74>&#39;mean_test_score&#39;</span>]<span style=color:#f92672>-</span>clf<span style=color:#f92672>.</span>cv_results_[<span style=color:#e6db74>&#39;std_test_score&#39;</span>],color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;r&#39;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>plot(min_samples_leaf,clf<span style=color:#f92672>.</span>cv_results_[<span style=color:#e6db74>&#39;mean_train_score&#39;</span>],<span style=color:#e6db74>&#39;ko-&#39;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>plot(min_samples_leaf,clf<span style=color:#f92672>.</span>cv_results_[<span style=color:#e6db74>&#39;mean_test_score&#39;</span>],<span style=color:#e6db74>&#39;g*-&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>legend()
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#39;GridSearchCV训练过程图&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>rcParams[<span style=color:#e6db74>&#39;font.sans-serif&#39;</span>] <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;SimHei&#39;</span>]
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>rcParams[<span style=color:#e6db74>&#39;font.serif&#39;</span>] <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;SimHei&#39;</span>]  <span style=color:#75715e># 设置正常显示中文</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><h5 id=2-cross_validation-调参>.2. Cross_validation 调参</h5><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn <span style=color:#f92672>import</span> datasets
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> train_test_split
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> GridSearchCV
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.metrics <span style=color:#f92672>import</span> classification_report
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.svm <span style=color:#f92672>import</span> SVC
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(__doc__)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Loading the Digits dataset</span>
</span></span><span style=display:flex><span>digits <span style=color:#f92672>=</span> datasets<span style=color:#f92672>.</span>load_digits()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># To apply an classifier on this data, we need to flatten the image, to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># turn the data in a (samples, feature) matrix:</span>
</span></span><span style=display:flex><span>n_samples <span style=color:#f92672>=</span> len(digits<span style=color:#f92672>.</span>images)
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> digits<span style=color:#f92672>.</span>images<span style=color:#f92672>.</span>reshape((n_samples, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> digits<span style=color:#f92672>.</span>target
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Split the dataset in two equal parts</span>
</span></span><span style=display:flex><span>X_train, X_test, y_train, y_test <span style=color:#f92672>=</span> train_test_split(
</span></span><span style=display:flex><span>    X, y, test_size<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Set the parameters by cross-validation</span>
</span></span><span style=display:flex><span>tuned_parameters <span style=color:#f92672>=</span> [{<span style=color:#e6db74>&#39;kernel&#39;</span>: [<span style=color:#e6db74>&#39;rbf&#39;</span>], <span style=color:#e6db74>&#39;gamma&#39;</span>: [<span style=color:#ae81ff>1e-3</span>, <span style=color:#ae81ff>1e-4</span>],
</span></span><span style=display:flex><span>                     <span style=color:#e6db74>&#39;C&#39;</span>: [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>100</span>, <span style=color:#ae81ff>1000</span>]},
</span></span><span style=display:flex><span>                    {<span style=color:#e6db74>&#39;kernel&#39;</span>: [<span style=color:#e6db74>&#39;linear&#39;</span>], <span style=color:#e6db74>&#39;C&#39;</span>: [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>100</span>, <span style=color:#ae81ff>1000</span>]}]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>scores <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;precision&#39;</span>, <span style=color:#e6db74>&#39;recall&#39;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> score <span style=color:#f92672>in</span> scores:
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;# Tuning hyper-parameters for </span><span style=color:#e6db74>%s</span><span style=color:#e6db74>&#34;</span> <span style=color:#f92672>%</span> score)
</span></span><span style=display:flex><span>    print()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    clf <span style=color:#f92672>=</span> GridSearchCV(
</span></span><span style=display:flex><span>        SVC(), tuned_parameters, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;</span><span style=color:#e6db74>%s</span><span style=color:#e6db74>_macro&#39;</span> <span style=color:#f92672>%</span> score
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    clf<span style=color:#f92672>.</span>fit(X_train, y_train)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;Best parameters set found on development set:&#34;</span>)
</span></span><span style=display:flex><span>    print()
</span></span><span style=display:flex><span>    print(clf<span style=color:#f92672>.</span>best_params_)
</span></span><span style=display:flex><span>    print()
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;Grid scores on development set:&#34;</span>)
</span></span><span style=display:flex><span>    print()
</span></span><span style=display:flex><span>    means <span style=color:#f92672>=</span> clf<span style=color:#f92672>.</span>cv_results_[<span style=color:#e6db74>&#39;mean_test_score&#39;</span>]
</span></span><span style=display:flex><span>    stds <span style=color:#f92672>=</span> clf<span style=color:#f92672>.</span>cv_results_[<span style=color:#e6db74>&#39;std_test_score&#39;</span>]
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> mean, std, params <span style=color:#f92672>in</span> zip(means, stds, clf<span style=color:#f92672>.</span>cv_results_[<span style=color:#e6db74>&#39;params&#39;</span>]):
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#34;</span><span style=color:#e6db74>%0.3f</span><span style=color:#e6db74> (+/-</span><span style=color:#e6db74>%0.03f</span><span style=color:#e6db74>) for </span><span style=color:#e6db74>%r</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>%</span> (mean, std <span style=color:#f92672>*</span> <span style=color:#ae81ff>2</span>, params))
</span></span><span style=display:flex><span>    print()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;Detailed classification report:&#34;</span>)
</span></span><span style=display:flex><span>    print()
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;The model is trained on the full development set.&#34;</span>)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;The scores are computed on the full evaluation set.&#34;</span>)
</span></span><span style=display:flex><span>    print()
</span></span><span style=display:flex><span>    y_true, y_pred <span style=color:#f92672>=</span> y_test, clf<span style=color:#f92672>.</span>predict(X_test)
</span></span><span style=display:flex><span>    print(classification_report(y_true, y_pred))
</span></span><span style=display:flex><span>    print()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Note the problem is too easy: the hyperparameter plateau is too flat and the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># output model is the same for precision and recall with ties in quality.</span>
</span></span></code></pre></div><h5 id=3-xgbclassifier>.3. <strong>XGBClassifier</strong></h5><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e>#分类器使用 xgboost</span>
</span></span><span style=display:flex><span>clf1 <span style=color:#f92672>=</span> xgb<span style=color:#f92672>.</span>XGBClassifier()
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span><span style=color:#75715e>#设定网格搜索的xgboost参数搜索范围，值搜索XGBoost的主要6个参数</span>
</span></span><span style=display:flex><span>param_dist <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;n_estimators&#39;</span>:range(<span style=color:#ae81ff>80</span>,<span style=color:#ae81ff>200</span>,<span style=color:#ae81ff>4</span>),
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;max_depth&#39;</span>:range(<span style=color:#ae81ff>2</span>,<span style=color:#ae81ff>15</span>,<span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;learning_rate&#39;</span>:np<span style=color:#f92672>.</span>linspace(<span style=color:#ae81ff>0.01</span>,<span style=color:#ae81ff>2</span>,<span style=color:#ae81ff>20</span>),
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;subsample&#39;</span>:np<span style=color:#f92672>.</span>linspace(<span style=color:#ae81ff>0.7</span>,<span style=color:#ae81ff>0.9</span>,<span style=color:#ae81ff>20</span>),
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;colsample_bytree&#39;</span>:np<span style=color:#f92672>.</span>linspace(<span style=color:#ae81ff>0.5</span>,<span style=color:#ae81ff>0.98</span>,<span style=color:#ae81ff>10</span>),
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;min_child_weight&#39;</span>:range(<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>9</span>,<span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span><span style=color:#75715e>#GridSearchCV参数说明，clf1设置训练的学习器</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#param_dist字典类型，放入参数搜索范围</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#scoring = &#39;neg_log_loss&#39;，精度评价方式设定为“neg_log_loss“</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#n_iter=300，训练300次，数值越大，获得的参数精度越大，但是搜索时间越长</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#n_jobs = -1，使用所有的CPU进行训练，默认为1，使用1个CPU</span>
</span></span><span style=display:flex><span>grid <span style=color:#f92672>=</span> GridSearchCV(clf1,param_dist,cv <span style=color:#f92672>=</span> <span style=color:#ae81ff>3</span>,scoring <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;neg_log_loss&#39;</span>,n_iter<span style=color:#f92672>=</span><span style=color:#ae81ff>300</span>,n_jobs <span style=color:#f92672>=</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span><span style=color:#75715e>#在训练集上训练</span>
</span></span><span style=display:flex><span>grid<span style=color:#f92672>.</span>fit(traindata<span style=color:#f92672>.</span>values,np<span style=color:#f92672>.</span>ravel(trainlabel<span style=color:#f92672>.</span>values))
</span></span><span style=display:flex><span><span style=color:#75715e>#返回最优的训练器</span>
</span></span><span style=display:flex><span>best_estimator <span style=color:#f92672>=</span> grid<span style=color:#f92672>.</span>best_estimator_
</span></span><span style=display:flex><span>print(best_estimator)
</span></span><span style=display:flex><span><span style=color:#75715e>#输出最优训练器的精度</span>
</span></span><span style=display:flex><span>print(grid<span style=color:#f92672>.</span>best_score_)
</span></span></code></pre></div><p><img class=lazyload src=/liudongdong1.github.io/svg/loading.min.svg data-src=https://gitee.com/github-25970295/blogImage/raw/master/img/20210414095030.png data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/20210414095030.png, https://gitee.com/github-25970295/blogImage/raw/master/img/20210414095030.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/20210414095030.png 2x" data-sizes=auto alt=https://gitee.com/github-25970295/blogImage/raw/master/img/20210414095030.png title=https://gitee.com/github-25970295/blogImage/raw/master/img/20210414095030.png></p><h5 id=4-mlpclassifier>.4. <strong>MLPClassifier</strong></h5><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn <span style=color:#f92672>import</span> neural_network
</span></span><span style=display:flex><span>mlp<span style=color:#f92672>=</span>neural_network<span style=color:#f92672>.</span>MLPClassifier(max_iter<span style=color:#f92672>=</span><span style=color:#ae81ff>1000</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>param_grid <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;hidden_layer_sizes&#39;</span>:[(<span style=color:#ae81ff>10</span>, ), (<span style=color:#ae81ff>20</span>, ), (<span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>5</span>)],
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;activation&#39;</span>:[<span style=color:#e6db74>&#39;logistic&#39;</span>, <span style=color:#e6db74>&#39;tanh&#39;</span>, <span style=color:#e6db74>&#39;relu&#39;</span>],
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;alpha&#39;</span>:[<span style=color:#ae81ff>0.001</span>, <span style=color:#ae81ff>0.01</span>, <span style=color:#ae81ff>0.1</span>, <span style=color:#ae81ff>0.4</span>, <span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>gscv <span style=color:#f92672>=</span> model_selection<span style=color:#f92672>.</span>GridSearchCV(estimator<span style=color:#f92672>=</span>mlp,
</span></span><span style=display:flex><span>                                   param_grid<span style=color:#f92672>=</span>param_grid,
</span></span><span style=display:flex><span>                                   scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;accuracy&#39;</span>, <span style=color:#75715e># 打分</span>
</span></span><span style=display:flex><span>                                   cv<span style=color:#f92672>=</span>gkf<span style=color:#f92672>.</span>split(X,y,groups), <span style=color:#75715e># cv 方法</span>
</span></span><span style=display:flex><span>                                   return_train_score<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, <span style=color:#75715e># 默认不返回 train 的score</span>
</span></span><span style=display:flex><span>                                   refit<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, <span style=color:#75715e># 默认为 True, 用最好的模型+全量数据再次训练，用 gscv.best_estimator_ 获取最好模型</span>
</span></span><span style=display:flex><span>                                   n_jobs<span style=color:#f92672>=-</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>gscv<span style=color:#f92672>.</span>fit(X,y)
</span></span><span style=display:flex><span>gscv<span style=color:#f92672>.</span>cv_results_
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>gscv<span style=color:#f92672>.</span>best_score_
</span></span><span style=display:flex><span>gscv<span style=color:#f92672>.</span>best_params_
</span></span><span style=display:flex><span>best_model <span style=color:#f92672>=</span> gscv<span style=color:#f92672>.</span>best_estimator_
</span></span><span style=display:flex><span>best_model<span style=color:#f92672>.</span>score(test_data, test_target)
</span></span></code></pre></div><h5 id=5-svc-调参数>.5. <strong>SVC 调参数</strong></h5><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e>#把要调整的参数以及其候选值 列出来；</span>
</span></span><span style=display:flex><span>param_grid <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>	{<span style=color:#e6db74>&#39;kernel&#39;</span>:[<span style=color:#e6db74>&#39;linear&#39;</span>],<span style=color:#e6db74>&#39;C&#39;</span>:[<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>10</span>,<span style=color:#ae81ff>100</span>,<span style=color:#ae81ff>1000</span>]},
</span></span><span style=display:flex><span>	{<span style=color:#e6db74>&#39;kernel&#39;</span>:[<span style=color:#e6db74>&#39;poly&#39;</span>],<span style=color:#e6db74>&#39;C&#39;</span>:[<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>10</span>],<span style=color:#e6db74>&#39;degree&#39;</span>:[<span style=color:#ae81ff>2</span>,<span style=color:#ae81ff>3</span>]},
</span></span><span style=display:flex><span>	{<span style=color:#e6db74>&#39;kernel&#39;</span>:[<span style=color:#e6db74>&#39;rbf&#39;</span>],<span style=color:#e6db74>&#39;C&#39;</span>:[<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>10</span>,<span style=color:#ae81ff>100</span>,<span style=color:#ae81ff>1000</span>],<span style=color:#e6db74>&#39;gamma&#39;</span>:[<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>0.1</span>, <span style=color:#ae81ff>0.01</span>, <span style=color:#ae81ff>0.001</span>]}]
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Parameters:</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(param_grid))
</span></span><span style=display:flex><span>grid_search <span style=color:#f92672>=</span> GridSearchCV(SVC(),param_grid,cv<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>) <span style=color:#75715e>#实例化一个GridSearchCV类</span>
</span></span><span style=display:flex><span>X_train,X_test,y_train,y_test <span style=color:#f92672>=</span> train_test_split(iris<span style=color:#f92672>.</span>data,iris<span style=color:#f92672>.</span>target,random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>grid_search<span style=color:#f92672>.</span>fit(X_train,y_train) <span style=color:#75715e>#训练，找到最优的参数，同时使用最优的参数实例化一个新的SVC estimator。</span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Test set score:</span><span style=color:#e6db74>{:.2f}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(grid_search<span style=color:#f92672>.</span>score(X_test,y_test)))
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Best parameters:</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(grid_search<span style=color:#f92672>.</span>best_params_))
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Best score on train set:</span><span style=color:#e6db74>{:.2f}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(grid_search<span style=color:#f92672>.</span>best_score_))
</span></span></code></pre></div><h5 id=6-multi-metric-evaluation-on-cross_val_score>.6. Multi-metric Evaluation on Cross_val_score</h5><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> matplotlib <span style=color:#f92672>import</span> pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.datasets <span style=color:#f92672>import</span> make_hastie_10_2
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> GridSearchCV
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.metrics <span style=color:#f92672>import</span> make_scorer
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.metrics <span style=color:#f92672>import</span> accuracy_score
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.tree <span style=color:#f92672>import</span> DecisionTreeClassifier
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(__doc__)
</span></span><span style=display:flex><span>X, y <span style=color:#f92672>=</span> make_hastie_10_2(n_samples<span style=color:#f92672>=</span><span style=color:#ae81ff>8000</span>, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># The scorers can be either one of the predefined metric strings or a scorer</span>
</span></span><span style=display:flex><span><span style=color:#75715e># callable, like the one returned by make_scorer</span>
</span></span><span style=display:flex><span>scoring <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#39;AUC&#39;</span>: <span style=color:#e6db74>&#39;roc_auc&#39;</span>, <span style=color:#e6db74>&#39;Accuracy&#39;</span>: make_scorer(accuracy_score)}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Setting refit=&#39;AUC&#39;, refits an estimator on the whole dataset with the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># parameter setting that has the best cross-validated AUC score.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># That estimator is made available at ``gs.best_estimator_`` along with</span>
</span></span><span style=display:flex><span><span style=color:#75715e># parameters like ``gs.best_score_``, ``gs.best_params_`` and</span>
</span></span><span style=display:flex><span><span style=color:#75715e># ``gs.best_index_``</span>
</span></span><span style=display:flex><span>gs <span style=color:#f92672>=</span> GridSearchCV(DecisionTreeClassifier(random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>),
</span></span><span style=display:flex><span>                  param_grid<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#39;min_samples_split&#39;</span>: range(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>403</span>, <span style=color:#ae81ff>10</span>)},
</span></span><span style=display:flex><span>                  scoring<span style=color:#f92672>=</span>scoring, refit<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;AUC&#39;</span>, return_train_score<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>gs<span style=color:#f92672>.</span>fit(X, y)
</span></span><span style=display:flex><span>results <span style=color:#f92672>=</span> gs<span style=color:#f92672>.</span>cv_results_
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>13</span>, <span style=color:#ae81ff>13</span>))
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#34;GridSearchCV evaluating using multiple scorers simultaneously&#34;</span>,
</span></span><span style=display:flex><span>          fontsize<span style=color:#f92672>=</span><span style=color:#ae81ff>16</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#34;min_samples_split&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#34;Score&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ax <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>gca()
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>set_xlim(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>402</span>)
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>set_ylim(<span style=color:#ae81ff>0.73</span>, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Get the regular numpy array from the MaskedArray</span>
</span></span><span style=display:flex><span>X_axis <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(results[<span style=color:#e6db74>&#39;param_min_samples_split&#39;</span>]<span style=color:#f92672>.</span>data, dtype<span style=color:#f92672>=</span>float)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> scorer, color <span style=color:#f92672>in</span> zip(sorted(scoring), [<span style=color:#e6db74>&#39;g&#39;</span>, <span style=color:#e6db74>&#39;k&#39;</span>]):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> sample, style <span style=color:#f92672>in</span> ((<span style=color:#e6db74>&#39;train&#39;</span>, <span style=color:#e6db74>&#39;--&#39;</span>), (<span style=color:#e6db74>&#39;test&#39;</span>, <span style=color:#e6db74>&#39;-&#39;</span>)):
</span></span><span style=display:flex><span>        sample_score_mean <span style=color:#f92672>=</span> results[<span style=color:#e6db74>&#39;mean_</span><span style=color:#e6db74>%s</span><span style=color:#e6db74>_</span><span style=color:#e6db74>%s</span><span style=color:#e6db74>&#39;</span> <span style=color:#f92672>%</span> (sample, scorer)]
</span></span><span style=display:flex><span>        sample_score_std <span style=color:#f92672>=</span> results[<span style=color:#e6db74>&#39;std_</span><span style=color:#e6db74>%s</span><span style=color:#e6db74>_</span><span style=color:#e6db74>%s</span><span style=color:#e6db74>&#39;</span> <span style=color:#f92672>%</span> (sample, scorer)]
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>fill_between(X_axis, sample_score_mean <span style=color:#f92672>-</span> sample_score_std,
</span></span><span style=display:flex><span>                        sample_score_mean <span style=color:#f92672>+</span> sample_score_std,
</span></span><span style=display:flex><span>                        alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span> <span style=color:#66d9ef>if</span> sample <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;test&#39;</span> <span style=color:#66d9ef>else</span> <span style=color:#ae81ff>0</span>, color<span style=color:#f92672>=</span>color)
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>plot(X_axis, sample_score_mean, style, color<span style=color:#f92672>=</span>color,
</span></span><span style=display:flex><span>                alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> <span style=color:#66d9ef>if</span> sample <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;test&#39;</span> <span style=color:#66d9ef>else</span> <span style=color:#ae81ff>0.7</span>,
</span></span><span style=display:flex><span>                label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>%s</span><span style=color:#e6db74> (</span><span style=color:#e6db74>%s</span><span style=color:#e6db74>)&#34;</span> <span style=color:#f92672>%</span> (scorer, sample))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    best_index <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>nonzero(results[<span style=color:#e6db74>&#39;rank_test_</span><span style=color:#e6db74>%s</span><span style=color:#e6db74>&#39;</span> <span style=color:#f92672>%</span> scorer] <span style=color:#f92672>==</span> <span style=color:#ae81ff>1</span>)[<span style=color:#ae81ff>0</span>][<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>    best_score <span style=color:#f92672>=</span> results[<span style=color:#e6db74>&#39;mean_test_</span><span style=color:#e6db74>%s</span><span style=color:#e6db74>&#39;</span> <span style=color:#f92672>%</span> scorer][best_index]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Plot a dotted vertical line at the best score for that scorer marked by x</span>
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>plot([X_axis[best_index], ] <span style=color:#f92672>*</span> <span style=color:#ae81ff>2</span>, [<span style=color:#ae81ff>0</span>, best_score],
</span></span><span style=display:flex><span>            linestyle<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;-.&#39;</span>, color<span style=color:#f92672>=</span>color, marker<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;x&#39;</span>, markeredgewidth<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, ms<span style=color:#f92672>=</span><span style=color:#ae81ff>8</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Annotate the best score for that scorer</span>
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>annotate(<span style=color:#e6db74>&#34;</span><span style=color:#e6db74>%0.2f</span><span style=color:#e6db74>&#34;</span> <span style=color:#f92672>%</span> best_score,
</span></span><span style=display:flex><span>                (X_axis[best_index], best_score <span style=color:#f92672>+</span> <span style=color:#ae81ff>0.005</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>legend(loc<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;best&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>grid(<span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><p><img class=lazyload src=/liudongdong1.github.io/svg/loading.min.svg data-src=https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210522185021612.png data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210522185021612.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210522185021612.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210522185021612.png 2x" data-sizes=auto alt=https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210522185021612.png title=https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210522185021612.png></p><h5 id=7-selecting-dimensionality-reduction-with-pipeline>.7. Selecting dimensionality reduction with Pipeline</h5><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.datasets <span style=color:#f92672>import</span> load_digits
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> GridSearchCV
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.pipeline <span style=color:#f92672>import</span> Pipeline
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.svm <span style=color:#f92672>import</span> LinearSVC
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.decomposition <span style=color:#f92672>import</span> PCA, NMF
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.feature_selection <span style=color:#f92672>import</span> SelectKBest, chi2
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(__doc__)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>pipe <span style=color:#f92672>=</span> Pipeline([
</span></span><span style=display:flex><span>    <span style=color:#75715e># the reduce_dim stage is populated by the param_grid</span>
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#39;reduce_dim&#39;</span>, <span style=color:#e6db74>&#39;passthrough&#39;</span>),
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#39;classify&#39;</span>, LinearSVC(dual<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>, max_iter<span style=color:#f92672>=</span><span style=color:#ae81ff>10000</span>))
</span></span><span style=display:flex><span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>N_FEATURES_OPTIONS <span style=color:#f92672>=</span> [<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>8</span>]
</span></span><span style=display:flex><span>C_OPTIONS <span style=color:#f92672>=</span> [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>100</span>, <span style=color:#ae81ff>1000</span>]
</span></span><span style=display:flex><span>param_grid <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;reduce_dim&#39;</span>: [PCA(iterated_power<span style=color:#f92672>=</span><span style=color:#ae81ff>7</span>), NMF()],
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;reduce_dim__n_components&#39;</span>: N_FEATURES_OPTIONS,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;classify__C&#39;</span>: C_OPTIONS
</span></span><span style=display:flex><span>    },
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;reduce_dim&#39;</span>: [SelectKBest(chi2)],
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;reduce_dim__k&#39;</span>: N_FEATURES_OPTIONS,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;classify__C&#39;</span>: C_OPTIONS
</span></span><span style=display:flex><span>    },
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>reducer_labels <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;PCA&#39;</span>, <span style=color:#e6db74>&#39;NMF&#39;</span>, <span style=color:#e6db74>&#39;KBest(chi2)&#39;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>grid <span style=color:#f92672>=</span> GridSearchCV(pipe, n_jobs<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, param_grid<span style=color:#f92672>=</span>param_grid)
</span></span><span style=display:flex><span>X, y <span style=color:#f92672>=</span> load_digits(return_X_y<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>grid<span style=color:#f92672>.</span>fit(X, y)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>mean_scores <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(grid<span style=color:#f92672>.</span>cv_results_[<span style=color:#e6db74>&#39;mean_test_score&#39;</span>])
</span></span><span style=display:flex><span><span style=color:#75715e># scores are in the order of param_grid iteration, which is alphabetical</span>
</span></span><span style=display:flex><span>mean_scores <span style=color:#f92672>=</span> mean_scores<span style=color:#f92672>.</span>reshape(len(C_OPTIONS), <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, len(N_FEATURES_OPTIONS))
</span></span><span style=display:flex><span><span style=color:#75715e># select score for best C</span>
</span></span><span style=display:flex><span>mean_scores <span style=color:#f92672>=</span> mean_scores<span style=color:#f92672>.</span>max(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>bar_offsets <span style=color:#f92672>=</span> (np<span style=color:#f92672>.</span>arange(len(N_FEATURES_OPTIONS)) <span style=color:#f92672>*</span>
</span></span><span style=display:flex><span>               (len(reducer_labels) <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>) <span style=color:#f92672>+</span> <span style=color:#ae81ff>.5</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure()
</span></span><span style=display:flex><span>COLORS <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;bgrcmyk&#39;</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i, (label, reducer_scores) <span style=color:#f92672>in</span> enumerate(zip(reducer_labels, mean_scores)):
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>bar(bar_offsets <span style=color:#f92672>+</span> i, reducer_scores, label<span style=color:#f92672>=</span>label, color<span style=color:#f92672>=</span>COLORS[i])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#34;Comparing feature reduction techniques&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#39;Reduced number of features&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>xticks(bar_offsets <span style=color:#f92672>+</span> len(reducer_labels) <span style=color:#f92672>/</span> <span style=color:#ae81ff>2</span>, N_FEATURES_OPTIONS)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#39;Digit classification accuracy&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>ylim((<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>legend(loc<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;upper left&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><h4 id=13-代码理解>1.3. 代码理解</h4><blockquote><p>该类在搜索参数空间的时候使用到：ParameterGrid:</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> <span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> ParameterGrid
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> param_grid <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#39;a&#39;</span>: [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>], <span style=color:#e6db74>&#39;b&#39;</span>: [<span style=color:#66d9ef>True</span>, <span style=color:#66d9ef>False</span>]}
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> list(ParameterGrid(param_grid)) <span style=color:#f92672>==</span> (
</span></span><span style=display:flex><span>    <span style=color:#f92672>...</span>    [{<span style=color:#e6db74>&#39;a&#39;</span>: <span style=color:#ae81ff>1</span>, <span style=color:#e6db74>&#39;b&#39;</span>: <span style=color:#66d9ef>True</span>}, {<span style=color:#e6db74>&#39;a&#39;</span>: <span style=color:#ae81ff>1</span>, <span style=color:#e6db74>&#39;b&#39;</span>: <span style=color:#66d9ef>False</span>},
</span></span><span style=display:flex><span>            <span style=color:#f92672>...</span>     {<span style=color:#e6db74>&#39;a&#39;</span>: <span style=color:#ae81ff>2</span>, <span style=color:#e6db74>&#39;b&#39;</span>: <span style=color:#66d9ef>True</span>}, {<span style=color:#e6db74>&#39;a&#39;</span>: <span style=color:#ae81ff>2</span>, <span style=color:#e6db74>&#39;b&#39;</span>: <span style=color:#66d9ef>False</span>}])
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> __getitem__(self, ind):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;Get the parameters that would be ``ind``th in iteration
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Parameters
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        ----------
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        ind : int
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            The iteration index
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Returns
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        -------
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        params : dict of str to any
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            Equal to list(self)[ind]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># This is used to make discrete sampling without replacement memory</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># efficient.</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> sub_grid <span style=color:#f92672>in</span> self<span style=color:#f92672>.</span>param_grid:
</span></span><span style=display:flex><span>            <span style=color:#75715e># XXX: could memoize information used here</span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> sub_grid:
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>if</span> ind <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>                    <span style=color:#66d9ef>return</span> {}
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>                    ind <span style=color:#f92672>-=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>                    <span style=color:#66d9ef>continue</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># Reverse so most frequent cycling parameter comes first</span>
</span></span><span style=display:flex><span>            keys, values_lists <span style=color:#f92672>=</span> zip(<span style=color:#f92672>*</span>sorted(sub_grid<span style=color:#f92672>.</span>items())[::<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>])
</span></span><span style=display:flex><span>            sizes <span style=color:#f92672>=</span> [len(v_list) <span style=color:#66d9ef>for</span> v_list <span style=color:#f92672>in</span> values_lists]
</span></span><span style=display:flex><span>            total <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>product(sizes)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> ind <span style=color:#f92672>&gt;=</span> total:
</span></span><span style=display:flex><span>                <span style=color:#75715e># Try the next grid</span>
</span></span><span style=display:flex><span>                ind <span style=color:#f92672>-=</span> total
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>                out <span style=color:#f92672>=</span> {}
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>for</span> key, v_list, n <span style=color:#f92672>in</span> zip(keys, values_lists, sizes):
</span></span><span style=display:flex><span>                    ind, offset <span style=color:#f92672>=</span> divmod(ind, n)
</span></span><span style=display:flex><span>                    out[key] <span style=color:#f92672>=</span> v_list[offset]
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>return</span> out
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>raise</span> <span style=color:#a6e22e>IndexError</span>(<span style=color:#e6db74>&#39;ParameterGrid index out of range&#39;</span>)
</span></span></code></pre></div><h4 id=14-自定义模型使用>1.4. 自定义模型使用</h4><ul><li>自定义评价函数</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.metrics <span style=color:#f92672>import</span> make_scorer
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>logloss</span>(act, pred):
</span></span><span style=display:flex><span>    epsilon <span style=color:#f92672>=</span> <span style=color:#ae81ff>1e-15</span>
</span></span><span style=display:flex><span>    pred <span style=color:#f92672>=</span> sp<span style=color:#f92672>.</span>maximum(epsilon, pred)
</span></span><span style=display:flex><span>    pred <span style=color:#f92672>=</span> sp<span style=color:#f92672>.</span>minimum(<span style=color:#ae81ff>1</span><span style=color:#f92672>-</span>epsilon, pred)
</span></span><span style=display:flex><span>    ll <span style=color:#f92672>=</span> sum(act<span style=color:#f92672>*</span>sp<span style=color:#f92672>.</span>log(pred) <span style=color:#f92672>+</span> sp<span style=color:#f92672>.</span>subtract(<span style=color:#ae81ff>1</span>, act)<span style=color:#f92672>*</span>sp<span style=color:#f92672>.</span>log(sp<span style=color:#f92672>.</span>subtract(<span style=color:#ae81ff>1</span>, pred)))
</span></span><span style=display:flex><span>    ll <span style=color:#f92672>=</span> ll <span style=color:#f92672>*</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1.0</span><span style=color:#f92672>/</span>len(act)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> ll
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span><span style=color:#75715e>#这里的greater_is_better参数决定了自定义的评价指标是越大越好还是越小越好</span>
</span></span><span style=display:flex><span>loss  <span style=color:#f92672>=</span> make_scorer(logloss, greater_is_better<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>score <span style=color:#f92672>=</span> make_scorer(logloss, greater_is_better<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span></code></pre></div><ul><li>自定义模型</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>mymodel</span>():
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, h<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>, lam<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>,maxiter<span style=color:#f92672>=</span><span style=color:#ae81ff>500</span>, tol<span style=color:#f92672>=</span><span style=color:#ae81ff>1e-6</span>):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>beta <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>h <span style=color:#f92672>=</span> h
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>dataset <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>maxiter <span style=color:#f92672>=</span> maxiter
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>tol <span style=color:#f92672>=</span> tol
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>funvalue <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>coef <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>dataset <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>lam<span style=color:#f92672>=</span>lam
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>iteration<span style=color:#f92672>=</span>maxiter
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>fit</span>(self, X_train, y_train):
</span></span><span style=display:flex><span>		<span style=color:#75715e>#用于训练模型参数，例如self.coef</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>coef, self<span style=color:#f92672>.</span>funvalue <span style=color:#f92672>=</span> myfun(X_train, y_train)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>predict</span>(self, X_new):
</span></span><span style=display:flex><span>		<span style=color:#75715e>#用于根据X预测y，返回y的预测值数组</span>
</span></span><span style=display:flex><span>		<span style=color:#75715e>#XXXXXXX</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> y_pre
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_params</span>(self, deep<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;Get parameters for this estimator.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Parameters
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        ----------
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        deep : boolean, optional
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            If True, will return the parameters for this estimator and
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            contained subobjects that are estimators.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Returns
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        -------
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        params : mapping of string to any
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            Parameter names mapped to their values.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        out <span style=color:#f92672>=</span> dict()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> key <span style=color:#f92672>in</span> [<span style=color:#e6db74>&#39;h&#39;</span>,<span style=color:#e6db74>&#39;lam&#39;</span>,<span style=color:#e6db74>&#39;maxiter&#39;</span>,<span style=color:#e6db74>&#39;tol&#39;</span>]:<span style=color:#75715e>#这里是所用超参数的list</span>
</span></span><span style=display:flex><span>            value <span style=color:#f92672>=</span> getattr(self, key, <span style=color:#66d9ef>None</span>)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> deep <span style=color:#f92672>and</span> hasattr(value, <span style=color:#e6db74>&#39;get_params&#39;</span>):
</span></span><span style=display:flex><span>                deep_items <span style=color:#f92672>=</span> value<span style=color:#f92672>.</span>get_params()<span style=color:#f92672>.</span>items()
</span></span><span style=display:flex><span>                out<span style=color:#f92672>.</span>update((key <span style=color:#f92672>+</span> <span style=color:#e6db74>&#39;__&#39;</span> <span style=color:#f92672>+</span> k, val) <span style=color:#66d9ef>for</span> k, val <span style=color:#f92672>in</span> deep_items)
</span></span><span style=display:flex><span>            out[key] <span style=color:#f92672>=</span> value
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> out
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>set_params</span>(self, <span style=color:#f92672>**</span>params):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;Set the parameters of this estimator.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        The method works on simple estimators as well as on nested objects
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        (such as pipelines). The latter have parameters of the form
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        ``&lt;component&gt;__&lt;parameter&gt;`` so that it&#39;s possible to update each
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        component of a nested object.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Returns
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        -------
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        self
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> params:
</span></span><span style=display:flex><span>            <span style=color:#75715e># Simple optimization to gain speed (inspect is slow)</span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>return</span> self
</span></span><span style=display:flex><span>        valid_params <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>get_params(deep<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> key, value <span style=color:#f92672>in</span> params<span style=color:#f92672>.</span>items():
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> key <span style=color:#f92672>not</span> <span style=color:#f92672>in</span> valid_params:
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>raise</span> <span style=color:#a6e22e>ValueError</span>(<span style=color:#e6db74>&#39;Invalid parameter </span><span style=color:#e6db74>%s</span><span style=color:#e6db74> for estimator </span><span style=color:#e6db74>%s</span><span style=color:#e6db74>. &#39;</span>
</span></span><span style=display:flex><span>                                 <span style=color:#e6db74>&#39;Check the list of available parameters &#39;</span>
</span></span><span style=display:flex><span>                                 <span style=color:#e6db74>&#39;with `estimator.get_params().keys()`.&#39;</span> <span style=color:#f92672>%</span>
</span></span><span style=display:flex><span>                                 (key, self))
</span></span><span style=display:flex><span>            setattr(self, key, value)
</span></span><span style=display:flex><span>            valid_params[key] <span style=color:#f92672>=</span> value
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> self
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>score</span>(self, X, y, sample_weight<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>    	<span style=color:#75715e>#如果这里不设置score函数，可以在GridSearchCV()的scoring参数中指定</span>
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;Returns the mean accuracy on the given test data and labels.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        In multi-label classification, this is the subset accuracy
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        which is a harsh metric since you require for each sample that
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        each label set be correctly predicted.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Parameters
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        ----------
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        X : array-like, shape = (n_samples, n_features)
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            Test samples.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        y : array-like, shape = (n_samples) or (n_samples, n_outputs)
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            True labels for X.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        sample_weight : array-like, shape = [n_samples], optional
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            Sample weights.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Returns
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        -------
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        score : float
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            Mean accuracy of self.predict(X) wrt. y.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> myloss_fun(y, self<span style=color:#f92672>.</span>predict(X), sample_weight<span style=color:#f92672>=</span>sample_weight)
</span></span></code></pre></div><h3 id=2-halvinggridsearchcvhttpsscikit-learnorgstablemodulesgeneratedsklearnmodel_selectionhalvinggridsearchcvhtmlsklearnmodel_selectionhalvinggridsearchcv--halvingrandomsearchcvhttpsscikit-learnorgstablemodulesgeneratedsklearnmodel_selectionhalvingrandomsearchcvhtmlsklearnmodel_selectionhalvingrandomsearchcv>2. <a href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV target=_blank rel="external nofollow noopener noreferrer">HalvingGridSearchCV<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a> & <a href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html#sklearn.model_selection.HalvingRandomSearchCV target=_blank rel="external nofollow noopener noreferrer">HalvingRandomSearchCV<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></h3><blockquote><p>新类使用锦标赛方法（tournament approach）选择最佳超参数。它们在观测数据的子集上训练超参数组合，得分最高的超参数组合会进入下一轮。在下一轮中，它们会在大量观测中获得分数。比赛一直持续到最后一轮。确定传递给 HalvingGridSearchCV 或 halvingAndomSearchCV 的超参数需要进行一些计算，你也可以使用合理的默认值。</p><ul><li>如果没有太多的超参数需要调优，并且 pipeline 运行时间不长，请使用 GridSearchCV；</li><li>对于较大的搜索空间和训练缓慢的模型，请使用 HalvingGridSearchCV；</li><li>对于非常大的搜索空间和训练缓慢的模型，请使用 HalvingRandomSearchCV。</li></ul></blockquote><blockquote><p><a href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV target=_blank rel="external nofollow noopener noreferrer"><code>HalvingGridSearchCV</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a> and <a href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html#sklearn.model_selection.HalvingRandomSearchCV target=_blank rel="external nofollow noopener noreferrer"><code>HalvingRandomSearchCV</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a> can be used as drop-in replacement for <a href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV target=_blank rel="external nofollow noopener noreferrer"><code>GridSearchCV</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a> and <a href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV target=_blank rel="external nofollow noopener noreferrer"><code>RandomizedSearchCV</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>. Successive Halving is an iterative selection process illustrated in the figure below. <code>The first iteration is run with a small amount of resources</code>, where the resource typically corresponds to the number of training samples, but can also be an arbitrary integer parameter such as <code>n_estimators</code> in a random forest. <code>Only a subset of the parameter candidates are selected for the next iteration</code>, which will be run with an increasing amount of allocated resources. <code>Only a subset of candidates will last until the end of the iteration process</code>, and the best parameter candidate is the one that has the highest score on the last iteration.</p></blockquote><p><img class=lazyload src=/liudongdong1.github.io/svg/loading.min.svg data-src=https://gitee.com/github-25970295/blogImage/raw/master/img/20210414101408.png data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/20210414101408.png, https://gitee.com/github-25970295/blogImage/raw/master/img/20210414101408.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/20210414101408.png 2x" data-sizes=auto alt=https://gitee.com/github-25970295/blogImage/raw/master/img/20210414101408.png title=https://gitee.com/github-25970295/blogImage/raw/master/img/20210414101408.png></p><h4 id=21-函数介绍>2.1. 函数介绍</h4><p><em>class</em> <code>sklearn.model_selection.``HalvingGridSearchCV</code>(<em>estimator</em>, <em>param_grid</em>, ***, <em>factor=3</em>, <em>resource=&lsquo;n_samples&rsquo;</em>, <em>max_resources=&lsquo;auto&rsquo;</em>, <em>min_resources=&lsquo;exhaust&rsquo;</em>, <em>aggressive_elimination=False</em>, <em>cv=5</em>, <em>scoring=None</em>, <em>refit=True</em>, <em>error_score=nan</em>, <em>return_train_score=True</em>, <em>random_state=None</em>, <em>n_jobs=None</em>, <em>verbose=0</em>)[<a href=https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/model_selection/_search_successive_halving.py#L335 target=_blank rel="external nofollow noopener noreferrer">source]<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a><a href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV target=_blank rel="external nofollow noopener noreferrer">¶<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></p><blockquote><p>The search strategy starts evaluating all the candidates with a small amount of resources and iteratively selects the best candidates, using more and more resources.</p></blockquote><p><em>class</em> <code>sklearn.model_selection.``HalvingRandomSearchCV</code>(<em>estimator</em>, <em>param_distributions</em>, ***, <em>n_candidates=&lsquo;exhaust&rsquo;</em>, <em>factor=3</em>, <em>resource=&lsquo;n_samples&rsquo;</em>, <em>max_resources=&lsquo;auto&rsquo;</em>, <em>min_resources=&lsquo;smallest&rsquo;</em>, <em>aggressive_elimination=False</em>, <em>cv=5</em>, <em>scoring=None</em>, <em>refit=True</em>, <em>error_score=nan</em>, <em>return_train_score=True</em>, <em>random_state=None</em>, <em>n_jobs=None</em>, <em>verbose=0</em>)[<a href=https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/model_selection/_search_successive_halving.py#L613 target=_blank rel="external nofollow noopener noreferrer">source]<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></p><blockquote><p>The search strategy starts evaluating all the candidates with a small amount of resources and iteratively selects the best candidates, using more and more resources.</p></blockquote><h4 id=22-使用案例>2.2. 使用案例</h4><h5 id=1-randomforestclassifier>.1. <strong>RandomForestClassifier</strong></h5><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> scipy.stats <span style=color:#f92672>import</span> randint
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.experimental <span style=color:#f92672>import</span> enable_halving_search_cv  <span style=color:#75715e># noqa</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> HalvingRandomSearchCV
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.ensemble <span style=color:#f92672>import</span> RandomForestClassifier
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.datasets <span style=color:#f92672>import</span> make_classification
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>rng <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>RandomState(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>X, y <span style=color:#f92672>=</span> make_classification(n_samples<span style=color:#f92672>=</span><span style=color:#ae81ff>700</span>, random_state<span style=color:#f92672>=</span>rng)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>clf <span style=color:#f92672>=</span> RandomForestClassifier(n_estimators<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>, random_state<span style=color:#f92672>=</span>rng)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>param_dist <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#34;max_depth&#34;</span>: [<span style=color:#ae81ff>3</span>, <span style=color:#66d9ef>None</span>],
</span></span><span style=display:flex><span>              <span style=color:#e6db74>&#34;max_features&#34;</span>: randint(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>11</span>),
</span></span><span style=display:flex><span>              <span style=color:#e6db74>&#34;min_samples_split&#34;</span>: randint(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>11</span>),
</span></span><span style=display:flex><span>              <span style=color:#e6db74>&#34;bootstrap&#34;</span>: [<span style=color:#66d9ef>True</span>, <span style=color:#66d9ef>False</span>],
</span></span><span style=display:flex><span>              <span style=color:#e6db74>&#34;criterion&#34;</span>: [<span style=color:#e6db74>&#34;gini&#34;</span>, <span style=color:#e6db74>&#34;entropy&#34;</span>]}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>rsh <span style=color:#f92672>=</span> HalvingRandomSearchCV(estimator<span style=color:#f92672>=</span>clf, param_distributions<span style=color:#f92672>=</span>param_dist,
</span></span><span style=display:flex><span>                            factor<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, random_state<span style=color:#f92672>=</span>rng)
</span></span><span style=display:flex><span>rsh<span style=color:#f92672>.</span>fit(X, y)
</span></span><span style=display:flex><span>rsh<span style=color:#f92672>.</span>best_params_
</span></span></code></pre></div><ul><li><strong>可视化代码</strong></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>results <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(rsh<span style=color:#f92672>.</span>cv_results_)
</span></span><span style=display:flex><span>results[<span style=color:#e6db74>&#39;params_str&#39;</span>] <span style=color:#f92672>=</span> results<span style=color:#f92672>.</span>params<span style=color:#f92672>.</span>apply(str)
</span></span><span style=display:flex><span>results<span style=color:#f92672>.</span>drop_duplicates(subset<span style=color:#f92672>=</span>(<span style=color:#e6db74>&#39;params_str&#39;</span>, <span style=color:#e6db74>&#39;iter&#39;</span>), inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>mean_scores <span style=color:#f92672>=</span> results<span style=color:#f92672>.</span>pivot(index<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;iter&#39;</span>, columns<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;params_str&#39;</span>,
</span></span><span style=display:flex><span>                            values<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;mean_test_score&#39;</span>)
</span></span><span style=display:flex><span>ax <span style=color:#f92672>=</span> mean_scores<span style=color:#f92672>.</span>plot(legend<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>.6</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>labels <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    <span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;iter=</span><span style=color:#e6db74>{</span>i<span style=color:#e6db74>}</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>n_samples=</span><span style=color:#e6db74>{</span>rsh<span style=color:#f92672>.</span>n_resources_[i]<span style=color:#e6db74>}</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;n_candidates=</span><span style=color:#e6db74>{</span>rsh<span style=color:#f92672>.</span>n_candidates_[i]<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(rsh<span style=color:#f92672>.</span>n_iterations_)
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>set_xticks(range(rsh<span style=color:#f92672>.</span>n_iterations_))
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>set_xticklabels(labels, rotation<span style=color:#f92672>=</span><span style=color:#ae81ff>45</span>, multialignment<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;left&#39;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>&#39;Scores of candidates over iterations&#39;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>set_ylabel(<span style=color:#e6db74>&#39;mean test score&#39;</span>, fontsize<span style=color:#f92672>=</span><span style=color:#ae81ff>15</span>)
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>set_xlabel(<span style=color:#e6db74>&#39;iterations&#39;</span>, fontsize<span style=color:#f92672>=</span><span style=color:#ae81ff>15</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>tight_layout()
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><h5 id=2-timecompare-visualization>.2. TimeCompare visualization</h5><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> time <span style=color:#f92672>import</span> time
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.svm <span style=color:#f92672>import</span> SVC
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn <span style=color:#f92672>import</span> datasets
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> GridSearchCV
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.experimental <span style=color:#f92672>import</span> enable_halving_search_cv  <span style=color:#75715e># noqa</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> HalvingGridSearchCV
</span></span><span style=display:flex><span>print(__doc__)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>rng <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>RandomState(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>X, y <span style=color:#f92672>=</span> datasets<span style=color:#f92672>.</span>make_classification(n_samples<span style=color:#f92672>=</span><span style=color:#ae81ff>1000</span>, random_state<span style=color:#f92672>=</span>rng)
</span></span><span style=display:flex><span>gammas <span style=color:#f92672>=</span> [<span style=color:#ae81ff>1e-1</span>, <span style=color:#ae81ff>1e-2</span>, <span style=color:#ae81ff>1e-3</span>, <span style=color:#ae81ff>1e-4</span>, <span style=color:#ae81ff>1e-5</span>, <span style=color:#ae81ff>1e-6</span>, <span style=color:#ae81ff>1e-7</span>]
</span></span><span style=display:flex><span>Cs <span style=color:#f92672>=</span> [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>100</span>, <span style=color:#ae81ff>1e3</span>, <span style=color:#ae81ff>1e4</span>, <span style=color:#ae81ff>1e5</span>]
</span></span><span style=display:flex><span>param_grid <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#39;gamma&#39;</span>: gammas, <span style=color:#e6db74>&#39;C&#39;</span>: Cs}
</span></span><span style=display:flex><span>clf <span style=color:#f92672>=</span> SVC(random_state<span style=color:#f92672>=</span>rng)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>tic <span style=color:#f92672>=</span> time()
</span></span><span style=display:flex><span>gsh <span style=color:#f92672>=</span> HalvingGridSearchCV(estimator<span style=color:#f92672>=</span>clf, param_grid<span style=color:#f92672>=</span>param_grid, factor<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>,
</span></span><span style=display:flex><span>                          random_state<span style=color:#f92672>=</span>rng)
</span></span><span style=display:flex><span>gsh<span style=color:#f92672>.</span>fit(X, y)
</span></span><span style=display:flex><span>gsh_time <span style=color:#f92672>=</span> time() <span style=color:#f92672>-</span> tic
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>tic <span style=color:#f92672>=</span> time()
</span></span><span style=display:flex><span>gs <span style=color:#f92672>=</span> GridSearchCV(estimator<span style=color:#f92672>=</span>clf, param_grid<span style=color:#f92672>=</span>param_grid)
</span></span><span style=display:flex><span>gs<span style=color:#f92672>.</span>fit(X, y)
</span></span><span style=display:flex><span>gs_time <span style=color:#f92672>=</span> time() <span style=color:#f92672>-</span> tic
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#visualization</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>make_heatmap</span>(ax, gs, is_sh<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>, make_cbar<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;Helper to make a heatmap.&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    results <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame<span style=color:#f92672>.</span>from_dict(gs<span style=color:#f92672>.</span>cv_results_)
</span></span><span style=display:flex><span>    results[<span style=color:#e6db74>&#39;params_str&#39;</span>] <span style=color:#f92672>=</span> results<span style=color:#f92672>.</span>params<span style=color:#f92672>.</span>apply(str)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> is_sh:
</span></span><span style=display:flex><span>        <span style=color:#75715e># SH dataframe: get mean_test_score values for the highest iter</span>
</span></span><span style=display:flex><span>        scores_matrix <span style=color:#f92672>=</span> results<span style=color:#f92672>.</span>sort_values(<span style=color:#e6db74>&#39;iter&#39;</span>)<span style=color:#f92672>.</span>pivot_table(
</span></span><span style=display:flex><span>                index<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;param_gamma&#39;</span>, columns<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;param_C&#39;</span>,
</span></span><span style=display:flex><span>                values<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;mean_test_score&#39;</span>, aggfunc<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;last&#39;</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>        scores_matrix <span style=color:#f92672>=</span> results<span style=color:#f92672>.</span>pivot(index<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;param_gamma&#39;</span>, columns<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;param_C&#39;</span>,
</span></span><span style=display:flex><span>                                      values<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;mean_test_score&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    im <span style=color:#f92672>=</span> ax<span style=color:#f92672>.</span>imshow(scores_matrix)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_xticks(np<span style=color:#f92672>.</span>arange(len(Cs)))
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_xticklabels([<span style=color:#e6db74>&#39;</span><span style=color:#e6db74>{:.0E}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(x) <span style=color:#66d9ef>for</span> x <span style=color:#f92672>in</span> Cs])
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_xlabel(<span style=color:#e6db74>&#39;C&#39;</span>, fontsize<span style=color:#f92672>=</span><span style=color:#ae81ff>15</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_yticks(np<span style=color:#f92672>.</span>arange(len(gammas)))
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_yticklabels([<span style=color:#e6db74>&#39;</span><span style=color:#e6db74>{:.0E}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(x) <span style=color:#66d9ef>for</span> x <span style=color:#f92672>in</span> gammas])
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_ylabel(<span style=color:#e6db74>&#39;gamma&#39;</span>, fontsize<span style=color:#f92672>=</span><span style=color:#ae81ff>15</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Rotate the tick labels and set their alignment.</span>
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>setp(ax<span style=color:#f92672>.</span>get_xticklabels(), rotation<span style=color:#f92672>=</span><span style=color:#ae81ff>45</span>, ha<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;right&#34;</span>,
</span></span><span style=display:flex><span>             rotation_mode<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;anchor&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> is_sh:
</span></span><span style=display:flex><span>        iterations <span style=color:#f92672>=</span> results<span style=color:#f92672>.</span>pivot_table(index<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;param_gamma&#39;</span>,
</span></span><span style=display:flex><span>                                         columns<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;param_C&#39;</span>, values<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;iter&#39;</span>,
</span></span><span style=display:flex><span>                                         aggfunc<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;max&#39;</span>)<span style=color:#f92672>.</span>values
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(len(gammas)):
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>for</span> j <span style=color:#f92672>in</span> range(len(Cs)):
</span></span><span style=display:flex><span>                ax<span style=color:#f92672>.</span>text(j, i, iterations[i, j],
</span></span><span style=display:flex><span>                        ha<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;center&#34;</span>, va<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;center&#34;</span>, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;w&#34;</span>, fontsize<span style=color:#f92672>=</span><span style=color:#ae81ff>20</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> make_cbar:
</span></span><span style=display:flex><span>        fig<span style=color:#f92672>.</span>subplots_adjust(right<span style=color:#f92672>=</span><span style=color:#ae81ff>0.8</span>)
</span></span><span style=display:flex><span>        cbar_ax <span style=color:#f92672>=</span> fig<span style=color:#f92672>.</span>add_axes([<span style=color:#ae81ff>0.85</span>, <span style=color:#ae81ff>0.15</span>, <span style=color:#ae81ff>0.05</span>, <span style=color:#ae81ff>0.7</span>])
</span></span><span style=display:flex><span>        fig<span style=color:#f92672>.</span>colorbar(im, cax<span style=color:#f92672>=</span>cbar_ax)
</span></span><span style=display:flex><span>        cbar_ax<span style=color:#f92672>.</span>set_ylabel(<span style=color:#e6db74>&#39;mean_test_score&#39;</span>, rotation<span style=color:#f92672>=-</span><span style=color:#ae81ff>90</span>, va<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;bottom&#34;</span>,
</span></span><span style=display:flex><span>                           fontsize<span style=color:#f92672>=</span><span style=color:#ae81ff>15</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig, axes <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots(ncols<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, sharey<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>ax1, ax2 <span style=color:#f92672>=</span> axes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>make_heatmap(ax1, gsh, is_sh<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>make_heatmap(ax2, gs, make_cbar<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ax1<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>&#39;Successive Halving</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>time = </span><span style=color:#e6db74>{:.3f}</span><span style=color:#e6db74>s&#39;</span><span style=color:#f92672>.</span>format(gsh_time),
</span></span><span style=display:flex><span>              fontsize<span style=color:#f92672>=</span><span style=color:#ae81ff>15</span>)
</span></span><span style=display:flex><span>ax2<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>&#39;GridSearch</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>time = </span><span style=color:#e6db74>{:.3f}</span><span style=color:#e6db74>s&#39;</span><span style=color:#f92672>.</span>format(gs_time), fontsize<span style=color:#f92672>=</span><span style=color:#ae81ff>15</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><h3 id=3-randomizedsearchcvhttpsscikit-learnorgstablemodulesgeneratedsklearnmodel_selectionrandomizedsearchcvhtmlsklearnmodel_selectionrandomizedsearchcv>3. <a href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV target=_blank rel="external nofollow noopener noreferrer">RandomizedSearchCV<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></h3><h4 id=31-函数介绍>3.1. 函数介绍</h4><p><em>class</em> <code>sklearn.model_selection.``RandomizedSearchCV</code>(<em>estimator</em>, <em>param_distributions</em>, ***, <em>n_iter=10</em>, <em>scoring=None</em>, <em>n_jobs=None</em>, <em>refit=True</em>, <em>cv=None</em>, <em>verbose=0</em>, <em>pre_dispatch=&lsquo;2*n_jobs&rsquo;</em>, <em>random_state=None</em>, <em>error_score=nan</em>, <em>return_train_score=False</em>)[<a href=https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/model_selection/_search.py#L1294 target=_blank rel="external nofollow noopener noreferrer">source]<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></p><ul><li><strong>estimator</strong>：我们要传入的模型，如KNN,LogisticRegression,RandomForestRegression等。</li><li><strong>params_distributions</strong>：参数分布，字典格式。将我们所传入模型当中的参数组合为一个字典。</li><li>n_iter：随机寻找参数组合的数量，默认值为10。</li><li><strong>scoring</strong>：<strong>模型的评估方法</strong>。在分类模型中有accuracy,precision,recall_score,roc_auc_score等，在回归模型中有MSE，RMSE等。</li><li><strong>n_jobs</strong>：并行计算时使用的计算机核心数量，默认值为1。当n_jobs的值设为-1时，则使用所有的处理器。</li><li>iid：bool变量，默认为deprecated，返回值为每折交叉验证的值。当iid = True时，返回的是交叉验证的均值。</li><li><strong>cv</strong>：交叉验证的折数，最新的sklearn库默认为5。</li></ul><h4 id=32-使用案例>3.2. 使用案例</h4><h5 id=1-xgbclassifier>.1. XGBClassifier</h5><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e>#分类器使用 xgboost</span>
</span></span><span style=display:flex><span>clf1 <span style=color:#f92672>=</span> xgb<span style=color:#f92672>.</span>XGBClassifier()
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span><span style=color:#75715e>#设定搜索的xgboost参数搜索范围，值搜索XGBoost的主要6个参数</span>
</span></span><span style=display:flex><span>param_dist <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;n_estimators&#39;</span>:range(<span style=color:#ae81ff>80</span>,<span style=color:#ae81ff>200</span>,<span style=color:#ae81ff>4</span>),
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;max_depth&#39;</span>:range(<span style=color:#ae81ff>2</span>,<span style=color:#ae81ff>15</span>,<span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;learning_rate&#39;</span>:np<span style=color:#f92672>.</span>linspace(<span style=color:#ae81ff>0.01</span>,<span style=color:#ae81ff>2</span>,<span style=color:#ae81ff>20</span>),
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;subsample&#39;</span>:np<span style=color:#f92672>.</span>linspace(<span style=color:#ae81ff>0.7</span>,<span style=color:#ae81ff>0.9</span>,<span style=color:#ae81ff>20</span>),
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;colsample_bytree&#39;</span>:np<span style=color:#f92672>.</span>linspace(<span style=color:#ae81ff>0.5</span>,<span style=color:#ae81ff>0.98</span>,<span style=color:#ae81ff>10</span>),
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;min_child_weight&#39;</span>:range(<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>9</span>,<span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span><span style=color:#75715e>#RandomizedSearchCV参数说明，clf1设置训练的学习器</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#param_dist字典类型，放入参数搜索范围</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#scoring = &#39;neg_log_loss&#39;，精度评价方式设定为“neg_log_loss“</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#n_iter=300，训练300次，数值越大，获得的参数精度越大，但是搜索时间越长</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#n_jobs = -1，使用所有的CPU进行训练，默认为1，使用1个CPU</span>
</span></span><span style=display:flex><span>grid <span style=color:#f92672>=</span> RandomizedSearchCV(clf1,param_dist,cv <span style=color:#f92672>=</span> <span style=color:#ae81ff>3</span>,scoring <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;neg_log_loss&#39;</span>,n_iter<span style=color:#f92672>=</span><span style=color:#ae81ff>300</span>,n_jobs <span style=color:#f92672>=</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span><span style=color:#75715e>#在训练集上训练</span>
</span></span><span style=display:flex><span>grid<span style=color:#f92672>.</span>fit(traindata<span style=color:#f92672>.</span>values,np<span style=color:#f92672>.</span>ravel(trainlabel<span style=color:#f92672>.</span>values))
</span></span><span style=display:flex><span><span style=color:#75715e>#返回最优的训练器</span>
</span></span><span style=display:flex><span>best_estimator <span style=color:#f92672>=</span> grid<span style=color:#f92672>.</span>best_estimator_
</span></span><span style=display:flex><span>print(best_estimator)
</span></span><span style=display:flex><span><span style=color:#75715e>#输出最优训练器的精度</span>
</span></span><span style=display:flex><span>print(grid<span style=color:#f92672>.</span>best_score_)
</span></span></code></pre></div><h5 id=2-randomforestregressor--随机网格搜索案例>.2. <strong>RandomForestRegressor</strong> <strong>随机+网格搜索案例</strong></h5><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> RandomizedSearchCV
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>RF <span style=color:#f92672>=</span> RandomForestRegressor()
</span></span><span style=display:flex><span><span style=color:#75715e>#设置初始的参数空间</span>
</span></span><span style=display:flex><span>n_estimators <span style=color:#f92672>=</span> [int(x) <span style=color:#66d9ef>for</span> x <span style=color:#f92672>in</span> np<span style=color:#f92672>.</span>linspace(start <span style=color:#f92672>=</span> <span style=color:#ae81ff>200</span>,stop <span style=color:#f92672>=</span> <span style=color:#ae81ff>2000</span>,num <span style=color:#f92672>=</span> <span style=color:#ae81ff>10</span>)]
</span></span><span style=display:flex><span>min_samples_split <span style=color:#f92672>=</span> [<span style=color:#ae81ff>2</span>,<span style=color:#ae81ff>5</span>,<span style=color:#ae81ff>10</span>]
</span></span><span style=display:flex><span>min_samples_leaf <span style=color:#f92672>=</span> [<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>2</span>,<span style=color:#ae81ff>4</span>]
</span></span><span style=display:flex><span>max_depth <span style=color:#f92672>=</span> [<span style=color:#ae81ff>5</span>,<span style=color:#ae81ff>8</span>,<span style=color:#ae81ff>10</span>]
</span></span><span style=display:flex><span>max_features <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;auto&#39;</span>,<span style=color:#e6db74>&#39;sqrt&#39;</span>]
</span></span><span style=display:flex><span>bootstrap <span style=color:#f92672>=</span> [<span style=color:#66d9ef>True</span>,<span style=color:#66d9ef>False</span>]
</span></span><span style=display:flex><span><span style=color:#75715e>#将参数整理为字典格式</span>
</span></span><span style=display:flex><span>random_params_group <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#39;n_estimators&#39;</span>:n_estimators,
</span></span><span style=display:flex><span>                      <span style=color:#e6db74>&#39;min_samples_split&#39;</span>:min_samples_split,
</span></span><span style=display:flex><span>                      <span style=color:#e6db74>&#39;min_samples_leaf&#39;</span>:min_samples_leaf,
</span></span><span style=display:flex><span>                      <span style=color:#e6db74>&#39;max_depth&#39;</span>:max_depth,
</span></span><span style=display:flex><span>                      <span style=color:#e6db74>&#39;max_features&#39;</span>:max_features,
</span></span><span style=display:flex><span>                      <span style=color:#e6db74>&#39;bootstrap&#39;</span>:bootstrap}
</span></span><span style=display:flex><span><span style=color:#75715e>#建立RandomizedSearchCV模型</span>
</span></span><span style=display:flex><span>random_model <span style=color:#f92672>=</span>RandomizedSearchCV(RF,param_distributions <span style=color:#f92672>=</span> random_params_group,n_iter <span style=color:#f92672>=</span> <span style=color:#ae81ff>100</span>,
</span></span><span style=display:flex><span>scoring <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;neg_mean_squared_error&#39;</span>,verbose <span style=color:#f92672>=</span> <span style=color:#ae81ff>2</span>,n_jobs <span style=color:#f92672>=</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>,cv <span style=color:#f92672>=</span> <span style=color:#ae81ff>3</span>,random_state <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span><span style=color:#75715e>#使用该模型训练数据</span>
</span></span><span style=display:flex><span>random_model<span style=color:#f92672>.</span>fit(train_features,train_labels)
</span></span><span style=display:flex><span><span style=color:#75715e>#获得Random_model最好的参数</span>
</span></span><span style=display:flex><span>random_model<span style=color:#f92672>.</span>best_params_
</span></span><span style=display:flex><span><span style=color:#75715e>#{&#39;n_estimators&#39;: 1200,</span>
</span></span><span style=display:flex><span><span style=color:#75715e># &#39;min_samples_split&#39;: 5,</span>
</span></span><span style=display:flex><span><span style=color:#75715e># &#39;min_samples_leaf&#39;: 4,</span>
</span></span><span style=display:flex><span><span style=color:#75715e># &#39;max_features&#39;: &#39;auto&#39;,</span>
</span></span><span style=display:flex><span><span style=color:#75715e># &#39;max_depth&#39;: 5,</span>
</span></span><span style=display:flex><span><span style=color:#75715e># &#39;bootstrap&#39;: True}</span>
</span></span><span style=display:flex><span>RF <span style=color:#f92672>=</span> RandomForestRegressor(n_estimators <span style=color:#f92672>=</span> <span style=color:#ae81ff>1200</span>,min_samples_split <span style=color:#f92672>=</span> <span style=color:#ae81ff>5</span>,
</span></span><span style=display:flex><span>                           min_samples_leaf <span style=color:#f92672>=</span> <span style=color:#ae81ff>4</span>,max_features <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;auto&#39;</span>,max_depth <span style=color:#f92672>=</span> <span style=color:#ae81ff>5</span>,bootstrap <span style=color:#f92672>=</span> <span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>RF<span style=color:#f92672>.</span>fit(train_features,train_labels)
</span></span><span style=display:flex><span>predictions <span style=color:#f92672>=</span> RF<span style=color:#f92672>.</span>predict(test_features)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>RMSE <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>sqrt(mean_squared_error(test_labels,predictions))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;模型预测误差:&#39;</span>,RMSE)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;模型的提升效果:</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(round(<span style=color:#ae81ff>100</span><span style=color:#f92672>*</span>(<span style=color:#ae81ff>5.06</span><span style=color:#f92672>-</span><span style=color:#ae81ff>4.96</span>)<span style=color:#f92672>/</span><span style=color:#ae81ff>5.06</span>),<span style=color:#ae81ff>2</span>),<span style=color:#e6db74>&#39;%&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#使用网格搜索进行细化处理</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> GridSearchCV
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> time
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>param_grid <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#39;n_estimators&#39;</span>:[<span style=color:#ae81ff>1100</span>,<span style=color:#ae81ff>1200</span>,<span style=color:#ae81ff>1300</span>],
</span></span><span style=display:flex><span>             <span style=color:#e6db74>&#39;min_samples_split&#39;</span>:[<span style=color:#ae81ff>4</span>,<span style=color:#ae81ff>5</span>,<span style=color:#ae81ff>6</span>,<span style=color:#ae81ff>7</span>],
</span></span><span style=display:flex><span>             <span style=color:#e6db74>&#39;min_samples_leaf&#39;</span>:[<span style=color:#ae81ff>3</span>,<span style=color:#ae81ff>4</span>,<span style=color:#ae81ff>5</span>],
</span></span><span style=display:flex><span>             <span style=color:#e6db74>&#39;max_depth&#39;</span>:[<span style=color:#ae81ff>4</span>,<span style=color:#ae81ff>5</span>,<span style=color:#ae81ff>6</span>,<span style=color:#ae81ff>7</span>]}
</span></span><span style=display:flex><span>RF <span style=color:#f92672>=</span> RandomForestRegressor()
</span></span><span style=display:flex><span>grid <span style=color:#f92672>=</span> GridSearchCV(RF,param_grid <span style=color:#f92672>=</span> param_grid,scoring <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;neg_mean_squared_error&#39;</span>,cv <span style=color:#f92672>=</span> <span style=color:#ae81ff>3</span>,n_jobs <span style=color:#f92672>=</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>start_time <span style=color:#f92672>=</span> time<span style=color:#f92672>.</span>time()
</span></span><span style=display:flex><span>grid<span style=color:#f92672>.</span>fit(train_features,train_labels)
</span></span><span style=display:flex><span>end_time <span style=color:#f92672>=</span> time<span style=color:#f92672>.</span>time()
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;模型训练用时:</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(end_time <span style=color:#f92672>-</span> start_time))
</span></span><span style=display:flex><span>grid<span style=color:#f92672>.</span>best_params_
</span></span><span style=display:flex><span><span style=color:#75715e>#{&#39;max_depth&#39;: 5,</span>
</span></span><span style=display:flex><span><span style=color:#75715e># &#39;min_samples_leaf&#39;: 5,</span>
</span></span><span style=display:flex><span><span style=color:#75715e># &#39;min_samples_split&#39;: 6,</span>
</span></span><span style=display:flex><span><span style=color:#75715e># &#39;n_estimators&#39;: 1100}</span>
</span></span><span style=display:flex><span>RF <span style=color:#f92672>=</span> RandomForestRegressor(n_estimators <span style=color:#f92672>=</span> <span style=color:#ae81ff>1100</span>,min_samples_split <span style=color:#f92672>=</span> <span style=color:#ae81ff>6</span>,
</span></span><span style=display:flex><span>                           min_samples_leaf <span style=color:#f92672>=</span> <span style=color:#ae81ff>5</span>,max_features <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;auto&#39;</span>,max_depth <span style=color:#f92672>=</span> <span style=color:#ae81ff>5</span>,bootstrap <span style=color:#f92672>=</span> <span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>RF<span style=color:#f92672>.</span>fit(train_features,train_labels)
</span></span><span style=display:flex><span>predictions <span style=color:#f92672>=</span> RF<span style=color:#f92672>.</span>predict(test_features)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>RMSE <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>sqrt(mean_squared_error(test_labels,predictions))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;模型预测误差:&#39;</span>,RMSE)
</span></span></code></pre></div><h4 id=33-代码理解>3.3. 代码理解</h4><ul><li>搜索策略：<strong>ParameterSampler</strong></li></ul><blockquote><p>（a）对于搜索范围是distribution的超参数，<code>根据给定的distribution随机采样</code>；</p><p>（b）对于<code>搜索范围是list的超参数，在给定的list中等概率采样</code>；</p><p>（c）对a、b两步中得到的<code>n_iter组采样结果，进行遍历</code>。</p><p>（补充）如果给定的搜索范围均为list，则不放回抽样n_iter次。</p></blockquote><h4 id=34-自定义模型>3.4. 自定义模型</h4><h3 id=4-跨框架调参>4. 跨框架调参</h3><h4 id=41-kears-转-sklearn进行调参>4.1. kears 转 sklearn进行调参</h4><blockquote><ul><li>使用scikit-learn封装Keras的模型</li><li>使用scikit-learn对Keras的模型进行交叉验证</li><li>使用scikit-learn，利用网格搜索调整Keras模型的超参</li></ul></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>房价预测数据集 使用sklearn执行超参数搜索
</span></span></span><span style=display:flex><span><span style=color:#e6db74>&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib <span style=color:#66d9ef>as</span> mpl
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> sklearn
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> os
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> sys
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> tensorflow <span style=color:#66d9ef>as</span> tf
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow_core.python.keras.api._v2 <span style=color:#f92672>import</span> keras <span style=color:#75715e># 不能使用 python</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> StandardScaler
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.datasets <span style=color:#f92672>import</span> fetch_california_housing
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> train_test_split, RandomizedSearchCV
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> scipy.stats <span style=color:#f92672>import</span> reciprocal
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>os<span style=color:#f92672>.</span>environ[<span style=color:#e6db74>&#39;TF_CPP_MIN_LOG_LEVEL&#39;</span>] <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;2&#39;</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>assert</span> tf<span style=color:#f92672>.</span>__version__<span style=color:#f92672>.</span>startswith(<span style=color:#e6db74>&#39;2.&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 0.打印导入模块的版本</span>
</span></span><span style=display:flex><span>print(tf<span style=color:#f92672>.</span>__version__)
</span></span><span style=display:flex><span>print(sys<span style=color:#f92672>.</span>version_info)
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> module <span style=color:#f92672>in</span> mpl, np, sklearn, pd, tf, keras:
</span></span><span style=display:flex><span>  print(<span style=color:#e6db74>&#34;</span><span style=color:#e6db74>%s</span><span style=color:#e6db74> version:</span><span style=color:#e6db74>%s</span><span style=color:#e6db74>&#34;</span> <span style=color:#f92672>%</span> (module<span style=color:#f92672>.</span>__name__, module<span style=color:#f92672>.</span>__version__))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 显示学习曲线</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>plot_learning_curves</span>(his):
</span></span><span style=display:flex><span>  pd<span style=color:#f92672>.</span>DataFrame(his<span style=color:#f92672>.</span>history)<span style=color:#f92672>.</span>plot(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>8</span>, <span style=color:#ae81ff>5</span>))
</span></span><span style=display:flex><span>  plt<span style=color:#f92672>.</span>grid(<span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>  plt<span style=color:#f92672>.</span>gca()<span style=color:#f92672>.</span>set_ylim(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>  plt<span style=color:#f92672>.</span>show()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 1.加载数据集 california 房价</span>
</span></span><span style=display:flex><span>housing <span style=color:#f92672>=</span> fetch_california_housing()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(housing<span style=color:#f92672>.</span>DESCR)
</span></span><span style=display:flex><span>print(housing<span style=color:#f92672>.</span>data<span style=color:#f92672>.</span>shape)
</span></span><span style=display:flex><span>print(housing<span style=color:#f92672>.</span>target<span style=color:#f92672>.</span>shape)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 2.拆分数据集 训练集 验证集 测试集</span>
</span></span><span style=display:flex><span>x_train_all, x_test, y_train_all, y_test <span style=color:#f92672>=</span> train_test_split(
</span></span><span style=display:flex><span>  housing<span style=color:#f92672>.</span>data, housing<span style=color:#f92672>.</span>target, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>7</span>)
</span></span><span style=display:flex><span>x_train, x_valid, y_train, y_valid <span style=color:#f92672>=</span> train_test_split(
</span></span><span style=display:flex><span>  x_train_all, y_train_all, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>11</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(x_train<span style=color:#f92672>.</span>shape, y_train<span style=color:#f92672>.</span>shape)
</span></span><span style=display:flex><span>print(x_valid<span style=color:#f92672>.</span>shape, y_valid<span style=color:#f92672>.</span>shape)
</span></span><span style=display:flex><span>print(x_test<span style=color:#f92672>.</span>shape, y_test<span style=color:#f92672>.</span>shape)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 3.数据集归一化</span>
</span></span><span style=display:flex><span>scaler <span style=color:#f92672>=</span> StandardScaler()
</span></span><span style=display:flex><span>x_train_scaled <span style=color:#f92672>=</span> scaler<span style=color:#f92672>.</span>fit_transform(x_train)
</span></span><span style=display:flex><span>x_valid_scaled <span style=color:#f92672>=</span> scaler<span style=color:#f92672>.</span>fit_transform(x_valid)
</span></span><span style=display:flex><span>x_test_scaled <span style=color:#f92672>=</span> scaler<span style=color:#f92672>.</span>fit_transform(x_test)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 创建keras模型</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>build_model</span>(hidden_layers<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, <span style=color:#75715e># 中间层的参数</span>
</span></span><span style=display:flex><span>        layer_size<span style=color:#f92672>=</span><span style=color:#ae81ff>30</span>,
</span></span><span style=display:flex><span>        learning_rate<span style=color:#f92672>=</span><span style=color:#ae81ff>3e-3</span>):
</span></span><span style=display:flex><span>  <span style=color:#75715e># 创建网络层</span>
</span></span><span style=display:flex><span>  model <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>models<span style=color:#f92672>.</span>Sequential()
</span></span><span style=display:flex><span>  model<span style=color:#f92672>.</span>add(keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Dense(layer_size, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;relu&#34;</span>,
</span></span><span style=display:flex><span>                 input_shape<span style=color:#f92672>=</span>x_train<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>:]))
</span></span><span style=display:flex><span> <span style=color:#75715e># 隐藏层设置</span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>for</span> _ <span style=color:#f92672>in</span> range(hidden_layers <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>):
</span></span><span style=display:flex><span>    model<span style=color:#f92672>.</span>add(keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Dense(layer_size,
</span></span><span style=display:flex><span>                   activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;relu&#34;</span>))
</span></span><span style=display:flex><span>  model<span style=color:#f92672>.</span>add(keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># 优化器学习率</span>
</span></span><span style=display:flex><span>  optimizer <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>optimizers<span style=color:#f92672>.</span>SGD(lr<span style=color:#f92672>=</span>learning_rate)
</span></span><span style=display:flex><span>  model<span style=color:#f92672>.</span>compile(loss<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;mse&#34;</span>, optimizer<span style=color:#f92672>=</span>optimizer)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> model
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>main</span>():
</span></span><span style=display:flex><span>  <span style=color:#75715e># RandomizedSearchCV</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># 1.转化为sklearn的model</span>
</span></span><span style=display:flex><span>  sk_learn_model <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>wrappers<span style=color:#f92672>.</span>scikit_learn<span style=color:#f92672>.</span>KerasRegressor(build_model)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  callbacks <span style=color:#f92672>=</span> [keras<span style=color:#f92672>.</span>callbacks<span style=color:#f92672>.</span>EarlyStopping(patience<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>, min_delta<span style=color:#f92672>=</span><span style=color:#ae81ff>1e-2</span>)]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  history <span style=color:#f92672>=</span> sk_learn_model<span style=color:#f92672>.</span>fit(x_train_scaled, y_train, epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>,
</span></span><span style=display:flex><span>                 validation_data<span style=color:#f92672>=</span>(x_valid_scaled, y_valid),
</span></span><span style=display:flex><span>                 callbacks<span style=color:#f92672>=</span>callbacks)
</span></span><span style=display:flex><span>  <span style=color:#75715e># 2.定义超参数集合</span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># f(x) = 1/(x*log(b/a)) a &lt;= x &lt;= b</span>
</span></span><span style=display:flex><span>  param_distribution <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;hidden_layers&#34;</span>: [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>4</span>],
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;layer_size&#34;</span>: np<span style=color:#f92672>.</span>arange(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>100</span>),
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;learning_rate&#34;</span>: reciprocal(<span style=color:#ae81ff>1e-4</span>, <span style=color:#ae81ff>1e-2</span>),
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># 3.执行超搜索参数</span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># cross_validation:训练集分成n份, n-1训练, 最后一份验证.</span>
</span></span><span style=display:flex><span>  random_search_cv <span style=color:#f92672>=</span> RandomizedSearchCV(sk_learn_model, param_distribution,
</span></span><span style=display:flex><span>                     n_iter<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>,
</span></span><span style=display:flex><span>                     cv<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>,
</span></span><span style=display:flex><span>                     n_jobs<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>  random_search_cv<span style=color:#f92672>.</span>fit(x_train_scaled, y_train, epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>,
</span></span><span style=display:flex><span>             validation_data<span style=color:#f92672>=</span>(x_valid_scaled, y_valid),
</span></span><span style=display:flex><span>             callbacks<span style=color:#f92672>=</span>callbacks)
</span></span><span style=display:flex><span>  <span style=color:#75715e># 4.显示超参数</span>
</span></span><span style=display:flex><span>  print(random_search_cv<span style=color:#f92672>.</span>best_params_)
</span></span><span style=display:flex><span>  print(random_search_cv<span style=color:#f92672>.</span>best_score_)
</span></span><span style=display:flex><span>  print(random_search_cv<span style=color:#f92672>.</span>best_estimator_)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  model <span style=color:#f92672>=</span> random_search_cv<span style=color:#f92672>.</span>best_estimator_<span style=color:#f92672>.</span>model
</span></span><span style=display:flex><span>  print(model<span style=color:#f92672>.</span>evaluate(x_test_scaled, y_test))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># 5.打印模型训练过程</span>
</span></span><span style=display:flex><span>  plot_learning_curves(history)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
</span></span><span style=display:flex><span>  main()
</span></span></code></pre></div><h3 id=学习资源>学习资源</h3><ul><li><a href=https://scikit-learn.org/stable/user_guide.html target=_blank rel="external nofollow noopener noreferrer">https://scikit-learn.org/stable/user_guide.html<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></li><li><a href=https://scikit-learn.org/stable/auto_examples/index.html target=_blank rel="external nofollow noopener noreferrer">https://scikit-learn.org/stable/auto_examples/index.html<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></li><li>ToLearn List:<ul><li><a href=https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection target=_blank rel="external nofollow noopener noreferrer">https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></li><li><a href=https://cnbeining.github.io/deep-learning-with-python-cn/3-multi-layer-perceptrons/ch9-use-keras-models-with-scikit-learn-for-general-machine-learning.html target=_blank rel="external nofollow noopener noreferrer">https://cnbeining.github.io/deep-learning-with-python-cn/3-multi-layer-perceptrons/ch9-use-keras-models-with-scikit-learn-for-general-machine-learning.html<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></li><li><a href=https://www.guofei.site/2019/09/28/model_selection.html target=_blank rel="external nofollow noopener noreferrer">https://www.guofei.site/2019/09/28/model_selection.html<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></li><li><code>关于参数的选择有没有可以优化的地方</code></li></ul></li></ul></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span title="2023-09-29 00:12:27">更新于 2023-09-29&nbsp;</span></div><div class=post-info-license><span><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div><div class=post-info-line><div class=post-info-md><span><a href=liudongdong1.github.io/sklearn-optimize/index.md title=阅读原始文档 class=link-to-markdown>阅读原始文档</a></span><span><a href=https://liudongdong1.github.io/edit/master/content/posts%5c%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%5cSklearn%5cSklearn%20Optimize.md title=编辑此页 target=_blank rel="external nofollow noopener noreferrer" class=link-to-edit>编辑此页</a></span></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 Twitter" data-sharer=twitter data-url=liudongdong1.github.io/sklearn-optimize/ data-title="SkLearn Optimize" data-hashtags=Sklearn,Math><i class="fa-brands fa-twitter fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Facebook" data-sharer=facebook data-url=liudongdong1.github.io/sklearn-optimize/ data-hashtag=Sklearn><i class="fa-brands fa-facebook-square fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=liudongdong1.github.io/sklearn-optimize/ data-title="SkLearn Optimize" data-image=https://gitee.com/github-25970295/blogImage/raw/master/img/20210501113542.png><i class="fa-brands fa-weibo fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fa-solid fa-tags fa-fw" aria-hidden=true></i>&nbsp;<a href=liudongdong1.github.io/tags/sklearn/>Sklearn</a>,&nbsp;<a href=liudongdong1.github.io/tags/math/>Math</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=liudongdong1.github.io/>主页</a></span></section></div><div class=post-nav><a href=liudongdong1.github.io/pptsegment/ class=prev rel=prev title=PPTSegment><i class="fa-solid fa-angle-left fa-fw" aria-hidden=true></i>PPTSegment</a>
<a href=liudongdong1.github.io/sklearnvisualization/ class=next rel=next title=SkLearnVisualization>SkLearnVisualization<i class="fa-solid fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></main><footer class=footer><div class=footer-container><div class="footer-line powered">由 <a href=https://gohugo.io/ target=_blank rel="external nofollow noopener noreferrer" title="Hugo 0.118.2">Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/hugo-fixit/FixIt target=_blank rel=external title="FixIt v0.2.17-RC"><img class=fixit-icon src=/liudongdong1.github.io/fixit.min.svg alt="FixIt logo">&nbsp;FixIt</a></div><div class="footer-line copyright" itemscope itemtype=http://schema.org/CreativeWork><i class="fa-regular fa-copyright fa-fw" aria-hidden=true></i>
<span itemprop=copyrightYear>2020 - 2023</span><span class=author itemprop=copyrightHolder>
<a href=https://liudongdong1.github.io/ target=_blank rel="external nofollow noopener noreferrer">LiuDongdong</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div><div class="footer-line statistics"><span class=site-time title='网站运行中 ...'><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden=true></i>&nbsp;<span class=run-times>网站运行中 ...</span></span></div><div class="footer-line ibruce"><span id=busuanzi_container_site_uv title=总访客数><i class="fa-regular fa-user fa-fw" aria-hidden=true></i>&nbsp;<span id=busuanzi_value_site_uv><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden=true></i></span></span><span id=busuanzi_container_site_pv class=footer-divider title=总访问量><i class="fa-regular fa-eye fa-fw" aria-hidden=true></i>&nbsp;<span id=busuanzi_value_site_pv><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden=true></i></span></span></div></div></footer></div><div class=widgets><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role=button aria-label=回到顶部><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><span class=variant-numeric>0%</span></div></div><a href=https://liudongdong1.github.io/ title="在 GitHub 上查看源代码" target=_blank rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115h15l12 27L250 250V0z"/><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentcolor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4l13.9-13.8C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8z" fill="currentcolor" class="octo-body"/></svg></a><div id=mask></div><div class=reading-progress-bar style=left:0;top:0;--bg-progress:#0076ff;--bg-progress-dark:#fff></div><noscript><div class=noscript-warning>FixIt 主题在启用 JavaScript 的情况下效果最佳。</div></noscript></div><link rel=stylesheet href=/liudongdong1.github.io/lib/katex/katex.min.css><link rel=stylesheet href=/liudongdong1.github.io/lib/cookieconsent/cookieconsent.min.css><script src=/liudongdong1.github.io/lib/autocomplete/autocomplete.min.js defer></script><script src=/liudongdong1.github.io/lib/algoliasearch/algoliasearch-lite.umd.min.js defer></script><script src=/liudongdong1.github.io/lib/lazysizes/lazysizes.min.js async defer></script><script src=/liudongdong1.github.io/lib/sharer/sharer.min.js async defer></script><script src=/liudongdong1.github.io/lib/typeit/index.umd.js defer></script><script src=/liudongdong1.github.io/lib/katex/katex.min.js defer></script><script src=/liudongdong1.github.io/lib/katex/auto-render.min.js defer></script><script src=/liudongdong1.github.io/lib/katex/copy-tex.min.js defer></script><script src=/liudongdong1.github.io/lib/katex/mhchem.min.js defer></script><script src=/liudongdong1.github.io/lib/cookieconsent/cookieconsent.min.js defer></script><script src=/liudongdong1.github.io/lib/pangu/pangu.min.js defer></script><script src=/liudongdong1.github.io/lib/cell-watermark/watermark.min.js defer></script><script src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js async defer></script><script>window.config={code:{copyTitle:"复制到剪贴板",editLockTitle:"锁定可编辑代码块",editUnLockTitle:"解锁可编辑代码块",editable:!0,maxShownLines:10},comment:{enable:!1},cookieconsent:{content:{dismiss:"同意",link:"了解更多",message:"本网站使用 Cookies 来改善您的浏览体验。"},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},data:{"typeit-header-subtitle-desktop":`<span style='font-family: MMT,"沐目体";'>吾日三省吾身</span>`,"typeit-header-subtitle-mobile":`<span style='font-family: MMT,"沐目体";'>吾日三省吾身</span>`},enablePWA:!0,enablePangu:!0,math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{algoliaAppID:"2R1K9SKLQZ",algoliaIndex:"index.zh-cn",algoliaSearchKey:"4a226aa1c5c98d6859e4d1386adb2bc7",highlightTag:"em",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50,type:"algolia"},siteTime:"2020-12-18T16:15:22+08:00",typeit:{cursorChar:"|",cursorSpeed:1e3,data:{"typeit-header-subtitle-desktop":["typeit-header-subtitle-desktop"],"typeit-header-subtitle-mobile":["typeit-header-subtitle-mobile"]},duration:-1,speed:100},watermark:{appendto:".wrapper>main",colspacing:30,content:'<img class="fixit-icon" src="/fixit.min.svg" alt="FixIt logo" /> FixIt 主题',enable:!0,fontfamily:"inherit",fontsize:.85,height:21,opacity:.0125,rotate:15,rowspacing:60,width:150}}</script><script src=/liudongdong1.github.io/js/theme.min.js defer></script><script src=/liudongdong1.github.io/js/custom.min.js defer></script></body></html>