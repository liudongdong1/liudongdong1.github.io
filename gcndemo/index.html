<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <head>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>GCNDemo - DAY By DAY</title><meta name="author" content="LiuDongdong">
<meta name="author-link" content="https://liudongdong1.github.io/">
<meta name="description" content="utils：定义了加载数据等工具性的函数 layers：定义了模块如何计算卷积 models：定义了模型train train：包含了模型训练信息" /><meta name="keywords" content='Pytorch, Model' /><meta itemprop="name" content="GCNDemo">
<meta itemprop="description" content="utils：定义了加载数据等工具性的函数 layers：定义了模块如何计算卷积 models：定义了模型train train：包含了模型训练信息"><meta itemprop="datePublished" content="2020-10-10T17:23:49+00:00" />
<meta itemprop="dateModified" content="2023-09-28T23:52:09+08:00" />
<meta itemprop="wordCount" content="5341"><meta itemprop="image" content="/logo.png"/>
<meta itemprop="keywords" content="Pytorch,Model," /><meta property="og:title" content="GCNDemo" />
<meta property="og:description" content="utils：定义了加载数据等工具性的函数 layers：定义了模块如何计算卷积 models：定义了模型train train：包含了模型训练信息" />
<meta property="og:type" content="article" />
<meta property="og:url" content="liudongdong1.github.io/gcndemo/" /><meta property="og:image" content="/logo.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-10-10T17:23:49+00:00" />
<meta property="article:modified_time" content="2023-09-28T23:52:09+08:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="/logo.png"/>

<meta name="twitter:title" content="GCNDemo"/>
<meta name="twitter:description" content="utils：定义了加载数据等工具性的函数 layers：定义了模块如何计算卷积 models：定义了模型train train：包含了模型训练信息"/>
<meta name="application-name" content="DAY By DAY">
<meta name="apple-mobile-web-app-title" content="DAY By DAY"><meta name="theme-color" data-light="#f8f8f8" data-dark="#252627" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="liudongdong1.github.io/gcndemo/" /><link rel="prev" href="liudongdong1.github.io/compat/" /><link rel="next" href="liudongdong1.github.io/gan/" /><link rel="stylesheet" href="/liudongdong1.github.io/css/style.min.css"><link rel="stylesheet" href="/liudongdong1.github.io/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/liudongdong1.github.io/lib/animate/animate.min.css"><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "GCNDemo",
    "inLanguage": "zh-CN",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "liudongdong1.github.io\/gcndemo\/"
    },"genre": "posts","keywords": "Pytorch, Model","wordcount":  5341 ,
    "url": "liudongdong1.github.io\/gcndemo\/","datePublished": "2020-10-10T17:23:49+00:00","dateModified": "2023-09-28T23:52:09+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
      "@type": "Organization",
      "name": "LiuDongdong","logo": "\/images\/person.png"},"author": {
        "@type": "Person",
        "name": "liudongdong1"
      },"description": ""
  }
  </script></head>
  <body data-header-desktop="auto" data-header-mobile="auto"><script>(window.localStorage?.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('data-theme', 'dark');</script><div class="wrapper"><header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper" data-github-corner="right">
    <div class="header-title">
      <a href="liudongdong1.github.io/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="DAY By DAY"
    title="DAY By DAY"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-desktop" class="typeit header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/posts/"
                
                
              ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/categories/"
                
                
              ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/tags/"
                
                
              ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/friends/"
                title="友情链接"
                
              ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/about/"
                
                
              ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li class="menu-item delimiter"></li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <ul class="sub-menu"><li class="menu-item">没有更多翻译</li></ul>
          </li><li class="menu-item search" id="search-desktop">
            <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-desktop">
            <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
              <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
            </a>
            <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
              <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
            </a>
            <span class="search-button search-loading" id="search-loading-desktop">
              <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
            </span>
          </li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li>
      </ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="liudongdong1.github.io/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="/fixit.min.svg"
    title="/fixit.min.svg"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-mobile" class="typeit header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li class="search-wrapper">
            <div class="search mobile" id="search-mobile">
              <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-mobile">
              <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
              </a>
              <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
              </a>
              <span class="search-button search-loading" id="search-loading-mobile">
                <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
              </span>
            </div>
            <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
              取消
            </a>
          </li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/posts/"
                  
                  
                ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/categories/"
                  
                  
                ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/tags/"
                  
                  
                ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/friends/"
                  title="友情链接"
                  
                ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/about/"
                  
                  
                ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li
              class="menu-item text-center"
            ><a
                  class="menu-link"
                  href="https://liudongdong1.github.io/"
                  title="GitHub"
                  rel="noopener noreferrer" target="_blank"
                ><i class='fa-brands fa-github fa-fw' aria-hidden='true'></i> </a></li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <select class="language-select" onchange="location = this.value;"><option disabled>没有更多翻译</option></select>
          </li></ul>
    </nav>
  </div>
</header><div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
  </div>
  <div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
  </div><main class="container" data-page-style="normal"><aside class="toc" id="toc-auto"><h2 class="toc-title">目录 <i class="toc-icon fa-solid fa-angle-down fa-fw"></i></h2>
      <div class="toc-content" id="toc-content-auto"></div></aside>

  <aside class="aside-custom" id="aside-sakana">
    

<div class="sakana-widget">
  <div class="sakana-item" id="takina-widget"></div>
  <div class="sakana-item" id="chisato-widget"></div>
</div>
<script>
  function initSakanaWidget() {
    const takina = SakanaWidget.getCharacter('takina')
    SakanaWidget.registerCharacter('takina-slow', takina);
    new SakanaWidget({
      character: 'takina-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#takina-widget');

    const chisato = SakanaWidget.getCharacter('chisato')
    SakanaWidget.registerCharacter('chisato-slow', chisato);
    new SakanaWidget({
      character: 'chisato-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#chisato-widget');
  }
</script>
<script async onload="initSakanaWidget()" src="https://cdn.jsdelivr.net/npm/sakana-widget@2.3.0/lib/sakana.min.js">
</script></aside>

  <article class="page single">
    <div class="header"><h1 class="single-title animate__animated animate__flipInX">
        <span>GCNDemo</span>
      </h1></div><div class="post-meta">
      <div class="post-meta-line"><span class="post-author"><span class="author"><i class="fa-solid fa-user-circle" aria-hidden="true"></i>
      liudongdong1</span></span>
          <span class="post-category">收录于 <a href="liudongdong1.github.io/categories/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;Categories</a>&ensp;<a href="liudongdong1.github.io/categories/%E6%97%B6%E7%A9%BA%E6%95%B0%E6%8D%AE/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;时空数据</a></span></div>
      <div class="post-meta-line"><span title=2020-10-10&#32;17:23:49>
            <i class="fa-regular fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2020-10-10" >2020-10-10</time>
          </span>&nbsp;<i class="fa-solid fa-pencil-alt fa-fw"></i>&nbsp;约 5341 字&nbsp;
        <i class="fa-regular fa-clock fa-fw"></i>&nbsp;预计阅读 11 分钟&nbsp;<span id="busuanzi_container_page_pv" class="busuanzi_visitors comment-visitors" data-flag-title="GCNDemo">
            <i class="fa-regular fa-eye fa-fw"></i>&nbsp;<span id="busuanzi_value_page_pv">-</span>&nbsp;次阅读
          </span>&nbsp;</div>
    </div><div class="featured-image"><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://cdn.pixabay.com/photo/2018/05/26/21/21/blueberries-3432295__340.jpg"
    data-srcset="https://cdn.pixabay.com/photo/2018/05/26/21/21/blueberries-3432295__340.jpg, https://cdn.pixabay.com/photo/2018/05/26/21/21/blueberries-3432295__340.jpg 1.5x, https://cdn.pixabay.com/photo/2018/05/26/21/21/blueberries-3432295__340.jpg 2x"
    data-sizes="auto"
    alt="https://cdn.pixabay.com/photo/2018/05/26/21/21/blueberries-3432295__340.jpg"
    title="https://cdn.pixabay.com/photo/2018/05/26/21/21/blueberries-3432295__340.jpg"/></div><div class="details toc" id="toc-static" kept="true">
        <div class="details-summary toc-title">
          <span>目录</span>
          <span><i class="details-icon fa-solid fa-angle-right"></i></span>
        </div>
        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#1数据集结构">1、数据集结构</a></li>
    <li><a href="#2数据集内容分析">2、数据集内容分析</a></li>
  </ul>

  <ul>
    <li><a href="#1代码总览">1、代码总览</a></li>
    <li><a href="#2特征独热码处理">2、特征独热码处理</a></li>
    <li><a href="#3特征归一化函数">3、特征归一化函数</a></li>
    <li><a href="#4稀疏矩阵转稀疏张量函数">4、稀疏矩阵转稀疏张量函数</a></li>
    <li><a href="#5精度计算函数">5、精度计算函数</a></li>
    <li><a href="#6数据载入及处理函数">6、数据载入及处理函数</a></li>
  </ul>

  <ul>
    <li><a href="#1代码总览-1">1、代码总览</a></li>
    <li><a href="#2代码分析">2、代码分析</a></li>
  </ul>

  <ul>
    <li><a href="#1代码总览-2">1、代码总览</a></li>
    <li><a href="#2属性定义">2、属性定义</a></li>
    <li><a href="#3参数初始化">3、参数初始化</a></li>
    <li><a href="#4前馈计算">4、前馈计算</a></li>
    <li><a href="#5字符串表达">5、字符串表达</a></li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#from">From</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
      </div><div
      class="content"
      id="content"
      
      
    ><p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://img-blog.csdnimg.cn/20200819103154483.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=,size_16,color_FFFFFF,t_70#pic_center"
    data-srcset="https://img-blog.csdnimg.cn/20200819103154483.png?x-oss-process=image/watermark%2ctype_ZmFuZ3poZW5naGVpdGk%2cshadow_10%2ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=%2csize_16%2ccolor_FFFFFF%2ct_70#pic_center, https://img-blog.csdnimg.cn/20200819103154483.png?x-oss-process=image/watermark%2ctype_ZmFuZ3poZW5naGVpdGk%2cshadow_10%2ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=%2csize_16%2ccolor_FFFFFF%2ct_70#pic_center 1.5x, https://img-blog.csdnimg.cn/20200819103154483.png?x-oss-process=image/watermark%2ctype_ZmFuZ3poZW5naGVpdGk%2cshadow_10%2ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=%2csize_16%2ccolor_FFFFFF%2ct_70#pic_center 2x"
    data-sizes="auto"
    alt="https://img-blog.csdnimg.cn/20200819103154483.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=,size_16,color_FFFFFF,t_70#pic_center"
    title="https://img-blog.csdnimg.cn/20200819103154483.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=,size_16,color_FFFFFF,t_70#pic_center"/></p>
<ul>
<li>utils：定义了加载数据等工具性的函数</li>
<li>layers：定义了模块如何计算卷积</li>
<li>models：定义了模型train</li>
<li>train：包含了模型训练信息
<img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://img-blog.csdnimg.cn/20200819103239794.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=,size_16,color_FFFFFF,t_70#pic_center"
    data-srcset="https://img-blog.csdnimg.cn/20200819103239794.png?x-oss-process=image/watermark%2ctype_ZmFuZ3poZW5naGVpdGk%2cshadow_10%2ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=%2csize_16%2ccolor_FFFFFF%2ct_70#pic_center, https://img-blog.csdnimg.cn/20200819103239794.png?x-oss-process=image/watermark%2ctype_ZmFuZ3poZW5naGVpdGk%2cshadow_10%2ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=%2csize_16%2ccolor_FFFFFF%2ct_70#pic_center 1.5x, https://img-blog.csdnimg.cn/20200819103239794.png?x-oss-process=image/watermark%2ctype_ZmFuZ3poZW5naGVpdGk%2cshadow_10%2ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=%2csize_16%2ccolor_FFFFFF%2ct_70#pic_center 2x"
    data-sizes="auto"
    alt="https://img-blog.csdnimg.cn/20200819103239794.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=,size_16,color_FFFFFF,t_70#pic_center"
    title="https://img-blog.csdnimg.cn/20200819103239794.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=,size_16,color_FFFFFF,t_70#pic_center"/></li>
</ul>
<h1 id="一数据集结构内容分析">一、数据集结构、内容分析</h1>
<h2 id="1数据集结构">1、数据集结构</h2>
<p>论文中所使用的数据集合是Cora数据集，总共有三部分构成：cora.content cora.cites 和README。</p>
<p><strong>README：</strong> 对数据集内容的描述；</p>
<p><strong>cora.content：</strong> 里面包含有每一篇论文各自独立的信息；</p>
<p>该文件总共包含2078行，每一行代表一篇论文，由论文编号、<code>论文词向量（1433维）(词向量的每个元素都对应一个词，且该元素只有0或1两个取值。取0表示该元素对应的词不在论文中，取1表示在论文中。所有的词来源于一个具有1433个词的字典。)</code>和论文的类别三个部分组成</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-txt" data-lang="txt"><span style="display:flex;"><span>31336	0	0.....	0	0	0	0	0	0	0	0	0	0	0	0	Neural_Networks
</span></span><span style="display:flex;"><span>1061127	0	0.....	0	0	0	0	0	0	0	0	0	0	0	0	Rule_Learning
</span></span><span style="display:flex;"><span>1106406	0	0.....	0	0	0	0	0	0	0	0	0	0	0	Reinforcement_Learning
</span></span></code></pre></div><p><strong>cora.cites:</strong> 里面包含有各论文之间的相互引用记录</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-txt" data-lang="txt"><span style="display:flex;"><span>35	1033
</span></span><span style="display:flex;"><span>35	103482
</span></span><span style="display:flex;"><span>35	103515
</span></span></code></pre></div><p>该文件总共包含5429行，每一行是两篇论文的编号，表示右边的论文引用左边的论文。</p>
<h2 id="2数据集内容分析">2、数据集内容分析</h2>
<p>该数据集总共有2078个样本，而且每个样本都为一篇论文。根据README可知，所有的论文被分为了7个类别，分别为：</p>
<ol>
<li>基于案列的论文</li>
<li>基于遗传算法的论文</li>
<li>基于神经网络的论文</li>
<li>基于概率方法的论文</li>
<li>基于强化学习的论文</li>
<li>基于规则学习的论文</li>
<li>理论描述类的论文</li>
</ol>
<p>此外，为了区分论文的类别，使用一个1433维的词向量，对每一篇论文进行描述，该向量的每个元素都为一个词语是否在论文中出现，如果出现则为“1”，否则为“0”。</p>
<h1 id="二utils代码分析">二、utils代码分析</h1>
<h2 id="1代码总览">1、代码总览</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> scipy.sparse <span style="color:#66d9ef">as</span> sp
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">encode_onehot</span>(labels):
</span></span><span style="display:flex;"><span>    classes <span style="color:#f92672">=</span> set(labels)
</span></span><span style="display:flex;"><span>    classes_dict <span style="color:#f92672">=</span> {c: np<span style="color:#f92672">.</span>identity(len(classes))[i, :] <span style="color:#66d9ef">for</span> i, c <span style="color:#f92672">in</span>
</span></span><span style="display:flex;"><span>                    enumerate(classes)}
</span></span><span style="display:flex;"><span>    labels_onehot <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(list(map(classes_dict<span style="color:#f92672">.</span>get, labels)),
</span></span><span style="display:flex;"><span>                             dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>int32)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> labels_onehot
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">load_data</span>(path<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;../data/cora/&#34;</span>, dataset<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;cora&#34;</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Load citation network dataset (cora only for now)&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#39;Loading </span><span style="color:#e6db74">{}</span><span style="color:#e6db74"> dataset...&#39;</span><span style="color:#f92672">.</span>format(dataset))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    idx_features_labels <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>genfromtxt(<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{}{}</span><span style="color:#e6db74">.content&#34;</span><span style="color:#f92672">.</span>format(path, dataset),
</span></span><span style="display:flex;"><span>                                        dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>dtype(str))
</span></span><span style="display:flex;"><span>    features <span style="color:#f92672">=</span> sp<span style="color:#f92672">.</span>csr_matrix(idx_features_labels[:, <span style="color:#ae81ff">1</span>:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>], dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>float32)
</span></span><span style="display:flex;"><span>    labels <span style="color:#f92672">=</span> encode_onehot(idx_features_labels[:, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># build graph</span>
</span></span><span style="display:flex;"><span>    idx <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(idx_features_labels[:, <span style="color:#ae81ff">0</span>], dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>int32)
</span></span><span style="display:flex;"><span>    idx_map <span style="color:#f92672">=</span> {j: i <span style="color:#66d9ef">for</span> i, j <span style="color:#f92672">in</span> enumerate(idx)}
</span></span><span style="display:flex;"><span>    edges_unordered <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>genfromtxt(<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{}{}</span><span style="color:#e6db74">.cites&#34;</span><span style="color:#f92672">.</span>format(path, dataset),
</span></span><span style="display:flex;"><span>                                    dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>int32)
</span></span><span style="display:flex;"><span>    edges <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(list(map(idx_map<span style="color:#f92672">.</span>get, edges_unordered<span style="color:#f92672">.</span>flatten())),
</span></span><span style="display:flex;"><span>                     dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>int32)<span style="color:#f92672">.</span>reshape(edges_unordered<span style="color:#f92672">.</span>shape)
</span></span><span style="display:flex;"><span>    adj <span style="color:#f92672">=</span> sp<span style="color:#f92672">.</span>coo_matrix((np<span style="color:#f92672">.</span>ones(edges<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]), (edges[:, <span style="color:#ae81ff">0</span>], edges[:, <span style="color:#ae81ff">1</span>])),
</span></span><span style="display:flex;"><span>                        shape<span style="color:#f92672">=</span>(labels<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>], labels<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]),
</span></span><span style="display:flex;"><span>                        dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>float32)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># build symmetric adjacency matrix</span>
</span></span><span style="display:flex;"><span>    adj <span style="color:#f92672">=</span> adj <span style="color:#f92672">+</span> adj<span style="color:#f92672">.</span>T<span style="color:#f92672">.</span>multiply(adj<span style="color:#f92672">.</span>T <span style="color:#f92672">&gt;</span> adj) <span style="color:#f92672">-</span> adj<span style="color:#f92672">.</span>multiply(adj<span style="color:#f92672">.</span>T <span style="color:#f92672">&gt;</span> adj)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    features <span style="color:#f92672">=</span> normalize(features)
</span></span><span style="display:flex;"><span>    adj <span style="color:#f92672">=</span> normalize(adj <span style="color:#f92672">+</span> sp<span style="color:#f92672">.</span>eye(adj<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    idx_train <span style="color:#f92672">=</span> range(<span style="color:#ae81ff">140</span>)
</span></span><span style="display:flex;"><span>    idx_val <span style="color:#f92672">=</span> range(<span style="color:#ae81ff">200</span>, <span style="color:#ae81ff">500</span>)
</span></span><span style="display:flex;"><span>    idx_test <span style="color:#f92672">=</span> range(<span style="color:#ae81ff">500</span>, <span style="color:#ae81ff">1500</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    features <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>FloatTensor(np<span style="color:#f92672">.</span>array(features<span style="color:#f92672">.</span>todense()))
</span></span><span style="display:flex;"><span>    labels <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>LongTensor(np<span style="color:#f92672">.</span>where(labels)[<span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>    adj <span style="color:#f92672">=</span> sparse_mx_to_torch_sparse_tensor(adj)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    idx_train <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>LongTensor(idx_train)
</span></span><span style="display:flex;"><span>    idx_val <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>LongTensor(idx_val)
</span></span><span style="display:flex;"><span>    idx_test <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>LongTensor(idx_test)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> adj, features, labels, idx_train, idx_val, idx_test
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">normalize</span>(mx):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Row-normalize sparse matrix&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    rowsum <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(mx<span style="color:#f92672">.</span>sum(<span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>    r_inv <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>power(rowsum, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>flatten()
</span></span><span style="display:flex;"><span>    r_inv[np<span style="color:#f92672">.</span>isinf(r_inv)] <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.</span>
</span></span><span style="display:flex;"><span>    r_mat_inv <span style="color:#f92672">=</span> sp<span style="color:#f92672">.</span>diags(r_inv)
</span></span><span style="display:flex;"><span>    mx <span style="color:#f92672">=</span> r_mat_inv<span style="color:#f92672">.</span>dot(mx)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> mx
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">accuracy</span>(output, labels):
</span></span><span style="display:flex;"><span>    preds <span style="color:#f92672">=</span> output<span style="color:#f92672">.</span>max(<span style="color:#ae81ff">1</span>)[<span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>type_as(labels)
</span></span><span style="display:flex;"><span>    correct <span style="color:#f92672">=</span> preds<span style="color:#f92672">.</span>eq(labels)<span style="color:#f92672">.</span>double()
</span></span><span style="display:flex;"><span>    correct <span style="color:#f92672">=</span> correct<span style="color:#f92672">.</span>sum()
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> correct <span style="color:#f92672">/</span> len(labels)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">sparse_mx_to_torch_sparse_tensor</span>(sparse_mx):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Convert a scipy sparse matrix to a torch sparse tensor.&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    sparse_mx <span style="color:#f92672">=</span> sparse_mx<span style="color:#f92672">.</span>tocoo()<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>float32)
</span></span><span style="display:flex;"><span>    indices <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>from_numpy(
</span></span><span style="display:flex;"><span>        np<span style="color:#f92672">.</span>vstack((sparse_mx<span style="color:#f92672">.</span>row, sparse_mx<span style="color:#f92672">.</span>col))<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>int64))
</span></span><span style="display:flex;"><span>    values <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>from_numpy(sparse_mx<span style="color:#f92672">.</span>data)
</span></span><span style="display:flex;"><span>    shape <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>Size(sparse_mx<span style="color:#f92672">.</span>shape)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> torch<span style="color:#f92672">.</span>sparse<span style="color:#f92672">.</span>FloatTensor(indices, values, shape)
</span></span></code></pre></div><h2 id="2特征独热码处理">2、特征独热码处理</h2>
<p>在很多的多分类问题中，特征的标签通常都是不连续的内容（如本文中特征是离散的字符串类型），为了便于后续的计算、处理，需要将所有的标签进行提取，并将标签映射到一个独热码向量中。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">encode_onehot</span>(labels):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#将所有的标签整合成一个不重复的列表</span>
</span></span><span style="display:flex;"><span>    classes <span style="color:#f92672">=</span> set(labels)   <span style="color:#75715e"># set() 函数创建一个无序不重复元素集</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;enumerate()函数生成序列，带有索引i和值c。
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    这一句将string类型的label变为int类型的label，建立映射关系
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    np.identity(len(classes)) 为创建一个classes的单位矩阵
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    创建一个字典，索引为 label， 值为独热码向量（就是之前生成的矩阵中的某一行）&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    classes_dict <span style="color:#f92672">=</span> {c: np<span style="color:#f92672">.</span>identity(len(classes))[i, :] <span style="color:#66d9ef">for</span> i, c <span style="color:#f92672">in</span>
</span></span><span style="display:flex;"><span>                    enumerate(classes)}
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 为所有的标签生成相应的独热码</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># map() 会根据提供的函数对指定序列做映射。</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 这一句将string类型的label替换为int类型的label</span>
</span></span><span style="display:flex;"><span>    labels_onehot <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(list(map(classes_dict<span style="color:#f92672">.</span>get, labels)),
</span></span><span style="display:flex;"><span>                             dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>int32)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> labels_onehot
</span></span></code></pre></div><p>输入labels为：
<img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://img-blog.csdnimg.cn/20200819155745635.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=,size_16,color_FFFFFF,t_70#pic_center"
    data-srcset="https://img-blog.csdnimg.cn/20200819155745635.png?x-oss-process=image/watermark%2ctype_ZmFuZ3poZW5naGVpdGk%2cshadow_10%2ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=%2csize_16%2ccolor_FFFFFF%2ct_70#pic_center, https://img-blog.csdnimg.cn/20200819155745635.png?x-oss-process=image/watermark%2ctype_ZmFuZ3poZW5naGVpdGk%2cshadow_10%2ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=%2csize_16%2ccolor_FFFFFF%2ct_70#pic_center 1.5x, https://img-blog.csdnimg.cn/20200819155745635.png?x-oss-process=image/watermark%2ctype_ZmFuZ3poZW5naGVpdGk%2cshadow_10%2ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=%2csize_16%2ccolor_FFFFFF%2ct_70#pic_center 2x"
    data-sizes="auto"
    alt="在这里插入图片描述"
    title="在这里插入图片描述"/>
执行完该程序后，输出的独热码为：
<img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://img-blog.csdnimg.cn/20200819155836640.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=,size_16,color_FFFFFF,t_70#pic_center"
    data-srcset="https://img-blog.csdnimg.cn/20200819155836640.png?x-oss-process=image/watermark%2ctype_ZmFuZ3poZW5naGVpdGk%2cshadow_10%2ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=%2csize_16%2ccolor_FFFFFF%2ct_70#pic_center, https://img-blog.csdnimg.cn/20200819155836640.png?x-oss-process=image/watermark%2ctype_ZmFuZ3poZW5naGVpdGk%2cshadow_10%2ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=%2csize_16%2ccolor_FFFFFF%2ct_70#pic_center 1.5x, https://img-blog.csdnimg.cn/20200819155836640.png?x-oss-process=image/watermark%2ctype_ZmFuZ3poZW5naGVpdGk%2cshadow_10%2ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=%2csize_16%2ccolor_FFFFFF%2ct_70#pic_center 2x"
    data-sizes="auto"
    alt="https://img-blog.csdnimg.cn/20200819155836640.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=,size_16,color_FFFFFF,t_70#pic_center"
    title="https://img-blog.csdnimg.cn/20200819155836640.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=,size_16,color_FFFFFF,t_70#pic_center"/></p>
<h2 id="3特征归一化函数">3、特征归一化函数</h2>
<p>该函数需要传入特征矩阵作为参数。对于本文使用的cora的数据集来说，每一行是一个样本，每一个样本是1433个特征。</p>
<blockquote>
<p>需要注意的是：由于特征中有很多的内容是“0”，因此使用稀疏矩阵的方式进行存储，因此经过该函数归一化之后的函数，仍然为一个稀疏矩阵。</p>
</blockquote>
<p>归一化函数实现的方式：对传入特征矩阵的每一行分别求和，取到数后就是每一行非零元素归一化的值，然后与传入特征矩阵进行点乘。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">normalize</span>(mx):
</span></span><span style="display:flex;"><span>    rowsum <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(mx<span style="color:#f92672">.</span>sum(<span style="color:#ae81ff">1</span>)) <span style="color:#75715e">#会得到一个（2708,1）的矩阵</span>
</span></span><span style="display:flex;"><span>    r_inv <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>power(rowsum, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>flatten() <span style="color:#75715e">#得到（2708，）的元祖</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#在计算倒数的时候存在一个问题，如果原来的值为0，则其倒数为无穷大，因此需要对r_inv中无穷大的值进行修正，更改为0</span>
</span></span><span style="display:flex;"><span>    r_inv[np<span style="color:#f92672">.</span>isinf(r_inv)] <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.</span>
</span></span><span style="display:flex;"><span>    r_mat_inv <span style="color:#f92672">=</span> sp<span style="color:#f92672">.</span>diags(r_inv)
</span></span><span style="display:flex;"><span>    mx <span style="color:#f92672">=</span> r_mat_inv<span style="color:#f92672">.</span>dot(mx)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> mx
</span></span></code></pre></div><p>本文中以领接矩阵作为示例说明上述问题，其输入矩阵mx如图所示：
<img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://img-blog.csdnimg.cn/2020081916014757.png#pic_center"
    data-srcset="https://img-blog.csdnimg.cn/2020081916014757.png#pic_center, https://img-blog.csdnimg.cn/2020081916014757.png#pic_center 1.5x, https://img-blog.csdnimg.cn/2020081916014757.png#pic_center 2x"
    data-sizes="auto"
    alt="https://img-blog.csdnimg.cn/2020081916014757.png#pic_center"
    title="https://img-blog.csdnimg.cn/2020081916014757.png#pic_center"/>
归一化之后输出的内容为：
<img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://img-blog.csdnimg.cn/20200819161004772.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=,size_16,color_FFFFFF,t_70#pic_center"
    data-srcset="https://img-blog.csdnimg.cn/20200819161004772.png?x-oss-process=image/watermark%2ctype_ZmFuZ3poZW5naGVpdGk%2cshadow_10%2ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=%2csize_16%2ccolor_FFFFFF%2ct_70#pic_center, https://img-blog.csdnimg.cn/20200819161004772.png?x-oss-process=image/watermark%2ctype_ZmFuZ3poZW5naGVpdGk%2cshadow_10%2ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=%2csize_16%2ccolor_FFFFFF%2ct_70#pic_center 1.5x, https://img-blog.csdnimg.cn/20200819161004772.png?x-oss-process=image/watermark%2ctype_ZmFuZ3poZW5naGVpdGk%2cshadow_10%2ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=%2csize_16%2ccolor_FFFFFF%2ct_70#pic_center 2x"
    data-sizes="auto"
    alt="https://img-blog.csdnimg.cn/20200819161004772.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=,size_16,color_FFFFFF,t_70#pic_center"
    title="https://img-blog.csdnimg.cn/20200819161004772.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2QxNzkyMTI5MzQ=,size_16,color_FFFFFF,t_70#pic_center"/></p>
<h2 id="4稀疏矩阵转稀疏张量函数">4、稀疏矩阵转稀疏张量函数</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">sparse_mx_to_torch_sparse_tensor</span>(sparse_mx):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Convert a scipy sparse matrix to a torch sparse tensor.&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    numpy中的ndarray转化成pytorch中的tensor : torch.from_numpy()
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    pytorch中的tensor转化成numpy中的ndarray : numpy()
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    sparse_mx <span style="color:#f92672">=</span> sparse_mx<span style="color:#f92672">.</span>tocoo()<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>float32)
</span></span><span style="display:flex;"><span>    indices <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>from_numpy(
</span></span><span style="display:flex;"><span>                np<span style="color:#f92672">.</span>vstack((sparse_mx<span style="color:#f92672">.</span>row, sparse_mx<span style="color:#f92672">.</span>col))<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>int64))
</span></span><span style="display:flex;"><span>    values <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>from_numpy(sparse_mx<span style="color:#f92672">.</span>data)
</span></span><span style="display:flex;"><span>    shape <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>Size(sparse_mx<span style="color:#f92672">.</span>shape)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> torch<span style="color:#f92672">.</span>sparse<span style="color:#f92672">.</span>FloatTensor(indices, values, shape)
</span></span></code></pre></div><h2 id="5精度计算函数">5、精度计算函数</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">accuracy</span>(output, labels):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 使用type_as(tesnor)将张量转换为给定类型的张量。</span>
</span></span><span style="display:flex;"><span>    preds <span style="color:#f92672">=</span> output<span style="color:#f92672">.</span>max(<span style="color:#ae81ff">1</span>)[<span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>type_as(labels)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 记录等于preds的label eq:equal</span>
</span></span><span style="display:flex;"><span>    correct <span style="color:#f92672">=</span> preds<span style="color:#f92672">.</span>eq(labels)<span style="color:#f92672">.</span>double()
</span></span><span style="display:flex;"><span>    correct <span style="color:#f92672">=</span> correct<span style="color:#f92672">.</span>sum()
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> correct <span style="color:#f92672">/</span> len(labels)
</span></span></code></pre></div><h2 id="6数据载入及处理函数">6、数据载入及处理函数</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">load_data</span>(path<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;data/cora/&#34;</span>, dataset<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;cora&#34;</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Load citation network daraser (cora only for now)&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#39;Loading </span><span style="color:#e6db74">{}</span><span style="color:#e6db74"> dataset...&#39;</span><span style="color:#f92672">.</span>format(dataset))
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#首先将文件中的内容读出，以二维数组的形式存储</span>
</span></span><span style="display:flex;"><span>    idx_features_labels <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>genfromtxt(<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{}{}</span><span style="color:#e6db74">.content&#34;</span><span style="color:#f92672">.</span>format(path,dataset), dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>dtype(str))
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#以稀疏矩阵（采用CSR格式压缩）将数据中的特征存储</span>
</span></span><span style="display:flex;"><span>    features <span style="color:#f92672">=</span> sp<span style="color:#f92672">.</span>csr_matrix(idx_features_labels[:, <span style="color:#ae81ff">1</span>:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>], dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>float32)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># label</span>
</span></span><span style="display:flex;"><span>    labels <span style="color:#f92672">=</span> encode_onehot(idx_features_labels[:, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;根据引用文件，生成无向图&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 将每篇文献的编号提取出来</span>
</span></span><span style="display:flex;"><span>    idx <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(idx_features_labels[:, <span style="color:#ae81ff">0</span>], dtype <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>int32)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 对文献的编号构建字典</span>
</span></span><span style="display:flex;"><span>    idx_map <span style="color:#f92672">=</span> {j : i <span style="color:#66d9ef">for</span> i, j <span style="color:#f92672">in</span> enumerate(idx)}
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#读取cite文件</span>
</span></span><span style="display:flex;"><span>    edges_unordered <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>genfromtxt(<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{}{}</span><span style="color:#e6db74">.cites&#34;</span><span style="color:#f92672">.</span>format(path,dataset), dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>int32)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 生成图的边，（x,y）其中x、y都是为以文章编号为索引得到的值，此外，y中引入x的文献</span>
</span></span><span style="display:flex;"><span>    edges <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(list(map(idx_map<span style="color:#f92672">.</span>get,edges_unordered<span style="color:#f92672">.</span>flatten())), dtype <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>int32)<span style="color:#f92672">.</span>reshape(edges_unordered<span style="color:#f92672">.</span>shape)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#生成领接矩阵，生成的矩阵为稀疏矩阵，对应的行和列坐标分别为边的两个点，该步骤之后得到的是一个有向图</span>
</span></span><span style="display:flex;"><span>    adj <span style="color:#f92672">=</span> sp<span style="color:#f92672">.</span>coo_matrix((np<span style="color:#f92672">.</span>ones(edges<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]), (edges[:,<span style="color:#ae81ff">0</span>],edges[:,<span style="color:#ae81ff">1</span>])), shape<span style="color:#f92672">=</span>(labels<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>],labels<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]),dtype <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>float32)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#无向图的领接矩阵是对称的，因此需要将上面得到的矩阵转换为对称的矩阵，从而得到无向图的领接矩阵</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    论文中采用的办法和下面两个语句是等价的，仅仅是为了产生对称的矩阵
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    adj_2 = adj + adj.T.multiply(adj.T &gt; adj)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    adj_3 = adj + adj.T
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    adj <span style="color:#f92672">=</span> adj <span style="color:#f92672">+</span> adj<span style="color:#f92672">.</span>T<span style="color:#f92672">.</span>multiply(adj<span style="color:#f92672">.</span>T <span style="color:#f92672">&gt;</span> adj) <span style="color:#f92672">-</span> adj<span style="color:#f92672">.</span>multiply(adj<span style="color:#f92672">.</span>T <span style="color:#f92672">&gt;</span> adj)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#进行归一化，对应于论文中的A^=(D~)^0.5 A~ (D~)^0.5,但是本代码实现的是A^=(D~)^-1 A~</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#A^=I+A</span>
</span></span><span style="display:flex;"><span>    adj <span style="color:#f92672">=</span> normalize(adj <span style="color:#f92672">+</span> sp<span style="color:#f92672">.</span>eye(adj<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 分别构建训练集、验证集、测试集，并创建特征矩阵、标签向量和邻接矩阵的tensor，用来做模型的输入</span>
</span></span><span style="display:flex;"><span>    idx_train <span style="color:#f92672">=</span> range(<span style="color:#ae81ff">140</span>)
</span></span><span style="display:flex;"><span>    idx_val <span style="color:#f92672">=</span> range(<span style="color:#ae81ff">200</span>, <span style="color:#ae81ff">500</span>)
</span></span><span style="display:flex;"><span>    idx_test <span style="color:#f92672">=</span> range(<span style="color:#ae81ff">500</span>, <span style="color:#ae81ff">1500</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 将特征转换为tensor</span>
</span></span><span style="display:flex;"><span>    features <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>FloatTensor(np<span style="color:#f92672">.</span>array(features<span style="color:#f92672">.</span>todense()))
</span></span><span style="display:flex;"><span>    labels <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>LongTensor(np<span style="color:#f92672">.</span>where(labels)[<span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>    adj <span style="color:#f92672">=</span> sparse_mx_to_torch_sparse_tensor(adj)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    idx_train <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>LongTensor(idx_train)
</span></span><span style="display:flex;"><span>    idx_val <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>LongTensor(idx_val)
</span></span><span style="display:flex;"><span>    idx_test <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>LongTensor(idx_test)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> adj, features, labels, idx_train, idx_val, idx_test
</span></span></code></pre></div><h1 id="三models代码分析">三、models代码分析</h1>
<h2 id="1代码总览-1">1、代码总览</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn.functional <span style="color:#66d9ef">as</span> F
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> pygcn.layers <span style="color:#f92672">import</span> GraphConvolution
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">GCN</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, nfeat, nhid, nclass, dropout):
</span></span><span style="display:flex;"><span>        super(GCN, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>gc1 <span style="color:#f92672">=</span> GraphConvolution(nfeat, nhid)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>gc2 <span style="color:#f92672">=</span> GraphConvolution(nhid, nclass)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>dropout <span style="color:#f92672">=</span> dropout
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x, adj):
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>relu(self<span style="color:#f92672">.</span>gc1(x, adj))
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>dropout(x, self<span style="color:#f92672">.</span>dropout, training<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>training)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>gc2(x, adj)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> F<span style="color:#f92672">.</span>log_softmax(x, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span></code></pre></div><h2 id="2代码分析">2、代码分析</h2>
<p><code>class GCN(nn.Module) </code>定义了一个图卷积神经网络，其有两个卷积层：</p>
<ul>
<li>卷积层1：输入的特征为nfeat，维度是2708，输出的特征为nhid，维度是16；</li>
<li>卷积层2：输入的特征为nhid，维度是16，输出的特征为nclass，维度是7（即类别的结果）</li>
</ul>
<p>forward是向前传播函数，最终得到网络向前传播的方式为：gc1-&gt;relu–&gt;fropout–&gt;gc2–&gt;softmax</p>
<h1 id="四layers代码分析">四、layers代码分析</h1>
<h2 id="1代码总览-2">1、代码总览</h2>
<blockquote>
<p>layers中主要定义了图数据实现卷积操作的层，类似于CNN中的卷积层，只是一个层而已。本节将分别通过属性定义、参数初始化、前向传播以及字符串表达四个方面对代码进一步解析。</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> math
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torch.nn.parameter <span style="color:#f92672">import</span> Parameter
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torch.nn.modules.module <span style="color:#f92672">import</span> Module
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">GraphConvolution</span>(Module):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, in_features, out_features, bias<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>):
</span></span><span style="display:flex;"><span>        super(GraphConvolution, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>in_features <span style="color:#f92672">=</span> in_features
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>out_features <span style="color:#f92672">=</span> out_features
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>weight <span style="color:#f92672">=</span> Parameter(torch<span style="color:#f92672">.</span>FloatTensor(in_features, out_features))
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> bias:
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>bias <span style="color:#f92672">=</span> Parameter(torch<span style="color:#f92672">.</span>FloatTensor(out_features))
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>register_parameter(<span style="color:#e6db74">&#39;bias&#39;</span>, <span style="color:#66d9ef">None</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>reset_parameters()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">reset_parameters</span>(self):
</span></span><span style="display:flex;"><span>        stdv <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.</span> <span style="color:#f92672">/</span> math<span style="color:#f92672">.</span>sqrt(self<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>uniform_(<span style="color:#f92672">-</span>stdv, stdv)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>bias <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>uniform_(<span style="color:#f92672">-</span>stdv, stdv)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, input, adj):
</span></span><span style="display:flex;"><span>        support <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>mm(input, self<span style="color:#f92672">.</span>weight)
</span></span><span style="display:flex;"><span>        output <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>spmm(adj, support)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>bias <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> output <span style="color:#f92672">+</span> self<span style="color:#f92672">.</span>bias
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> output
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __repr__(self):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>__class__<span style="color:#f92672">.</span>__name__ <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39; (&#39;</span> \
</span></span><span style="display:flex;"><span>               <span style="color:#f92672">+</span> str(self<span style="color:#f92672">.</span>in_features) <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39; -&gt; &#39;</span> \
</span></span><span style="display:flex;"><span>               <span style="color:#f92672">+</span> str(self<span style="color:#f92672">.</span>out_features) <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;)&#39;</span>
</span></span></code></pre></div><h2 id="2属性定义">2、属性定义</h2>
<p><code>GraphConvolution </code>作为一个类，首先需要定义其相关属性。本文中主要定义了其输入特征 <code>in_feature </code>、输出特征 <code>out_feature </code>两个输入，以及权重 <code>weight </code>和偏移向量 <code>bias </code>两个参数，同时调用了其参数初始化的方法（参数初始化此处不做详细说明）。</p>
<p>由于在训练过程中，参数是可以训练的，即可以求其梯度，因此使用parameter的方式定义。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, in_features, out_features, bias<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>):
</span></span><span style="display:flex;"><span>        super(GraphConvolution, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>in_features <span style="color:#f92672">=</span> in_features
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>out_features <span style="color:#f92672">=</span> out_features
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 由于weight是可以训练的，因此使用parameter定义</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>weight <span style="color:#f92672">=</span> Parameter(torch<span style="color:#f92672">.</span>FloatTensor(in_features, out_features))
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 由于bias是可以训练的，因此使用parameter定义</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> bias:
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>bias <span style="color:#f92672">=</span> Parameter(torch<span style="color:#f92672">.</span>FloatTensor(out_features))
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span> :
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>register_parameter(<span style="color:#e6db74">&#39;bias&#39;</span>, <span style="color:#66d9ef">None</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>reset_parameter()
</span></span></code></pre></div><h2 id="3参数初始化">3、参数初始化</h2>
<p>为了让每次训练产生的初始参数尽可能的相同，从而便于实验结果的复现，可以设置固定的随机数生成种子。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">reset_parameter</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># size()函数主要是用来统计矩阵元素个数，或矩阵某一维上的元素个数的函数  size（1）为行</span>
</span></span><span style="display:flex;"><span>        stdv <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.</span> <span style="color:#f92672">/</span> math<span style="color:#f92672">.</span>sqrt(self<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># uniform() 方法将随机生成下一个实数，它在 [x, y] 范围内</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>uniform_(<span style="color:#f92672">-</span>stdv, stdv)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>bias <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>uniform_(<span style="color:#f92672">-</span>stdv, stdv)
</span></span></code></pre></div><h2 id="4前馈计算">4、前馈计算</h2>
<p>此处主要定义的是本层的前向传播，通常采用的是 A * X * W A ∗ X ∗ W 的计算方法。由于A是一个sparse变量，因此其与X进行卷积的结果也是稀疏矩阵。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, input, adj) :
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># torch.mm(a, b)是矩阵a和b矩阵相乘，torch.mul(a, b)是矩阵a和b对应位相乘，a和b的维度必须相等</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># torch.spmm(a,b)是稀疏矩阵相乘</span>
</span></span><span style="display:flex;"><span>        support <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>mm(input, self<span style="color:#f92672">.</span>weight)
</span></span><span style="display:flex;"><span>        output <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>spmm(adj, support)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>bias <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> output <span style="color:#f92672">+</span> self<span style="color:#f92672">.</span>bias
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span> :
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> output
</span></span></code></pre></div><h2 id="5字符串表达">5、字符串表达</h2>
<p><code>__repr__() </code>方法是类的实例化对象用来做“自我介绍”的方法，默认情况下，它会返回当前对象的“类名+object at+内存地址”， 而如果对该方法进行重写，可以为其制作自定义的自我描述信息。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __repr__(self):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>__class__<span style="color:#f92672">.</span>__name__ <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;(&#39;</span> \
</span></span><span style="display:flex;"><span>               <span style="color:#f92672">+</span> str(self<span style="color:#f92672">.</span>in_features) <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;-&gt;&#39;</span> \
</span></span><span style="display:flex;"><span>               <span style="color:#f92672">+</span> str(self<span style="color:#f92672">.</span>out_features) <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;)&#39;</span>
</span></span></code></pre></div><h1 id="五train代码分析">五、train代码分析</h1>
<blockquote>
<p>train代码主要完成了函数的训练步骤，由于该文件主要完成对上述函数的调用，因此只是在程序中进行详细的注释，不在分函数进行介绍。</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 在 Python2 中导入未来的支持的语言特征中division (精确除法)，</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 即from __future__ import division ，当我们在程序中没有导入该特征时，</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># &#34;/“操作符执行的只能是整除，也就是取整数，只有当我们导入division(精确算法)以后，</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ”/&#34;执行的才是精确算法。</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> __future__ <span style="color:#f92672">import</span> division
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 在开头加上from __future__ import print_function这句之后，即使在python2.X，</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 使用print就得像python3.X那样加括号使用。python2.X中print不需要括号，而在python3.X中则需要。</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> __future__ <span style="color:#f92672">import</span> print_function
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> sys
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> time
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> argparse
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn.functional <span style="color:#66d9ef">as</span> F
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.optim <span style="color:#66d9ef">as</span> optim
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> utils <span style="color:#f92672">import</span> load_data, accuracy
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> models <span style="color:#f92672">import</span> GCN
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;&#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">定义一个显示超参数的函数，将代码中所有的超参数打印
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">show_Hyperparameter</span>(args):
</span></span><span style="display:flex;"><span>    argsDict <span style="color:#f92672">=</span> args<span style="color:#f92672">.</span>__dict__
</span></span><span style="display:flex;"><span>    print(argsDict)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#39;the settings are as following&#39;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> key <span style="color:#f92672">in</span> argsDict:
</span></span><span style="display:flex;"><span>        print(key,<span style="color:#e6db74">&#39;:&#39;</span>,argsDict[key])
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;&#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">训练设置
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>parser <span style="color:#f92672">=</span> argparse<span style="color:#f92672">.</span>ArgumentParser()
</span></span><span style="display:flex;"><span>parser<span style="color:#f92672">.</span>add_argument(<span style="color:#e6db74">&#39;--no-cuda&#39;</span>, action<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;store_true&#39;</span>, default<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>                    help<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Disables CUDA training.&#39;</span>)
</span></span><span style="display:flex;"><span>parser<span style="color:#f92672">.</span>add_argument(<span style="color:#e6db74">&#39;--fastmode&#39;</span>,action<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;store_true&#39;</span>, default<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>                    help<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Validate during traing pass&#39;</span>)
</span></span><span style="display:flex;"><span>parser<span style="color:#f92672">.</span>add_argument(<span style="color:#e6db74">&#39;--seed&#39;</span>, type<span style="color:#f92672">=</span>int, default<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>, help<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Random seed&#39;</span>)
</span></span><span style="display:flex;"><span>parser<span style="color:#f92672">.</span>add_argument(<span style="color:#e6db74">&#39;--epochs&#39;</span>, type<span style="color:#f92672">=</span>int, default<span style="color:#f92672">=</span><span style="color:#ae81ff">200</span>,
</span></span><span style="display:flex;"><span>                    help<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Number of epochs to train&#39;</span>)
</span></span><span style="display:flex;"><span>parser<span style="color:#f92672">.</span>add_argument(<span style="color:#e6db74">&#39;--lr&#39;</span>, type<span style="color:#f92672">=</span>float, default<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>,
</span></span><span style="display:flex;"><span>                    help<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Initial learning rate&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 权重衰减</span>
</span></span><span style="display:flex;"><span>parser<span style="color:#f92672">.</span>add_argument(<span style="color:#e6db74">&#39;--weight_decay&#39;</span>, type<span style="color:#f92672">=</span>float, default<span style="color:#f92672">=</span><span style="color:#ae81ff">5e-4</span>,
</span></span><span style="display:flex;"><span>                    help<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Weight decay (L2 loss on parameters)&#39;</span>)
</span></span><span style="display:flex;"><span>parser<span style="color:#f92672">.</span>add_argument(<span style="color:#e6db74">&#39;--hidden&#39;</span>, type<span style="color:#f92672">=</span>int, default<span style="color:#f92672">=</span><span style="color:#ae81ff">16</span>,
</span></span><span style="display:flex;"><span>                    help<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Number of hidden units&#39;</span>)
</span></span><span style="display:flex;"><span>parser<span style="color:#f92672">.</span>add_argument(<span style="color:#e6db74">&#39;--dropout&#39;</span>, type<span style="color:#f92672">=</span>float, default<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>,
</span></span><span style="display:flex;"><span>                    help<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Dropout rate (1 - keep probability)&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 如果程序不禁止使用gpu且当前主机的gpu可用，arg.cuda就为True</span>
</span></span><span style="display:flex;"><span>args <span style="color:#f92672">=</span> parser<span style="color:#f92672">.</span>parse_args()
</span></span><span style="display:flex;"><span>show_Hyperparameter(args)
</span></span><span style="display:flex;"><span>args<span style="color:#f92672">.</span>cuda <span style="color:#f92672">=</span> <span style="color:#f92672">not</span> args<span style="color:#f92672">.</span>no_cuda <span style="color:#f92672">and</span> torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>is_available()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 指定生成随机数的种子，从而每次生成的随机数都是相同的，通过设定随机数种子的好处是，使模型初始化的可学习参数相同，从而使每次的运行结果可以复现。</span>
</span></span><span style="display:flex;"><span>np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(args<span style="color:#f92672">.</span>seed)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> args<span style="color:#f92672">.</span>cuda:
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>manual_seed(args<span style="color:#f92672">.</span>seed)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">.</span>manual_seed(args<span style="color:#f92672">.</span>seed)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;&#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">开始训练
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 载入数据</span>
</span></span><span style="display:flex;"><span>adj, features, labels, idx_train, idx_val, idx_test <span style="color:#f92672">=</span> load_data()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Model and optimizer</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> GCN(nfeat<span style="color:#f92672">=</span>features<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>],
</span></span><span style="display:flex;"><span>            nhid<span style="color:#f92672">=</span>args<span style="color:#f92672">.</span>hidden,
</span></span><span style="display:flex;"><span>            nclass<span style="color:#f92672">=</span>labels<span style="color:#f92672">.</span>max()<span style="color:#f92672">.</span>item() <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>,
</span></span><span style="display:flex;"><span>            dropout<span style="color:#f92672">=</span>args<span style="color:#f92672">.</span>dropout)
</span></span><span style="display:flex;"><span>optimizer <span style="color:#f92672">=</span> optim<span style="color:#f92672">.</span>Adam(model<span style="color:#f92672">.</span>parameters(),
</span></span><span style="display:flex;"><span>                       lr<span style="color:#f92672">=</span>args<span style="color:#f92672">.</span>lr, weight_decay<span style="color:#f92672">=</span>args<span style="color:#f92672">.</span>weight_decay)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 如果可以使用GPU，数据写入cuda，便于后续加速</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># .cuda()会分配到显存里（如果gpu可用）</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> args<span style="color:#f92672">.</span>cuda:
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>cuda()
</span></span><span style="display:flex;"><span>    features <span style="color:#f92672">=</span> features<span style="color:#f92672">.</span>cuda()
</span></span><span style="display:flex;"><span>    adj <span style="color:#f92672">=</span> adj<span style="color:#f92672">.</span>cuda()
</span></span><span style="display:flex;"><span>    labels <span style="color:#f92672">=</span> labels<span style="color:#f92672">.</span>cuda()
</span></span><span style="display:flex;"><span>    idx_val <span style="color:#f92672">=</span> idx_val<span style="color:#f92672">.</span>cuda()
</span></span><span style="display:flex;"><span>    idx_test <span style="color:#f92672">=</span> idx_test<span style="color:#f92672">.</span>cuda()
</span></span><span style="display:flex;"><span>    idx_train <span style="color:#f92672">=</span> idx_train<span style="color:#f92672">.</span>cuda()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">train</span>(epoch):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 返回当前时间</span>
</span></span><span style="display:flex;"><span>    t <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 将模型转为训练模式，并将优化器梯度置零</span>
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>train()
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># optimizer.zero_grad()意思是把梯度置零，也就是把loss关于weight的导数变成0.</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># pytorch中每一轮batch需要设置optimizer.zero_grad</span>
</span></span><span style="display:flex;"><span>    optimizer<span style="color:#f92672">.</span>zero_grad()
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 由于在算output时已经使用了log_softmax，这里使用的损失函数就是NLLloss，如果前面没有加log运算，</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 这里就要使用CrossEntropyLoss了</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 损失函数NLLLoss() 的输入是一个对数概率向量和一个目标标签. 它不会为我们计算对数概率，</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 适合最后一层是log_softmax()的网络. 损失函数 CrossEntropyLoss() 与 NLLLoss() 类似,</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 唯一的不同是它为我们去做 softmax.可以理解为：CrossEntropyLoss()=log_softmax() + NLLLoss()</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 理论上对于单标签多分类问题，直接经过softmax求出概率分布，然后把这个概率分布用crossentropy做一个似然估计误差。</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 但是softmax求出来的概率分布，每一个概率都是(0,1)的，这就会导致有些概率过小，导致下溢。 考虑到这个概率分布总归是</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 要经过crossentropy的，而crossentropy的计算是把概率分布外面套一个-log 来似然，那么直接在计算概率分布的时候加</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 上log,把概率从（0，1）变为（-∞，0），这样就防止中间会有下溢出。 所以log_softmax说白了就是将本来应该由crossentropy做</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 的套log的工作提到预测概率分布来，跳过了中间的存储步骤，防止中间数值会有下溢出，使得数据更加稳定。 正是由于把log这一步从计</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 算误差提到前面，所以用log_softmax之后，下游的计算误差的function就应该变成NLLLoss(它没有套log这一步，直接将输入取反，</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 然后计算和label的乘积求和平均)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 计算输出时，对所有的节点都进行计算</span>
</span></span><span style="display:flex;"><span>    output <span style="color:#f92672">=</span> model(features, adj)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 损失函数，仅对训练集的节点进行计算，即：优化对训练数据集进行</span>
</span></span><span style="display:flex;"><span>    loss_train <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>nll_loss(output[idx_train], labels[idx_train])
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 计算准确率</span>
</span></span><span style="display:flex;"><span>    acc_train <span style="color:#f92672">=</span> accuracy(output[idx_train], labels[idx_train])
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 反向求导  Back Propagation</span>
</span></span><span style="display:flex;"><span>    loss_train<span style="color:#f92672">.</span>backward()
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 更新所有的参数</span>
</span></span><span style="display:flex;"><span>    optimizer<span style="color:#f92672">.</span>step()
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 通过计算训练集损失和反向传播及优化，带标签的label信息就可以smooth到整个图上（label information is smoothed over the graph）。</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 先是通过model.eval()转为测试模式，之后计算输出，并单独对测试集计算损失函数和准确率。</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> args<span style="color:#f92672">.</span>fastmode:
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Evaluate validation set performance separately,</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># deactivates dropout during validation run.</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># eval() 函数用来执行一个字符串表达式，并返回表达式的值</span>
</span></span><span style="display:flex;"><span>        model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>        output <span style="color:#f92672">=</span> model(features, adj)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 验证集的损失函数</span>
</span></span><span style="display:flex;"><span>    loss_val <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>nll_loss(output[idx_val], labels[idx_val])
</span></span><span style="display:flex;"><span>    acc_val <span style="color:#f92672">=</span> accuracy(output[idx_val], labels[idx_val])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#39;Epoch: </span><span style="color:#e6db74">{:04d}</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>format(epoch<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#39;loss_train: </span><span style="color:#e6db74">{:.4f}</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>format(loss_train<span style="color:#f92672">.</span>item()),
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#39;acc_train: </span><span style="color:#e6db74">{:.4f}</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>format(acc_train<span style="color:#f92672">.</span>item()),
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#39;loss_val: </span><span style="color:#e6db74">{:.4f}</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>format(loss_val<span style="color:#f92672">.</span>item()),
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#39;acc_val: </span><span style="color:#e6db74">{:.4f}</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>format(acc_val<span style="color:#f92672">.</span>item()),
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#39;time: </span><span style="color:#e6db74">{:.4f}</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>format(time<span style="color:#f92672">.</span>time() <span style="color:#f92672">-</span> t))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 定义测试函数，相当于对已有的模型在测试集上运行对应的loss与accuracy</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">test</span>():
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>    output <span style="color:#f92672">=</span> model(features, adj)
</span></span><span style="display:flex;"><span>    loss_test <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>nll_loss(output[idx_test], labels[idx_test])
</span></span><span style="display:flex;"><span>    acc_test <span style="color:#f92672">=</span> accuracy(output[idx_test], labels[idx_test])
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;Test set results:&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;loss= </span><span style="color:#e6db74">{:.4f}</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format(loss_test<span style="color:#f92672">.</span>item()),
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;accuracy= </span><span style="color:#e6db74">{:.4f}</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format(acc_test<span style="color:#f92672">.</span>item()))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Train model  逐个epoch进行train，最后test</span>
</span></span><span style="display:flex;"><span>t_total <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(args<span style="color:#f92672">.</span>epochs):
</span></span><span style="display:flex;"><span>    train(epoch)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Optimization Finished!&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Total time elapsed: </span><span style="color:#e6db74">{:.4f}</span><span style="color:#e6db74">s&#34;</span><span style="color:#f92672">.</span>format(time<span style="color:#f92672">.</span>time() <span style="color:#f92672">-</span> t_total))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>test()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>empty_cache()
</span></span></code></pre></div><h3 id="from">From</h3>
<ul>
<li><a href="https://blog.csdn.net/d179212934/article/details/108093614"target="_blank" rel="external nofollow noopener noreferrer">https://blog.csdn.net/d179212934/article/details/108093614<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
</ul>
</div>
<div class="post-footer" id="post-footer">
  <div class="post-info">
    <div class="post-info-line">
      <div class="post-info-mod">
        <span title=2023-09-28&#32;23:52:09>更新于 2023-09-28&nbsp;</span>
      </div><div class="post-info-license">
          <span><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span>
        </div></div>
    <div class="post-info-line">
      <div class="post-info-md"><span><a href="liudongdong1.github.io/gcndemo/index.md" title="阅读原始文档" class="link-to-markdown">阅读原始文档</a></span><span><a href="https://liudongdong1.github.io/edit/master/content/posts%5c%e6%97%b6%e7%a9%ba%e6%95%b0%e6%8d%ae%5cGNN%5cGCNDemo.md" title="编辑此页"target="_blank" rel="external nofollow noopener noreferrer" class="link-to-edit">编辑此页</a></span></div>
      <div class="post-info-share">
        <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="liudongdong1.github.io/gcndemo/" data-title="GCNDemo" data-hashtags="Pytorch,Model"><i class="fa-brands fa-twitter fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="liudongdong1.github.io/gcndemo/" data-hashtag="Pytorch"><i class="fa-brands fa-facebook-square fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="liudongdong1.github.io/gcndemo/" data-title="GCNDemo" data-image="https://cdn.pixabay.com/photo/2018/05/26/21/21/blueberries-3432295__340.jpg"><i class="fa-brands fa-weibo fa-fw" aria-hidden="true"></i></a>
  </span>
      </div>
    </div>
  </div>

  <div class="post-info-more">
    <section class="post-tags"><i class="fa-solid fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="liudongdong1.github.io/tags/pytorch/">Pytorch</a>,&nbsp;<a href="liudongdong1.github.io/tags/model/">Model</a></section>
    <section>
      <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="liudongdong1.github.io/">主页</a></span>
    </section>
  </div>

  <div class="post-nav"><a href="liudongdong1.github.io/compat/" class="prev" rel="prev" title="FlowerClassifyPytorch"><i class="fa-solid fa-angle-left fa-fw" aria-hidden="true"></i>FlowerClassifyPytorch</a>
      <a href="liudongdong1.github.io/gan/" class="next" rel="next" title="GANIntroduce">GANIntroduce<i class="fa-solid fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article></main><footer class="footer">
    <div class="footer-container"><div class="footer-line powered">由 <a href="https://gohugo.io/" target="_blank" rel="external nofollow noopener noreferrer" title="Hugo 0.118.2">Hugo</a> 强力驱动 | 主题 - <a href="https://github.com/hugo-fixit/FixIt" target="_blank" rel="external" title="FixIt v0.2.17-RC"><img class="fixit-icon" src="/liudongdong1.github.io/fixit.min.svg" alt="FixIt logo" />&nbsp;FixIt</a>
        </div><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">2020 - 2023</span><span class="author" itemprop="copyrightHolder">
              <a href="https://liudongdong1.github.io/"target="_blank" rel="external nofollow noopener noreferrer">LiuDongdong</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div><div class="footer-line statistics"><span class="site-time" title='网站运行中 ...'><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden="true"></i>&nbsp;<span class="run-times">网站运行中 ...</span></span></div><div class="footer-line ibruce">
          <span id="busuanzi_container_site_uv" title='总访客数'><i class="fa-regular fa-user fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span><span id="busuanzi_container_site_pv" class="footer-divider" title='总访问量'><i class="fa-regular fa-eye fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span>
        </div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="回到顶部"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric">0%</span>
        </div></div><a href="https://liudongdong1.github.io/" title="在 GitHub 上查看源代码"target="_blank" rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><div id="mask"></div><div class="reading-progress-bar" style="left: 0;top: 0;--bg-progress: #0076ff;--bg-progress-dark: #fff;"></div><noscript>
    <div class="noscript-warning">FixIt 主题在启用 JavaScript 的情况下效果最佳。</div>
  </noscript>
</div><link rel="stylesheet" href="/liudongdong1.github.io/lib/katex/katex.min.css"><link rel="stylesheet" href="/liudongdong1.github.io/lib/cookieconsent/cookieconsent.min.css"><script src="/liudongdong1.github.io/lib/autocomplete/autocomplete.min.js" defer></script><script src="/liudongdong1.github.io/lib/algoliasearch/algoliasearch-lite.umd.min.js" defer></script><script src="/liudongdong1.github.io/lib/lazysizes/lazysizes.min.js" async defer></script><script src="/liudongdong1.github.io/lib/sharer/sharer.min.js" async defer></script><script src="/liudongdong1.github.io/lib/typeit/index.umd.js" defer></script><script src="/liudongdong1.github.io/lib/katex/katex.min.js" defer></script><script src="/liudongdong1.github.io/lib/katex/auto-render.min.js" defer></script><script src="/liudongdong1.github.io/lib/katex/copy-tex.min.js" defer></script><script src="/liudongdong1.github.io/lib/katex/mhchem.min.js" defer></script><script src="/liudongdong1.github.io/lib/cookieconsent/cookieconsent.min.js" defer></script><script src="/liudongdong1.github.io/lib/pangu/pangu.min.js" defer></script><script src="/liudongdong1.github.io/lib/cell-watermark/watermark.min.js" defer></script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async defer></script><script>window.config={"code":{"copyTitle":"复制到剪贴板","editLockTitle":"锁定可编辑代码块","editUnLockTitle":"解锁可编辑代码块","editable":true,"maxShownLines":10},"comment":{"enable":false},"cookieconsent":{"content":{"dismiss":"同意","link":"了解更多","message":"本网站使用 Cookies 来改善您的浏览体验。"},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"data":{"typeit-header-subtitle-desktop":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e","typeit-header-subtitle-mobile":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e"},"enablePWA":true,"enablePangu":true,"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"2R1K9SKLQZ","algoliaIndex":"index.zh-cn","algoliaSearchKey":"4a226aa1c5c98d6859e4d1386adb2bc7","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"},"siteTime":"2020-12-18T16:15:22+08:00","typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"typeit-header-subtitle-desktop":["typeit-header-subtitle-desktop"],"typeit-header-subtitle-mobile":["typeit-header-subtitle-mobile"]},"duration":-1,"speed":100},"watermark":{"appendto":".wrapper\u003emain","colspacing":30,"content":"\u003cimg class=\"fixit-icon\" src=\"/fixit.min.svg\" alt=\"FixIt logo\" /\u003e FixIt 主题","enable":true,"fontfamily":"inherit","fontsize":0.85,"height":21,"opacity":0.0125,"rotate":15,"rowspacing":60,"width":150}};</script><script src="/liudongdong1.github.io/js/theme.min.js" defer></script><script src="/liudongdong1.github.io/js/custom.min.js" defer></script></body>
</html>
