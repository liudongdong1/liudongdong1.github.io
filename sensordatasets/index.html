<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <head>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>SensorDatasets - DAY By DAY</title><meta name="author" content="LiuDongdong">
<meta name="author-link" content="https://liudongdong1.github.io/">
<meta name="description" content="1. 加速度 1.1. UCI dataset 来源于UCI（即UC Irvine，加州大学欧文分校）。数据由年龄在19-48岁之间的30位志愿者，智能手机固定于他们的腰部，执" /><meta name="keywords" content='Dataset' /><meta itemprop="name" content="SensorDatasets">
<meta itemprop="description" content="1. 加速度 1.1. UCI dataset 来源于UCI（即UC Irvine，加州大学欧文分校）。数据由年龄在19-48岁之间的30位志愿者，智能手机固定于他们的腰部，执"><meta itemprop="datePublished" content="2020-11-24T16:00:04+00:00" />
<meta itemprop="dateModified" content="2023-12-31T14:03:43+08:00" />
<meta itemprop="wordCount" content="7030"><meta itemprop="image" content="https://liudongdong1.github.io/logo.png"/>
<meta itemprop="keywords" content="Dataset," /><meta property="og:title" content="SensorDatasets" />
<meta property="og:description" content="1. 加速度 1.1. UCI dataset 来源于UCI（即UC Irvine，加州大学欧文分校）。数据由年龄在19-48岁之间的30位志愿者，智能手机固定于他们的腰部，执" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://liudongdong1.github.io/sensordatasets/" /><meta property="og:image" content="https://liudongdong1.github.io/logo.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-11-24T16:00:04+00:00" />
<meta property="article:modified_time" content="2023-12-31T14:03:43+08:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://liudongdong1.github.io/logo.png"/>

<meta name="twitter:title" content="SensorDatasets"/>
<meta name="twitter:description" content="1. 加速度 1.1. UCI dataset 来源于UCI（即UC Irvine，加州大学欧文分校）。数据由年龄在19-48岁之间的30位志愿者，智能手机固定于他们的腰部，执"/>
<meta name="application-name" content="DAY By DAY">
<meta name="apple-mobile-web-app-title" content="DAY By DAY"><meta name="theme-color" data-light="#f8f8f8" data-dark="#252627" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://liudongdong1.github.io/sensordatasets/" /><link rel="prev" href="https://liudongdong1.github.io/tools_butterknite/" /><link rel="next" href="https://liudongdong1.github.io/objectdetection/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "SensorDatasets",
    "inLanguage": "zh-CN",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https:\/\/liudongdong1.github.io\/sensordatasets\/"
    },"genre": "posts","keywords": "Dataset","wordcount":  7030 ,
    "url": "https:\/\/liudongdong1.github.io\/sensordatasets\/","datePublished": "2020-11-24T16:00:04+00:00","dateModified": "2023-12-31T14:03:43+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
      "@type": "Organization",
      "name": "LiuDongdong","logo": "https:\/\/liudongdong1.github.io\/images\/person.png"},"author": {
        "@type": "Person",
        "name": "liudongdong1"
      },"description": ""
  }
  </script></head>
  <body data-header-desktop="auto" data-header-mobile="auto"><script>(window.localStorage?.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('data-theme', 'dark');</script><div class="wrapper"><script type="text/javascript"
        async
        src="https://cdnjs.cloudflare.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>
<header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper" data-github-corner="right">
    <div class="header-title">
      <a href="/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="DAY By DAY"
    title="DAY By DAY"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-desktop" class="typeit header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a
                class="menu-link"
                href="/posts/"
                
                
              ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/categories/"
                
                
              ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/tags/"
                
                
              ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/friends/"
                title="友情链接"
                
              ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/about/"
                
                
              ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li class="menu-item delimiter"></li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <ul class="sub-menu"><li class="menu-item">没有更多翻译</li></ul>
          </li><li class="menu-item search" id="search-desktop">
            <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-desktop">
            <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
              <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
            </a>
            <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
              <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
            </a>
            <span class="search-button search-loading" id="search-loading-desktop">
              <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
            </span>
          </li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li>
      </ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="/fixit.min.svg"
    title="/fixit.min.svg"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-mobile" class="typeit header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li class="search-wrapper">
            <div class="search mobile" id="search-mobile">
              <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-mobile">
              <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
              </a>
              <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
              </a>
              <span class="search-button search-loading" id="search-loading-mobile">
                <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
              </span>
            </div>
            <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
              取消
            </a>
          </li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/posts/"
                  
                  
                ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/categories/"
                  
                  
                ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/tags/"
                  
                  
                ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/friends/"
                  title="友情链接"
                  
                ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/about/"
                  
                  
                ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li
              class="menu-item text-center"
            ><a
                  class="menu-link"
                  href="/"
                  title="GitHub"
                  
                ><i class='fa-brands fa-github fa-fw' aria-hidden='true'></i> </a></li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <select class="language-select" onchange="location = this.value;"><option disabled>没有更多翻译</option></select>
          </li></ul>
    </nav>
  </div>
</header><div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
  </div>
  <div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
  </div><main class="container" data-page-style="normal"><aside class="toc" id="toc-auto"><h2 class="toc-title">目录 <i class="toc-icon fa-solid fa-angle-down fa-fw"></i></h2>
      <div class="toc-content" id="toc-content-auto"></div></aside>

  <aside class="aside-custom" id="aside-sakana">
    

<div class="sakana-widget">
  <div class="sakana-item" id="takina-widget"></div>
  <div class="sakana-item" id="chisato-widget"></div>
</div>
<script>
  function initSakanaWidget() {
    const takina = SakanaWidget.getCharacter('takina')
    SakanaWidget.registerCharacter('takina-slow', takina);
    new SakanaWidget({
      character: 'takina-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#takina-widget');

    const chisato = SakanaWidget.getCharacter('chisato')
    SakanaWidget.registerCharacter('chisato-slow', chisato);
    new SakanaWidget({
      character: 'chisato-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#chisato-widget');
  }
</script>
<script async onload="initSakanaWidget()" src="https://cdn.jsdelivr.net/npm/sakana-widget@2.3.0/lib/sakana.min.js">
</script></aside>

  <article class="page single">
    <div class="header"><h1 class="single-title animate__animated animate__flipInX">
        <span>SensorDatasets</span>
      </h1></div><div class="post-meta">
      <div class="post-meta-line"><span class="post-author"><span class="author"><i class="fa-solid fa-user-circle" aria-hidden="true"></i>
      liudongdong1</span></span>
          <span class="post-category">收录于 <a href="/categories/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;Categories</a>&ensp;<a href="/categories/aiot/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;AIOT</a></span></div>
      <div class="post-meta-line"><span title=2020-11-24&#32;16:00:04>
            <i class="fa-regular fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2020-11-24" >2020-11-24</time>
          </span>&nbsp;<i class="fa-solid fa-pencil-alt fa-fw"></i>&nbsp;约 7030 字&nbsp;
        <i class="fa-regular fa-clock fa-fw"></i>&nbsp;预计阅读 15 分钟&nbsp;<span id="busuanzi_container_page_pv" class="busuanzi_visitors comment-visitors" data-flag-title="SensorDatasets">
            <i class="fa-regular fa-eye fa-fw"></i>&nbsp;<span id="busuanzi_value_page_pv">-</span>&nbsp;次阅读
          </span>&nbsp;</div>
    </div><div class="featured-image"><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/sunset-background-lighting-at-dusk-sky-evening-sky.jpg"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/sunset-background-lighting-at-dusk-sky-evening-sky.jpg, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/sunset-background-lighting-at-dusk-sky-evening-sky.jpg 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/sunset-background-lighting-at-dusk-sky-evening-sky.jpg 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/sunset-background-lighting-at-dusk-sky-evening-sky.jpg"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/sunset-background-lighting-at-dusk-sky-evening-sky.jpg"/></div><div class="details toc" id="toc-static" kept="true">
        <div class="details-summary toc-title">
          <span>目录</span>
          <span><i class="details-icon fa-solid fa-angle-right"></i></span>
        </div>
        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#1-加速度">1. 加速度</a>
      <ul>
        <li><a href="#11-uci-datasethttpsarchiveicsuciedumldatasetshumanactivityrecognitionusingsmartphones">1.1. <a href="https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones">UCI dataset</a></a></li>
        <li><a href="#12-coremotion">1.2. CoreMotion</a></li>
      </ul>
    </li>
    <li><a href="#2-姿态求解">2. 姿态求解</a>
      <ul>
        <li><a href="#21-ahrshttpsx-iocoukopen-source-imu-and-ahrs-algorithms">2.1. <a href="https://x-io.co.uk/open-source-imu-and-ahrs-algorithms/">AHRS</a></a></li>
      </ul>
    </li>
    <li><a href="#3--相关adr论文">3.  相关ADR论文</a>
      <ul>
        <li><a href="#32-位置相关识别">3.2. 位置相关识别</a></li>
        <li><a href="#33-迁移">3.3. 迁移</a></li>
        <li><a href="#34-others">3.4. others</a></li>
      </ul>
    </li>
    <li><a href="#4--har-datasetshttpsgithubcomjindongwangactivityrecognitionblobmasternotesdataset20descriptionmd">4.  <a href="https://github.com/jindongwang/activityrecognition/blob/master/notes/dataset%20description.md">HAR datasets</a></a></li>
    <li><a href="#5-资源链接">5. 资源链接</a>
      <ul>
        <li><a href="#heading"></a></li>
      </ul>
    </li>
  </ul>
</nav></div>
      </div><div
      class="content"
      id="content"
      
      
    ><h2 id="1-加速度">1. 加速度</h2>
<h3 id="11-uci-datasethttpsarchiveicsuciedumldatasetshumanactivityrecognitionusingsmartphones">1.1. <a href="https://archive.ics.uci.edu/ml/datasets/human&#43;activity&#43;recognition&#43;using&#43;smartphones"target="_blank" rel="external nofollow noopener noreferrer">UCI dataset<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></h3>
<blockquote>
<p>来源于UCI（即UC Irvine，加州大学欧文分校）。数据由年龄在19-48岁之间的30位志愿者，<code>智能手机固定于他们的腰部，执行六项动作，即行走、上楼梯、下楼梯、坐、站立、躺下</code>，同时在手机中存储传感器（加速度传感器和陀螺仪）的三维（XYZ轴）数据。传感器的频率被设置为<code>50HZ</code>（即每秒50次记录）。对于所输出传感器的维度数据，进行噪声过滤（Noise Filter），<code>以2.56秒的固定窗口滑动，同时窗口之间包含50%的重叠</code>，即每个窗口的数据维度是128（2.56*50）维，根据不同的运动类别，将数据进行标注。传感器含有三类：身体（Body）的加速度传感器、整体（Total）的加速度传感器、陀螺仪。</p>
</blockquote>
<ul>
<li>
<p><a href="https://www.cis.fordham.edu/wisdm/dataset.php"target="_blank" rel="external nofollow noopener noreferrer">下载链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> <a href="https://archive.ics.uci.edu/ml/machine-learning-databases/00240/"target="_blank" rel="external nofollow noopener noreferrer">https://archive.ics.uci.edu/ml/machine-learning-databases/00240/<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</li>
<li>
<p><a href="https://github.com/linw7/Activity-Recognition"target="_blank" rel="external nofollow noopener noreferrer">识别代码<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</li>
</ul>
<h3 id="12-coremotion">1.2. CoreMotion</h3>
<ul>
<li>
<p>功能：</p>
<ul>
<li>通过测量三个轴的加速度大小来判断人体运动</li>
<li>通过测量设备周围地磁场的强度和方向来判断朝向</li>
<li>通过测量三个轴的旋转速率来判断朝向</li>
<li>无须物理接触就判断附近物体的存在</li>
</ul>
</li>
<li>
<p>主要局限性</p>
<ul>
<li>受重力干扰大，瞬时误差大</li>
<li>误差大， 容易受其他磁场和金属物体影响。主要用于校正其他设备</li>
<li>误差会累积，长时间读数的准确性差</li>
<li>不通用，大多数只针对几种材质</li>
</ul>
</li>
<li>
<p><a href="https://github.com/jindongwang/activityrecognition/tree/master/code"target="_blank" rel="external nofollow noopener noreferrer">特征提取<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>：</p>
<ul>
<li>滑动窗口： 窗口大小，滑动步长</li>
<li>合成加速度： 常规采集的都是三个方向的加速度，在处理过程中，会用到三轴加速度合成一个加速度(为了减少计算性)</li>
<li>时域特征： 均值，标准差，众数，MAX/MIN, Range，相关系数，信号幅值面积SMA,过零点个数，最大值与最小值之差，众数</li>
<li>频域特征：  直流分量，幅度，功率谱密度PSD, 图形的均值、方差、标准差、斜度、峭度，幅度的均值、方差、标准差、斜度</li>
</ul>
</li>
</ul>
<h2 id="2-姿态求解">2. 姿态求解</h2>
<h3 id="21-ahrshttpsx-iocoukopen-source-imu-and-ahrs-algorithms">2.1. <a href="https://x-io.co.uk/open-source-imu-and-ahrs-algorithms/"target="_blank" rel="external nofollow noopener noreferrer">AHRS<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></h3>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201125155901178.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201125155901178.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201125155901178.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201125155901178.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201125155901178.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201125155901178.png"/></p>
<h2 id="3--相关adr论文">3.  相关ADR论文</h2>
<table>
<thead>
<tr>
<th>题目</th>
<th>目的</th>
<th>传感器</th>
<th>算法</th>
<th>会议</th>
<th>年份</th>
<th>引用</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Quantitative study of music listening behavior in a social and affective context</td>
<td>推测用户听音乐的行为</td>
<td>加速度计、磁力计、方向感应计、旋转感应计、光感应器、距离感应器、位置感应</td>
<td>SVM,Open Sensing Framework</td>
<td>ACM Transactions on Interactive Intelligent Systems</td>
<td>2015</td>
<td>Yang Y H, Liu J Y. Quantitative study of music listening behavior in a social and affective context[J]. Multimedia, IEEE Transactions on, 2013, 15(6): 1304-1315.</td>
</tr>
<tr>
<td>2</td>
<td>Predicting User Traits From a Snapshot of Apps Installed on a Smartphone</td>
<td>通过手机上装的应用推测用户的特征（宗教、关系、语言。。。）</td>
<td>手机屏幕</td>
<td>SVM</td>
<td>Mobile Computing and Communications Review</td>
<td>2014</td>
<td>Seneviratne S, Seneviratne A, Mohapatra P, et al. Predicting user traits from a snapshot of apps installed on a smartphone[J]. ACM SIGMOBILE Mobile Computing and Communications Review, 2014, 18(2): 1-8.</td>
</tr>
<tr>
<td>3</td>
<td>Understanding in-car smartphone usage pattern with an un-obfuscated observation</td>
<td>挖掘用户在开车时使用手机的习惯</td>
<td>无</td>
<td>频繁模式挖掘</td>
<td>CHI</td>
<td>2014</td>
<td>Oh C, Lee J. Understanding in-car smartphone usage pattern with an un-obfuscated observation[C]//CHI'14 Extended Abstracts on Human Factors in Computing Systems. ACM, 2014: 1795-1800.</td>
</tr>
<tr>
<td>4</td>
<td>Preference, context and communities: a multi-faceted approach to predicting smartphone app usage patterns</td>
<td>通过挖掘手机的使用特征看用户使用手机的习惯</td>
<td>手机本身</td>
<td>NNC</td>
<td>ISWC</td>
<td>2013</td>
<td>Xu Y, Lin M, Lu H, et al. Preference, context and communities: a multi-faceted approach to predicting smartphone app usage patterns[C]//Proceedings of the 2013 International Symposium on Wearable Computers. ACM, 2013: 69-76.</td>
</tr>
<tr>
<td>5</td>
<td>Driving Behavior Analysis for Smartphone-based Insurance Telematics</td>
<td>通过手机来判断车内的用户行为</td>
<td>加速度计、陀螺仪</td>
<td>无</td>
<td>WPA</td>
<td>2015</td>
<td>Wahlstr?m J, Skog I, H?ndel P. Driving Behavior Analysis for Smartphone-based Insurance Telematics[C]//Proceedings of the 2nd workshop on Workshop on Physical Analytics. ACM, 2015: 19-24.</td>
</tr>
<tr>
<td>6</td>
<td>My Smartphone Knows I am Hungry</td>
<td>在手机上装studentlife应用来收集用户的信息，通过推测的用户购买行为和位置行为为推测用户什么时候吃饭</td>
<td>加速度计、距离感应、光感应、麦克风、位置、应用使用情况</td>
<td>决策树</td>
<td>WPA</td>
<td>2014</td>
<td>Chen F, Wang R, Zhou X, et al. My smartphone knows i am hungry[C]//Proceedings of the 2014 workshop on physical analytics. ACM, 2014: 9-14.</td>
</tr>
<tr>
<td>7</td>
<td>MoodScope: Building a Mood Sensor from smartphone usage patterns</td>
<td>通过统计应用使用情况分析用户使用手机的情绪</td>
<td>应用使用情况</td>
<td>线性回归</td>
<td>MobiSys</td>
<td>2013</td>
<td>LiKamWa R, Liu Y, Lane N D, et al. Moodscope: Building a mood sensor from smartphone usage patterns[C]//Proceeding of the 11th annual international conference on Mobile systems, applications, and services. ACM, 2013: 389-402.</td>
</tr>
<tr>
<td>8</td>
<td>A smartphone based method to enhance road pavement anomaly detection by analyzing the driver behavior</td>
<td>用手机的传感器识别车内用户的行为来检测行车的异常</td>
<td>加速度计</td>
<td>na</td>
<td>ISWC</td>
<td>2015</td>
<td>SERAJ F, ZHANG K, TURKES O, MERATNIA N, HAVINGA P J M，. A smartphone based method to enhance road pavement anomaly detection by analyzing the driver behavior[C]//ACM Press, 2015: 1169�1177.</td>
</tr>
<tr>
<td>9</td>
<td>A smartphone-based sensing platform to model aggressive driving behaviors</td>
<td>用手机的传感器侦测有过激行为的开车行为</td>
<td>加速度计</td>
<td>朴素贝叶斯</td>
<td>CHI</td>
<td>2014</td>
<td>Jin-Hyuk Hong, Ben Margines, and Anind K. Dey. 2014. A smartphone-based sensing platform to model aggressive driving behaviors. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI &lsquo;14). ACM, New York, NY, USA, 4047-4056</td>
</tr>
<tr>
<td>10</td>
<td>DOWELL: Dwell-time Based Smartphone Control Solution for People with Upper Limb Disabilities</td>
<td>智能手机界面辅助上肢残疾的人进行界面操作</td>
<td>无</td>
<td>无</td>
<td>CHI</td>
<td>2015</td>
<td>Ahn H, Yoon J, Chung G, et al. DOWELL: Dwell-time Based Smartphone Control Solution for People with Upper Limb Disabilities[C]//Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems. ACM, 2015: 887-892.</td>
</tr>
<tr>
<td>11</td>
<td>Estimating heart rate variation during walking with smartphone</td>
<td>通过手机加速度计来判断心跳</td>
<td>加速度计</td>
<td>神经网络</td>
<td>Ubicomp</td>
<td>2013</td>
<td>Sumida M, Mizumoto T, Yasumoto K. Estimating heart rate variation during walking with smartphone[C]//Proceedings of the 2013 ACM international joint conference on Pervasive and ubiquitous computing. ACM, 2013: 245-254.</td>
</tr>
<tr>
<td>12</td>
<td>Evaluating tooth brushing performance with smartphone sound data</td>
<td>用手机中的麦克风录音来分析刷牙的动作标准程度并给出预测</td>
<td>麦克风</td>
<td>HMM</td>
<td>Ubicomp</td>
<td>2015</td>
<td>KORPELA J, MIYAJI R, MAEKAWA T, NOZAKI K, TAMAGAWA H，. Evaluating tooth brushing performance with smartphone sound data[C]//ACM Press, 2015: 109�120.</td>
</tr>
<tr>
<td>13</td>
<td>Oh app, where art thou?: on app launching habits of smartphone users</td>
<td>分析启动手机应用的习惯</td>
<td>无</td>
<td>无</td>
<td>MobileCHI</td>
<td>2013</td>
<td>HANG A, DE LUCA A, HARTMANN J, HUSSMANN H，. Oh app, where art thou?: on app launching habits of smartphone users[C]//ACM Press, 2013: 392.</td>
</tr>
<tr>
<td>14</td>
<td>Smartphone-based monitoring system for activities of daily living for elderly people and their relatives etc.</td>
<td>通过手机记录老人的行动log反馈给亲属</td>
<td>加速度计、GPS、麦克风</td>
<td>无</td>
<td>Ubicomp</td>
<td>2013</td>
<td>OUCHI K, DOI M，. Smartphone-based monitoring system for activities of daily living for elderly people and their relatives etc.[C]//ACM Press, 2013: 103�106.</td>
</tr>
</tbody>
</table>
<h3 id="32-位置相关识别">3.2. 位置相关识别</h3>
<table>
<thead>
<tr>
<th>序号</th>
<th>方法</th>
<th>传感器</th>
<th>位置</th>
<th>方法与数据</th>
<th>引文</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>用6个eWatch放在不同的6个位置，只是用了不同位置的传感器来组合识别行为，并没有迁移，效果很好</td>
<td>2轴加速度、光感</td>
<td>左手，要带，脖子，右裤口袋，上衣口袋，包</td>
<td>6个人，6种行为，KNN等4种</td>
<td>Maurer U, Smailagic A, Siewiorek D P, et al. Activity recognition and monitoring using multiple sensors on different body positions[C]//International Workshop on Wearable and Implantable Body Sensor Networks (BSN'06). IEEE, 2006: 4 pp.-116.</td>
</tr>
<tr>
<td>2</td>
<td>通过手机放在口袋里不同位置和不同朝向来识别行为，用的是SVM。没有进行迁移，只是用了不同位置单独的数据，以及组合。</td>
<td>加速度</td>
<td>口袋的6个位置</td>
<td>SVM，7个人，7种行为</td>
<td>Sun L, Zhang D, Li B, et al. Activity recognition on an accelerometer embedded mobile phone with varying positions and orientations [C]//International Conference on Ubiquitous Intelligence and Computing. Springer Berlin Heidelberg, 2010: 548-562.</td>
</tr>
<tr>
<td>3</td>
<td>不同的传感器位置对行为识别影响很大，文章设计了基于LDA的方法，对位置鲁棒。没有涉及到位置迁移识别。</td>
<td>加速度</td>
<td>口袋的5个位置</td>
<td>LDA，7种行为</td>
<td>Khan A M, Lee Y K, Lee S, et al. Accelerometer’s position independent physical activity recognition system for long-term activity monitoring in the elderly[J]. Medical &amp; biological engineering &amp; computing, 2010, 48(12): 1271-1279.</td>
</tr>
<tr>
<td>4</td>
<td>加速度</td>
<td></td>
<td>有研究检测最优的行为检测位置；目前的研究倾向于研究最优的放置位置</td>
<td></td>
<td>Lara O D, Labrador M A. A survey on human activity recognition using wearable sensors[J]. IEEE Communications Surveys &amp; Tutorials, 2013, 15(3): 1192-1209.</td>
</tr>
<tr>
<td>5</td>
<td>稳重指出目前尚未有研究来说明传感器的最优位置对行为识别的影响。文章主要是在不同的位置放了传感器，来看对高层行为、低层行为、过度行为等的识别率，从中分析出哪些地方可能对哪些行为有特定的精度，不是迁移。</td>
<td>加速度</td>
<td></td>
<td>15种行为，7个人</td>
<td>Atallah L, Lo B, King R, et al. Sensor positioning for activity recognition using wearable accelerometers[J]. IEEE transactions on biomedical circuits and systems, 2011, 5(4): 320-329.</td>
</tr>
<tr>
<td>6</td>
<td>recognizes actions by measuring the circumference of body parts。用了柔性材料的衣服，布满传感器，通过测量衣服的形变与肢体的圆周关系来识别行为。</td>
<td>加速度</td>
<td>Wrist，waist，ankle</td>
<td>识别率很高</td>
<td>Tsubaki K, Terada T, Tsukamoto M. An Activity Recognition Method by Measuring Circumference of Body Parts[C]//Proceedings of the 7th Augmented Human International Conference 2016. ACM, 2016: 13.</td>
</tr>
<tr>
<td>7</td>
<td>识别传感器在身体的不同位置，同时提出了位置无关的行为识别算法。没有涉及到迁移。</td>
<td>加速度</td>
<td>7个：head, chest, upper arm, waist, forearm, thigh, and shin</td>
<td>8种行为，15个人，数据集公开</td>
<td>Sztyler T, Stuckenschmidt H. On-body localization of wearable devices: An investigation of position-aware activity recognition[C]//2016 IEEE International Conference on Pervasive Computing and Communications (PerCom). IEEE, 2016: 1-9.</td>
</tr>
<tr>
<td>8</td>
<td>先识别不同位置，然后再进行行为识别，精度还可以.对行为进行分组，根据相似性进行分组</td>
<td>加速度</td>
<td>4个：hand, coat pocket, trouser pocket and the rear pocket</td>
<td>几种日常行为</td>
<td>Guo Q, Liu B, Chen C W. A two-layer and multi-strategy framework for human activity recognition using smartphone[C]//2016 IEEE International Conference on Communications (ICC). IEEE, 2016: 1-6.</td>
</tr>
<tr>
<td>9</td>
<td>通过实验看不同的位置对行为识别的影响度</td>
<td>加速度、陀螺仪</td>
<td>身体和躯干的几种不同位置</td>
<td></td>
<td>Kunze K, Lukowicz P. Sensor placement variations in wearable activity recognition[J]. IEEE Pervasive Computing, 2014, 13(4): 32-41.</td>
</tr>
</tbody>
</table>
<h3 id="33-迁移">3.3. 迁移</h3>
<table>
<thead>
<tr>
<th>编号</th>
<th>迁移方法</th>
<th>数据集</th>
<th>对比方法</th>
<th>实验方法</th>
<th>文章</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Adaptive Multiple Kernel Learning (A-MKL)加上SVM。用pyramid match算法，首先将两条视频的距离降到最短，然后用若干个kernel SVM去学习</td>
<td>(1) Kodak Consumer Video Benchmark Data(2) 从youtube上下载的部分web video</td>
<td>1.Adaptive-SVM，2.domain transfer SVM，3.multiple kernel learning</td>
<td>从第一部分video向第二部分迁移</td>
<td>Visual event recognition in videos by learning from web data</td>
</tr>
<tr>
<td>2</td>
<td>Importance weighted least-squares probabilistic classifier (IWLSPC)。一中基于adaptive采样的概率方法。Instance transfer【有源代码】</td>
<td>Alkan加速度数据集：由ipod touch收集，有手中的有口袋里的。计算时提取了与位置无关的特征（均值、方差等5个）.</td>
<td>LapRLS+CV LapRLS+IWCV KLR+CV IWKLR+IWCV LSPC+CV IWLSPC+IWCV</td>
<td>2000个labeled数据，800个无label数据</td>
<td>Importance weighted least-squares probabilistic classifier for covariate shiftAdaptation with application to human activity recognition</td>
</tr>
<tr>
<td>3</td>
<td>Cost sensitive的boosting方法。目标是，给定同分部和不同分布的样本，预测同分布的部分的精确度。</td>
<td>2轴加速度计，在实验室和家里分别收集5种手势。</td>
<td>AdaBoost，TrAdaBoost</td>
<td>把数据分成两个环境都有的几部分，然后根据现有的两种环境数据去预测其他的</td>
<td>Cost-sensitive Boosting for Concept Drift</td>
</tr>
<tr>
<td>4</td>
<td>TrAdaBoost：减少对不同分布数据的权重。解决问题：少量有label数据，分为同分布和不同分布的部分，去预测一个无label数据</td>
<td>新闻数据集3个</td>
<td>TSVM。SVM</td>
<td>不同的3个数据集之间迁移</td>
<td>Boosting for Transfer Learning</td>
</tr>
<tr>
<td>5</td>
<td>用可调整权重的SVM</td>
<td>Youtube的视频数据</td>
<td>用户评价参与度</td>
<td>分成两部分进行迁移，正常迁移</td>
<td>Interactive Event Search Through Transfer Learning</td>
</tr>
<tr>
<td>6</td>
<td>用两个不同domain的label信息的相似度去获取两个domain样本的相似度。Label信息相似度由web search获取。然后用一个加权SVM去做。</td>
<td>1. Amsterdam数据集（1个人生活，14个状态传感器）2. MIT PLIA13. Intel</td>
<td>没有方法对比，仅多做了MMD和余弦相似度的对比</td>
<td>每一个数据集中，一部分label迁移到另一部分label</td>
<td>Cross-Domain Activity Recognition</td>
</tr>
<tr>
<td>7</td>
<td>用基于HMM的迁移学习模型去做迁移。将两个房子的传感器进行映射，然后用EM算法去学习HMM的参数。</td>
<td>2个房子的数据</td>
<td>没有方法对比</td>
<td>一个迁移到另一个</td>
<td>Recognizing Activities in Multiple Contexts using Transfer Learning</td>
</tr>
<tr>
<td>8</td>
<td>可以对特征空间、特征分布、label空间的不同做迁移。用概率的方法，把问题分成两个部分。</td>
<td>1.MIT数据集，2。1个人房子数据</td>
<td>对比了不同参数下的精度</td>
<td>一个迁移到另一个</td>
<td>Transfer Learning for Activity Recognition via Sensor Mapping</td>
</tr>
<tr>
<td>9</td>
<td>用二部图的匹配进行迁移，挖掘图像的高层特征，这些特征可以被共享。</td>
<td>图像数据IXMAS多视角数据</td>
<td>不同的其他三种cross view方法</td>
<td>一个视角迁移到另一个</td>
<td>Cross-View Action Recognition via View Knowledge Transfer</td>
</tr>
<tr>
<td>10</td>
<td>针对特征分布不一样的问题，用特征迁移，不需要label，把两部分映射到一个重构希尔伯特空间中最小化两都之间的距离</td>
<td>Wifi定位</td>
<td>KPCA、KMM</td>
<td>不同的设置相互迁移</td>
<td>Domain adaptation via transfer component analysis</td>
</tr>
<tr>
<td>11</td>
<td>用ISOMAP，将source和target降维到同样的空间，然后选择置信度最高的标签进行</td>
<td>SEMG数据</td>
<td>KE、TCA、LWE</td>
<td>SEMG数据的迁移</td>
<td>Topology Preserving Domain Adaptation for Addressing Subject Based Variability in SEMG Signal</td>
</tr>
<tr>
<td>12</td>
<td>用了层次化的复杂行为感知。先感知低层次的行为，做准确识别，然后将这些低层次行为进行组合，识别高层的行为。与HMM结合。</td>
<td>1.BookShelf数据，人身上安装3个传感器进行安装书架，2.Mirror数据</td>
<td>在bookshelf中识别简单子行为，在mirror数据进行迁移复杂行为</td>
<td>没有对比</td>
<td>Remember and Transfer what you have Learned �Recognizing Composite Activities based on Activity Spotting</td>
</tr>
<tr>
<td>13</td>
<td>用HMM算法来做迁移。迁移的是meta-feature</td>
<td>3个房间的生活数据</td>
<td>不同的房间相互迁移</td>
<td>Meta-feature和sensor-feature的对比、迁移与不迁移的对比</td>
<td>Transferring Knowledge of Activity Recognition across Sensor Networks</td>
</tr>
<tr>
<td>14</td>
<td>把行为建模成传感器、时间、空间模型，然后进行source和target中传感器的映射</td>
<td>3个房间的数据</td>
<td>不同的房间相互迁移</td>
<td>不同数量的target data标记的对比</td>
<td>Activity Recognition Based on Home to Home Transfer Learning</td>
</tr>
<tr>
<td>15</td>
<td>多类SVM进行迁移</td>
<td>几个房间不同人动作的数据视频</td>
<td>不同camera相互迁移</td>
<td>不同增量数量的对比</td>
<td>Transferring Activities: Updating Human Behavior Analysis</td>
</tr>
<tr>
<td>16</td>
<td>第1步：用label数据训练一个模型,第2步：用这个模型去分类unlabeled数据，第3步：用这些数据反过来调整模型a，使得其适应unlabeled数据，形成模型b，对B进行下采样，用A进行预测，有了标签之后进行聚类，就有了label</td>
<td>不同手机的数据</td>
<td>不同采样率</td>
<td>不同采样率</td>
<td>Cross-mobile ELM based Activity Recognition</td>
</tr>
<tr>
<td>17</td>
<td>用了一个决策树先对第一个人训练一个模型，然后识别第二个人，进行聚类</td>
<td>10个人用同样的手机</td>
<td>SVM、NB</td>
<td>不同人之间</td>
<td>Cross-People Mobile-Phone Based Activity Recognition</td>
</tr>
<tr>
<td>18</td>
<td>针对源和目标都无label的情况，利用彼此之间的知识训练3个聚类算法，精度很不错</td>
<td>图像数据</td>
<td>Co-clustering</td>
<td>不同图像</td>
<td>Self-taught clustering</td>
</tr>
<tr>
<td>19</td>
<td>从无label数据中自学习</td>
<td>图像、文本等</td>
<td>PCA</td>
<td>不同域之间</td>
<td>Self-taught Learning: Transfer Learning from Unlabeled Data</td>
</tr>
<tr>
<td>20</td>
<td>无监督的迁移降维方法</td>
<td>人脸识别</td>
<td>LWF，PCA，LPP，DisKmeans</td>
<td>不同人脸之间</td>
<td>Transferred Dimensionality Reduction</td>
</tr>
<tr>
<td>21</td>
<td>用markov logic进行迁移，属于关系之间的迁移</td>
<td>蛋白质和社交网络</td>
<td>几种不同的参数设置</td>
<td>不同数据集之间</td>
<td>Deep Transfer via Second-Order Markov Logic</td>
</tr>
<tr>
<td>22</td>
<td>用构造方法对新来传感器迁移已经学习到的模型</td>
<td>自己采集的动作数据</td>
<td>KNN、SVM</td>
<td>新来的传感器</td>
<td>Automatic transfer of activity recognition capabilities between body-worn motion sensors: training newcomers to recognize locomotion</td>
</tr>
<tr>
<td>23</td>
<td>用GMM对数据进行建模，然后进行GMM参数的迁移</td>
<td>图像数据集</td>
<td>一些已有的方法</td>
<td>不同数据集之间</td>
<td>Cross-Dataset Action Detection</td>
</tr>
<tr>
<td>24</td>
<td>用EM和CRF做迁移</td>
<td>生理数据辅助进行行为识别</td>
<td>一些已有的基于CRF的方法</td>
<td>不同数据之间</td>
<td>Activity Recognition from Physiological Data using Conditional Random Fields</td>
</tr>
<tr>
<td>25</td>
<td>用的RBM，不同的特征空间进行迁移</td>
<td>行为数据和文本数据</td>
<td>SCL</td>
<td>文本数据辅助行为识别</td>
<td>Heterogeneous Transfer Learning with RBMs</td>
</tr>
<tr>
<td>26</td>
<td>用了NB和SVM混合，对new user有比较好的预测精度。</td>
<td>自己收集的28个人数据</td>
<td>NB、SVM</td>
<td>新来人的行为预测</td>
<td>Hong J H, Ramos J, Dey A K. Toward Personalized Activity Recognition Systems With a Semipopulation Approach[J]. IEEE Transactions on Human-Machine Systems, 2016, 46(1): 101-112.</td>
</tr>
<tr>
<td>27</td>
<td>深度迁移学习方面的第一篇文章</td>
<td>OPP、Skoda</td>
<td>无</td>
<td><code>不同用户、不同设备、不同位置等</code>行为预测</td>
<td>Morales F J O, Roggen D. Deep convolutional feature transfer across mobile activity recognition domains, sensor modalities and locations[C]//Proceedings of the 2016 ACM International Symposium on Wearable Computers. ACM, 2016: 92-99.</td>
</tr>
</tbody>
</table>
<h3 id="34-others">3.4. others</h3>
<ol>
<li><a href="https://mega.nz/#!hegygZwL!l25twe-8Krjl-6QxAKtpMxiInO4issQhtuvyeZguQA0"target="_blank" rel="external nofollow noopener noreferrer">A Class Incremental Extreme Learning Machine for Activity Recognition<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> 提出一种类增量ELM算法，算法可以学习新出现的行为类别。</li>
<li><a href="https://mega.nz/#!cXAjEAyY!Pcu1oqClxnPnP8qsT6Y-8EOsgfR3Y-RwcUMxXQCOX6M"target="_blank" rel="external nofollow noopener noreferrer">A Framework for Wireless Sensor Network Based Mobile Mashup Applications<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> 提出一种框架，包含无线传感器、智能手机作为网关以及服务器三者组成的通用的采集提取传感器数据的框架。</li>
<li><a href="https://mega.nz/#!5eZwBLLC!5qenQvSzf7u7-_-N9p8WWaeZlER1pIKKYz0lt1QIUM4"target="_blank" rel="external nofollow noopener noreferrer">A MOBILE DEVICE ORIENTED FRAMEWORK FOR CONTEXT INFORMATION MANAGEMENT<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> 提出一种智能手机为中心的管理传感器网络上下文的框架</li>
<li><a href="https://mega.nz/#!AbYnCRQY!20tk8gbG1zbl1vRSOiSJVKJswAZscSFZ2AziEEE8hEU"target="_blank" rel="external nofollow noopener noreferrer">A Nonintrusive and Single-Point Infrastructure-Mediated Sensing Approach for Water-Use Activity Recognition<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> 通过在水管表面加装三轴加速度计来检测用户的用水行为（Bathing, Flushing toilet, Cooking and Washing）</li>
<li><a href="https://mega.nz/#!MP5F1AwC!n7N0YZvULU5x1CMn4YnbsfWRev-KctpGJFULJEc_qlQ"target="_blank" rel="external nofollow noopener noreferrer">PPCare: A Personal and Pervasive Health Care System for the Elderly<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> 提出PPCare手机软件，检测老人行为，包括四大块：<code>运动，卡路里消耗，跌倒检测，身体指数追踪</code></li>
<li><a href="https://mega.nz/#!BDIxxaKD!jHsw_3Zg7sjGtECRBcjNlJIuNnvHJvmDcvmYtsKsuBI"target="_blank" rel="external nofollow noopener noreferrer">Wearable Accelerometer Based Extendable Activity Recognition System<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> 基于<code>加速度计的穿戴设备进行行为识别，能识别未知的行为</code>.</li>
<li><a href="https://mega.nz/#!EXID1YhB!ow8E1NRMSnGi53aUWauELhwhS2JWY3DUqRdG3WzAN58"target="_blank" rel="external nofollow noopener noreferrer">b-COELM: A fast, lightweight and accurate activity recognition model for mini-wearable devices<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> 提出一种<code>基于ELM的算法来用于mini穿戴设备的行为识别</code>，解决现有<code>设备运算量小</code>的问题。</li>
</ol>
<h2 id="4--har-datasetshttpsgithubcomjindongwangactivityrecognitionblobmasternotesdataset20descriptionmd">4.  <a href="https://github.com/jindongwang/activityrecognition/blob/master/notes/dataset%20description.md"target="_blank" rel="external nofollow noopener noreferrer">HAR datasets<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></h2>
<ul>
<li>
<p>1.Opportunity</p>
<ul>
<li><a href="https://archive.ics.uci.edu/ml/datasets/OPPORTUNITY&#43;Activity&#43;Recognition"target="_blank" rel="external nofollow noopener noreferrer">1.1网址与下载<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li>描述
<ul>
<li>数据集包括4个用户的6种大类（track）的将近100种行为： 这6个track及其行为是： Unique index - Track name - Label name;</li>
<li>一共使用了3大类传感器：惯性、物体传感器、环境传感器。</li>
<li>数据分为24个子文件，每个用户有6个文件，分别以S-0X开头。最后一个文件是drill，表示是用户按照预先要求的动作序列做出相应的动作。</li>
</ul>
</li>
<li>[1.3引用此数据集的文章](<a href="https://github.com/jindongwang/activityrecognition/blob/master/notes/dataset"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/jindongwang/activityrecognition/blob/master/notes/dataset<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> description.md#13引用此数据集的文章)</li>
</ul>
</li>
<li>
<p>2.UCI daily and sports dataset</p>
<ul>
<li>
<p><a href="http://archive.ics.uci.edu/ml/datasets/Daily&#43;and&#43;Sports&#43;Activities"target="_blank" rel="external nofollow noopener noreferrer">2.1网址与下载<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</li>
<li>
<p>2.2描述</p>
<p>（1）运动人数：8人(4 female, 4 male, between the ages 20 and 30)</p>
<p>（2）运动时间：5分钟/人</p>
<p>（3）行为类别：19种日常行为，分别用1-19这19个数据来表示</p>
<p>（4）数据尺寸：每人记录5分钟的总运动时长</p>
<p>（5）采样频率：25Hz</p>
<p>（6）传感器：三轴加速度计、三轴陀螺仪、三轴磁力计</p>
</li>
<li>
<p>[2.3引用此数据集的文章](<a href="https://github.com/jindongwang/activityrecognition/blob/master/notes/dataset"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/jindongwang/activityrecognition/blob/master/notes/dataset<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> description.md#23引用此数据集的文章)</p>
</li>
</ul>
</li>
<li>
<p>3.Activity recognition from single chest-mounted accelerometer data set</p>
<ul>
<li>[3.3引用此数据集的文章](<a href="https://github.com/jindongwang/activityrecognition/blob/master/notes/dataset"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/jindongwang/activityrecognition/blob/master/notes/dataset<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> description.md#33引用此数据集的文章)</li>
</ul>
</li>
<li>
<p>4.Gas sensors for home activity monitoring Data Set</p>
<ul>
<li>[4.1网址与下载](<a href="https://github.com/jindongwang/activityrecognition/blob/master/notes/dataset"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/jindongwang/activityrecognition/blob/master/notes/dataset<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> description.md#41网址与下载)</li>
<li>[4.2描述](<a href="https://github.com/jindongwang/activityrecognition/blob/master/notes/dataset"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/jindongwang/activityrecognition/blob/master/notes/dataset<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> description.md#42描述)</li>
<li>[4.3引用此数据集的文章](<a href="https://github.com/jindongwang/activityrecognition/blob/master/notes/dataset"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/jindongwang/activityrecognition/blob/master/notes/dataset<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> description.md#43引用此数据集的文章)</li>
</ul>
</li>
<li>
<p>5.Human activity recognition using smartphones data set</p>
<ul>
<li><a href="https://archive.ics.uci.edu/ml/datasets/Human&#43;Activity&#43;Recognition&#43;Using&#43;Smartphones"target="_blank" rel="external nofollow noopener noreferrer">5.1网址与下载<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
</ul>
</li>
</ul>
<blockquote>
<p>采样：30个人，年龄在19-48之间</p>
<p>活动类型：WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING</p>
<p>传感器：加速度传感器、陀螺仪</p>
<p>采样频率：50HZ</p>
<p>数据集：70%训练样本，30%测试样本</p>
<p>预处理：噪声滤波，滑动窗口（2.56sec，50%overlap），其中加速度传感器信号使用巴特沃斯低通滤波器（Butterworth low-pass filter）分离成身体加速度和重力。由于重力只有低频率成分,因此滤波器使用0.3HZ截止频率。在每个窗口,一个向量的特性是通过计算变量的时间和频率域得到的，共561个特征。</p>
<p>更新的数据集：Smartphone-Based Recognition of Human Activities and Postural Transitions Data Set，在这个数据集中作者在已有的六个活动基础上增加了stand-to-sit, sit-to-stand, sit-to-lie, lie-to-sit, stand-to-lie, and lie-to-stand.这些状态改变的样本，并且此数据集的数据为原始数据，而不是预处理后的数据。</p>
</blockquote>
<ul>
<li>6.Heterogeneity activity recognition data set
<ul>
<li><a href="https://archive.ics.uci.edu/ml/datasets/Heterogeneity&#43;Activity&#43;Recognition"target="_blank" rel="external nofollow noopener noreferrer">6.1网址与下载<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
</ul>
</li>
</ul>
<blockquote>
<p>样本数量：43930257</p>
<p>属性：16 Activities: ‘Biking’, ‘Sitting’, ‘Standing’, ‘Walking’, ‘Stair Up’ and ‘Stair down’.</p>
<p>Sensors: Sensors: Two embedded sensors, i.e., Accelerometer and Gyroscope, sampled at the highest frequency the respective device allows.</p>
<p>Devices: 4 smartwatches (2 LG watches, 2 Samsung Galaxy Gears)</p>
<p>8 smartphones (2 Samsung Galaxy S3 mini, 2 Samsung Galaxy S3, 2 LG Nexus 4, 2 Samsung Galaxy S+)</p>
<p>Recordings: 9 users</p>
<p>Activity recognition exp.zip包含了不同设备、不同传感器的行为数据</p>
<p>Still exp.zip增加了手机放置的位置，不同位置下包含了多种设备所采集的行为数据</p>
</blockquote>
<ul>
<li>
<p>7.chest-mounted accelerometer dataset</p>
<ul>
<li>
<p>加速度数据未校准,52hz, 7  labels;</p>
</li>
<li>
<p>1: Working at Computer</p>
<p>2: Standing Up, Walking and Going updown stairs</p>
<p>3: Standing</p>
<p>4: Walking</p>
<p>5: Going UpDown Stairs</p>
<p>6: Walking and Talking with Someone</p>
<p>7: Talking while Standing</p>
</li>
</ul>
</li>
<li>
<p>8.<a href="https://catalogue.data.govt.nz/dataset/fall-data"target="_blank" rel="external nofollow noopener noreferrer">https://catalogue.data.govt.nz/dataset/fall-data<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</li>
</ul>
<h2 id="5-资源链接">5. 资源链接</h2>
<ul>
<li><a href="https://github.com/jindongwang/activityrecognition/blob/master/notes/dataset%20description.md"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/jindongwang/activityrecognition/blob/master/notes/dataset%20description.md<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><a href="https://catalogue.data.govt.nz/dataset/fall-data"target="_blank" rel="external nofollow noopener noreferrer">https://catalogue.data.govt.nz/dataset/fall-data<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
</ul>
<h3 id="heading"></h3>
</div>
<div class="post-footer" id="post-footer">
  <div class="post-info">
    <div class="post-info-line">
      <div class="post-info-mod">
        <span title=2023-12-31&#32;14:03:43>更新于 2023-12-31&nbsp;</span>
      </div><div class="post-info-license">
          <span><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span>
        </div></div>
    <div class="post-info-line">
      <div class="post-info-md"><span><a href="/sensordatasets/index.md" title="阅读原始文档" class="link-to-markdown">阅读原始文档</a></span><span><a href="https://liudongdong1.github.io/edit/master/content/posts%5cAIOT%5cMobileDevices%5cSensorDatasets.md" title="编辑此页"target="_blank" rel="external nofollow noopener noreferrer" class="link-to-edit">编辑此页</a></span></div>
      <div class="post-info-share">
        <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="https://liudongdong1.github.io/sensordatasets/" data-title="SensorDatasets" data-hashtags="Dataset"><i class="fa-brands fa-twitter fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="https://liudongdong1.github.io/sensordatasets/" data-hashtag="Dataset"><i class="fa-brands fa-facebook-square fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="https://liudongdong1.github.io/sensordatasets/" data-title="SensorDatasets" data-image="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/sunset-background-lighting-at-dusk-sky-evening-sky.jpg"><i class="fa-brands fa-weibo fa-fw" aria-hidden="true"></i></a>
  </span>
      </div>
    </div>
  </div>

  <div class="post-info-more">
    <section class="post-tags"><i class="fa-solid fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/dataset/">Dataset</a></section>
    <section>
      <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
    </section>
  </div>

  <div class="post-nav"><a href="/tools_butterknite/" class="prev" rel="prev" title="Tools_ButterKnife"><i class="fa-solid fa-angle-left fa-fw" aria-hidden="true"></i>Tools_ButterKnife</a>
      <a href="/objectdetection/" class="next" rel="next" title="ObjectDetection">ObjectDetection<i class="fa-solid fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article></main><footer class="footer">
    <div class="footer-container"><div class="footer-line powered">由 <a href="https://gohugo.io/" target="_blank" rel="external nofollow noopener noreferrer" title="Hugo 0.118.2">Hugo</a> 强力驱动 | 主题 - <a href="https://github.com/hugo-fixit/FixIt" target="_blank" rel="external" title="FixIt v0.2.17-RC"><img class="fixit-icon" src="/fixit.min.svg" alt="FixIt logo" />&nbsp;FixIt</a>
        </div><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">2020 - 2023</span><span class="author" itemprop="copyrightHolder">
              <a href="https://liudongdong1.github.io/"target="_blank" rel="external nofollow noopener noreferrer">LiuDongdong</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div><div class="footer-line statistics"><span class="site-time" title='网站运行中 ...'><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden="true"></i>&nbsp;<span class="run-times">网站运行中 ...</span></span></div><div class="footer-line ibruce">
          <span id="busuanzi_container_site_uv" title='总访客数'><i class="fa-regular fa-user fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span><span id="busuanzi_container_site_pv" class="footer-divider" title='总访问量'><i class="fa-regular fa-eye fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span>
        </div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="回到顶部"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric">0%</span>
        </div></div><a href="https://liudongdong1.github.io/" title="在 GitHub 上查看源代码"target="_blank" rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><div id="mask"></div><div class="reading-progress-bar" style="left: 0;top: 0;--bg-progress: #0076ff;--bg-progress-dark: #fff;"></div><noscript>
    <div class="noscript-warning">FixIt 主题在启用 JavaScript 的情况下效果最佳。</div>
  </noscript>
</div><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script src="/lib/autocomplete/autocomplete.min.js" defer></script><script src="/lib/algoliasearch/algoliasearch-lite.umd.min.js" defer></script><script src="/lib/lazysizes/lazysizes.min.js" async defer></script><script src="/lib/sharer/sharer.min.js" async defer></script><script src="/lib/typeit/index.umd.js" defer></script><script src="/lib/katex/katex.min.js" defer></script><script src="/lib/katex/auto-render.min.js" defer></script><script src="/lib/katex/copy-tex.min.js" defer></script><script src="/lib/katex/mhchem.min.js" defer></script><script src="/lib/cookieconsent/cookieconsent.min.js" defer></script><script src="/lib/pangu/pangu.min.js" defer></script><script src="/lib/cell-watermark/watermark.min.js" defer></script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async defer></script><script>window.config={"code":{"copyTitle":"复制到剪贴板","editLockTitle":"锁定可编辑代码块","editUnLockTitle":"解锁可编辑代码块","editable":true,"maxShownLines":10},"comment":{"enable":false},"cookieconsent":{"content":{"dismiss":"同意","link":"了解更多","message":"本网站使用 Cookies 来改善您的浏览体验。"},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"data":{"typeit-header-subtitle-desktop":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e","typeit-header-subtitle-mobile":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e"},"enablePWA":true,"enablePangu":true,"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"2R1K9SKLQZ","algoliaIndex":"index.zh-cn","algoliaSearchKey":"4a226aa1c5c98d6859e4d1386adb2bc7","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"},"siteTime":"2020-12-18T16:15:22+08:00","typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"typeit-header-subtitle-desktop":["typeit-header-subtitle-desktop"],"typeit-header-subtitle-mobile":["typeit-header-subtitle-mobile"]},"duration":-1,"speed":100},"watermark":{"appendto":".wrapper\u003emain","colspacing":30,"content":"\u003cimg class=\"fixit-icon\" src=\"/fixit.min.svg\" alt=\"FixIt logo\" /\u003e FixIt 主题","enable":true,"fontfamily":"inherit","fontsize":0.85,"height":21,"opacity":0.0125,"rotate":15,"rowspacing":60,"width":150}};</script><script src="/js/theme.min.js" defer></script><script src="/js/custom.min.js" defer></script></body>
</html>
