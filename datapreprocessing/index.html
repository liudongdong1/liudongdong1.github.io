<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>DataPreprocessing - DAY By DAY</title><meta name=author content="LiuDongdong"><meta name=author-link content="https://liudongdong1.github.io/"><meta name=description content="0. Preprocessing preprocessing.Binarizer(*[, threshold, copy]) Binarize data (set feature values to 0 or 1) according to a threshold. preprocessing.FunctionTransformer([func, …]) Constructs a transformer from an arbitrary callable. preprocessing.KBinsDiscretizer([n_bins, …]) Bin continuous data into intervals. preprocessing.KernelCenterer() Center a kernel matrix. preprocessing.LabelBinarizer(*[, neg_label, …]) Binarize labels in a one-vs-all fashion. preprocessing.LabelEncoder() Encode target labels with value between 0 and n_classes-1. preprocessing.MultiLabelBinarizer(*[, …]) Transform between"><meta name=keywords content="SkLearn"><meta itemprop=name content="DataPreprocessing"><meta itemprop=description content="0. Preprocessing preprocessing.Binarizer(*[, threshold, copy]) Binarize data (set feature values to 0 or 1) according to a threshold. preprocessing.FunctionTransformer([func, …]) Constructs a transformer from an arbitrary callable. preprocessing.KBinsDiscretizer([n_bins, …]) Bin continuous data into intervals. preprocessing.KernelCenterer() Center a kernel matrix. preprocessing.LabelBinarizer(*[, neg_label, …]) Binarize labels in a one-vs-all fashion. preprocessing.LabelEncoder() Encode target labels with value between 0 and n_classes-1. preprocessing.MultiLabelBinarizer(*[, …]) Transform between"><meta itemprop=datePublished content="2021-02-24T08:56:09+00:00"><meta itemprop=dateModified content="2023-09-28T22:45:34+08:00"><meta itemprop=wordCount content="2696"><meta itemprop=image content="/logo.png"><meta itemprop=keywords content="SkLearn,"><meta property="og:title" content="DataPreprocessing"><meta property="og:description" content="0. Preprocessing preprocessing.Binarizer(*[, threshold, copy]) Binarize data (set feature values to 0 or 1) according to a threshold. preprocessing.FunctionTransformer([func, …]) Constructs a transformer from an arbitrary callable. preprocessing.KBinsDiscretizer([n_bins, …]) Bin continuous data into intervals. preprocessing.KernelCenterer() Center a kernel matrix. preprocessing.LabelBinarizer(*[, neg_label, …]) Binarize labels in a one-vs-all fashion. preprocessing.LabelEncoder() Encode target labels with value between 0 and n_classes-1. preprocessing.MultiLabelBinarizer(*[, …]) Transform between"><meta property="og:type" content="article"><meta property="og:url" content="liudongdong1.github.io/datapreprocessing/"><meta property="og:image" content="/logo.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-02-24T08:56:09+00:00"><meta property="article:modified_time" content="2023-09-28T22:45:34+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="/logo.png"><meta name=twitter:title content="DataPreprocessing"><meta name=twitter:description content="0. Preprocessing preprocessing.Binarizer(*[, threshold, copy]) Binarize data (set feature values to 0 or 1) according to a threshold. preprocessing.FunctionTransformer([func, …]) Constructs a transformer from an arbitrary callable. preprocessing.KBinsDiscretizer([n_bins, …]) Bin continuous data into intervals. preprocessing.KernelCenterer() Center a kernel matrix. preprocessing.LabelBinarizer(*[, neg_label, …]) Binarize labels in a one-vs-all fashion. preprocessing.LabelEncoder() Encode target labels with value between 0 and n_classes-1. preprocessing.MultiLabelBinarizer(*[, …]) Transform between"><meta name=application-name content="DAY By DAY"><meta name=apple-mobile-web-app-title content="DAY By DAY"><meta name=theme-color data-light=#f8f8f8 data-dark=#252627 content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=liudongdong1.github.io/datapreprocessing/><link rel=prev href=liudongdong1.github.io/sklearndataflow/><link rel=next href=liudongdong1.github.io/distribution/><link rel=stylesheet href=/liudongdong1.github.io/css/style.min.css><link rel=stylesheet href=/liudongdong1.github.io/lib/fontawesome-free/all.min.css><link rel=stylesheet href=/liudongdong1.github.io/lib/animate/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"DataPreprocessing","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"liudongdong1.github.io\/datapreprocessing\/"},"genre":"posts","keywords":"SkLearn","wordcount":2696,"url":"liudongdong1.github.io\/datapreprocessing\/","datePublished":"2021-02-24T08:56:09+00:00","dateModified":"2023-09-28T22:45:34+08:00","license":"This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher":{"@type":"Organization","name":"LiuDongdong","logo":"\/images\/person.png"},"author":{"@type":"Person","name":"liudongdong1"},"description":""}</script></head><body data-header-desktop=auto data-header-mobile=auto><script>(window.localStorage?.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("data-theme","dark")</script><div class=wrapper><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper data-github-corner=right><div class=header-title><a href=liudongdong1.github.io/ title="DAY By DAY"><img class="lazyload logo" src=/liudongdong1.github.io/svg/loading.min.svg data-src=/fixit.min.svg data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x" data-sizes=auto alt="DAY By DAY" title="DAY By DAY"><span class=header-title-text></span></a><span id=typeit-header-subtitle-desktop class="typeit header-subtitle"></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 所有文章</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/friends/ title=友情链接><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden=true></i> 友链</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/about/><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden=true></i> 关于</a></li><li class="menu-item delimiter"></li><li class="menu-item language"><span role=button aria-label=选择语言 title=选择语言>简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden=true></i></span><ul class=sub-menu><li class=menu-item>没有更多翻译</li></ul></li><li class="menu-item search" id=search-desktop><input type=text placeholder="搜索文章标题或内容 ..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i></a>
<span class="search-button search-loading" id=search-loading-desktop><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></li><li class="menu-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=liudongdong1.github.io/ title="DAY By DAY"><img class="lazyload logo" src=/liudongdong1.github.io/svg/loading.min.svg data-src=/fixit.min.svg data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x" data-sizes=auto alt=/fixit.min.svg title=/fixit.min.svg><span class=header-title-text></span></a><span id=typeit-header-subtitle-mobile class="typeit header-subtitle"></span></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder="搜索文章标题或内容 ..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i></a>
<span class="search-button search-loading" id=search-loading-mobile><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 所有文章</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/friends/ title=友情链接><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden=true></i> 友链</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/about/><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden=true></i> 关于</a></li><li class="menu-item text-center"><a class=menu-link href=https://liudongdong1.github.io/ title=GitHub rel="noopener noreferrer" target=_blank><i class='fa-brands fa-github fa-fw' aria-hidden=true></i></a></li><li class="menu-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li><li class="menu-item language"><span role=button aria-label=选择语言 title=选择语言>简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden=true></i></span>
<select class=language-select onchange="location=this.value"><option disabled>没有更多翻译</option></select></li></ul></nav></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=container data-page-style=normal><aside class=toc id=toc-auto><h2 class=toc-title>目录 <i class="toc-icon fa-solid fa-angle-down fa-fw"></i></h2><div class=toc-content id=toc-content-auto></div></aside><aside class=aside-custom id=aside-sakana><div class=sakana-widget><div class=sakana-item id=takina-widget></div><div class=sakana-item id=chisato-widget></div></div><script>function initSakanaWidget(){const e=SakanaWidget.getCharacter("takina");SakanaWidget.registerCharacter("takina-slow",e),new SakanaWidget({character:"takina-slow",controls:!1,autoFit:!0,stroke:{color:"#b4b4b4",width:2}}).mount("#takina-widget");const t=SakanaWidget.getCharacter("chisato");SakanaWidget.registerCharacter("chisato-slow",t),new SakanaWidget({character:"chisato-slow",controls:!1,autoFit:!0,stroke:{color:"#b4b4b4",width:2}}).mount("#chisato-widget")}</script><script async onload=initSakanaWidget() src=https://cdn.jsdelivr.net/npm/sakana-widget@2.3.0/lib/sakana.min.js></script></aside><article class="page single"><div class=header><h1 class="single-title animate__animated animate__flipInX"><span>DataPreprocessing</span></h1></div><div class=post-meta><div class=post-meta-line><span class=post-author><span class=author><i class="fa-solid fa-user-circle" aria-hidden=true></i>
liudongdong1</span></span>
<span class=post-category>收录于 <a href=liudongdong1.github.io/categories/><i class="fa-regular fa-folder fa-fw"></i>&nbsp;Categories</a>&ensp;<a href=liudongdong1.github.io/categories/ai/><i class="fa-regular fa-folder fa-fw"></i>&nbsp;AI</a></span></div><div class=post-meta-line><span title="2021-02-24 08:56:09"><i class="fa-regular fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2021-02-24>2021-02-24</time>
</span>&nbsp;<i class="fa-solid fa-pencil-alt fa-fw"></i>&nbsp;约 2696 字&nbsp;
<i class="fa-regular fa-clock fa-fw"></i>&nbsp;预计阅读 6 分钟&nbsp;<span id=busuanzi_container_page_pv class="busuanzi_visitors comment-visitors" data-flag-title=DataPreprocessing>
<i class="fa-regular fa-eye fa-fw"></i>&nbsp;<span id=busuanzi_value_page_pv>-</span>&nbsp;次阅读
</span>&nbsp;</div></div><div class=featured-image><img class=lazyload src=/liudongdong1.github.io/svg/loading.min.svg data-src=https://gitee.com/github-25970295/blogImage/raw/master/img/20210522212626.png data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/20210522212626.png, https://gitee.com/github-25970295/blogImage/raw/master/img/20210522212626.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/20210522212626.png 2x" data-sizes=auto alt=https://gitee.com/github-25970295/blogImage/raw/master/img/20210522212626.png title=https://gitee.com/github-25970295/blogImage/raw/master/img/20210522212626.png></div><div class="details toc" id=toc-static kept=true><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fa-solid fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><ul><li><a href=#0-preprocessing>0. Preprocessing</a></li><li><a href=#1-feature-discretization>1. Feature discretization</a></li><li><a href=#2-map-data-to-normal-distribution>2. Map data to normal distribution</a></li><li><a href=#3-kbinsdiscretizer>3. KBinsDiscretizer</a></li><li><a href=#4-feature-scaling>4. Feature Scaling</a></li><li><a href=#resource>Resource</a></li></ul></li></ul></nav></div></div><div class=content id=content><h3 id=0-preprocessing>0. Preprocessing</h3><table><thead><tr><th><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Binarizer.html#sklearn.preprocessing.Binarizer target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.Binarizer</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>(*[, threshold, copy])</th><th>Binarize data (set feature values to 0 or 1) according to a threshold.</th></tr></thead><tbody><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.FunctionTransformer</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>([func, …])</td><td>Constructs a transformer from an arbitrary callable.</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html#sklearn.preprocessing.KBinsDiscretizer target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.KBinsDiscretizer</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>([n_bins, …])</td><td>Bin continuous data into intervals.</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KernelCenterer.html#sklearn.preprocessing.KernelCenterer target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.KernelCenterer</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>()</td><td>Center a kernel matrix.</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.LabelBinarizer</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>(*[, neg_label, …])</td><td>Binarize labels in a one-vs-all fashion.</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.LabelEncoder</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>()</td><td>Encode target labels with value between 0 and n_classes-1.</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html#sklearn.preprocessing.MultiLabelBinarizer target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.MultiLabelBinarizer</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>(*[, …])</td><td>Transform between iterable of iterables and a multilabel format.</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.MaxAbsScaler</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>(*[, copy])</td><td>Scale each feature by its maximum absolute value.</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.MinMaxScaler</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>([feature_range, …])</td><td>Transform features by scaling each feature to a given range.</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.Normalizer</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>([norm, copy])</td><td>Normalize samples individually to unit norm.</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.OneHotEncoder</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>(*[, categories, …])</td><td>Encode categorical features as a one-hot numeric array.</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html#sklearn.preprocessing.OrdinalEncoder target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.OrdinalEncoder</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>(*[, …])</td><td>Encode categorical features as an integer array.</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html#sklearn.preprocessing.PolynomialFeatures target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.PolynomialFeatures</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>([degree, …])</td><td>Generate polynomial and interaction features.</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html#sklearn.preprocessing.PowerTransformer target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.PowerTransformer</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>([method, …])</td><td>Apply a power transform featurewise to make data more Gaussian-like.</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html#sklearn.preprocessing.QuantileTransformer target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.QuantileTransformer</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>(*[, …])</td><td>Transform features using quantiles information.</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.RobustScaler</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>(*[, …])</td><td>Scale features using statistics that are robust to outliers.</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.StandardScaler</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>(*[, copy, …])</td><td>Standardize features by removing the mean and scaling to unit variance</td></tr></tbody></table><table><thead><tr><th><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.add_dummy_feature.html#sklearn.preprocessing.add_dummy_feature target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.add_dummy_feature</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>(X[, value])</th><th>Augment dataset with an additional dummy feature.</th></tr></thead><tbody><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.binarize.html#sklearn.preprocessing.binarize target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.binarize</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>(X, *[, threshold, copy])</td><td>Boolean thresholding of array-like or scipy.sparse matrix.</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.label_binarize.html#sklearn.preprocessing.label_binarize target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.label_binarize</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>(y, *, classes)</td><td>Binarize labels in a one-vs-all fashion.</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.maxabs_scale.html#sklearn.preprocessing.maxabs_scale target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.maxabs_scale</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>(X, *[, axis, copy])</td><td>Scale each feature to the [-1, 1] range without breaking the sparsity.</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.minmax_scale.html#sklearn.preprocessing.minmax_scale target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.minmax_scale</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>(X[, …])</td><td>Transform features by scaling each feature to a given range.</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html#sklearn.preprocessing.normalize target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.normalize</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>(X[, norm, axis, …])</td><td>Scale input vectors individually to unit norm (vector length).</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.quantile_transform.html#sklearn.preprocessing.quantile_transform target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.quantile_transform</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>(X, *[, …])</td><td>Transform features using quantiles information.</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.robust_scale.html#sklearn.preprocessing.robust_scale target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.robust_scale</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>(X, *[, axis, …])</td><td>Standardize a dataset along any axis</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html#sklearn.preprocessing.scale target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.scale</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>(X, *[, axis, with_mean, …])</td><td>Standardize a dataset along any axis.</td></tr><tr><td><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.power_transform.html#sklearn.preprocessing.power_transform target=_blank rel="external nofollow noopener noreferrer"><code>preprocessing.power_transform</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>(X[, method, …])</td><td>Power transforms are a family of parametric, monotonic transformations that are applied to make data more Gaussian-like.</td></tr></tbody></table><h3 id=1-feature-discretization>1. Feature discretization</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> matplotlib.colors <span style=color:#f92672>import</span> ListedColormap
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> train_test_split
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> StandardScaler
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.datasets <span style=color:#f92672>import</span> make_moons, make_circles, make_classification
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.linear_model <span style=color:#f92672>import</span> LogisticRegression
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> GridSearchCV
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.pipeline <span style=color:#f92672>import</span> make_pipeline
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> KBinsDiscretizer
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.svm <span style=color:#f92672>import</span> SVC, LinearSVC
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.ensemble <span style=color:#f92672>import</span> GradientBoostingClassifier
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.utils._testing <span style=color:#f92672>import</span> ignore_warnings
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.exceptions <span style=color:#f92672>import</span> ConvergenceWarning
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(__doc__)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>h <span style=color:#f92672>=</span> <span style=color:#ae81ff>.02</span>  <span style=color:#75715e># step size in the mesh</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_name</span>(estimator):
</span></span><span style=display:flex><span>    name <span style=color:#f92672>=</span> estimator<span style=color:#f92672>.</span>__class__<span style=color:#f92672>.</span>__name__
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> name <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;Pipeline&#39;</span>:
</span></span><span style=display:flex><span>        name <span style=color:#f92672>=</span> [get_name(est[<span style=color:#ae81ff>1</span>]) <span style=color:#66d9ef>for</span> est <span style=color:#f92672>in</span> estimator<span style=color:#f92672>.</span>steps]
</span></span><span style=display:flex><span>        name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39; + &#39;</span><span style=color:#f92672>.</span>join(name)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> name
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># list of (estimator, param_grid), where param_grid is used in GridSearchCV</span>
</span></span><span style=display:flex><span>classifiers <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    (LogisticRegression(random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>), {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;C&#39;</span>: np<span style=color:#f92672>.</span>logspace(<span style=color:#f92672>-</span><span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>    }),
</span></span><span style=display:flex><span>    (LinearSVC(random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>), {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;C&#39;</span>: np<span style=color:#f92672>.</span>logspace(<span style=color:#f92672>-</span><span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>    }),
</span></span><span style=display:flex><span>    (make_pipeline(
</span></span><span style=display:flex><span>        KBinsDiscretizer(encode<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;onehot&#39;</span>),
</span></span><span style=display:flex><span>        LogisticRegression(random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)), {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;kbinsdiscretizer__n_bins&#39;</span>: np<span style=color:#f92672>.</span>arange(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>10</span>),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;logisticregression__C&#39;</span>: np<span style=color:#f92672>.</span>logspace(<span style=color:#f92672>-</span><span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>10</span>),
</span></span><span style=display:flex><span>        }),
</span></span><span style=display:flex><span>    (make_pipeline(
</span></span><span style=display:flex><span>        KBinsDiscretizer(encode<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;onehot&#39;</span>), LinearSVC(random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)), {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;kbinsdiscretizer__n_bins&#39;</span>: np<span style=color:#f92672>.</span>arange(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>10</span>),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;linearsvc__C&#39;</span>: np<span style=color:#f92672>.</span>logspace(<span style=color:#f92672>-</span><span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>10</span>),
</span></span><span style=display:flex><span>        }),
</span></span><span style=display:flex><span>    (GradientBoostingClassifier(n_estimators<span style=color:#f92672>=</span><span style=color:#ae81ff>50</span>, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>), {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;learning_rate&#39;</span>: np<span style=color:#f92672>.</span>logspace(<span style=color:#f92672>-</span><span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>    }),
</span></span><span style=display:flex><span>    (SVC(random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>), {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;C&#39;</span>: np<span style=color:#f92672>.</span>logspace(<span style=color:#f92672>-</span><span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>    }),
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>names <span style=color:#f92672>=</span> [get_name(e) <span style=color:#66d9ef>for</span> e, g <span style=color:#f92672>in</span> classifiers]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>n_samples <span style=color:#f92672>=</span> <span style=color:#ae81ff>100</span>
</span></span><span style=display:flex><span>datasets <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    make_moons(n_samples<span style=color:#f92672>=</span>n_samples, noise<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>),
</span></span><span style=display:flex><span>    make_circles(n_samples<span style=color:#f92672>=</span>n_samples, noise<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>, factor<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>    make_classification(n_samples<span style=color:#f92672>=</span>n_samples, n_features<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, n_redundant<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>,
</span></span><span style=display:flex><span>                        n_informative<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>,
</span></span><span style=display:flex><span>                        n_clusters_per_class<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig, axes <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots(nrows<span style=color:#f92672>=</span>len(datasets), ncols<span style=color:#f92672>=</span>len(classifiers) <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>                         figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>21</span>, <span style=color:#ae81ff>9</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cm <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>cm<span style=color:#f92672>.</span>PiYG
</span></span><span style=display:flex><span>cm_bright <span style=color:#f92672>=</span> ListedColormap([<span style=color:#e6db74>&#39;#b30065&#39;</span>, <span style=color:#e6db74>&#39;#178000&#39;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># iterate over datasets</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> ds_cnt, (X, y) <span style=color:#f92672>in</span> enumerate(datasets):
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#39;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>dataset </span><span style=color:#e6db74>%d</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>---------&#39;</span> <span style=color:#f92672>%</span> ds_cnt)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># preprocess dataset, split into training and test part</span>
</span></span><span style=display:flex><span>    X <span style=color:#f92672>=</span> StandardScaler()<span style=color:#f92672>.</span>fit_transform(X)
</span></span><span style=display:flex><span>    X_train, X_test, y_train, y_test <span style=color:#f92672>=</span> train_test_split(
</span></span><span style=display:flex><span>        X, y, test_size<span style=color:#f92672>=</span><span style=color:#ae81ff>.5</span>, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># create the grid for background colors</span>
</span></span><span style=display:flex><span>    x_min, x_max <span style=color:#f92672>=</span> X[:, <span style=color:#ae81ff>0</span>]<span style=color:#f92672>.</span>min() <span style=color:#f92672>-</span> <span style=color:#ae81ff>.5</span>, X[:, <span style=color:#ae81ff>0</span>]<span style=color:#f92672>.</span>max() <span style=color:#f92672>+</span> <span style=color:#ae81ff>.5</span>
</span></span><span style=display:flex><span>    y_min, y_max <span style=color:#f92672>=</span> X[:, <span style=color:#ae81ff>1</span>]<span style=color:#f92672>.</span>min() <span style=color:#f92672>-</span> <span style=color:#ae81ff>.5</span>, X[:, <span style=color:#ae81ff>1</span>]<span style=color:#f92672>.</span>max() <span style=color:#f92672>+</span> <span style=color:#ae81ff>.5</span>
</span></span><span style=display:flex><span>    xx, yy <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>meshgrid(
</span></span><span style=display:flex><span>        np<span style=color:#f92672>.</span>arange(x_min, x_max, h), np<span style=color:#f92672>.</span>arange(y_min, y_max, h))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># plot the dataset first</span>
</span></span><span style=display:flex><span>    ax <span style=color:#f92672>=</span> axes[ds_cnt, <span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> ds_cnt <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>&#34;Input data&#34;</span>)
</span></span><span style=display:flex><span>    <span style=color:#75715e># plot the training points</span>
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>scatter(X_train[:, <span style=color:#ae81ff>0</span>], X_train[:, <span style=color:#ae81ff>1</span>], c<span style=color:#f92672>=</span>y_train, cmap<span style=color:#f92672>=</span>cm_bright,
</span></span><span style=display:flex><span>               edgecolors<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;k&#39;</span>)
</span></span><span style=display:flex><span>    <span style=color:#75715e># and testing points</span>
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>scatter(X_test[:, <span style=color:#ae81ff>0</span>], X_test[:, <span style=color:#ae81ff>1</span>], c<span style=color:#f92672>=</span>y_test, cmap<span style=color:#f92672>=</span>cm_bright, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.6</span>,
</span></span><span style=display:flex><span>               edgecolors<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;k&#39;</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_xlim(xx<span style=color:#f92672>.</span>min(), xx<span style=color:#f92672>.</span>max())
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_ylim(yy<span style=color:#f92672>.</span>min(), yy<span style=color:#f92672>.</span>max())
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_xticks(())
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_yticks(())
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># iterate over classifiers</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> est_idx, (name, (estimator, param_grid)) <span style=color:#f92672>in</span> \
</span></span><span style=display:flex><span>            enumerate(zip(names, classifiers)):
</span></span><span style=display:flex><span>        ax <span style=color:#f92672>=</span> axes[ds_cnt, est_idx <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        clf <span style=color:#f92672>=</span> GridSearchCV(estimator<span style=color:#f92672>=</span>estimator, param_grid<span style=color:#f92672>=</span>param_grid)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>with</span> ignore_warnings(category<span style=color:#f92672>=</span>ConvergenceWarning):
</span></span><span style=display:flex><span>            clf<span style=color:#f92672>.</span>fit(X_train, y_train)
</span></span><span style=display:flex><span>        score <span style=color:#f92672>=</span> clf<span style=color:#f92672>.</span>score(X_test, y_test)
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#39;</span><span style=color:#e6db74>%s</span><span style=color:#e6db74>: </span><span style=color:#e6db74>%.2f</span><span style=color:#e6db74>&#39;</span> <span style=color:#f92672>%</span> (name, score))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># plot the decision boundary. For that, we will assign a color to each</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># point in the mesh [x_min, x_max]*[y_min, y_max].</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> hasattr(clf, <span style=color:#e6db74>&#34;decision_function&#34;</span>):
</span></span><span style=display:flex><span>            Z <span style=color:#f92672>=</span> clf<span style=color:#f92672>.</span>decision_function(np<span style=color:#f92672>.</span>c_[xx<span style=color:#f92672>.</span>ravel(), yy<span style=color:#f92672>.</span>ravel()])
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>            Z <span style=color:#f92672>=</span> clf<span style=color:#f92672>.</span>predict_proba(np<span style=color:#f92672>.</span>c_[xx<span style=color:#f92672>.</span>ravel(), yy<span style=color:#f92672>.</span>ravel()])[:, <span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># put the result into a color plot</span>
</span></span><span style=display:flex><span>        Z <span style=color:#f92672>=</span> Z<span style=color:#f92672>.</span>reshape(xx<span style=color:#f92672>.</span>shape)
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>contourf(xx, yy, Z, cmap<span style=color:#f92672>=</span>cm, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>.8</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># plot the training points</span>
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>scatter(X_train[:, <span style=color:#ae81ff>0</span>], X_train[:, <span style=color:#ae81ff>1</span>], c<span style=color:#f92672>=</span>y_train, cmap<span style=color:#f92672>=</span>cm_bright,
</span></span><span style=display:flex><span>                   edgecolors<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;k&#39;</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># and testing points</span>
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>scatter(X_test[:, <span style=color:#ae81ff>0</span>], X_test[:, <span style=color:#ae81ff>1</span>], c<span style=color:#f92672>=</span>y_test, cmap<span style=color:#f92672>=</span>cm_bright,
</span></span><span style=display:flex><span>                   edgecolors<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;k&#39;</span>, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.6</span>)
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>set_xlim(xx<span style=color:#f92672>.</span>min(), xx<span style=color:#f92672>.</span>max())
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>set_ylim(yy<span style=color:#f92672>.</span>min(), yy<span style=color:#f92672>.</span>max())
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>set_xticks(())
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>set_yticks(())
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> ds_cnt <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>            ax<span style=color:#f92672>.</span>set_title(name<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#39; + &#39;</span>, <span style=color:#e6db74>&#39;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#39;</span>))
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>text(<span style=color:#ae81ff>0.95</span>, <span style=color:#ae81ff>0.06</span>, (<span style=color:#e6db74>&#39;</span><span style=color:#e6db74>%.2f</span><span style=color:#e6db74>&#39;</span> <span style=color:#f92672>%</span> score)<span style=color:#f92672>.</span>lstrip(<span style=color:#e6db74>&#39;0&#39;</span>), size<span style=color:#f92672>=</span><span style=color:#ae81ff>15</span>,
</span></span><span style=display:flex><span>                bbox<span style=color:#f92672>=</span>dict(boxstyle<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;round&#39;</span>, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.8</span>, facecolor<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;white&#39;</span>),
</span></span><span style=display:flex><span>                transform<span style=color:#f92672>=</span>ax<span style=color:#f92672>.</span>transAxes, horizontalalignment<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;right&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>tight_layout()
</span></span><span style=display:flex><span><span style=color:#75715e># Add suptitles above the figure</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>subplots_adjust(top<span style=color:#f92672>=</span><span style=color:#ae81ff>0.90</span>)
</span></span><span style=display:flex><span>suptitles <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;Linear classifiers&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;Feature discretization and linear classifiers&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;Non-linear classifiers&#39;</span>,
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i, suptitle <span style=color:#f92672>in</span> zip([<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>5</span>], suptitles):
</span></span><span style=display:flex><span>    ax <span style=color:#f92672>=</span> axes[<span style=color:#ae81ff>0</span>, i]
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>text(<span style=color:#ae81ff>1.05</span>, <span style=color:#ae81ff>1.25</span>, suptitle, transform<span style=color:#f92672>=</span>ax<span style=color:#f92672>.</span>transAxes,
</span></span><span style=display:flex><span>            horizontalalignment<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;center&#39;</span>, size<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;x-large&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><p><img class=lazyload src=/liudongdong1.github.io/svg/loading.min.svg data-src=https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210522204223565.png data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210522204223565.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210522204223565.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210522204223565.png 2x" data-sizes=auto alt=https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210522204223565.png title=https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210522204223565.png></p><h3 id=2-map-data-to-normal-distribution>2. Map data to normal distribution</h3><blockquote><p>the Box-Cox and Yeo-Johnson transforms through <a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html#sklearn.preprocessing.PowerTransformer target=_blank rel="external nofollow noopener noreferrer"><code>PowerTransformer</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a> to map data from various distributions to a normal distribution. Below are examples of Box-Cox and Yeo-Johnwon applied to six different probability distributions: Lognormal, Chi-squared, Weibull, Gaussian, Uniform, and Bimodal.</p><ul><li>Box-Cox does not support inputs with negative values.</li><li><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html#sklearn.preprocessing.QuantileTransformer target=_blank rel="external nofollow noopener noreferrer"><code>QuantileTransformer</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a> can force any arbitrary distribution into a gaussian,</li></ul></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> PowerTransformer
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> QuantileTransformer
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> train_test_split
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(__doc__)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>N_SAMPLES <span style=color:#f92672>=</span> <span style=color:#ae81ff>1000</span>
</span></span><span style=display:flex><span>FONT_SIZE <span style=color:#f92672>=</span> <span style=color:#ae81ff>6</span>
</span></span><span style=display:flex><span>BINS <span style=color:#f92672>=</span> <span style=color:#ae81ff>30</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>rng <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>RandomState(<span style=color:#ae81ff>304</span>)
</span></span><span style=display:flex><span>bc <span style=color:#f92672>=</span> PowerTransformer(method<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;box-cox&#39;</span>)
</span></span><span style=display:flex><span>yj <span style=color:#f92672>=</span> PowerTransformer(method<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;yeo-johnson&#39;</span>)
</span></span><span style=display:flex><span><span style=color:#75715e># n_quantiles is set to the training set size rather than the default value</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to avoid a warning being raised by this example</span>
</span></span><span style=display:flex><span>qt <span style=color:#f92672>=</span> QuantileTransformer(n_quantiles<span style=color:#f92672>=</span><span style=color:#ae81ff>500</span>, output_distribution<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;normal&#39;</span>,
</span></span><span style=display:flex><span>                         random_state<span style=color:#f92672>=</span>rng)
</span></span><span style=display:flex><span>size <span style=color:#f92672>=</span> (N_SAMPLES, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># lognormal distribution</span>
</span></span><span style=display:flex><span>X_lognormal <span style=color:#f92672>=</span> rng<span style=color:#f92672>.</span>lognormal(size<span style=color:#f92672>=</span>size)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># chi-squared distribution</span>
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> <span style=color:#ae81ff>3</span>
</span></span><span style=display:flex><span>X_chisq <span style=color:#f92672>=</span> rng<span style=color:#f92672>.</span>chisquare(df<span style=color:#f92672>=</span>df, size<span style=color:#f92672>=</span>size)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># weibull distribution</span>
</span></span><span style=display:flex><span>a <span style=color:#f92672>=</span> <span style=color:#ae81ff>50</span>
</span></span><span style=display:flex><span>X_weibull <span style=color:#f92672>=</span> rng<span style=color:#f92672>.</span>weibull(a<span style=color:#f92672>=</span>a, size<span style=color:#f92672>=</span>size)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># gaussian distribution</span>
</span></span><span style=display:flex><span>loc <span style=color:#f92672>=</span> <span style=color:#ae81ff>100</span>
</span></span><span style=display:flex><span>X_gaussian <span style=color:#f92672>=</span> rng<span style=color:#f92672>.</span>normal(loc<span style=color:#f92672>=</span>loc, size<span style=color:#f92672>=</span>size)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># uniform distribution</span>
</span></span><span style=display:flex><span>X_uniform <span style=color:#f92672>=</span> rng<span style=color:#f92672>.</span>uniform(low<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, high<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, size<span style=color:#f92672>=</span>size)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># bimodal distribution</span>
</span></span><span style=display:flex><span>loc_a, loc_b <span style=color:#f92672>=</span> <span style=color:#ae81ff>100</span>, <span style=color:#ae81ff>105</span>
</span></span><span style=display:flex><span>X_a, X_b <span style=color:#f92672>=</span> rng<span style=color:#f92672>.</span>normal(loc<span style=color:#f92672>=</span>loc_a, size<span style=color:#f92672>=</span>size), rng<span style=color:#f92672>.</span>normal(loc<span style=color:#f92672>=</span>loc_b, size<span style=color:#f92672>=</span>size)
</span></span><span style=display:flex><span>X_bimodal <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>concatenate([X_a, X_b], axis<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># create plots</span>
</span></span><span style=display:flex><span>distributions <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#39;Lognormal&#39;</span>, X_lognormal),
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#39;Chi-squared&#39;</span>, X_chisq),
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#39;Weibull&#39;</span>, X_weibull),
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#39;Gaussian&#39;</span>, X_gaussian),
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#39;Uniform&#39;</span>, X_uniform),
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#39;Bimodal&#39;</span>, X_bimodal)
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>colors <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;#D81B60&#39;</span>, <span style=color:#e6db74>&#39;#0188FF&#39;</span>, <span style=color:#e6db74>&#39;#FFC107&#39;</span>,
</span></span><span style=display:flex><span>          <span style=color:#e6db74>&#39;#B7A2FF&#39;</span>, <span style=color:#e6db74>&#39;#000000&#39;</span>, <span style=color:#e6db74>&#39;#2EC5AC&#39;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig, axes <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots(nrows<span style=color:#f92672>=</span><span style=color:#ae81ff>8</span>, ncols<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, figsize<span style=color:#f92672>=</span>plt<span style=color:#f92672>.</span>figaspect(<span style=color:#ae81ff>2</span>))
</span></span><span style=display:flex><span>axes <span style=color:#f92672>=</span> axes<span style=color:#f92672>.</span>flatten()
</span></span><span style=display:flex><span>axes_idxs <span style=color:#f92672>=</span> [(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>9</span>), (<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>10</span>), (<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>8</span>, <span style=color:#ae81ff>11</span>), (<span style=color:#ae81ff>12</span>, <span style=color:#ae81ff>15</span>, <span style=color:#ae81ff>18</span>, <span style=color:#ae81ff>21</span>),
</span></span><span style=display:flex><span>             (<span style=color:#ae81ff>13</span>, <span style=color:#ae81ff>16</span>, <span style=color:#ae81ff>19</span>, <span style=color:#ae81ff>22</span>), (<span style=color:#ae81ff>14</span>, <span style=color:#ae81ff>17</span>, <span style=color:#ae81ff>20</span>, <span style=color:#ae81ff>23</span>)]
</span></span><span style=display:flex><span>axes_list <span style=color:#f92672>=</span> [(axes[i], axes[j], axes[k], axes[l])
</span></span><span style=display:flex><span>             <span style=color:#66d9ef>for</span> (i, j, k, l) <span style=color:#f92672>in</span> axes_idxs]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> distribution, color, axes <span style=color:#f92672>in</span> zip(distributions, colors, axes_list):
</span></span><span style=display:flex><span>    name, X <span style=color:#f92672>=</span> distribution
</span></span><span style=display:flex><span>    X_train, X_test <span style=color:#f92672>=</span> train_test_split(X, test_size<span style=color:#f92672>=</span><span style=color:#ae81ff>.5</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># perform power transforms and quantile transform</span>
</span></span><span style=display:flex><span>    X_trans_bc <span style=color:#f92672>=</span> bc<span style=color:#f92672>.</span>fit(X_train)<span style=color:#f92672>.</span>transform(X_test)
</span></span><span style=display:flex><span>    lmbda_bc <span style=color:#f92672>=</span> round(bc<span style=color:#f92672>.</span>lambdas_[<span style=color:#ae81ff>0</span>], <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>    X_trans_yj <span style=color:#f92672>=</span> yj<span style=color:#f92672>.</span>fit(X_train)<span style=color:#f92672>.</span>transform(X_test)
</span></span><span style=display:flex><span>    lmbda_yj <span style=color:#f92672>=</span> round(yj<span style=color:#f92672>.</span>lambdas_[<span style=color:#ae81ff>0</span>], <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>    X_trans_qt <span style=color:#f92672>=</span> qt<span style=color:#f92672>.</span>fit(X_train)<span style=color:#f92672>.</span>transform(X_test)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    ax_original, ax_bc, ax_yj, ax_qt <span style=color:#f92672>=</span> axes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    ax_original<span style=color:#f92672>.</span>hist(X_train, color<span style=color:#f92672>=</span>color, bins<span style=color:#f92672>=</span>BINS)
</span></span><span style=display:flex><span>    ax_original<span style=color:#f92672>.</span>set_title(name, fontsize<span style=color:#f92672>=</span>FONT_SIZE)
</span></span><span style=display:flex><span>    ax_original<span style=color:#f92672>.</span>tick_params(axis<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;both&#39;</span>, which<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;major&#39;</span>, labelsize<span style=color:#f92672>=</span>FONT_SIZE)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> ax, X_trans, meth_name, lmbda <span style=color:#f92672>in</span> zip(
</span></span><span style=display:flex><span>            (ax_bc, ax_yj, ax_qt),
</span></span><span style=display:flex><span>            (X_trans_bc, X_trans_yj, X_trans_qt),
</span></span><span style=display:flex><span>            (<span style=color:#e6db74>&#39;Box-Cox&#39;</span>, <span style=color:#e6db74>&#39;Yeo-Johnson&#39;</span>, <span style=color:#e6db74>&#39;Quantile transform&#39;</span>),
</span></span><span style=display:flex><span>            (lmbda_bc, lmbda_yj, <span style=color:#66d9ef>None</span>)):
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>hist(X_trans, color<span style=color:#f92672>=</span>color, bins<span style=color:#f92672>=</span>BINS)
</span></span><span style=display:flex><span>        title <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;After </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(meth_name)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> lmbda <span style=color:#f92672>is</span> <span style=color:#f92672>not</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>            title <span style=color:#f92672>+=</span> <span style=color:#e6db74>&#39;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>$</span><span style=color:#ae81ff>\\</span><span style=color:#e6db74>lambda$ = </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(lmbda)
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>set_title(title, fontsize<span style=color:#f92672>=</span>FONT_SIZE)
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>tick_params(axis<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;both&#39;</span>, which<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;major&#39;</span>, labelsize<span style=color:#f92672>=</span>FONT_SIZE)
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>set_xlim([<span style=color:#f92672>-</span><span style=color:#ae81ff>3.5</span>, <span style=color:#ae81ff>3.5</span>])
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>tight_layout()
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><p><img class=lazyload src=/liudongdong1.github.io/svg/loading.min.svg data-src=https://scikit-learn.org/stable/_images/sphx_glr_plot_map_data_to_normal_001.png data-srcset="https://scikit-learn.org/stable/_images/sphx_glr_plot_map_data_to_normal_001.png, https://scikit-learn.org/stable/_images/sphx_glr_plot_map_data_to_normal_001.png 1.5x, https://scikit-learn.org/stable/_images/sphx_glr_plot_map_data_to_normal_001.png 2x" data-sizes=auto alt="Lognormal, Chi-squared, Weibull, After Box-Cox $\lambda$ = 0.02, After Box-Cox $\lambda$ = 0.28, After Box-Cox $\lambda$ = 12.12, After Yeo-Johnson $\lambda$ = -0.8, After Yeo-Johnson $\lambda$ = -0.11, After Yeo-Johnson $\lambda$ = 23.52, After Quantile transform, After Quantile transform, After Quantile transform, Gaussian, Uniform, Bimodal, After Box-Cox $\lambda$ = 6.99, After Box-Cox $\lambda$ = 0.68, After Box-Cox $\lambda$ = 1.61, After Yeo-Johnson $\lambda$ = 7.05, After Yeo-Johnson $\lambda$ = 0.64, After Yeo-Johnson $\lambda$ = 1.62, After Quantile transform, After Quantile transform, After Quantile transform" title="Lognormal, Chi-squared, Weibull, After Box-Cox $\lambda$ = 0.02, After Box-Cox $\lambda$ = 0.28, After Box-Cox $\lambda$ = 12.12, After Yeo-Johnson $\lambda$ = -0.8, After Yeo-Johnson $\lambda$ = -0.11, After Yeo-Johnson $\lambda$ = 23.52, After Quantile transform, After Quantile transform, After Quantile transform, Gaussian, Uniform, Bimodal, After Box-Cox $\lambda$ = 6.99, After Box-Cox $\lambda$ = 0.68, After Box-Cox $\lambda$ = 1.61, After Yeo-Johnson $\lambda$ = 7.05, After Yeo-Johnson $\lambda$ = 0.64, After Yeo-Johnson $\lambda$ = 1.62, After Quantile transform, After Quantile transform, After Quantile transform"></p><h3 id=3-kbinsdiscretizer>3. KBinsDiscretizer</h3><blockquote><p>make linear model more powerful on continuous data is to use discretization (also known as binning). In the example, we discretize the feature and one-hot encode the transformed data. Note that if the bins are not reasonably wide, there would appear to be a substantially increased risk of overfitting, so the discretizer parameters should usually be tuned under cross validation.</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>fig, (ax1, ax2) <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots(ncols<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, sharey<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>4</span>))
</span></span><span style=display:flex><span>line <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>linspace(<span style=color:#f92672>-</span><span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>1000</span>, endpoint<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)<span style=color:#f92672>.</span>reshape(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>reg <span style=color:#f92672>=</span> LinearRegression()<span style=color:#f92672>.</span>fit(X, y)
</span></span><span style=display:flex><span>ax1<span style=color:#f92672>.</span>plot(line, reg<span style=color:#f92672>.</span>predict(line), linewidth<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;green&#39;</span>,
</span></span><span style=display:flex><span>         label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;linear regression&#34;</span>)
</span></span><span style=display:flex><span>reg <span style=color:#f92672>=</span> DecisionTreeRegressor(min_samples_split<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)<span style=color:#f92672>.</span>fit(X, y)
</span></span><span style=display:flex><span>ax1<span style=color:#f92672>.</span>plot(line, reg<span style=color:#f92672>.</span>predict(line), linewidth<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;red&#39;</span>,
</span></span><span style=display:flex><span>         label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;decision tree&#34;</span>)
</span></span><span style=display:flex><span>ax1<span style=color:#f92672>.</span>plot(X[:, <span style=color:#ae81ff>0</span>], y, <span style=color:#e6db74>&#39;o&#39;</span>, c<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;k&#39;</span>)
</span></span><span style=display:flex><span>ax1<span style=color:#f92672>.</span>legend(loc<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;best&#34;</span>)
</span></span><span style=display:flex><span>ax1<span style=color:#f92672>.</span>set_ylabel(<span style=color:#e6db74>&#34;Regression output&#34;</span>)
</span></span><span style=display:flex><span>ax1<span style=color:#f92672>.</span>set_xlabel(<span style=color:#e6db74>&#34;Input feature&#34;</span>)
</span></span><span style=display:flex><span>ax1<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>&#34;Result before discretization&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># predict with transformed dataset</span>
</span></span><span style=display:flex><span>line_binned <span style=color:#f92672>=</span> enc<span style=color:#f92672>.</span>transform(line)
</span></span><span style=display:flex><span>reg <span style=color:#f92672>=</span> LinearRegression()<span style=color:#f92672>.</span>fit(X_binned, y)
</span></span><span style=display:flex><span>ax2<span style=color:#f92672>.</span>plot(line, reg<span style=color:#f92672>.</span>predict(line_binned), linewidth<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;green&#39;</span>,
</span></span><span style=display:flex><span>         linestyle<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;-&#39;</span>, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;linear regression&#39;</span>)
</span></span><span style=display:flex><span>reg <span style=color:#f92672>=</span> DecisionTreeRegressor(min_samples_split<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>,
</span></span><span style=display:flex><span>                            random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)<span style=color:#f92672>.</span>fit(X_binned, y)
</span></span><span style=display:flex><span>ax2<span style=color:#f92672>.</span>plot(line, reg<span style=color:#f92672>.</span>predict(line_binned), linewidth<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;red&#39;</span>,
</span></span><span style=display:flex><span>         linestyle<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;:&#39;</span>, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;decision tree&#39;</span>)
</span></span><span style=display:flex><span>ax2<span style=color:#f92672>.</span>plot(X[:, <span style=color:#ae81ff>0</span>], y, <span style=color:#e6db74>&#39;o&#39;</span>, c<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;k&#39;</span>)
</span></span><span style=display:flex><span>ax2<span style=color:#f92672>.</span>vlines(enc<span style=color:#f92672>.</span>bin_edges_[<span style=color:#ae81ff>0</span>], <span style=color:#f92672>*</span>plt<span style=color:#f92672>.</span>gca()<span style=color:#f92672>.</span>get_ylim(), linewidth<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>.2</span>)
</span></span><span style=display:flex><span>ax2<span style=color:#f92672>.</span>legend(loc<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;best&#34;</span>)
</span></span><span style=display:flex><span>ax2<span style=color:#f92672>.</span>set_xlabel(<span style=color:#e6db74>&#34;Input feature&#34;</span>)
</span></span><span style=display:flex><span>ax2<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>&#34;Result after discretization&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>tight_layout()
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><p><img class=lazyload src=/liudongdong1.github.io/svg/loading.min.svg data-src=https://gitee.com/github-25970295/blogImage/raw/master/img/20210522210521.png data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/20210522210521.png, https://gitee.com/github-25970295/blogImage/raw/master/img/20210522210521.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/20210522210521.png 2x" data-sizes=auto alt=https://gitee.com/github-25970295/blogImage/raw/master/img/20210522210521.png title=https://gitee.com/github-25970295/blogImage/raw/master/img/20210522210521.png></p><h4 id=1-strateges>.1. Strateges</h4><blockquote><ul><li>‘uniform’: The discretization is uniform in each feature, which means that the bin widths are constant in each dimension.</li><li>quantile’: The discretization is done on the quantiled values, which means that each bin has approximately the same number of samples.</li><li>‘kmeans’: The discretization is based on the centroids of a KMeans clustering procedure.</li></ul></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> KBinsDiscretizer
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.datasets <span style=color:#f92672>import</span> make_blobs
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(__doc__)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>strategies <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;uniform&#39;</span>, <span style=color:#e6db74>&#39;quantile&#39;</span>, <span style=color:#e6db74>&#39;kmeans&#39;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>n_samples <span style=color:#f92672>=</span> <span style=color:#ae81ff>200</span>
</span></span><span style=display:flex><span>centers_0 <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>], [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>5</span>], [<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>4</span>], [<span style=color:#ae81ff>8</span>, <span style=color:#ae81ff>8</span>]])
</span></span><span style=display:flex><span>centers_1 <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>], [<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>1</span>]])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># construct the datasets</span>
</span></span><span style=display:flex><span>random_state <span style=color:#f92672>=</span> <span style=color:#ae81ff>42</span>
</span></span><span style=display:flex><span>X_list <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>RandomState(random_state)<span style=color:#f92672>.</span>uniform(<span style=color:#f92672>-</span><span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>, size<span style=color:#f92672>=</span>(n_samples, <span style=color:#ae81ff>2</span>)),
</span></span><span style=display:flex><span>    make_blobs(n_samples<span style=color:#f92672>=</span>[n_samples <span style=color:#f92672>//</span> <span style=color:#ae81ff>10</span>, n_samples <span style=color:#f92672>*</span> <span style=color:#ae81ff>4</span> <span style=color:#f92672>//</span> <span style=color:#ae81ff>10</span>,
</span></span><span style=display:flex><span>                          n_samples <span style=color:#f92672>//</span> <span style=color:#ae81ff>10</span>, n_samples <span style=color:#f92672>*</span> <span style=color:#ae81ff>4</span> <span style=color:#f92672>//</span> <span style=color:#ae81ff>10</span>],
</span></span><span style=display:flex><span>               cluster_std<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>, centers<span style=color:#f92672>=</span>centers_0,
</span></span><span style=display:flex><span>               random_state<span style=color:#f92672>=</span>random_state)[<span style=color:#ae81ff>0</span>],
</span></span><span style=display:flex><span>    make_blobs(n_samples<span style=color:#f92672>=</span>[n_samples <span style=color:#f92672>//</span> <span style=color:#ae81ff>5</span>, n_samples <span style=color:#f92672>*</span> <span style=color:#ae81ff>4</span> <span style=color:#f92672>//</span> <span style=color:#ae81ff>5</span>],
</span></span><span style=display:flex><span>               cluster_std<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>, centers<span style=color:#f92672>=</span>centers_1,
</span></span><span style=display:flex><span>               random_state<span style=color:#f92672>=</span>random_state)[<span style=color:#ae81ff>0</span>],
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>figure <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>14</span>, <span style=color:#ae81ff>9</span>))
</span></span><span style=display:flex><span>i <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> ds_cnt, X <span style=color:#f92672>in</span> enumerate(X_list):
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    ax <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplot(len(X_list), len(strategies) <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>, i)
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>scatter(X[:, <span style=color:#ae81ff>0</span>], X[:, <span style=color:#ae81ff>1</span>], edgecolors<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;k&#39;</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> ds_cnt <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>&#34;Input data&#34;</span>, size<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    xx, yy <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>meshgrid(
</span></span><span style=display:flex><span>        np<span style=color:#f92672>.</span>linspace(X[:, <span style=color:#ae81ff>0</span>]<span style=color:#f92672>.</span>min(), X[:, <span style=color:#ae81ff>0</span>]<span style=color:#f92672>.</span>max(), <span style=color:#ae81ff>300</span>),
</span></span><span style=display:flex><span>        np<span style=color:#f92672>.</span>linspace(X[:, <span style=color:#ae81ff>1</span>]<span style=color:#f92672>.</span>min(), X[:, <span style=color:#ae81ff>1</span>]<span style=color:#f92672>.</span>max(), <span style=color:#ae81ff>300</span>))
</span></span><span style=display:flex><span>    grid <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>c_[xx<span style=color:#f92672>.</span>ravel(), yy<span style=color:#f92672>.</span>ravel()]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_xlim(xx<span style=color:#f92672>.</span>min(), xx<span style=color:#f92672>.</span>max())
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_ylim(yy<span style=color:#f92672>.</span>min(), yy<span style=color:#f92672>.</span>max())
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_xticks(())
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_yticks(())
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    i <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># transform the dataset with KBinsDiscretizer</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> strategy <span style=color:#f92672>in</span> strategies:
</span></span><span style=display:flex><span>        enc <span style=color:#f92672>=</span> KBinsDiscretizer(n_bins<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>, encode<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;ordinal&#39;</span>, strategy<span style=color:#f92672>=</span>strategy)
</span></span><span style=display:flex><span>        enc<span style=color:#f92672>.</span>fit(X)
</span></span><span style=display:flex><span>        grid_encoded <span style=color:#f92672>=</span> enc<span style=color:#f92672>.</span>transform(grid)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        ax <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplot(len(X_list), len(strategies) <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>, i)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># horizontal stripes</span>
</span></span><span style=display:flex><span>        horizontal <span style=color:#f92672>=</span> grid_encoded[:, <span style=color:#ae81ff>0</span>]<span style=color:#f92672>.</span>reshape(xx<span style=color:#f92672>.</span>shape)
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>contourf(xx, yy, horizontal, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>.5</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># vertical stripes</span>
</span></span><span style=display:flex><span>        vertical <span style=color:#f92672>=</span> grid_encoded[:, <span style=color:#ae81ff>1</span>]<span style=color:#f92672>.</span>reshape(xx<span style=color:#f92672>.</span>shape)
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>contourf(xx, yy, vertical, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>.5</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>scatter(X[:, <span style=color:#ae81ff>0</span>], X[:, <span style=color:#ae81ff>1</span>], edgecolors<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;k&#39;</span>)
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>set_xlim(xx<span style=color:#f92672>.</span>min(), xx<span style=color:#f92672>.</span>max())
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>set_ylim(yy<span style=color:#f92672>.</span>min(), yy<span style=color:#f92672>.</span>max())
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>set_xticks(())
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>set_yticks(())
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> ds_cnt <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>            ax<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>&#34;strategy=&#39;</span><span style=color:#e6db74>%s</span><span style=color:#e6db74>&#39;&#34;</span> <span style=color:#f92672>%</span> (strategy, ), size<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        i <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>tight_layout()
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><p><img class=lazyload src=/liudongdong1.github.io/svg/loading.min.svg data-src=https://gitee.com/github-25970295/blogImage/raw/master/img/20210522210815.png data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/20210522210815.png, https://gitee.com/github-25970295/blogImage/raw/master/img/20210522210815.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/20210522210815.png 2x" data-sizes=auto alt=https://gitee.com/github-25970295/blogImage/raw/master/img/20210522210815.png title=https://gitee.com/github-25970295/blogImage/raw/master/img/20210522210815.png></p><h3 id=4-feature-scaling>4. Feature Scaling</h3><h4 id=1-standardscaler>.1. StandardScaler</h4><blockquote><p>Standardization involves rescaling the features such that they have the properties of a standard normal distribution with a mean of zero and a standard deviation of one.</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> train_test_split
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> StandardScaler
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.decomposition <span style=color:#f92672>import</span> PCA
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.naive_bayes <span style=color:#f92672>import</span> GaussianNB
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn <span style=color:#f92672>import</span> metrics
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.datasets <span style=color:#f92672>import</span> load_wine
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.pipeline <span style=color:#f92672>import</span> make_pipeline
</span></span><span style=display:flex><span>print(__doc__)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Code source: Tyler Lanigan &lt;tylerlanigan@gmail.com&gt;</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#              Sebastian Raschka &lt;mail@sebastianraschka.com&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># License: BSD 3 clause</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>RANDOM_STATE <span style=color:#f92672>=</span> <span style=color:#ae81ff>42</span>
</span></span><span style=display:flex><span>FIG_SIZE <span style=color:#f92672>=</span> (<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>7</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>features, target <span style=color:#f92672>=</span> load_wine(return_X_y<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Make a train/test split using 30% test size</span>
</span></span><span style=display:flex><span>X_train, X_test, y_train, y_test <span style=color:#f92672>=</span> train_test_split(features, target,
</span></span><span style=display:flex><span>                                                    test_size<span style=color:#f92672>=</span><span style=color:#ae81ff>0.30</span>,
</span></span><span style=display:flex><span>                                                    random_state<span style=color:#f92672>=</span>RANDOM_STATE)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Fit to data and predict using pipelined GNB and PCA.</span>
</span></span><span style=display:flex><span>unscaled_clf <span style=color:#f92672>=</span> make_pipeline(PCA(n_components<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>), GaussianNB())
</span></span><span style=display:flex><span>unscaled_clf<span style=color:#f92672>.</span>fit(X_train, y_train)
</span></span><span style=display:flex><span>pred_test <span style=color:#f92672>=</span> unscaled_clf<span style=color:#f92672>.</span>predict(X_test)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Fit to data and predict using pipelined scaling, GNB and PCA.</span>
</span></span><span style=display:flex><span>std_clf <span style=color:#f92672>=</span> make_pipeline(StandardScaler(), PCA(n_components<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>), GaussianNB())
</span></span><span style=display:flex><span>std_clf<span style=color:#f92672>.</span>fit(X_train, y_train)
</span></span><span style=display:flex><span>pred_test_std <span style=color:#f92672>=</span> std_clf<span style=color:#f92672>.</span>predict(X_test)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Show prediction accuracies in scaled and unscaled data.</span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>Prediction accuracy for the normal test dataset with PCA&#39;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;</span><span style=color:#e6db74>{:.2%}</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(metrics<span style=color:#f92672>.</span>accuracy_score(y_test, pred_test)))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>Prediction accuracy for the standardized test dataset with PCA&#39;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;</span><span style=color:#e6db74>{:.2%}</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(metrics<span style=color:#f92672>.</span>accuracy_score(y_test, pred_test_std)))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Extract PCA from pipeline</span>
</span></span><span style=display:flex><span>pca <span style=color:#f92672>=</span> unscaled_clf<span style=color:#f92672>.</span>named_steps[<span style=color:#e6db74>&#39;pca&#39;</span>]
</span></span><span style=display:flex><span>pca_std <span style=color:#f92672>=</span> std_clf<span style=color:#f92672>.</span>named_steps[<span style=color:#e6db74>&#39;pca&#39;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Show first principal components</span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>PC 1 without scaling:</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#39;</span>, pca<span style=color:#f92672>.</span>components_[<span style=color:#ae81ff>0</span>])
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>PC 1 with scaling:</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#39;</span>, pca_std<span style=color:#f92672>.</span>components_[<span style=color:#ae81ff>0</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Use PCA without and with scale on X_train data for visualization.</span>
</span></span><span style=display:flex><span>X_train_transformed <span style=color:#f92672>=</span> pca<span style=color:#f92672>.</span>transform(X_train)
</span></span><span style=display:flex><span>scaler <span style=color:#f92672>=</span> std_clf<span style=color:#f92672>.</span>named_steps[<span style=color:#e6db74>&#39;standardscaler&#39;</span>]
</span></span><span style=display:flex><span>X_train_std_transformed <span style=color:#f92672>=</span> pca_std<span style=color:#f92672>.</span>transform(scaler<span style=color:#f92672>.</span>transform(X_train))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># visualize standardized vs. untouched dataset with PCA performed</span>
</span></span><span style=display:flex><span>fig, (ax1, ax2) <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots(ncols<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, figsize<span style=color:#f92672>=</span>FIG_SIZE)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> l, c, m <span style=color:#f92672>in</span> zip(range(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>3</span>), (<span style=color:#e6db74>&#39;blue&#39;</span>, <span style=color:#e6db74>&#39;red&#39;</span>, <span style=color:#e6db74>&#39;green&#39;</span>), (<span style=color:#e6db74>&#39;^&#39;</span>, <span style=color:#e6db74>&#39;s&#39;</span>, <span style=color:#e6db74>&#39;o&#39;</span>)):
</span></span><span style=display:flex><span>    ax1<span style=color:#f92672>.</span>scatter(X_train_transformed[y_train <span style=color:#f92672>==</span> l, <span style=color:#ae81ff>0</span>],
</span></span><span style=display:flex><span>                X_train_transformed[y_train <span style=color:#f92672>==</span> l, <span style=color:#ae81ff>1</span>],
</span></span><span style=display:flex><span>                color<span style=color:#f92672>=</span>c,
</span></span><span style=display:flex><span>                label<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;class </span><span style=color:#e6db74>%s</span><span style=color:#e6db74>&#39;</span> <span style=color:#f92672>%</span> l,
</span></span><span style=display:flex><span>                alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>,
</span></span><span style=display:flex><span>                marker<span style=color:#f92672>=</span>m
</span></span><span style=display:flex><span>                )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> l, c, m <span style=color:#f92672>in</span> zip(range(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>3</span>), (<span style=color:#e6db74>&#39;blue&#39;</span>, <span style=color:#e6db74>&#39;red&#39;</span>, <span style=color:#e6db74>&#39;green&#39;</span>), (<span style=color:#e6db74>&#39;^&#39;</span>, <span style=color:#e6db74>&#39;s&#39;</span>, <span style=color:#e6db74>&#39;o&#39;</span>)):
</span></span><span style=display:flex><span>    ax2<span style=color:#f92672>.</span>scatter(X_train_std_transformed[y_train <span style=color:#f92672>==</span> l, <span style=color:#ae81ff>0</span>],
</span></span><span style=display:flex><span>                X_train_std_transformed[y_train <span style=color:#f92672>==</span> l, <span style=color:#ae81ff>1</span>],
</span></span><span style=display:flex><span>                color<span style=color:#f92672>=</span>c,
</span></span><span style=display:flex><span>                label<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;class </span><span style=color:#e6db74>%s</span><span style=color:#e6db74>&#39;</span> <span style=color:#f92672>%</span> l,
</span></span><span style=display:flex><span>                alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>,
</span></span><span style=display:flex><span>                marker<span style=color:#f92672>=</span>m
</span></span><span style=display:flex><span>                )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ax1<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>&#39;Training dataset after PCA&#39;</span>)
</span></span><span style=display:flex><span>ax2<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>&#39;Standardized training dataset after PCA&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> ax <span style=color:#f92672>in</span> (ax1, ax2):
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_xlabel(<span style=color:#e6db74>&#39;1st principal component&#39;</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_ylabel(<span style=color:#e6db74>&#39;2nd principal component&#39;</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>legend(loc<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;upper right&#39;</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>grid()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>tight_layout()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><p><img class=lazyload src=/liudongdong1.github.io/svg/loading.min.svg data-src=https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210522211134973.png data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210522211134973.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210522211134973.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210522211134973.png 2x" data-sizes=auto alt=https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210522211134973.png title=https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210522211134973.png></p><h4 id=2-different-scalers>.2. Different Scalers</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib <span style=color:#66d9ef>as</span> mpl
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> matplotlib <span style=color:#f92672>import</span> pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> matplotlib <span style=color:#f92672>import</span> cm
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> MinMaxScaler
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> minmax_scale
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> MaxAbsScaler
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> StandardScaler
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> RobustScaler
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> Normalizer
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> QuantileTransformer
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> PowerTransformer
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.datasets <span style=color:#f92672>import</span> fetch_california_housing
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(__doc__)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>dataset <span style=color:#f92672>=</span> fetch_california_housing()
</span></span><span style=display:flex><span>X_full, y_full <span style=color:#f92672>=</span> dataset<span style=color:#f92672>.</span>data, dataset<span style=color:#f92672>.</span>target
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Take only 2 features to make visualization easier</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Feature of 0 has a long tail distribution.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Feature 5 has a few but very large outliers.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> X_full[:, [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>5</span>]]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>distributions <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#39;Unscaled data&#39;</span>, X),
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#39;Data after standard scaling&#39;</span>,
</span></span><span style=display:flex><span>        StandardScaler()<span style=color:#f92672>.</span>fit_transform(X)),
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#39;Data after min-max scaling&#39;</span>,
</span></span><span style=display:flex><span>        MinMaxScaler()<span style=color:#f92672>.</span>fit_transform(X)),
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#39;Data after max-abs scaling&#39;</span>,
</span></span><span style=display:flex><span>        MaxAbsScaler()<span style=color:#f92672>.</span>fit_transform(X)),
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#39;Data after robust scaling&#39;</span>,
</span></span><span style=display:flex><span>        RobustScaler(quantile_range<span style=color:#f92672>=</span>(<span style=color:#ae81ff>25</span>, <span style=color:#ae81ff>75</span>))<span style=color:#f92672>.</span>fit_transform(X)),
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#39;Data after power transformation (Yeo-Johnson)&#39;</span>,
</span></span><span style=display:flex><span>     PowerTransformer(method<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;yeo-johnson&#39;</span>)<span style=color:#f92672>.</span>fit_transform(X)),
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#39;Data after power transformation (Box-Cox)&#39;</span>,
</span></span><span style=display:flex><span>     PowerTransformer(method<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;box-cox&#39;</span>)<span style=color:#f92672>.</span>fit_transform(X)),
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#39;Data after quantile transformation (uniform pdf)&#39;</span>,
</span></span><span style=display:flex><span>        QuantileTransformer(output_distribution<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;uniform&#39;</span>)
</span></span><span style=display:flex><span>        <span style=color:#f92672>.</span>fit_transform(X)),
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#39;Data after quantile transformation (gaussian pdf)&#39;</span>,
</span></span><span style=display:flex><span>        QuantileTransformer(output_distribution<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;normal&#39;</span>)
</span></span><span style=display:flex><span>        <span style=color:#f92672>.</span>fit_transform(X)),
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#39;Data after sample-wise L2 normalizing&#39;</span>,
</span></span><span style=display:flex><span>        Normalizer()<span style=color:#f92672>.</span>fit_transform(X)),
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># scale the output between 0 and 1 for the colorbar</span>
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> minmax_scale(y_full)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># plasma does not exist in matplotlib &lt; 1.5</span>
</span></span><span style=display:flex><span>cmap <span style=color:#f92672>=</span> getattr(cm, <span style=color:#e6db74>&#39;plasma_r&#39;</span>, cm<span style=color:#f92672>.</span>hot_r)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>create_axes</span>(title, figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>16</span>, <span style=color:#ae81ff>6</span>)):
</span></span><span style=display:flex><span>    fig <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>figsize)
</span></span><span style=display:flex><span>    fig<span style=color:#f92672>.</span>suptitle(title)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># define the axis for the first plot</span>
</span></span><span style=display:flex><span>    left, width <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.1</span>, <span style=color:#ae81ff>0.22</span>
</span></span><span style=display:flex><span>    bottom, height <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.1</span>, <span style=color:#ae81ff>0.7</span>
</span></span><span style=display:flex><span>    bottom_h <span style=color:#f92672>=</span> height <span style=color:#f92672>+</span> <span style=color:#ae81ff>0.15</span>
</span></span><span style=display:flex><span>    left_h <span style=color:#f92672>=</span> left <span style=color:#f92672>+</span> width <span style=color:#f92672>+</span> <span style=color:#ae81ff>0.02</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    rect_scatter <span style=color:#f92672>=</span> [left, bottom, width, height]
</span></span><span style=display:flex><span>    rect_histx <span style=color:#f92672>=</span> [left, bottom_h, width, <span style=color:#ae81ff>0.1</span>]
</span></span><span style=display:flex><span>    rect_histy <span style=color:#f92672>=</span> [left_h, bottom, <span style=color:#ae81ff>0.05</span>, height]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    ax_scatter <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>axes(rect_scatter)
</span></span><span style=display:flex><span>    ax_histx <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>axes(rect_histx)
</span></span><span style=display:flex><span>    ax_histy <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>axes(rect_histy)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># define the axis for the zoomed-in plot</span>
</span></span><span style=display:flex><span>    left <span style=color:#f92672>=</span> width <span style=color:#f92672>+</span> left <span style=color:#f92672>+</span> <span style=color:#ae81ff>0.2</span>
</span></span><span style=display:flex><span>    left_h <span style=color:#f92672>=</span> left <span style=color:#f92672>+</span> width <span style=color:#f92672>+</span> <span style=color:#ae81ff>0.02</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    rect_scatter <span style=color:#f92672>=</span> [left, bottom, width, height]
</span></span><span style=display:flex><span>    rect_histx <span style=color:#f92672>=</span> [left, bottom_h, width, <span style=color:#ae81ff>0.1</span>]
</span></span><span style=display:flex><span>    rect_histy <span style=color:#f92672>=</span> [left_h, bottom, <span style=color:#ae81ff>0.05</span>, height]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    ax_scatter_zoom <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>axes(rect_scatter)
</span></span><span style=display:flex><span>    ax_histx_zoom <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>axes(rect_histx)
</span></span><span style=display:flex><span>    ax_histy_zoom <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>axes(rect_histy)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># define the axis for the colorbar</span>
</span></span><span style=display:flex><span>    left, width <span style=color:#f92672>=</span> width <span style=color:#f92672>+</span> left <span style=color:#f92672>+</span> <span style=color:#ae81ff>0.13</span>, <span style=color:#ae81ff>0.01</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    rect_colorbar <span style=color:#f92672>=</span> [left, bottom, width, height]
</span></span><span style=display:flex><span>    ax_colorbar <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>axes(rect_colorbar)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> ((ax_scatter, ax_histy, ax_histx),
</span></span><span style=display:flex><span>            (ax_scatter_zoom, ax_histy_zoom, ax_histx_zoom),
</span></span><span style=display:flex><span>            ax_colorbar)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>plot_distribution</span>(axes, X, y, hist_nbins<span style=color:#f92672>=</span><span style=color:#ae81ff>50</span>, title<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;&#34;</span>,
</span></span><span style=display:flex><span>                      x0_label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;&#34;</span>, x1_label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;&#34;</span>):
</span></span><span style=display:flex><span>    ax, hist_X1, hist_X0 <span style=color:#f92672>=</span> axes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_title(title)
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_xlabel(x0_label)
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_ylabel(x1_label)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># The scatter plot</span>
</span></span><span style=display:flex><span>    colors <span style=color:#f92672>=</span> cmap(y)
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>scatter(X[:, <span style=color:#ae81ff>0</span>], X[:, <span style=color:#ae81ff>1</span>], alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>, marker<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;o&#39;</span>, s<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>, lw<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, c<span style=color:#f92672>=</span>colors)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Removing the top and the right spine for aesthetics</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># make nice axis layout</span>
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>spines[<span style=color:#e6db74>&#39;top&#39;</span>]<span style=color:#f92672>.</span>set_visible(<span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>spines[<span style=color:#e6db74>&#39;right&#39;</span>]<span style=color:#f92672>.</span>set_visible(<span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>get_xaxis()<span style=color:#f92672>.</span>tick_bottom()
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>get_yaxis()<span style=color:#f92672>.</span>tick_left()
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>spines[<span style=color:#e6db74>&#39;left&#39;</span>]<span style=color:#f92672>.</span>set_position((<span style=color:#e6db74>&#39;outward&#39;</span>, <span style=color:#ae81ff>10</span>))
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>spines[<span style=color:#e6db74>&#39;bottom&#39;</span>]<span style=color:#f92672>.</span>set_position((<span style=color:#e6db74>&#39;outward&#39;</span>, <span style=color:#ae81ff>10</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Histogram for axis X1 (feature 5)</span>
</span></span><span style=display:flex><span>    hist_X1<span style=color:#f92672>.</span>set_ylim(ax<span style=color:#f92672>.</span>get_ylim())
</span></span><span style=display:flex><span>    hist_X1<span style=color:#f92672>.</span>hist(X[:, <span style=color:#ae81ff>1</span>], bins<span style=color:#f92672>=</span>hist_nbins, orientation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;horizontal&#39;</span>,
</span></span><span style=display:flex><span>                 color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;grey&#39;</span>, ec<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;grey&#39;</span>)
</span></span><span style=display:flex><span>    hist_X1<span style=color:#f92672>.</span>axis(<span style=color:#e6db74>&#39;off&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Histogram for axis X0 (feature 0)</span>
</span></span><span style=display:flex><span>    hist_X0<span style=color:#f92672>.</span>set_xlim(ax<span style=color:#f92672>.</span>get_xlim())
</span></span><span style=display:flex><span>    hist_X0<span style=color:#f92672>.</span>hist(X[:, <span style=color:#ae81ff>0</span>], bins<span style=color:#f92672>=</span>hist_nbins, orientation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;vertical&#39;</span>,
</span></span><span style=display:flex><span>                 color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;grey&#39;</span>, ec<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;grey&#39;</span>)
</span></span><span style=display:flex><span>    hist_X0<span style=color:#f92672>.</span>axis(<span style=color:#e6db74>&#39;off&#39;</span>)
</span></span><span style=display:flex><span><span style=color:#75715e># 不同的scale 处理效果</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>make_plot</span>(item_idx):
</span></span><span style=display:flex><span>    title, X <span style=color:#f92672>=</span> distributions[item_idx]
</span></span><span style=display:flex><span>    ax_zoom_out, ax_zoom_in, ax_colorbar <span style=color:#f92672>=</span> create_axes(title)
</span></span><span style=display:flex><span>    axarr <span style=color:#f92672>=</span> (ax_zoom_out, ax_zoom_in)
</span></span><span style=display:flex><span>    plot_distribution(axarr[<span style=color:#ae81ff>0</span>], X, y, hist_nbins<span style=color:#f92672>=</span><span style=color:#ae81ff>200</span>,
</span></span><span style=display:flex><span>                      x0_label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Median Income&#34;</span>,
</span></span><span style=display:flex><span>                      x1_label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Number of households&#34;</span>,
</span></span><span style=display:flex><span>                      title<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Full data&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># zoom-in</span>
</span></span><span style=display:flex><span>    zoom_in_percentile_range <span style=color:#f92672>=</span> (<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>99</span>)
</span></span><span style=display:flex><span>    cutoffs_X0 <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>percentile(X[:, <span style=color:#ae81ff>0</span>], zoom_in_percentile_range)
</span></span><span style=display:flex><span>    cutoffs_X1 <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>percentile(X[:, <span style=color:#ae81ff>1</span>], zoom_in_percentile_range)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    non_outliers_mask <span style=color:#f92672>=</span> (
</span></span><span style=display:flex><span>        np<span style=color:#f92672>.</span>all(X <span style=color:#f92672>&gt;</span> [cutoffs_X0[<span style=color:#ae81ff>0</span>], cutoffs_X1[<span style=color:#ae81ff>0</span>]], axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>) <span style=color:#f92672>&amp;</span>
</span></span><span style=display:flex><span>        np<span style=color:#f92672>.</span>all(X <span style=color:#f92672>&lt;</span> [cutoffs_X0[<span style=color:#ae81ff>1</span>], cutoffs_X1[<span style=color:#ae81ff>1</span>]], axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span>    plot_distribution(axarr[<span style=color:#ae81ff>1</span>], X[non_outliers_mask], y[non_outliers_mask],
</span></span><span style=display:flex><span>                      hist_nbins<span style=color:#f92672>=</span><span style=color:#ae81ff>50</span>,
</span></span><span style=display:flex><span>                      x0_label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Median Income&#34;</span>,
</span></span><span style=display:flex><span>                      x1_label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Number of households&#34;</span>,
</span></span><span style=display:flex><span>                      title<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Zoom-in&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    norm <span style=color:#f92672>=</span> mpl<span style=color:#f92672>.</span>colors<span style=color:#f92672>.</span>Normalize(y_full<span style=color:#f92672>.</span>min(), y_full<span style=color:#f92672>.</span>max())
</span></span><span style=display:flex><span>    mpl<span style=color:#f92672>.</span>colorbar<span style=color:#f92672>.</span>ColorbarBase(ax_colorbar, cmap<span style=color:#f92672>=</span>cmap,
</span></span><span style=display:flex><span>                              norm<span style=color:#f92672>=</span>norm, orientation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;vertical&#39;</span>,
</span></span><span style=display:flex><span>                              label<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Color mapping for values of y&#39;</span>)
</span></span></code></pre></div><h5 id=1-minmaxscaler>.1. MinMaxScaler</h5><blockquote><p><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler target=_blank rel="external nofollow noopener noreferrer"><code>MinMaxScaler</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a> rescales the data set such that all feature values are in the range [0, 1] as shown in the right panel below.</p></blockquote><h5 id=2-standscaler>.2. StandScaler</h5><blockquote><p><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler target=_blank rel="external nofollow noopener noreferrer"><code>StandardScaler</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a> removes the mean and scales the data to unit variance.</p></blockquote><h5 id=3-maxabsscaler>.3. MaxAbsScaler</h5><blockquote><p><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler target=_blank rel="external nofollow noopener noreferrer"><code>MaxAbsScaler</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a> is similar to <a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler target=_blank rel="external nofollow noopener noreferrer"><code>MinMaxScaler</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a> except that the values are mapped in the range [0, 1]. On positive only data, both scalers behave similarly. <a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler target=_blank rel="external nofollow noopener noreferrer"><code>MaxAbsScaler</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a> therefore also suffers from the presence of large outliers.</p></blockquote><h5 id=4-robustscaler>.4. RobustScaler</h5><blockquote><p>the centering and scaling statistics of <a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler target=_blank rel="external nofollow noopener noreferrer"><code>RobustScaler</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a> is <code>based on percentiles</code> and are therefore<code> not influenced by a few number of very large marginal outliers.</code></p></blockquote><h5 id=5-powertransformer>.5. PowerTransformer</h5><blockquote><p><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html#sklearn.preprocessing.PowerTransformer target=_blank rel="external nofollow noopener noreferrer"><code>PowerTransformer</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a> applies a power transformation to each feature to make the data <code>more Gaussian-like in order</code> to <code>stabilize variance and minimize skewness</code>.</p></blockquote><h5 id=6-quantiletransformer>.6. QuantileTransformer</h5><blockquote><p><a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html#sklearn.preprocessing.QuantileTransformer target=_blank rel="external nofollow noopener noreferrer"><code>QuantileTransformer</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a> applies a <code>non-linear transformation</code> such that the probability density function of each feature will be mapped to a<code> uniform or Gaussian distribution</code>. In this case, all the data, including outliers, will be mapped to a uniform distribution with the range [0, 1], making outliers indistinguishable from inliers.</p></blockquote><h5 id=7-normalizer>.7. Normalizer</h5><blockquote><p>The <a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer target=_blank rel="external nofollow noopener noreferrer"><code>Normalizer</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a> rescales the vector for each sample to have unit norm, independently of the distribution of the samples.</p></blockquote><h3 id=resource>Resource</h3><ul><li><a href=https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing target=_blank rel="external nofollow noopener noreferrer">https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></li></ul></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span title="2023-09-28 22:45:34">更新于 2023-09-28&nbsp;</span></div><div class=post-info-license><span><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div><div class=post-info-line><div class=post-info-md><span><a href=liudongdong1.github.io/datapreprocessing/index.md title=阅读原始文档 class=link-to-markdown>阅读原始文档</a></span><span><a href=https://liudongdong1.github.io/edit/master/content/posts%5c%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%5cSklearn%5cDataPreprocessing.md title=编辑此页 target=_blank rel="external nofollow noopener noreferrer" class=link-to-edit>编辑此页</a></span></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 Twitter" data-sharer=twitter data-url=liudongdong1.github.io/datapreprocessing/ data-title=DataPreprocessing data-hashtags=SkLearn><i class="fa-brands fa-twitter fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Facebook" data-sharer=facebook data-url=liudongdong1.github.io/datapreprocessing/ data-hashtag=SkLearn><i class="fa-brands fa-facebook-square fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=liudongdong1.github.io/datapreprocessing/ data-title=DataPreprocessing data-image=https://gitee.com/github-25970295/blogImage/raw/master/img/20210522212626.png><i class="fa-brands fa-weibo fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fa-solid fa-tags fa-fw" aria-hidden=true></i>&nbsp;<a href=liudongdong1.github.io/tags/sklearn/>Sklearn</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=liudongdong1.github.io/>主页</a></span></section></div><div class=post-nav><a href=liudongdong1.github.io/sklearndataflow/ class=prev rel=prev title=SkLearnDataFlow><i class="fa-solid fa-angle-left fa-fw" aria-hidden=true></i>SkLearnDataFlow</a>
<a href=liudongdong1.github.io/distribution/ class=next rel=next title=Distribution>Distribution<i class="fa-solid fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></main><footer class=footer><div class=footer-container><div class="footer-line powered">由 <a href=https://gohugo.io/ target=_blank rel="external nofollow noopener noreferrer" title="Hugo 0.118.2">Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/hugo-fixit/FixIt target=_blank rel=external title="FixIt v0.2.17-RC"><img class=fixit-icon src=/liudongdong1.github.io/fixit.min.svg alt="FixIt logo">&nbsp;FixIt</a></div><div class="footer-line copyright" itemscope itemtype=http://schema.org/CreativeWork><i class="fa-regular fa-copyright fa-fw" aria-hidden=true></i>
<span itemprop=copyrightYear>2020 - 2023</span><span class=author itemprop=copyrightHolder>
<a href=https://liudongdong1.github.io/ target=_blank rel="external nofollow noopener noreferrer">LiuDongdong</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div><div class="footer-line statistics"><span class=site-time title='网站运行中 ...'><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden=true></i>&nbsp;<span class=run-times>网站运行中 ...</span></span></div><div class="footer-line ibruce"><span id=busuanzi_container_site_uv title=总访客数><i class="fa-regular fa-user fa-fw" aria-hidden=true></i>&nbsp;<span id=busuanzi_value_site_uv><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden=true></i></span></span><span id=busuanzi_container_site_pv class=footer-divider title=总访问量><i class="fa-regular fa-eye fa-fw" aria-hidden=true></i>&nbsp;<span id=busuanzi_value_site_pv><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden=true></i></span></span></div></div></footer></div><div class=widgets><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role=button aria-label=回到顶部><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><span class=variant-numeric>0%</span></div></div><a href=https://liudongdong1.github.io/ title="在 GitHub 上查看源代码" target=_blank rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115h15l12 27L250 250V0z"/><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentcolor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4l13.9-13.8C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8z" fill="currentcolor" class="octo-body"/></svg></a><div id=mask></div><div class=reading-progress-bar style=left:0;top:0;--bg-progress:#0076ff;--bg-progress-dark:#fff></div><noscript><div class=noscript-warning>FixIt 主题在启用 JavaScript 的情况下效果最佳。</div></noscript></div><link rel=stylesheet href=/liudongdong1.github.io/lib/katex/katex.min.css><link rel=stylesheet href=/liudongdong1.github.io/lib/cookieconsent/cookieconsent.min.css><script src=/liudongdong1.github.io/lib/autocomplete/autocomplete.min.js defer></script><script src=/liudongdong1.github.io/lib/algoliasearch/algoliasearch-lite.umd.min.js defer></script><script src=/liudongdong1.github.io/lib/lazysizes/lazysizes.min.js async defer></script><script src=/liudongdong1.github.io/lib/sharer/sharer.min.js async defer></script><script src=/liudongdong1.github.io/lib/typeit/index.umd.js defer></script><script src=/liudongdong1.github.io/lib/katex/katex.min.js defer></script><script src=/liudongdong1.github.io/lib/katex/auto-render.min.js defer></script><script src=/liudongdong1.github.io/lib/katex/copy-tex.min.js defer></script><script src=/liudongdong1.github.io/lib/katex/mhchem.min.js defer></script><script src=/liudongdong1.github.io/lib/cookieconsent/cookieconsent.min.js defer></script><script src=/liudongdong1.github.io/lib/pangu/pangu.min.js defer></script><script src=/liudongdong1.github.io/lib/cell-watermark/watermark.min.js defer></script><script src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js async defer></script><script>window.config={code:{copyTitle:"复制到剪贴板",editLockTitle:"锁定可编辑代码块",editUnLockTitle:"解锁可编辑代码块",editable:!0,maxShownLines:10},comment:{enable:!1},cookieconsent:{content:{dismiss:"同意",link:"了解更多",message:"本网站使用 Cookies 来改善您的浏览体验。"},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},data:{"typeit-header-subtitle-desktop":`<span style='font-family: MMT,"沐目体";'>吾日三省吾身</span>`,"typeit-header-subtitle-mobile":`<span style='font-family: MMT,"沐目体";'>吾日三省吾身</span>`},enablePWA:!0,enablePangu:!0,math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{algoliaAppID:"2R1K9SKLQZ",algoliaIndex:"index.zh-cn",algoliaSearchKey:"4a226aa1c5c98d6859e4d1386adb2bc7",highlightTag:"em",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50,type:"algolia"},siteTime:"2020-12-18T16:15:22+08:00",typeit:{cursorChar:"|",cursorSpeed:1e3,data:{"typeit-header-subtitle-desktop":["typeit-header-subtitle-desktop"],"typeit-header-subtitle-mobile":["typeit-header-subtitle-mobile"]},duration:-1,speed:100},watermark:{appendto:".wrapper>main",colspacing:30,content:'<img class="fixit-icon" src="/fixit.min.svg" alt="FixIt logo" /> FixIt 主题',enable:!0,fontfamily:"inherit",fontsize:.85,height:21,opacity:.0125,rotate:15,rowspacing:60,width:150}}</script><script src=/liudongdong1.github.io/js/theme.min.js defer></script><script src=/liudongdong1.github.io/js/custom.min.js defer></script></body></html>