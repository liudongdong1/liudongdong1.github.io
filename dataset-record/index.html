<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <head>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>DataSet_Record - DAY By DAY</title><meta name="author" content="LiuDongdong">
<meta name="author-link" content="https://liudongdong1.github.io/">
<meta name="description" content="在以数据驱动的人工智能时代，本文用于平时学习或者阅读论文中所涉及到的开源数据集积累。dataset知识图谱 More:https://www.codetd.com/article/7219369 Dataset: https://www.cnblogs.com/xiaojianliu/p/9446358.html FaceScape 一个大规模高质量的3D人脸" /><meta name="keywords" content='Dataset' /><meta itemprop="name" content="DataSet_Record">
<meta itemprop="description" content="在以数据驱动的人工智能时代，本文用于平时学习或者阅读论文中所涉及到的开源数据集积累。dataset知识图谱 More:https://www.codetd.com/article/7219369 Dataset: https://www.cnblogs.com/xiaojianliu/p/9446358.html FaceScape 一个大规模高质量的3D人脸"><meta itemprop="datePublished" content="2020-07-13T10:30:29+00:00" />
<meta itemprop="dateModified" content="2023-12-31T16:55:08+08:00" />
<meta itemprop="wordCount" content="5754"><meta itemprop="image" content="https://liudongdong1.github.io/logo.png"/>
<meta itemprop="keywords" content="Dataset," /><meta property="og:title" content="DataSet_Record" />
<meta property="og:description" content="在以数据驱动的人工智能时代，本文用于平时学习或者阅读论文中所涉及到的开源数据集积累。dataset知识图谱 More:https://www.codetd.com/article/7219369 Dataset: https://www.cnblogs.com/xiaojianliu/p/9446358.html FaceScape 一个大规模高质量的3D人脸" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://liudongdong1.github.io/dataset-record/" /><meta property="og:image" content="https://liudongdong1.github.io/logo.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-07-13T10:30:29+00:00" />
<meta property="article:modified_time" content="2023-12-31T16:55:08+08:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://liudongdong1.github.io/logo.png"/>

<meta name="twitter:title" content="DataSet_Record"/>
<meta name="twitter:description" content="在以数据驱动的人工智能时代，本文用于平时学习或者阅读论文中所涉及到的开源数据集积累。dataset知识图谱 More:https://www.codetd.com/article/7219369 Dataset: https://www.cnblogs.com/xiaojianliu/p/9446358.html FaceScape 一个大规模高质量的3D人脸"/>
<meta name="application-name" content="DAY By DAY">
<meta name="apple-mobile-web-app-title" content="DAY By DAY"><meta name="theme-color" data-light="#f8f8f8" data-dark="#252627" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://liudongdong1.github.io/dataset-record/" /><link rel="prev" href="https://liudongdong1.github.io/siamesenetwork/" /><link rel="next" href="https://liudongdong1.github.io/pytorchpoint/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "DataSet_Record",
    "inLanguage": "zh-CN",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https:\/\/liudongdong1.github.io\/dataset-record\/"
    },"genre": "posts","keywords": "Dataset","wordcount":  5754 ,
    "url": "https:\/\/liudongdong1.github.io\/dataset-record\/","datePublished": "2020-07-13T10:30:29+00:00","dateModified": "2023-12-31T16:55:08+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
      "@type": "Organization",
      "name": "LiuDongdong","logo": "https:\/\/liudongdong1.github.io\/images\/person.png"},"author": {
        "@type": "Person",
        "name": "liudongdong1"
      },"description": ""
  }
  </script></head>
  <body data-header-desktop="auto" data-header-mobile="auto"><script>(window.localStorage?.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('data-theme', 'dark');</script><div class="wrapper"><script type="text/javascript"
        async
        src="https://cdnjs.cloudflare.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>
<header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper" data-github-corner="right">
    <div class="header-title">
      <a href="/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="DAY By DAY"
    title="DAY By DAY"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-desktop" class="typeit header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a
                class="menu-link"
                href="/posts/"
                
                
              ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/categories/"
                
                
              ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/tags/"
                
                
              ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/friends/"
                title="友情链接"
                
              ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/about/"
                
                
              ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li class="menu-item delimiter"></li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <ul class="sub-menu"><li class="menu-item">没有更多翻译</li></ul>
          </li><li class="menu-item search" id="search-desktop">
            <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-desktop">
            <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
              <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
            </a>
            <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
              <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
            </a>
            <span class="search-button search-loading" id="search-loading-desktop">
              <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
            </span>
          </li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li>
      </ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="/fixit.min.svg"
    title="/fixit.min.svg"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-mobile" class="typeit header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li class="search-wrapper">
            <div class="search mobile" id="search-mobile">
              <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-mobile">
              <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
              </a>
              <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
              </a>
              <span class="search-button search-loading" id="search-loading-mobile">
                <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
              </span>
            </div>
            <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
              取消
            </a>
          </li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/posts/"
                  
                  
                ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/categories/"
                  
                  
                ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/tags/"
                  
                  
                ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/friends/"
                  title="友情链接"
                  
                ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/about/"
                  
                  
                ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li
              class="menu-item text-center"
            ><a
                  class="menu-link"
                  href="/"
                  title="GitHub"
                  
                ><i class='fa-brands fa-github fa-fw' aria-hidden='true'></i> </a></li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <select class="language-select" onchange="location = this.value;"><option disabled>没有更多翻译</option></select>
          </li></ul>
    </nav>
  </div>
</header><div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
  </div>
  <div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
  </div><main class="container" data-page-style="normal"><aside class="toc" id="toc-auto"><h2 class="toc-title">目录 <i class="toc-icon fa-solid fa-angle-down fa-fw"></i></h2>
      <div class="toc-content" id="toc-content-auto"></div></aside>

  <aside class="aside-custom" id="aside-sakana">
    

<div class="sakana-widget">
  <div class="sakana-item" id="takina-widget"></div>
  <div class="sakana-item" id="chisato-widget"></div>
</div>
<script>
  function initSakanaWidget() {
    const takina = SakanaWidget.getCharacter('takina')
    SakanaWidget.registerCharacter('takina-slow', takina);
    new SakanaWidget({
      character: 'takina-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#takina-widget');

    const chisato = SakanaWidget.getCharacter('chisato')
    SakanaWidget.registerCharacter('chisato-slow', chisato);
    new SakanaWidget({
      character: 'chisato-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#chisato-widget');
  }
</script>
<script async onload="initSakanaWidget()" src="https://cdn.jsdelivr.net/npm/sakana-widget@2.3.0/lib/sakana.min.js">
</script></aside>

  <article class="page single">
    <div class="header"><h1 class="single-title animate__animated animate__flipInX">
        <span>DataSet_Record</span>
      </h1></div><div class="post-meta">
      <div class="post-meta-line"><span class="post-author"><span class="author"><i class="fa-solid fa-user-circle" aria-hidden="true"></i>
      liudongdong1</span></span>
          <span class="post-category">收录于 <a href="/categories/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;Categories</a>&ensp;<a href="/categories/%E8%A7%86%E8%A7%89ai/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;视觉AI</a></span></div>
      <div class="post-meta-line"><span title=2020-07-13&#32;10:30:29>
            <i class="fa-regular fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2020-07-13" >2020-07-13</time>
          </span>&nbsp;<i class="fa-solid fa-pencil-alt fa-fw"></i>&nbsp;约 5754 字&nbsp;
        <i class="fa-regular fa-clock fa-fw"></i>&nbsp;预计阅读 12 分钟&nbsp;<span id="busuanzi_container_page_pv" class="busuanzi_visitors comment-visitors" data-flag-title="DataSet_Record">
            <i class="fa-regular fa-eye fa-fw"></i>&nbsp;<span id="busuanzi_value_page_pv">-</span>&nbsp;次阅读
          </span>&nbsp;</div>
    </div><div class="featured-image"><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://cdn.stocksnap.io/img-thumbs/280h/O00MGHPXG6.jpg"
    data-srcset="https://cdn.stocksnap.io/img-thumbs/280h/O00MGHPXG6.jpg, https://cdn.stocksnap.io/img-thumbs/280h/O00MGHPXG6.jpg 1.5x, https://cdn.stocksnap.io/img-thumbs/280h/O00MGHPXG6.jpg 2x"
    data-sizes="auto"
    alt="https://cdn.stocksnap.io/img-thumbs/280h/O00MGHPXG6.jpg"
    title="https://cdn.stocksnap.io/img-thumbs/280h/O00MGHPXG6.jpg"/></div><div class="details toc" id="toc-static" kept="true">
        <div class="details-summary toc-title">
          <span>目录</span>
          <span><i class="details-icon fa-solid fa-angle-right"></i></span>
        </div>
        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#1-image-analysis">1. Image Analysis</a></li>
    <li><a href="#2-image-motiontracking">2. Image Motion&amp;&amp;Tracking</a></li>
    <li><a href="#3-video-analysis--scene-understanding">3. Video Analysis &amp; Scene Understanding</a></li>
    <li><a href="#4-3d-computer-vision">4. 3D Computer Vision</a></li>
    <li><a href="#5-analyzing-humans-in-images">5. Analyzing Humans in Images</a></li>
    <li><a href="#6-application">6. Application</a></li>
    <li><a href="#7-low---mid-level-vision">7. Low- &amp; Mid-Level Vision</a></li>
    <li><a href="#8-text">8. Text</a></li>
    <li><a href="#9-car-relative">9. Car Relative</a></li>
  </ul>
</nav></div>
      </div><div
      class="content"
      id="content"
      
      
    ><blockquote>
<p>在以数据驱动的人工智能时代，本文用于平时学习或者阅读论文中所涉及到的开源数据集积累。<a href="https://lod-cloud.net/"target="_blank" rel="external nofollow noopener noreferrer">dataset知识图谱<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</blockquote>
<p>More:https://www.codetd.com/article/7219369</p>
<ul>
<li>
<p>Dataset: <a href="https://www.cnblogs.com/xiaojianliu/p/9446358.html"target="_blank" rel="external nofollow noopener noreferrer">https://www.cnblogs.com/xiaojianliu/p/9446358.html<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</li>
<li>
<p><a href="https://facescape.nju.edu.cn/"target="_blank" rel="external nofollow noopener noreferrer"><strong>FaceScape</strong><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</li>
</ul>
<blockquote>
<p>一个大规模高质量的3D人脸数据集，包括18760张高质量3D人脸模型，对938名志愿者实现20种表情采集，该数据训练可以实现对单张图像预测3D人脸的细节。</p>
</blockquote>
<ul>
<li><a href="https://oasis.cs.princeton.edu/"target="_blank" rel="external nofollow noopener noreferrer">OASIS<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
</ul>
<blockquote>
<p>开放的单图表面标注，是大规模的单图三维表面数据集。该数据集采用了14万张的互联网图像，人工标注实现了三维表面像素级重建。该数据集可以在深度估算、三维表面重建、边缘检测、实例分割等方向上帮助研究者。</p>
</blockquote>
<ul>
<li><a href="https://waymo.com/open"target="_blank" rel="external nofollow noopener noreferrer">Waymo<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
</ul>
<blockquote>
<p>Waymo开源的大规模、高质量、自动驾驶数据集。该数据包含大量高质量手动标注的3D与2D图像，包含了1150个场景，涵盖雷达与相机导航数据，城市与乡村道路。</p>
</blockquote>
<ul>
<li><a href="https://github.com/cvdfoundation/google-landmark"target="_blank" rel="external nofollow noopener noreferrer">人脸landmark 数据<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
</ul>
<blockquote>
<p>Google Landmarks Dataset v2，一个大规模的图像检索与识别基准数据集。采集了20W人的500W的数据。</p>
</blockquote>
<ul>
<li><a href="https://sdolivia.github.io/FineGym/"target="_blank" rel="external nofollow noopener noreferrer">FineGym<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
</ul>
<blockquote>
<p>基于细粒度动作理解的层次化视频数据集，主要为了动作识别领域的研究需要，由港中大开发的大规模、高质量的动作细粒度识别数据集。数据集在动作和子动作两个层次上实现标注，具有三个层次的语义，具有多个不同层次的语义。</p>
</blockquote>
<ul>
<li><a href="https://github.com/zhixuany/HUMBI"target="_blank" rel="external nofollow noopener noreferrer">HUMBI<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
</ul>
<blockquote>
<p>一个新的大规模多视角人体表达数据集，包含多个视角的自然衣着状态下的人体表达，这个数据集的主要目的是帮助更加有效的学习与重建人体，它是MPII-Gaze, Multi-PIE, Human3.6M, and Panoptic Studio datasets这些数据集的补充。</p>
</blockquote>
<ul>
<li><a href="https://github.com/jimmy646/violin"target="_blank" rel="external nofollow noopener noreferrer">VIOLIN<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
</ul>
<blockquote>
<p>视频与语言推理，一个新的大规模数据集，总计15887个视频片段包含95322个视频假设对，超过582个小时的视频，这些视频内容丰富，时间跨度大。主要来自流行的电视剧、电影剪切片段、油管。</p>
</blockquote>
<h2 id="1-image-analysis">1. Image Analysis</h2>
<table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody>
<tr>
<td>Flickr30k</td>
<td>图片描述</td>
<td>31,783 images，每张图片5个语句标注</td>
<td><a href="http://web.engr.illinois.edu/~bplumme2/Flickr30kEntities/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Microsoft COCO</td>
<td>图片描述</td>
<td>330,000 images,每张图片至少5个语句标注</td>
<td><a href="http://cocodataset.org/#download"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>ESP Game</td>
<td>多标签定义图像</td>
<td>20,770 images，268 tags，诸如bed, light man,music</td>
<td><a href="https://www.kaggle.com/c/challenges-in-representation-learning-multi-modal-learning/data"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>IAPRTC-12</td>
<td>多标签定义图像</td>
<td>19,452 images,291 tags</td>
<td><a href="http://www.imageclef.org/photodata"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>NUS-WIDE</td>
<td>多标签定义图像</td>
<td>269,648 images,several tags (2-5 on average) per image</td>
<td><a href="http://lms.comp.nus.edu.sg/research/NUS-WIDE.htm"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>CUHK-PEDES</td>
<td>以文搜图</td>
<td>34,054 images，每张图片2条描述</td>
<td><a href="http://cuhk-pedes.shuanglee.me/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>VRD</td>
<td>视觉关系检测</td>
<td>5,000 images, 100目录，37,993对关系</td>
<td><a href="https://cs.stanford.edu/people/ranjaykrishna/vrd/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>sVG</td>
<td>视觉关系检测</td>
<td>108,000 images, 998,000对关系</td>
<td><a href="https://drive.google.com/file/d/0B5RJWjAhdT04SXRfVHBKZ0dOTzQ/view"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Visual Genome Dataset</td>
<td>图像属性检测</td>
<td>108,077 images, 5.4 M 区域块，2.8 M 属性，2.3 M 关系</td>
<td><a href="https://visualgenome.org/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>VQA</td>
<td>问答系统</td>
<td>1,105,904问题，11,059,040 回答</td>
<td><a href="http://www.visualqa.org/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Visual7W</td>
<td>问答系统</td>
<td>327,939 问答对</td>
<td><a href="http://web.stanford.edu/~yukez/visual7w/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>TID2013</td>
<td>图像质量评价</td>
<td>25张参考图像，24个失真类型</td>
<td><a href="http://www.ponomarenko.info/tid2013.htm"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>CSIQ</td>
<td>图像质量评价</td>
<td>30张参考图像，6个失真类型</td>
<td><a href="http://vision.eng.shizuoka.ac.jp/mod/page/view.php?id=23"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>LIVE</td>
<td>图像质量评价</td>
<td>29张参考图像，5个失真类型</td>
<td><a href="http://live.ece.utexas.edu/research/quality/subjective.htm"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>WATERLOO</td>
<td>图像质量评价</td>
<td>4744张参考图像，20个失真类型</td>
<td><a href="https://ece.uwaterloo.ca/~k29ma/exploration/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>photo.net</td>
<td>图像美观评价</td>
<td>20,278张图像，打分[0,10]</td>
<td><a href="http://ritendra.weebly.com/aesthetics-datasets.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>DPChallenge.com</td>
<td>图像美观评价</td>
<td>16,509张图像，打分[0,10]</td>
<td><a href="http://ritendra.weebly.com/aesthetics-datasets.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>CUHK</td>
<td>图像美观评价</td>
<td>28,410张图像，只分高质量和低质量</td>
<td><a href="http://mmlab.ie.cuhk.edu.hk/archive/CUHKPQ/Dataset.htm"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>AVA</td>
<td>图像美观评价</td>
<td>255,500张图像，打分[0,10]</td>
<td><a href="https://github.com/mtobeiyf/ava_downloader"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
</tbody>
</table>
<h2 id="2-image-motiontracking">2. Image Motion&amp;&amp;Tracking</h2>
<table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody>
<tr>
<td>CUHK03</td>
<td>Person re-identification(人重识别)</td>
<td>image num:13164 person num:1360 camera num:10( 5 pairs)</td>
<td><a href="http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>CUHK02</td>
<td>Person re-identification(人重识别)</td>
<td>image num:7264 person num:1816 camera num:10( 5 pairs)</td>
<td><a href="http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>CUHK01</td>
<td>Person re-identification(人重识别)</td>
<td>image num:3884 person num:971 camera num: 2</td>
<td><a href="http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>VIPeR</td>
<td>Person re-identification(人重识别)</td>
<td>image num:1264 person num:632 camera num:2</td>
<td><a href="https://vision.soe.ucsc.edu/node/178"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>ETH1,2,3</td>
<td>Person re-identification(人重识别)</td>
<td>image num:8580 person num:83,35,28 camera num:1</td>
<td><a href="http://homepages.dcc.ufmg.br/~william/datasets.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>PRID2011</td>
<td>Person re-identification(人重识别)</td>
<td>image num:24541 person num:934 camera num:2</td>
<td><a href="https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/PRID11/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>MARS</td>
<td>Person re-identification(人重识别)</td>
<td>image num:11910031 person num:1261 camera num:6</td>
<td><a href="http://www.liangzheng.com.cn/Project/project_mars.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Market1501</td>
<td>Person re-identification(人重识别)</td>
<td>image num:32217 person num:1501 camera num:6</td>
<td><a href="http://www.liangzheng.org/Project/project_reid.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Epic Fail (EF) dataset</td>
<td>Risk Assessment(风险评估)</td>
<td>video num:3000</td>
<td><a href="https://vision.soe.ucsc.edu/?q=node/178"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Street Accident (SA) dataset</td>
<td>Risk Assessment(风险评估)</td>
<td>video num:1733</td>
<td><a href="https://vision.soe.ucsc.edu/?q=node/178"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>OTB-50</td>
<td>visual tracking(跟踪)</td>
<td>video num:50</td>
<td><a href="http://www.visual-tracking.net/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>OTB-100</td>
<td>visual tracking(跟踪)</td>
<td>video num:100</td>
<td><a href="http://www.visual-tracking.net/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>VOT2015</td>
<td>visual tracking(跟踪)</td>
<td>video num:60</td>
<td><a href="http://www.votchallenge.net/vot2015/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>ALOV300</td>
<td>visual tracking(跟踪)</td>
<td>video num:314</td>
<td><a href="http://alov300pp.joomlafree.it/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>MOT</td>
<td>visual tracking(跟踪)</td>
<td>video num🚋11 test:11</td>
<td><a href="https://motchallenge.net/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>THUMOS</td>
<td>Temporal action localization(动作定位)</td>
<td>video num:~3K activities class:20 instances:~3K</td>
<td><a href="http://crcv.ucf.edu/THUMOS14/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>ActivityNet</td>
<td>Temporal action localization(动作定位)</td>
<td>video num:20k activities class:200 instances:7.6K</td>
<td><a href="http://activity-net.org/challenges/2016/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Mexaction2</td>
<td>Temporal action localization(动作定位)</td>
<td>activities class:2 instances:1975</td>
<td><a href="http://mexculture.cnam.fr/xwiki/bin/view/Datasets/Mex&#43;action&#43;dataset"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>FlyingChairs dataset</td>
<td>optical flow(光流)</td>
<td>image pairs：22k</td>
<td><a href="https://lmb.informatik.uni-freiburg.de/resources/datasets/FlyingChairs.en.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>FlyingThings3D</td>
<td>optical flow(光流)</td>
<td>image pairs：22k</td>
<td><a href="https://lmb.informatik.uni-freiburg.de/resources/datasets/SceneFlowDatasets.en.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>KITTI benchmark suite</td>
<td>optical flow(光流)</td>
<td>image pairs：1600</td>
<td><a href="http://www.cvlibs.net/datasets/kitti/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>MPI Sintel</td>
<td>optical flow(光流)</td>
<td>image pairs：1064</td>
<td><a href="http://sintel.is.tue.mpg.de/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
</tbody>
</table>
<h2 id="3-video-analysis--scene-understanding">3. Video Analysis &amp; Scene Understanding</h2>
<table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody>
<tr>
<td>UCF101</td>
<td>动作行为识别</td>
<td>13320 video,101类动作，主要是五大类：1)人-物交互；2)肢体运动；3)人-人交互；4)弹奏乐器；5)运动</td>
<td><a href="http://crcv.ucf.edu/data/UCF101.php"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>HMDB51</td>
<td>动作行为识别</td>
<td>7000 videos,51类，包括人脸表情动作，身体动作，人与人交互等</td>
<td><a href="http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/#Downloads"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Moments-in-Time</td>
<td>动作行为识别</td>
<td>1,000,000 videos,339类</td>
<td><a href="http://moments.csail.mit.edu/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>ActivityNet 1.3</td>
<td>动作行为识别</td>
<td>20,000 videos,200类</td>
<td><a href="http://activity-net.org/challenges/2016/guidelines.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Kinetics</td>
<td>动作行为识别</td>
<td>300,000 videos，400类</td>
<td><a href="https://deepmind.com/research/open-source/open-source-datasets/kinetics/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>AVA</td>
<td>动作行为识别</td>
<td>57,600 videos，80类</td>
<td><a href="https://research.google.com/ava/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Collective Activity Dataset</td>
<td>群体活动行为识别</td>
<td>44 videos,穿叉、行走、等待、交谈和排队 五类</td>
<td><a href="http://vhosts.eecs.umich.edu/vision//activity-dataset.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Choi’s New Dataset</td>
<td>群体活动行为识别</td>
<td>32 videos，聚会，谈话，分开，一起走，追逐和排队 六类</td>
<td>None</td>
</tr>
<tr>
<td>ActivityNet 1.3</td>
<td>检测动作事件的起始时间和终止时间</td>
<td>20,000 videos,200类动作的起始时间和终止时间</td>
<td><a href="http://activity-net.org/challenges/2016/guidelines.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>THUMOS</td>
<td>检测动作事件的起始时间和终止时间</td>
<td>15,000 videos，101类动作的起始时间和终止时间</td>
<td><a href="http://www.thumos.info/download.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>MED</td>
<td>事件检测</td>
<td>32,744 videos,20个事件</td>
<td><a href="http://www-nlpir.nist.gov/projects/tv2017/data/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>EventNet</td>
<td>事件检测</td>
<td>90,000 videos，500个事件</td>
<td><a href="http://eventnet.ee.columbia.edu/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Columbia Consumer Video</td>
<td>事件检测</td>
<td>9,317 videos，20个事件</td>
<td><a href="http://www.ee.columbia.edu/ln/dvmm/CCV/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>ADE20K</td>
<td>事件检测</td>
<td>20,210 videos，900个事件</td>
<td><a href="http://sceneparsing.csail.mit.edu/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>DAVIS</td>
<td>视频主物体分割</td>
<td>50 videos，分割标注</td>
<td><a href="http://davischallenge.org/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>FBMS</td>
<td>视频主物体分割</td>
<td>59 videos，分割标注</td>
<td><a href="https://lmb.informatik.uni-freiburg.de/resources/datasets/moseg.en.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>IJB-C</td>
<td>视频人脸识别</td>
<td>11,000 videos，</td>
<td><a href="https://www.nist.gov/programs-projects/face-challenges"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>YouTube Faces</td>
<td>视频人脸识别</td>
<td>3,425 videos，1595 人</td>
<td><a href="https://www.cs.tau.ac.il/~wolf/ytfaces/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>MS-Celeb-1M</td>
<td>视频人脸识别</td>
<td>1,000,000 images，21,000人</td>
<td><a href="http://www.msceleb.org/download/sampleset"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>MSVD</td>
<td>视频描述</td>
<td>1,970 videos</td>
<td><a href="http://www.cs.utexas.edu/users/ml/clamp/videoDescription/YouTubeClips.tar"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>MSR-VTT-10K</td>
<td>视频描述</td>
<td>10，000 videos</td>
<td><a href="http://ms-multimedia-challenge.com/2017/dataset"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>MSR-VTT-10K</td>
<td>视频描述</td>
<td>无</td>
<td><a href="https://sites.google.com/site/describingmovies/lsmdc-2016/download"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
</tbody>
</table>
<h2 id="4-3d-computer-vision">4. 3D Computer Vision</h2>
<table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody>
<tr>
<td>photoface database</td>
<td>基于光度立体视觉的二维和三维人脸识别数据库</td>
<td>总共7356张图像，包含1839个session和261个subjects</td>
<td>None</td>
</tr>
<tr>
<td>NYU Depth V2 dataset</td>
<td>关于RGBD 图像场景理解的数据库</td>
<td>提供1449张深度图片和他们的密集2d点类标注</td>
<td><a href="https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>SUN RGBD dataset</td>
<td>是上面的NYU Depth V2 dataset的超集，多了3D bounding boxes和room layouts的标注。</td>
<td>有10,000张RGB-D图片，有58,657个3D包围框和146,617 个2d包围框。</td>
<td><a href="http://rgbd.cs.princeton.edu/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>PASCAL3D+</td>
<td>新的三维物体检测和姿态估计数据集，从PASCAL VOC 演化而来，包含图像，注解，和3D CAD模型</td>
<td>总共12个类，平均每个类别有3000多个实例</td>
<td><a href="http://cvgl.stanford.edu/projects/pascal3d.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>IKEA</td>
<td>包含典型室内场景的三维模型的数据库，例如桌子椅子等</td>
<td>包含大约759张图片和219个3D模型</td>
<td><a href="http://ikea.csail.mit.edu/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>New Tsukuba Dataset</td>
<td>包含了很多立体物体对的数据库，用于立体物体匹配</td>
<td>总共1800个立体物体对，以及每立体对的立体视差图、遮挡图和不连续图</td>
<td><a href="https://cvlab-home.blogspot.jp/2012/05/h2fecha-2581457116665894170-displaynone.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Oxford RobotCar Dataset</td>
<td>关于户外自动驾驶的数据集。</td>
<td>包含在驾驶汽车过程从6个摄像头收集的2000w张图片，和当时的激光雷达，GPS和地面实况标注。</td>
<td><a href="http://robotcar-dataset.robots.ox.ac.uk/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Middlebury V3</td>
<td>包含高分辨率物体立体视差标注的数据库</td>
<td>包含33个类，没有明说每类有多少数据</td>
<td><a href="http://vision.middlebury.edu/stereo/eval3/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>ShapeNet</td>
<td>包含3D模型，和3d模型的类别标注的数据集，覆盖了常用的3D数据集PASCAL 3D+。</td>
<td>它涵盖55个常见的对象类别，有大约51,300个3D模型</td>
<td><a href="https://www.shapenet.org/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>MICC dataset</td>
<td>包含了3D人脸扫描和在不同分辨率，条件和缩放级别下的几个视频序列的数据库。</td>
<td>有53个人的立体人脸数据</td>
<td><a href="https://www.micc.unifi.it/resources/datasets/florence-3d-faces/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>CMU MoCap Dataset</td>
<td>包含了3D人体关键点标注和骨架移动标注的数据集。</td>
<td>有6个类别和23个子类别，总共2605个数据。</td>
<td><a href="http://mocap.cs.cmu.edu/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>DTU dataset</td>
<td>关于3D场景的数据集。</td>
<td>有124个场景，每场景有49/64个位置的RGB图像和结构光标注。</td>
<td><a href="http://roboimagedata.compute.dtu.dk/?page_id=36"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
</tbody>
</table>
<h2 id="5-analyzing-humans-in-images">5. Analyzing Humans in Images</h2>
<table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody>
<tr>
<td>MSR-Action3D</td>
<td>包含深度的动作识别数据集，</td>
<td>有20个动作，总共557个序列。</td>
<td><a href="http://users.eecs.northwestern.edu/~jwa368/my_data.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Florence-3D</td>
<td>包含深度的动作识别数据集，</td>
<td>有9个动作，总共215个动作序列。</td>
<td><a href="https://www.micc.unifi.it/resources/datasets/florence-3d-actions-dataset/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Berkeley MHAD</td>
<td>包含深度的动作识别数据集，</td>
<td>有11个动作，产生660个动作序列。</td>
<td><a href="http://tele-immersion.citris-uc.org/berkeley_mhad"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Online Action Detection</td>
<td>包含深度的动作识别数据集，</td>
<td>数据集包含59个长序列，包含10种不同的日常生活行为。</td>
<td><a href="http://homes.esat.kuleuven.be/~rdegeest/OnlineActionDetection.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>ChaLearn LAP IsoGD Dataset</td>
<td>RGB-D图像的手势识别的数据集。</td>
<td>包括47933个RGB-D手势视频，有249个手势标签。Training有35878视频，Validation有5784个，test有6271个</td>
<td><a href="http://gesture.chalearn.org/2016-looking-at-people-cvpr-challenge/isogd-and-congd-datasets"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>MAFA dataset</td>
<td>关于面部遮挡问题的数据集</td>
<td>有30, 811张人脸和35806张有遮挡的脸组成。</td>
<td><a href="http://www.escience.cn/people/geshiming/mafa.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>MSRC-12 Kinect Gesture Dataset</td>
<td>手势识别数据集</td>
<td>有4900张图片，包含12个不同手势，</td>
<td><a href="https://www.microsoft.com/en-us/download/details.aspx?id=52283"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>2013 Chalearn Gesture Challenge dataset</td>
<td>手势识别数据集</td>
<td>有11000张图片，包含20个不同手势，</td>
<td><a href="http://gesture.chalearn.org/2013-multi-modal-challenge"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>WIDER FACE</td>
<td>人脸检测数据集</td>
<td>有 32,203 张图片，标注了393703个人脸。</td>
<td><a href="http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>FDDB</td>
<td>人脸检测数据集</td>
<td>2845张图片，标注了5171张人脸。</td>
<td><a href="http://vis-www.cs.umass.edu/fddb/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>300-VW dataset</td>
<td>面部表情数据集</td>
<td>包含114个视频和总计218,595帧。</td>
<td><a href="https://ibug.doc.ic.ac.uk/resources/300-VW/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>HMDB51</td>
<td>人类行为识别的数据集</td>
<td>包含51个动作，总共有6766个视频剪辑</td>
<td><a href="http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>MPII Cooking Activities Dataset</td>
<td>人类行为识别的数据集</td>
<td>包含65个动作，有5609个视频</td>
<td><a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/human-activity-recognition/mpii-cooking-activities-dataset/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>UCF101</td>
<td>人类行为识别的数据集</td>
<td>包含101个动作，有13320个视频</td>
<td><a href="http://crcv.ucf.edu/data/UCF101.php"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>IJB-A dataset</td>
<td>包含视频和图片人脸识别的数据集</td>
<td>包含5712个图像和2085个视频</td>
<td><a href="https://www.nist.gov/programs-projects/face-challenges"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>YouTube celebrities</td>
<td>视频人脸识别的数据集</td>
<td>包含47位名人的1910个视频</td>
<td><a href="https://www.cs.tau.ac.il/~wolf/ytfaces/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>COX</td>
<td>视频人脸识别的数据集</td>
<td>包含1000个主题的4000个视频</td>
<td><a href="http://vipl.ict.ac.cn/view_database.php?id=3"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Human3.6M</td>
<td>人体姿态估计的数据集</td>
<td>360万张3D照片，11名受试者在4个视点下执行15个了不同的动作</td>
<td><a href="http://vision.imar.ro/human3.6m/description.php"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>iLIDS</td>
<td>行人重识别的数据集</td>
<td>476 张图像，包含119个人</td>
<td><a href="http://www.eecs.qmul.ac.uk/~xiatian/downloads_qmul_iLIDS-VID_ReID_dataset.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>VIPeR</td>
<td>行人重识别的数据集</td>
<td>632个行人图片对（由两个相机拍摄）</td>
<td><a href="https://iiw.kuleuven.be/onderzoek/eavise/viper/dataset"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>CUHK01</td>
<td>行人重识别的数据集</td>
<td>包含971行人, 3884张图片</td>
<td><a href="http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>CUHK03</td>
<td>行人重识别的数据集</td>
<td>包含1360行人, 13164张图片</td>
<td><a href="http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>RWTH-PHOENIX-Weather multi-signer 2014</td>
<td>手语识别的数据集</td>
<td>包含了5672个德语手语的句子，有65,227个手语姿势和799,006帧</td>
<td><a href="https://www-i6.informatik.rwth-aachen.de/~forster/database-rwth-phoenix.php"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>AFLW</td>
<td>人类面部关键点的数据集</td>
<td>总共约有25k张脸，每幅图像标注了大约21个位置。</td>
<td><a href="https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/aflw"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>CMU mocap database</td>
<td>动作识别的数据集</td>
<td>2235个数据，包含144个不同的动作。</td>
<td><a href="http://mocap.cs.cmu.edu/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Georgia Tech (GT) database</td>
<td>人脸识别数据库</td>
<td>50个人每人15张人脸。</td>
<td><a href="http://www.anefian.com/research/face_reco.htm"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>ORL</td>
<td>人脸识别数据库</td>
<td>40个人每个人10张图。</td>
<td><a href="https://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
</tbody>
</table>
<h2 id="6-application">6. Application</h2>
<table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody>
<tr>
<td>DogCentric Activity Dataset</td>
<td>第一视角的狗和人之间的相互行为的数据集（视频）</td>
<td>总共有10类，具体数据量没有明说，y是动作类别</td>
<td><a href="http://robotics.ait.kyushu-u.ac.jp/yumi/db/first_dog.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>JPL First-Person Interaction Dataset</td>
<td>第一视角观察动作的数据集</td>
<td>57个视频，8个大类，y是动作类别</td>
<td><a href="http://michaelryoo.com/jpl-interaction.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>NUS-WIDE</td>
<td>关于图像文本匹配的数据集</td>
<td>269,648个图像和对应的标签</td>
<td><a href="http://lms.comp.nus.edu.sg/research/NUS-WIDE.htm"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>LabelMe Dataset</td>
<td>关于图像文本匹配的数据集</td>
<td>3825个图像和对应标签</td>
<td><a href="http://labelme.csail.mit.edu/Release3.0/browserTools/php/dataset.php"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Pascal Dataset</td>
<td>关于图像文本匹配的数据集</td>
<td>5011张训练图像和4952张测试图像</td>
<td>)</td>
</tr>
<tr>
<td>ICDAR 2015</td>
<td>关于文本检测的数据集</td>
<td>1500张训练，1000张测试，y为四边形的四个顶点。</td>
<td><a href="http://rrc.cvc.uab.es/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>COCO-Text</td>
<td>关于文本检测的数据集</td>
<td>63686张图片，其中43686张被选为训练集，剩下的2万用于测试。</td>
<td><a href="https://vision.cornell.edu/se3/coco-text-2/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>MSRA-TD500</td>
<td>关于文本检测的数据集</td>
<td>300个训练，200个测试图像</td>
<td><a href="http://www.iapr-tc11.org/mediawiki/index.php/MSRA_Text_Detection_500_Database_%28MSRA-TD500%29"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Microsoft 7-Scenes Dataset</td>
<td>室内人体运动的数据集</td>
<td>有7种不同室内环境，每包含500-1000张图像视频序列。</td>
<td><a href="https://www.microsoft.com/en-us/research/project/rgb-d-dataset-7-scenes/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Oxford RobotCar</td>
<td>户外自动驾驶数据集</td>
<td>包含图像，激光扫描结果和GPS数据。</td>
<td><a href="http://robotcar-dataset.robots.ox.ac.uk/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
</tbody>
</table>
<h2 id="7-low---mid-level-vision">7. Low- &amp; Mid-Level Vision</h2>
<table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody>
<tr>
<td>Deep Video Deblurring for Hand-held Cameras</td>
<td>video/image deblurring(图像去模糊)</td>
<td>video num:71 video time: 3-5s blurry and sharp pair image num:6708</td>
<td><a href="https://www.cs.ubc.ca/labs/imager/tr/2017/DeepVideoDeblurring/#dataset"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>GOPRO dataset</td>
<td>video/image deblurring(图像去模糊)</td>
<td>blurry and sharp pair image num:3214 train num:2103 test num:1111</td>
<td><a href="https://github.com/SeungjunNah/DeepDeblur_release"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>BSD68</td>
<td>image restoration(图像修复)/高斯降噪</td>
<td>image num:68</td>
<td><a href="https://www.robots.ox.ac.uk/~vgg/data/dtd/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>BSD100</td>
<td>“image restoration(图像修复)super resolution超分辨率重建”</td>
<td>image num:100</td>
<td><a href="https://github.com/jbhuang0604/SelfExSR/tree/master/data"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Set5</td>
<td>“image restoration(图像修复)super resolution超分辨率重建”</td>
<td>image num:5</td>
<td><a href="https://github.com/jbhuang0604/SelfExSR/tree/master/data"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Set14</td>
<td>“image restoration(图像修复)super resolution超分辨率重建”</td>
<td>image num:14</td>
<td><a href="https://github.com/jbhuang0604/SelfExSR/tree/master/data"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Urban100</td>
<td>“image restoration(图像修复)super resolution超分辨率重建”</td>
<td>image num:100</td>
<td><a href="https://github.com/jbhuang0604/SelfExSR/tree/master/data"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>NYU v2 dataset</td>
<td>“image restoration(图像修复)depth super resolution深度超分辨率重建”</td>
<td>image num:1449</td>
<td><a href="https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Middlebury dataset</td>
<td>“image restoration(图像修复)depth super resolution深度超分辨率重建”</td>
<td>image pair num: 33</td>
<td><a href="http://vision.middlebury.edu/stereo/data/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>alpha matting benchmark</td>
<td>Natural image matting(抠图)</td>
<td>“train num:27,test num:8”</td>
<td><a href="http://www.alphamatting.com/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>real image benchmark</td>
<td>Natural image matting(抠图)</td>
<td>“train num:49300,test num:1000”</td>
<td><a href="https://sites.google.com/view/deepimagematting"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>MSRA10K/MSRA-B</td>
<td>Image saliency detection(显著性区域检测)</td>
<td>image num(MSRA10K):10000 image num(MSRA-B):5000</td>
<td><a href="https://mmcheng.net/zh/msra10k/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>ECSSD</td>
<td>Image saliency detection(显著性区域检测)</td>
<td>image num:1000</td>
<td><a href="http://www.cse.cuhk.edu.hk/leojia/projects/hsaliency/dataset.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>DUT-OMRON</td>
<td>Image saliency detection(显著性区域检测)</td>
<td>image num:5168</td>
<td><a href="http://saliencydetection.net/dut-omron/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>PASCAL-S</td>
<td>Image saliency detection(显著性区域检测)</td>
<td>image num:850</td>
<td><a href="http://cbi.gatech.edu/salobj/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>HKU-IS</td>
<td>Image saliency detection(显著性区域检测)</td>
<td>image num:4447</td>
<td><a href="http://i.cs.hku.hk/~gbli/deep_saliency.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>SOD</td>
<td>Image saliency detection(显著性区域检测)</td>
<td>image num:300</td>
<td><a href="http://i.cs.hku.hk/~gbli/deep_saliency.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Describable Textures Dataset</td>
<td>texture synthesis(纹理合成)</td>
<td>image num:5640 category num:47 split train:val:test = 1:1:1</td>
<td><a href="https://www.robots.ox.ac.uk/~vgg/data/dtd/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>CVPPP leaf segmentation</td>
<td>Instance segmentation(样例分割)</td>
<td>image num: 161 train num: 128 test num: 33</td>
<td><a href="https://www.plant-phenotyping.org/CVPPP2014-dataset"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>KITTI car segmentation</td>
<td>Instance segmentation(样例分割)</td>
<td>image num: 3976 train num: 3712 test num: 144 val:120</td>
<td><a href="http://www.cvlibs.net/datasets/kitti/eval_semantics.php"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Cityscapes</td>
<td>Instance segmentation(样例分割)</td>
<td>image num: 5000 train num: 2975 test num: 1525 val:500</td>
<td><a href="https://www.cityscapes-dataset.com/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>SYMMAX</td>
<td>Symmetry Detection(对称性检测)</td>
<td>image num: train:200 test:100</td>
<td><a href="https://github.com/KevinKecc/SRN"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>WHSYMMAX</td>
<td>Symmetry Detection(对称性检测)</td>
<td>image num: train:228 test:100 object num: 1</td>
<td><a href="https://github.com/KevinKecc/SRN"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>SK506</td>
<td>Symmetry Detection(对称性检测)</td>
<td>image num: train:300 test:206 object num: 16</td>
<td><a href="https://github.com/KevinKecc/SRN"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Sym-PASCAL</td>
<td>Symmetry Detection(对称性检测)</td>
<td>image num: train:648 test:787 object num: 14</td>
<td><a href="https://github.com/KevinKecc/SRN"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Color Checker Dataset</td>
<td>Color constancy(颜色恒定)</td>
<td>image num: 568</td>
<td><a href="http://www.eecs.harvard.edu/~ayanc/oldcc/dbs.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>NUS 8-Camera Dataset</td>
<td>Color constancy(颜色恒定)</td>
<td>image num: 1736</td>
<td><a href="http://www.comp.nus.edu.sg/~whitebal/illuminant/illuminant.html"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
</tbody>
</table>
<h2 id="8-text">8. Text</h2>
<table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody>
<tr>
<td>Stanford Sentiment Treebank</td>
<td>文本情感分析</td>
<td>11855个句子划分为239231个短语，每个短语有个概率值，越小越负面，越大越正面</td>
<td><a href="https://nlp.stanford.edu/sentiment/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>IMDB</td>
<td>文本情感分析</td>
<td>100,000句子，正面负面两类</td>
<td><a href="http://ai.stanford.edu/~amaas/data/sentiment/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Yelp</td>
<td>文本情感分析</td>
<td>无</td>
<td><a href="https://www.yelp.com/dataset/challenge"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Multi-Domain Sentiment Dataset(Amazon product)</td>
<td>文本情感分析</td>
<td>100,000+句子，正面负面2类或强正面、弱正面、中立、弱负面、强负面5类</td>
<td><a href="http://www.cs.jhu.edu/~mdredze/datasets/sentiment/"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>SemEval</td>
<td>文本情感分析</td>
<td>20,632句子，三类（正面、负面、中立）</td>
<td><a href="http://alt.qcri.org/semeval2017/task4/index.php?id=data-and-tools"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
<tr>
<td>Sentiment140(STS)</td>
<td>文本情感分析</td>
<td>1,600,000句子,三类（正面、负面、中立）</td>
<td><a href="https://drive.google.com/uc?id=0B04GJPshIjmPRnZManQwWEdTZjg&amp;export=download"target="_blank" rel="external nofollow noopener noreferrer">链接<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></td>
</tr>
</tbody>
</table>
<p>人脸数据集：http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html</p>
<p><strong>From:</strong> <a href="https://www.cnblogs.com/xiaojianliu/p/9446358.html"target="_blank" rel="external nofollow noopener noreferrer">https://www.cnblogs.com/xiaojianliu/p/9446358.html<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<p>​		https://blog.csdn.net/weixin_41036461/article/details/80667690</p>
<h2 id="9-car-relative">9. Car Relative</h2>
<ul>
<li>江苏数林数据标注公司</li>
</ul>
<blockquote>
<p>江苏数林数据标注公司近期自主采集了30000名驾驶员动作行为数据集，类别含有12种：</p>
<p>抽烟，喝水，打电话，玩手机，回头拿东西，调广播，打瞌睡，连续眨眼挤眼睛，打哈欠，头连续转动，聊天，正常行驶，总共396万段视频，包括白天和晚上的。</p>
<p>标注类别</p>
<ol>
<li>人脸关键点</li>
<li>手持物体框</li>
<li>人脸、人体框</li>
</ol>
</blockquote>
</div>
<div class="post-footer" id="post-footer">
  <div class="post-info">
    <div class="post-info-line">
      <div class="post-info-mod">
        <span title=2023-12-31&#32;16:55:08>更新于 2023-12-31&nbsp;</span>
      </div><div class="post-info-license">
          <span><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span>
        </div></div>
    <div class="post-info-line">
      <div class="post-info-md"><span><a href="/dataset-record/index.md" title="阅读原始文档" class="link-to-markdown">阅读原始文档</a></span><span><a href="https://liudongdong1.github.io/edit/master/content/posts%5c%e8%a7%86%e8%a7%89%e8%bf%90%e5%8a%a8%5cDataSet-Record.md" title="编辑此页"target="_blank" rel="external nofollow noopener noreferrer" class="link-to-edit">编辑此页</a></span></div>
      <div class="post-info-share">
        <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="https://liudongdong1.github.io/dataset-record/" data-title="DataSet_Record" data-hashtags="Dataset"><i class="fa-brands fa-twitter fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="https://liudongdong1.github.io/dataset-record/" data-hashtag="Dataset"><i class="fa-brands fa-facebook-square fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="https://liudongdong1.github.io/dataset-record/" data-title="DataSet_Record" data-image="https://cdn.stocksnap.io/img-thumbs/280h/O00MGHPXG6.jpg"><i class="fa-brands fa-weibo fa-fw" aria-hidden="true"></i></a>
  </span>
      </div>
    </div>
  </div>

  <div class="post-info-more">
    <section class="post-tags"><i class="fa-solid fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/dataset/">Dataset</a></section>
    <section>
      <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
    </section>
  </div>

  <div class="post-nav"><a href="/siamesenetwork/" class="prev" rel="prev" title="SiameseNetwork"><i class="fa-solid fa-angle-left fa-fw" aria-hidden="true"></i>SiameseNetwork</a>
      <a href="/pytorchpoint/" class="next" rel="next" title="PytorchPoint">PytorchPoint<i class="fa-solid fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article></main><footer class="footer">
    <div class="footer-container"><div class="footer-line powered">由 <a href="https://gohugo.io/" target="_blank" rel="external nofollow noopener noreferrer" title="Hugo 0.118.2">Hugo</a> 强力驱动 | 主题 - <a href="https://github.com/hugo-fixit/FixIt" target="_blank" rel="external" title="FixIt v0.2.17-RC"><img class="fixit-icon" src="/fixit.min.svg" alt="FixIt logo" />&nbsp;FixIt</a>
        </div><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">2020 - 2024</span><span class="author" itemprop="copyrightHolder">
              <a href="https://liudongdong1.github.io/"target="_blank" rel="external nofollow noopener noreferrer">LiuDongdong</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div><div class="footer-line statistics"><span class="site-time" title='网站运行中 ...'><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden="true"></i>&nbsp;<span class="run-times">网站运行中 ...</span></span></div><div class="footer-line ibruce">
          <span id="busuanzi_container_site_uv" title='总访客数'><i class="fa-regular fa-user fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span><span id="busuanzi_container_site_pv" class="footer-divider" title='总访问量'><i class="fa-regular fa-eye fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span>
        </div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="回到顶部"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric">0%</span>
        </div></div><a href="https://liudongdong1.github.io/" title="在 GitHub 上查看源代码"target="_blank" rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><div id="mask"></div><div class="reading-progress-bar" style="left: 0;top: 0;--bg-progress: #0076ff;--bg-progress-dark: #fff;"></div><noscript>
    <div class="noscript-warning">FixIt 主题在启用 JavaScript 的情况下效果最佳。</div>
  </noscript>
</div><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script src="/lib/autocomplete/autocomplete.min.js" defer></script><script src="/lib/algoliasearch/algoliasearch-lite.umd.min.js" defer></script><script src="/lib/lazysizes/lazysizes.min.js" async defer></script><script src="/lib/sharer/sharer.min.js" async defer></script><script src="/lib/typeit/index.umd.js" defer></script><script src="/lib/katex/katex.min.js" defer></script><script src="/lib/katex/auto-render.min.js" defer></script><script src="/lib/katex/copy-tex.min.js" defer></script><script src="/lib/katex/mhchem.min.js" defer></script><script src="/lib/cookieconsent/cookieconsent.min.js" defer></script><script src="/lib/pangu/pangu.min.js" defer></script><script src="/lib/cell-watermark/watermark.min.js" defer></script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async defer></script><script>window.config={"code":{"copyTitle":"复制到剪贴板","editLockTitle":"锁定可编辑代码块","editUnLockTitle":"解锁可编辑代码块","editable":true,"maxShownLines":10},"comment":{"enable":false},"cookieconsent":{"content":{"dismiss":"同意","link":"了解更多","message":"本网站使用 Cookies 来改善您的浏览体验。"},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"data":{"typeit-header-subtitle-desktop":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e","typeit-header-subtitle-mobile":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e"},"enablePWA":true,"enablePangu":true,"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"2R1K9SKLQZ","algoliaIndex":"index.zh-cn","algoliaSearchKey":"4a226aa1c5c98d6859e4d1386adb2bc7","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"},"siteTime":"2020-12-18T16:15:22+08:00","typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"typeit-header-subtitle-desktop":["typeit-header-subtitle-desktop"],"typeit-header-subtitle-mobile":["typeit-header-subtitle-mobile"]},"duration":-1,"speed":100},"watermark":{"appendto":".wrapper\u003emain","colspacing":30,"content":"\u003cimg class=\"fixit-icon\" src=\"/fixit.min.svg\" alt=\"FixIt logo\" /\u003e FixIt 主题","enable":true,"fontfamily":"inherit","fontsize":0.85,"height":21,"opacity":0.0125,"rotate":15,"rowspacing":60,"width":150}};</script><script src="/js/theme.min.js" defer></script><script src="/js/custom.min.js" defer></script></body>
</html>
