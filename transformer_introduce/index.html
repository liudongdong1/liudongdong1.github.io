<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <head>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>Transformer_Introduce - DAY By DAY</title><meta name="author" content="LiuDongdong">
<meta name="author-link" content="https://liudongdong1.github.io/">
<meta name="description" content="The Transformer starts by generating initial representations, or embeddings, for each word. These are represented by the unfilled circles. Then, using self-attention, it aggregates information from all of the other words, generating a new representation per word informed by the entire context, represented by the filled balls. This step is then repeated multiple times in parallel for all words, successively generating new representations. 代码讲解地址：" /><meta name="keywords" content='Model' /><meta itemprop="name" content="Transformer_Introduce">
<meta itemprop="description" content="The Transformer starts by generating initial representations, or embeddings, for each word. These are represented by the unfilled circles. Then, using self-attention, it aggregates information from all of the other words, generating a new representation per word informed by the entire context, represented by the filled balls. This step is then repeated multiple times in parallel for all words, successively generating new representations. 代码讲解地址："><meta itemprop="datePublished" content="2020-07-13T09:47:19+00:00" />
<meta itemprop="dateModified" content="2023-09-28T23:52:33+08:00" />
<meta itemprop="wordCount" content="1596"><meta itemprop="image" content="/logo.png"/>
<meta itemprop="keywords" content="Model," /><meta property="og:title" content="Transformer_Introduce" />
<meta property="og:description" content="The Transformer starts by generating initial representations, or embeddings, for each word. These are represented by the unfilled circles. Then, using self-attention, it aggregates information from all of the other words, generating a new representation per word informed by the entire context, represented by the filled balls. This step is then repeated multiple times in parallel for all words, successively generating new representations. 代码讲解地址：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="liudongdong1.github.io/transformer_introduce/" /><meta property="og:image" content="/logo.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-07-13T09:47:19+00:00" />
<meta property="article:modified_time" content="2023-09-28T23:52:33+08:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="/logo.png"/>

<meta name="twitter:title" content="Transformer_Introduce"/>
<meta name="twitter:description" content="The Transformer starts by generating initial representations, or embeddings, for each word. These are represented by the unfilled circles. Then, using self-attention, it aggregates information from all of the other words, generating a new representation per word informed by the entire context, represented by the filled balls. This step is then repeated multiple times in parallel for all words, successively generating new representations. 代码讲解地址："/>
<meta name="application-name" content="DAY By DAY">
<meta name="apple-mobile-web-app-title" content="DAY By DAY"><meta name="theme-color" data-light="#f8f8f8" data-dark="#252627" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="liudongdong1.github.io/transformer_introduce/" /><link rel="prev" href="liudongdong1.github.io/ctc_introduce/" /><link rel="next" href="liudongdong1.github.io/similaritymetric/" /><link rel="stylesheet" href="/liudongdong1.github.io/css/style.min.css"><link rel="stylesheet" href="/liudongdong1.github.io/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/liudongdong1.github.io/lib/animate/animate.min.css"><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "Transformer_Introduce",
    "inLanguage": "zh-CN",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "liudongdong1.github.io\/transformer_introduce\/"
    },"genre": "posts","keywords": "Model","wordcount":  1596 ,
    "url": "liudongdong1.github.io\/transformer_introduce\/","datePublished": "2020-07-13T09:47:19+00:00","dateModified": "2023-09-28T23:52:33+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
      "@type": "Organization",
      "name": "LiuDongdong","logo": "\/images\/person.png"},"author": {
        "@type": "Person",
        "name": "liudongdong1"
      },"description": ""
  }
  </script></head>
  <body data-header-desktop="auto" data-header-mobile="auto"><script>(window.localStorage?.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('data-theme', 'dark');</script><div class="wrapper"><header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper" data-github-corner="right">
    <div class="header-title">
      <a href="liudongdong1.github.io/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="DAY By DAY"
    title="DAY By DAY"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-desktop" class="typeit header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/posts/"
                
                
              ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/categories/"
                
                
              ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/tags/"
                
                
              ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/friends/"
                title="友情链接"
                
              ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/about/"
                
                
              ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li class="menu-item delimiter"></li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <ul class="sub-menu"><li class="menu-item">没有更多翻译</li></ul>
          </li><li class="menu-item search" id="search-desktop">
            <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-desktop">
            <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
              <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
            </a>
            <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
              <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
            </a>
            <span class="search-button search-loading" id="search-loading-desktop">
              <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
            </span>
          </li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li>
      </ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="liudongdong1.github.io/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="/fixit.min.svg"
    title="/fixit.min.svg"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-mobile" class="typeit header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li class="search-wrapper">
            <div class="search mobile" id="search-mobile">
              <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-mobile">
              <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
              </a>
              <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
              </a>
              <span class="search-button search-loading" id="search-loading-mobile">
                <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
              </span>
            </div>
            <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
              取消
            </a>
          </li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/posts/"
                  
                  
                ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/categories/"
                  
                  
                ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/tags/"
                  
                  
                ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/friends/"
                  title="友情链接"
                  
                ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/about/"
                  
                  
                ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li
              class="menu-item text-center"
            ><a
                  class="menu-link"
                  href="https://liudongdong1.github.io/"
                  title="GitHub"
                  rel="noopener noreferrer" target="_blank"
                ><i class='fa-brands fa-github fa-fw' aria-hidden='true'></i> </a></li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <select class="language-select" onchange="location = this.value;"><option disabled>没有更多翻译</option></select>
          </li></ul>
    </nav>
  </div>
</header><div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
  </div>
  <div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
  </div><main class="container" data-page-style="normal"><aside class="toc" id="toc-auto"><h2 class="toc-title">目录 <i class="toc-icon fa-solid fa-angle-down fa-fw"></i></h2>
      <div class="toc-content" id="toc-content-auto"></div></aside>

  <aside class="aside-custom" id="aside-sakana">
    

<div class="sakana-widget">
  <div class="sakana-item" id="takina-widget"></div>
  <div class="sakana-item" id="chisato-widget"></div>
</div>
<script>
  function initSakanaWidget() {
    const takina = SakanaWidget.getCharacter('takina')
    SakanaWidget.registerCharacter('takina-slow', takina);
    new SakanaWidget({
      character: 'takina-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#takina-widget');

    const chisato = SakanaWidget.getCharacter('chisato')
    SakanaWidget.registerCharacter('chisato-slow', chisato);
    new SakanaWidget({
      character: 'chisato-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#chisato-widget');
  }
</script>
<script async onload="initSakanaWidget()" src="https://cdn.jsdelivr.net/npm/sakana-widget@2.3.0/lib/sakana.min.js">
</script></aside>

  <article class="page single">
    <div class="header"><h1 class="single-title animate__animated animate__flipInX">
        <span>Transformer_Introduce</span>
      </h1></div><div class="post-meta">
      <div class="post-meta-line"><span class="post-author"><span class="author"><i class="fa-solid fa-user-circle" aria-hidden="true"></i>
      liudongdong1</span></span>
          <span class="post-category">收录于 <a href="liudongdong1.github.io/categories/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;Categories</a>&ensp;<a href="liudongdong1.github.io/categories/ai/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;AI</a></span></div>
      <div class="post-meta-line"><span title=2020-07-13&#32;09:47:19>
            <i class="fa-regular fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2020-07-13" >2020-07-13</time>
          </span>&nbsp;<i class="fa-solid fa-pencil-alt fa-fw"></i>&nbsp;约 1596 字&nbsp;
        <i class="fa-regular fa-clock fa-fw"></i>&nbsp;预计阅读 4 分钟&nbsp;<span id="busuanzi_container_page_pv" class="busuanzi_visitors comment-visitors" data-flag-title="Transformer_Introduce">
            <i class="fa-regular fa-eye fa-fw"></i>&nbsp;<span id="busuanzi_value_page_pv">-</span>&nbsp;次阅读
          </span>&nbsp;</div>
    </div><div class="featured-image"><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715201109572.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715201109572.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715201109572.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715201109572.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715201109572.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715201109572.png"/></div><div class="details toc" id="toc-static" kept="true">
        <div class="details-summary toc-title">
          <span>目录</span>
          <span><i class="details-icon fa-solid fa-angle-right"></i></span>
        </div>
        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#1-embedding">1. Embedding</a></li>
    <li><a href="#2-encode">2. <strong>Encode</strong></a></li>
    <li><a href="#3-matrix-calculation-of-self-attention">3. <strong>Matrix Calculation of Self-Attention</strong></a></li>
    <li><a href="#4-the-beast-with-many-heads">4. The Beast With Many Heads</a></li>
    <li><a href="#5-representing-the-order-of-the-sequence-using-positional-encoding">5. Representing The Order of The Sequence Using Positional Encoding</a></li>
    <li><a href="#6-residuals">6. Residuals</a></li>
    <li><a href="#7-decoder-side">7. Decoder Side</a></li>
    <li><a href="#8-final-linear-and-softmax-layer">8. Final Linear and Softmax Layer</a></li>
    <li><a href="#9go-forth-and-transform">9.Go Forth And Transform</a></li>
  </ul>

  <ul>
    <li>
      <ul>
        <li></li>
      </ul>
    </li>
  </ul>
</nav></div>
      </div><div
      class="content"
      id="content"
      
      
    ><blockquote>
<p>The Transformer starts by generating initial representations, or embeddings, for each word. These are represented by the unfilled circles. Then, using self-attention, it aggregates information from all of the other words, generating a new representation per word informed by the entire context, represented by the filled balls. This step is then repeated multiple times in parallel for all words, successively generating new representations.</p>
</blockquote>
<ul>
<li>代码讲解地址：http://nlp.seas.harvard.edu/2018/04/03/attention.html</li>
</ul>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715201421532.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715201421532.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715201421532.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715201421532.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715201421532.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715201421532.png"/></p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<h2 id="1-embedding">1. Embedding</h2>
<blockquote>
<p>After embedding the words in our input sequence, each of them flows through each of the two layers of the encoder.</p>
<p>The word in each position flows through its own path in the encoder. There are dependencies between these paths in the self-attention layer. The feed-forward layer does not have those dependencies, however, and thus the various paths can be executed in parallel while flowing through the feed-forward layer.</p>
</blockquote>
<!-- raw HTML omitted -->
<h2 id="2-encode">2. <strong>Encode</strong></h2>
<blockquote>
<p>an encoder receives a list of vectors as input. It processes this list by passing these vectors into a ‘self-attention’ layer, then into a feed-forward neural network, then sends out the output upwards to the next encoder.</p>
</blockquote>
<ul>
<li>
<p><strong>Self-Attention</strong></p>
<ul>
<li>create vectors from each of the encoder’s input vectors (in this case, the embedding of each word). <!-- raw HTML omitted -->For each word, we create a Query vector, a Key vector, and a Value vector.<!-- raw HTML omitted --></li>
</ul>
<!-- raw HTML omitted -->
<ul>
<li>calculating self-attention is to calculate a score <!-- raw HTML omitted -->这一步具体是怎么实现的<!-- raw HTML omitted --></li>
</ul>
<!-- raw HTML omitted -->
<blockquote>
<p>Say we’re calculating the self-attention for the first word in this example, “Thinking”. We need to score each word of the input sentence against this word. The score determines how much focus to place on other parts of the input sentence as we encode a word at a certain position.</p>
</blockquote>
<ul>
<li><strong>third and forth steps</strong> are to divide the scores by 8 (the square root of the dimension of the key vectors used in the paper – 64. This leads to having more stable gradients. There could be other possible values here, but this is the default), then pass the result through a softmax operation. Softmax normalizes the scores so they’re all positive and add up to 1.</li>
</ul>
<!-- raw HTML omitted -->
<ul>
<li><strong>fifth step</strong> is to multiply each value vector by the softmax score (in preparation to sum them up). The intuition here is to keep intact the values of the word(s) we want to focus on, and drown-out irrelevant words (by multiplying them by tiny numbers like 0.001, for example).</li>
<li><strong>sixth step</strong> is to sum up the weighted value vectors. This produces the output of the self-attention layer at this position (for the first word).</li>
</ul>
</li>
</ul>
<h2 id="3-matrix-calculation-of-self-attention">3. <strong>Matrix Calculation of Self-Attention</strong></h2>
<ul>
<li><strong>the first step</strong> is to calculate the Query, Key, and Value matrices. We do that by packing our embeddings into a matrix X, and multiplying it by the weight matrices we’ve trained (WQ, WK, WV).</li>
</ul>
<!-- raw HTML omitted -->
<ul>
<li>condense steps two through six in one formula to calculate the outputs of the self-attention layer.</li>
</ul>
<!-- raw HTML omitted -->
<blockquote>
<p>RNNs maintain a hidden state allows an RNN to incorporate its representation of previous words/vectors it has processed with the current one it’s processing. Self-attention is the method the Transformer uses to bake the “understanding” of other relevant words into the one we’re currently processing.</p>
</blockquote>
<h2 id="4-the-beast-with-many-heads">4. The Beast With Many Heads</h2>
<ul>
<li><strong>“multi-headed” attention</strong></li>
</ul>
<blockquote>
<ol>
<li><!-- raw HTML omitted -->It expands the model’s ability to focus on different positions.<!-- raw HTML omitted --> Yes, in the example above, z1 contains a little bit of every other encoding, but it could be dominated by the the actual word itself. It would be useful if we’re translating a sentence like “The animal didn’t cross the street because it was too tired”, we would want to know which word “it” refers to.</li>
<li><!-- raw HTML omitted -->It gives the attention layer multiple “representation subspaces”.<!-- raw HTML omitted --> As we’ll see next, with multi-headed attention we have not only one, but multiple sets of Query/Key/Value weight matrices (the Transformer uses eight attention heads, so we end up with eight sets for each encoder/decoder). Each of these sets is randomly initialized. Then, after training, each set is used to project the input embeddings (or vectors from lower encoders/decoders) into a different representation subspace.</li>
</ol>
</blockquote>
<!-- raw HTML omitted -->
<blockquote>
<p>If we do the same self-attention calculation we outlined above, just eight different times with different weight matrices, we end up with eight different Z matrices</p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180613767.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180613767.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180613767.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180613767.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180613767.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180613767.png"/></p>
<ul>
<li>concat the matrices then multiple them by an additional weights matrix WO.</li>
</ul>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180644829.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180644829.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180644829.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180644829.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180644829.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180644829.png"/></p>
<ul>
<li>Multi-Headed self-attention visualization</li>
</ul>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180725827.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180725827.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180725827.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180725827.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180725827.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180725827.png"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180900704.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180900704.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180900704.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180900704.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180900704.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715180900704.png"/></p>
<blockquote>
<p>As we encode the word &ldquo;it&rdquo;, <!-- raw HTML omitted -->one attention head<!-- raw HTML omitted --> is focusing most on &ldquo;the animal&rdquo;, while another is focusing on &ldquo;tired&rdquo; &ndash; in a sense, the model&rsquo;s representation of the word &ldquo;it&rdquo; bakes in some of the representation of both &ldquo;animal&rdquo; and &ldquo;tired&rdquo;.</p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181015153.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181015153.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181015153.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181015153.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181015153.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181015153.png"/></p>
<h2 id="5-representing-the-order-of-the-sequence-using-positional-encoding">5. Representing The Order of The Sequence Using Positional Encoding</h2>
<blockquote>
<p>helps it determine the position of each word, or the distance between different words in the sequence.</p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181211222.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181211222.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181211222.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181211222.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181211222.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181211222.png"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181250522.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181250522.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181250522.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181250522.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181250522.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181250522.png"/></p>
<blockquote>
<p>In the following figure, each row corresponds the a positional encoding of a vector. So the first row would be the vector we’d add to the embedding of the first word in an input sequence. Each row contains 512 values – each with a value between 1 and -1. We’ve color-coded them so the pattern is visible.</p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181350421.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181350421.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181350421.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181350421.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181350421.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181350421.png"/></p>
<h2 id="6-residuals">6. Residuals</h2>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181554087.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181554087.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181554087.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181554087.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181554087.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181554087.png"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181715394.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181715394.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181715394.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715181715394.png 2x"
    data-sizes="auto"
    alt="Transformer of 2 stacked encoders and decoders"
    title="Transformer of 2 stacked encoders and decoders"/></p>
<h2 id="7-decoder-side">7. Decoder Side</h2>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/transformer_decoding_1.gif"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/transformer_decoding_1.gif, https://gitee.com/github-25970295/blogImage/raw/master/img/transformer_decoding_1.gif 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/transformer_decoding_1.gif 2x"
    data-sizes="auto"
    alt="transformer_decoding_1"
    title="transformer_decoding_1"/></p>
<blockquote>
<p>The following steps repeat the process until a special symbol is reached indicating the transformer decoder has completed its output. The output of each step is fed to the bottom decoder in the next time step, and the decoders bubble up their decoding results just like the encoders did. And just like we did with the encoder inputs, we embed and add positional encoding to those decoder inputs to indicate the position of each word.</p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/transformer_decoding_2.gif"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/transformer_decoding_2.gif, https://gitee.com/github-25970295/blogImage/raw/master/img/transformer_decoding_2.gif 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/transformer_decoding_2.gif 2x"
    data-sizes="auto"
    alt="transformer_decoding_2"
    title="transformer_decoding_2"/></p>
<h2 id="8-final-linear-and-softmax-layer">8. Final Linear and Softmax Layer</h2>
<blockquote>
<p>The decoder stack outputs a vector of floats.The Linear layer is a simple fully connected neural network that projects the vector produced by the stack of decoders, into a much, much larger vector called a logits vector.</p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715182513674.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715182513674.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715182513674.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715182513674.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715182513674.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715182513674.png"/></p>
<h2 id="9go-forth-and-transform">9.Go Forth And Transform</h2>
<ul>
<li>Watch <a href="https://www.youtube.com/watch?v=rBCqOTEfxvg"target="_blank" rel="external nofollow noopener noreferrer">Łukasz Kaiser’s talk<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> walking through the model and its details</li>
<li>Play with the <a href="https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb"target="_blank" rel="external nofollow noopener noreferrer">Jupyter Notebook provided as part of the Tensor2Tensor repo<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li>Explore the <a href="https://github.com/tensorflow/tensor2tensor"target="_blank" rel="external nofollow noopener noreferrer">Tensor2Tensor repo<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>.</li>
</ul>
<p>Follow-up works:</p>
<ul>
<li><a href="https://arxiv.org/abs/1706.03059"target="_blank" rel="external nofollow noopener noreferrer">Depthwise Separable Convolutions for Neural Machine Translation<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><a href="https://arxiv.org/abs/1706.05137"target="_blank" rel="external nofollow noopener noreferrer">One Model To Learn Them All<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><a href="https://arxiv.org/abs/1801.09797"target="_blank" rel="external nofollow noopener noreferrer">Discrete Autoencoders for Sequence Models<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><a href="https://arxiv.org/abs/1801.10198"target="_blank" rel="external nofollow noopener noreferrer">Generating Wikipedia by Summarizing Long Sequences<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><a href="https://arxiv.org/abs/1802.05751"target="_blank" rel="external nofollow noopener noreferrer">Image Transformer<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><a href="https://arxiv.org/abs/1804.00247"target="_blank" rel="external nofollow noopener noreferrer">Training Tips for the Transformer Model<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><a href="https://arxiv.org/abs/1803.02155"target="_blank" rel="external nofollow noopener noreferrer">Self-Attention with Relative Position Representations<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><a href="https://arxiv.org/abs/1803.03382"target="_blank" rel="external nofollow noopener noreferrer">Fast Decoding in Sequence Models using Discrete Latent Variables<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><a href="https://arxiv.org/abs/1804.04235"target="_blank" rel="external nofollow noopener noreferrer">Adafactor: Adaptive Learning Rates with Sublinear Memory Cost<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
</ul>
<p>转载学习于：</p>
<ul>
<li><a href="https://jalammar.github.io/illustrated-transformer/"target="_blank" rel="external nofollow noopener noreferrer">https://jalammar.github.io/illustrated-transformer/<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li>视频介绍：https://www.youtube.com/watch?v=rBCqOTEfxvg</li>
</ul>
<p><strong>author</strong>: Google Brain; Google Research
<strong>date</strong>: 2017
<strong>keyword</strong>:</p>
<ul>
<li>model</li>
</ul>
<blockquote>
<p>Vaswani, Ashish, et al. &ldquo;Attention is all you need.&rdquo; <em>Advances in neural information processing systems</em>. 2017.  cited by 11535</p>
</blockquote>
<hr>
<h1 id="paper-attention">Paper: Attention</h1>
<!-- raw HTML omitted -->
<h4 id="summary">Summary</h4>
<ol>
<li>propose the transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output.</li>
<li>the Transformer allows for significantly more parallelization and can reach a new state o fthe art in translation quality.</li>
</ol>
<h4 id="methods">Methods</h4>
<ul>
<li><strong>system overview</strong>:</li>
</ul>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715201421532.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715201421532.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715201421532.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715201421532.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715201421532.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715201421532.png"/></p>
<p><strong>【Module One】 Encoder and Decoder Stacks</strong></p>
<ul>
<li><strong>Encoder</strong></li>
</ul>
<blockquote>
<ul>
<li>composed of a stack of N=6 identical layers</li>
<li>each layer has multi-head self-attention mechanism, and position-wise fully connected feed-forward network.</li>
<li>employ a residual connection around each of the two sub-layers, followed by layer normalization.</li>
</ul>
</blockquote>
<ul>
<li><strong>Decoder</strong></li>
</ul>
<blockquote>
<ul>
<li>composed of stack of N=6 identical layers;</li>
<li>the decoder also inserts a third sub-layer, which performs multi-head attention over the output of the encoder stack.</li>
<li>modify the self-attention sub-layer in the decoder stack to pervent positions from attending to subsequent positions, called masking, ensures that the predictions for position i can depend only on the knownn outputs at positions less than i.</li>
</ul>
</blockquote>
<p><strong>【Attention】</strong></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/20200901102523.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/20200901102523.png, https://gitee.com/github-25970295/blogImage/raw/master/img/20200901102523.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/20200901102523.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/20200901102523.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/20200901102523.png"/></p>
<ul>
<li><strong>Scaled Dot-Product Attention</strong></li>
</ul>
<p>$$
Attention(Q,K,V)=softmax(QK^T/sqrt(d_k))V
$$</p>
<ul>
<li><strong>Multi-Head Attention</strong></li>
</ul>
<p>$$
MultiHead(Q,K,V)=Concat(head_1,&hellip;,head_h)W^o\
head_i=Attention(QW_i^Q,KW_i^K,VW_i^V)\
W_i^Q \epsilon R^{d_{model}<em>d_k}\
W^o \epsilon R^{hd_v</em>d_{model}}
$$</p>
<p><strong>【Application of Attention 】</strong></p>
<ul>
<li>allow every position in the decoder to attend over all positions in the input sequence;</li>
<li>each position in the encoder can attend to all positions in the previous layer of the encoder;</li>
</ul>
<p><strong>【Position-wise Feed-Forward Networks 】</strong>
$$
FFN(x)=max(0,xW_1+b_1)W_2+b_2
$$</p>
</div>
<div class="post-footer" id="post-footer">
  <div class="post-info">
    <div class="post-info-line">
      <div class="post-info-mod">
        <span title=2023-09-28&#32;23:52:33>更新于 2023-09-28&nbsp;</span>
      </div><div class="post-info-license">
          <span><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span>
        </div></div>
    <div class="post-info-line">
      <div class="post-info-md"><span><a href="liudongdong1.github.io/transformer_introduce/index.md" title="阅读原始文档" class="link-to-markdown">阅读原始文档</a></span><span><a href="https://liudongdong1.github.io/edit/master/content/posts%5c%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%5cmodel%5cTransformer_Introduce.md" title="编辑此页"target="_blank" rel="external nofollow noopener noreferrer" class="link-to-edit">编辑此页</a></span></div>
      <div class="post-info-share">
        <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="liudongdong1.github.io/transformer_introduce/" data-title="Transformer_Introduce" data-hashtags="Model"><i class="fa-brands fa-twitter fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="liudongdong1.github.io/transformer_introduce/" data-hashtag="Model"><i class="fa-brands fa-facebook-square fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="liudongdong1.github.io/transformer_introduce/" data-title="Transformer_Introduce" data-image="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200715201109572.png"><i class="fa-brands fa-weibo fa-fw" aria-hidden="true"></i></a>
  </span>
      </div>
    </div>
  </div>

  <div class="post-info-more">
    <section class="post-tags"><i class="fa-solid fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="liudongdong1.github.io/tags/model/">Model</a></section>
    <section>
      <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="liudongdong1.github.io/">主页</a></span>
    </section>
  </div>

  <div class="post-nav"><a href="liudongdong1.github.io/ctc_introduce/" class="prev" rel="prev" title="CTC_Introduce"><i class="fa-solid fa-angle-left fa-fw" aria-hidden="true"></i>CTC_Introduce</a>
      <a href="liudongdong1.github.io/similaritymetric/" class="next" rel="next" title="SimilarityMetric">SimilarityMetric<i class="fa-solid fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article></main><footer class="footer">
    <div class="footer-container"><div class="footer-line powered">由 <a href="https://gohugo.io/" target="_blank" rel="external nofollow noopener noreferrer" title="Hugo 0.118.2">Hugo</a> 强力驱动 | 主题 - <a href="https://github.com/hugo-fixit/FixIt" target="_blank" rel="external" title="FixIt v0.2.17-RC"><img class="fixit-icon" src="/liudongdong1.github.io/fixit.min.svg" alt="FixIt logo" />&nbsp;FixIt</a>
        </div><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">2020 - 2023</span><span class="author" itemprop="copyrightHolder">
              <a href="https://liudongdong1.github.io/"target="_blank" rel="external nofollow noopener noreferrer">LiuDongdong</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div><div class="footer-line statistics"><span class="site-time" title='网站运行中 ...'><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden="true"></i>&nbsp;<span class="run-times">网站运行中 ...</span></span></div><div class="footer-line ibruce">
          <span id="busuanzi_container_site_uv" title='总访客数'><i class="fa-regular fa-user fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span><span id="busuanzi_container_site_pv" class="footer-divider" title='总访问量'><i class="fa-regular fa-eye fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span>
        </div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="回到顶部"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric">0%</span>
        </div></div><a href="https://liudongdong1.github.io/" title="在 GitHub 上查看源代码"target="_blank" rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><div id="mask"></div><div class="reading-progress-bar" style="left: 0;top: 0;--bg-progress: #0076ff;--bg-progress-dark: #fff;"></div><noscript>
    <div class="noscript-warning">FixIt 主题在启用 JavaScript 的情况下效果最佳。</div>
  </noscript>
</div><link rel="stylesheet" href="/liudongdong1.github.io/lib/katex/katex.min.css"><link rel="stylesheet" href="/liudongdong1.github.io/lib/cookieconsent/cookieconsent.min.css"><script src="/liudongdong1.github.io/lib/autocomplete/autocomplete.min.js" defer></script><script src="/liudongdong1.github.io/lib/algoliasearch/algoliasearch-lite.umd.min.js" defer></script><script src="/liudongdong1.github.io/lib/lazysizes/lazysizes.min.js" async defer></script><script src="/liudongdong1.github.io/lib/sharer/sharer.min.js" async defer></script><script src="/liudongdong1.github.io/lib/typeit/index.umd.js" defer></script><script src="/liudongdong1.github.io/lib/katex/katex.min.js" defer></script><script src="/liudongdong1.github.io/lib/katex/auto-render.min.js" defer></script><script src="/liudongdong1.github.io/lib/katex/copy-tex.min.js" defer></script><script src="/liudongdong1.github.io/lib/katex/mhchem.min.js" defer></script><script src="/liudongdong1.github.io/lib/cookieconsent/cookieconsent.min.js" defer></script><script src="/liudongdong1.github.io/lib/pangu/pangu.min.js" defer></script><script src="/liudongdong1.github.io/lib/cell-watermark/watermark.min.js" defer></script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async defer></script><script>window.config={"code":{"copyTitle":"复制到剪贴板","editLockTitle":"锁定可编辑代码块","editUnLockTitle":"解锁可编辑代码块","editable":true,"maxShownLines":10},"comment":{"enable":false},"cookieconsent":{"content":{"dismiss":"同意","link":"了解更多","message":"本网站使用 Cookies 来改善您的浏览体验。"},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"data":{"typeit-header-subtitle-desktop":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e","typeit-header-subtitle-mobile":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e"},"enablePWA":true,"enablePangu":true,"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"2R1K9SKLQZ","algoliaIndex":"index.zh-cn","algoliaSearchKey":"4a226aa1c5c98d6859e4d1386adb2bc7","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"},"siteTime":"2020-12-18T16:15:22+08:00","typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"typeit-header-subtitle-desktop":["typeit-header-subtitle-desktop"],"typeit-header-subtitle-mobile":["typeit-header-subtitle-mobile"]},"duration":-1,"speed":100},"watermark":{"appendto":".wrapper\u003emain","colspacing":30,"content":"\u003cimg class=\"fixit-icon\" src=\"/fixit.min.svg\" alt=\"FixIt logo\" /\u003e FixIt 主题","enable":true,"fontfamily":"inherit","fontsize":0.85,"height":21,"opacity":0.0125,"rotate":15,"rowspacing":60,"width":150}};</script><script src="/liudongdong1.github.io/js/theme.min.js" defer></script><script src="/liudongdong1.github.io/js/custom.min.js" defer></script></body>
</html>
