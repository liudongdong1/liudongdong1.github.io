<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <head>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>PoseRelative - DAY By DAY</title><meta name="author" content="LiuDongdong">
<meta name="author-link" content="https://liudongdong1.github.io/">
<meta name="description" content="Meng, Zhen, et al. &ldquo;Gait recognition for co-existing multiple people using millimeter wave sensing.&rdquo; Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. No. 01. 2020. CCF -A Paper: mmGait Summary build and publicly achieve a first-of-its-kind mmWave gait data set, which is collected from 95 volunteers and lasts about 30 hours in total; propose a new deep learning model mmGaitNet to exact features for each attribute of point" /><meta name="keywords" content='mmwave' /><meta itemprop="name" content="PoseRelative">
<meta itemprop="description" content="Meng, Zhen, et al. &ldquo;Gait recognition for co-existing multiple people using millimeter wave sensing.&rdquo; Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. No. 01. 2020. CCF -A Paper: mmGait Summary build and publicly achieve a first-of-its-kind mmWave gait data set, which is collected from 95 volunteers and lasts about 30 hours in total; propose a new deep learning model mmGaitNet to exact features for each attribute of point"><meta itemprop="datePublished" content="2021-06-30T16:00:04+00:00" />
<meta itemprop="dateModified" content="2023-12-31T16:10:48+08:00" />
<meta itemprop="wordCount" content="2616"><meta itemprop="image" content="https://liudongdong1.github.io/logo.png"/>
<meta itemprop="keywords" content="mmwave," /><meta property="og:title" content="PoseRelative" />
<meta property="og:description" content="Meng, Zhen, et al. &ldquo;Gait recognition for co-existing multiple people using millimeter wave sensing.&rdquo; Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. No. 01. 2020. CCF -A Paper: mmGait Summary build and publicly achieve a first-of-its-kind mmWave gait data set, which is collected from 95 volunteers and lasts about 30 hours in total; propose a new deep learning model mmGaitNet to exact features for each attribute of point" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://liudongdong1.github.io/poserelative/" /><meta property="og:image" content="https://liudongdong1.github.io/logo.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-06-30T16:00:04+00:00" />
<meta property="article:modified_time" content="2023-12-31T16:10:48+08:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://liudongdong1.github.io/logo.png"/>

<meta name="twitter:title" content="PoseRelative"/>
<meta name="twitter:description" content="Meng, Zhen, et al. &ldquo;Gait recognition for co-existing multiple people using millimeter wave sensing.&rdquo; Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. No. 01. 2020. CCF -A Paper: mmGait Summary build and publicly achieve a first-of-its-kind mmWave gait data set, which is collected from 95 volunteers and lasts about 30 hours in total; propose a new deep learning model mmGaitNet to exact features for each attribute of point"/>
<meta name="application-name" content="DAY By DAY">
<meta name="apple-mobile-web-app-title" content="DAY By DAY"><meta name="theme-color" data-light="#f8f8f8" data-dark="#252627" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://liudongdong1.github.io/poserelative/" /><link rel="prev" href="https://liudongdong1.github.io/ssh_usage/" /><link rel="next" href="https://liudongdong1.github.io/githubsearch/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "PoseRelative",
    "inLanguage": "zh-CN",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https:\/\/liudongdong1.github.io\/poserelative\/"
    },"genre": "posts","keywords": "mmwave","wordcount":  2616 ,
    "url": "https:\/\/liudongdong1.github.io\/poserelative\/","datePublished": "2021-06-30T16:00:04+00:00","dateModified": "2023-12-31T16:10:48+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
      "@type": "Organization",
      "name": "LiuDongdong","logo": "https:\/\/liudongdong1.github.io\/images\/person.png"},"author": {
        "@type": "Person",
        "name": "liudongdong1"
      },"description": ""
  }
  </script></head>
  <body data-header-desktop="auto" data-header-mobile="auto"><script>(window.localStorage?.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('data-theme', 'dark');</script><div class="wrapper"><script type="text/javascript"
        async
        src="https://cdnjs.cloudflare.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>
<header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper" data-github-corner="right">
    <div class="header-title">
      <a href="/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="DAY By DAY"
    title="DAY By DAY"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-desktop" class="typeit header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a
                class="menu-link"
                href="/posts/"
                
                
              ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/categories/"
                
                
              ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/tags/"
                
                
              ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/friends/"
                title="友情链接"
                
              ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/about/"
                
                
              ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li class="menu-item delimiter"></li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <ul class="sub-menu"><li class="menu-item">没有更多翻译</li></ul>
          </li><li class="menu-item search" id="search-desktop">
            <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-desktop">
            <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
              <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
            </a>
            <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
              <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
            </a>
            <span class="search-button search-loading" id="search-loading-desktop">
              <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
            </span>
          </li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li>
      </ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="/fixit.min.svg"
    title="/fixit.min.svg"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-mobile" class="typeit header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li class="search-wrapper">
            <div class="search mobile" id="search-mobile">
              <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-mobile">
              <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
              </a>
              <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
              </a>
              <span class="search-button search-loading" id="search-loading-mobile">
                <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
              </span>
            </div>
            <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
              取消
            </a>
          </li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/posts/"
                  
                  
                ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/categories/"
                  
                  
                ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/tags/"
                  
                  
                ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/friends/"
                  title="友情链接"
                  
                ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/about/"
                  
                  
                ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li
              class="menu-item text-center"
            ><a
                  class="menu-link"
                  href="/"
                  title="GitHub"
                  
                ><i class='fa-brands fa-github fa-fw' aria-hidden='true'></i> </a></li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <select class="language-select" onchange="location = this.value;"><option disabled>没有更多翻译</option></select>
          </li></ul>
    </nav>
  </div>
</header><div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
  </div>
  <div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
  </div><main class="container" data-page-style="normal"><aside class="toc" id="toc-auto"><h2 class="toc-title">目录 <i class="toc-icon fa-solid fa-angle-down fa-fw"></i></h2>
      <div class="toc-content" id="toc-content-auto"></div></aside>

  <aside class="aside-custom" id="aside-sakana">
    

<div class="sakana-widget">
  <div class="sakana-item" id="takina-widget"></div>
  <div class="sakana-item" id="chisato-widget"></div>
</div>
<script>
  function initSakanaWidget() {
    const takina = SakanaWidget.getCharacter('takina')
    SakanaWidget.registerCharacter('takina-slow', takina);
    new SakanaWidget({
      character: 'takina-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#takina-widget');

    const chisato = SakanaWidget.getCharacter('chisato')
    SakanaWidget.registerCharacter('chisato-slow', chisato);
    new SakanaWidget({
      character: 'chisato-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#chisato-widget');
  }
</script>
<script async onload="initSakanaWidget()" src="https://cdn.jsdelivr.net/npm/sakana-widget@2.3.0/lib/sakana.min.js">
</script></aside>

  <article class="page single">
    <div class="header"><h1 class="single-title animate__animated animate__flipInX">
        <span>PoseRelative</span>
      </h1></div><div class="post-meta">
      <div class="post-meta-line"><span class="post-author"><span class="author"><i class="fa-solid fa-user-circle" aria-hidden="true"></i>
      liudongdong1</span></span>
          <span class="post-category">收录于 <a href="/categories/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;Categories</a>&ensp;<a href="/categories/aiot/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;AIOT</a></span></div>
      <div class="post-meta-line"><span title=2021-06-30&#32;16:00:04>
            <i class="fa-regular fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2021-06-30" >2021-06-30</time>
          </span>&nbsp;<i class="fa-solid fa-pencil-alt fa-fw"></i>&nbsp;约 2616 字&nbsp;
        <i class="fa-regular fa-clock fa-fw"></i>&nbsp;预计阅读 6 分钟&nbsp;<span id="busuanzi_container_page_pv" class="busuanzi_visitors comment-visitors" data-flag-title="PoseRelative">
            <i class="fa-regular fa-eye fa-fw"></i>&nbsp;<span id="busuanzi_value_page_pv">-</span>&nbsp;次阅读
          </span>&nbsp;</div>
    </div><div class="featured-image"><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://cdn.pixabay.com/photo/2021/05/10/14/48/rain-6243559__340.jpg"
    data-srcset="https://cdn.pixabay.com/photo/2021/05/10/14/48/rain-6243559__340.jpg, https://cdn.pixabay.com/photo/2021/05/10/14/48/rain-6243559__340.jpg 1.5x, https://cdn.pixabay.com/photo/2021/05/10/14/48/rain-6243559__340.jpg 2x"
    data-sizes="auto"
    alt="https://cdn.pixabay.com/photo/2021/05/10/14/48/rain-6243559__340.jpg"
    title="https://cdn.pixabay.com/photo/2021/05/10/14/48/rain-6243559__340.jpg"/></div><div class="details toc" id="toc-static" kept="true">
        <div class="details-summary toc-title">
          <span>目录</span>
          <span><i class="details-icon fa-solid fa-angle-right"></i></span>
        </div>
        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li></li>
      </ul>
    </li>
  </ul>
</nav></div>
      </div><div
      class="content"
      id="content"
      
      
    ><blockquote>
<p>Meng, Zhen, et al. &ldquo;Gait recognition for co-existing multiple people using millimeter wave sensing.&rdquo; <em>Proceedings of the <code>AAAI Conference on Artificial Intelligence</code></em>. Vol. 34. No. 01. <code>2020</code>.  <code>CCF -A</code></p>
</blockquote>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629134431230.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629134431230.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629134431230.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629134431230.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629134431230.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629134431230.png"/></p>
<hr>
<h1 id="paper--mmgait">Paper:  mmGait</h1>
<!-- raw HTML omitted -->
<h4 id="summary">Summary</h4>
<ol>
<li>build and publicly achieve a<code> first-of-its-kind mmWave gait data set</code>, which is collected from 95 volunteers and lasts about 30 hours in total;</li>
<li>propose a new deep learning model <code>mmGaitNet to exact features for each attribute of point cloud</code>.</li>
<li>Procedures
<ol>
<li>using two mmWave devices <code>capturing reflected signal</code> from walking persons to <code>forms point clouds.</code></li>
<li><code>segment</code> the point cloud of multi-people who are walking at the same time to get a single person&rsquo; s gait point cloud data.
<ul>
<li>using clustering algorithm <code>DBscan</code> to cluster point cloud;</li>
<li>using <code>Hungarian algorithm</code> to tack the point cloud clusters of one person&rsquo;s routes;</li>
<li>matching the route with corresponding volunteers one by one;</li>
</ul>
</li>
</ol>
</li>
<li>the accuracy of gait recognition decreases with the increase of number of co-existent walking people;</li>
<li>the accuracy of gait recognition increases if using more mmWave devices.</li>
</ol>
<h4 id="research-objective">Research Objective</h4>
<ul>
<li><strong>Application Area</strong>: <code>security check</code>,  <code>health monitoring,</code> <code>novel human-computer interaction</code></li>
<li><strong>Purpose</strong>:  accomplish person identification while <code>preserving privacy </code>even <code>under non-line-of-sight scenarios</code>, such as in <code>black weak light</code> or <code>blockage conditions</code>.</li>
</ul>
<h4 id="proble-statement">Proble Statement</h4>
<ul>
<li>each person&rsquo;s unique walking posture leads to a <code>unique wireless signal variation pattern</code>.</li>
</ul>
<p><strong>previous work:</strong></p>
<ul>
<li><code>Computer vision</code>:  <code>privacy concerns</code>,<code> lighting condition sensitive</code>;</li>
<li><code>wireless perception</code>:  difficult ot be segmented to <code>isolate the impact of each person</code>.
<ul>
<li>Channel state information(CSI): <code>WiFiUm,</code> <code>wiwho</code>, <code>AutoID</code>,</li>
</ul>
</li>
<li>human tracking and identify with mmWave radars (Zhao et al 2019)
<ul>
<li><code>autonomous environment mapping</code> using comodity mmWave;</li>
<li><code>robot navigation</code> in dynamic environment</li>
<li><code>vital sign monitoring</code></li>
<li>gesture recogniton: soli</li>
</ul>
</li>
</ul>
<h4 id="advantage">Advantage</h4>
<ul>
<li>emerging 5G technologies</li>
<li>mmWave provide much <code>fine-grained spatial resolution</code></li>
</ul>
<h4 id="methods">Methods</h4>
<h5 id="module-1-data-collection">【Module 1】 Data Collection</h5>
<ul>
<li><code>Time Synchronization</code>:   run time synchronization NTP on two computers, use the client computer to synchronize with the time of the server.</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629170334401.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629170334401.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629170334401.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629170334401.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629170334401.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629170334401.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629170831328.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629170831328.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629170831328.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629170831328.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629170831328.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629170831328.png"/></p>
<blockquote>
<p>Figure 2: The number of mmWave <code>reflection points</code>. In scene1 (a) and scene2 (c), as <code>the number of volunteers walking increases simultaneously</code>, <code>the number of points in the point cloud increases slowly.</code> In scene1 (b) and scene2 (d), as the number of walking volunteers increases simultaneously,<code>the number of points for a volunteer in the point cloud decreases.</code></p>
<ul>
<li>max cloud point output by devices</li>
<li>occlusion increased.</li>
</ul>
</blockquote>
<h5 id="module-2-data-annotation">【Module 2】 Data Annotation</h5>
<ul>
<li>remove noise points reflected by static objects utilizing static clutter removal <a href="https://zhuanlan.zhihu.com/p/269840008"target="_blank" rel="external nofollow noopener noreferrer">CFAR<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>.</li>
<li>adopt <a href="https://github.com/choffstein/dbscan"target="_blank" rel="external nofollow noopener noreferrer">DBSCAN<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> clustering to remove the noise points in the point cloud. the closet distance between two side-by-side people is about 0.3m.</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629184431564.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629184431564.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629184431564.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629184431564.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629184431564.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629184431564.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629184538151.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629184538151.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629184538151.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629184538151.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629184538151.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629184538151.png"/></p>
<h5 id="module-3-data-merge">【Module 3】 Data Merge</h5>
<ul>
<li>
<p><strong>Coordinate transformation</strong></p>
<ul>
<li>rotate the coordinate system of the two devices clockwise to make the two coordinate systems in the same direction.</li>
<li>translate the coordinate system of IWR6843 consistent with IWR1443.</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629185105205.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629185105205.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629185105205.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629185105205.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629185105205.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629185105205.png"/></p>
</li>
<li>
<p><strong>merge the point cloud from two devices who&rsquo;s time difference is less than specific threshold</strong></p>
</li>
</ul>
<h5 id="module-4-ai-mode">【Module 4】 AI Mode</h5>
<ul>
<li>input: point clouds&rsquo; five attributes: spatial location(x,y,z), radial speed, signal strength of the points. the input of each attribute network is a p*t matrix, p: number of points(128), t: time(3s).</li>
<li>output: the jth person;</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629185510729.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629185510729.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629185510729.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629185510729.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629185510729.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629185510729.png"/></p>
<h4 id="evaluation">Evaluation</h4>
<ul>
<li><strong>Environment</strong>:</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629152330692.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629152330692.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629152330692.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629152330692.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629152330692.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629152330692.png"/></p>
<blockquote>
<p>the two devices are configured to use all their three transmitter antennas and four receiver antennas to generate 3D point cloud data, outputing a frame of 3D point cloud in every 0.1s.</p>
</blockquote>
<ul>
<li>Result</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629190024594.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629190024594.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629190024594.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629190024594.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629190024594.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629190024594.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629190137949.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629190137949.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629190137949.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629190137949.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629190137949.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629190137949.png"/></p>
<h4 id="notes">Notes</h4>
<h5 id="ntp-时间同步httpszhuanlanzhihucomp138339057"><a href="https://zhuanlan.zhihu.com/p/138339057"target="_blank" rel="external nofollow noopener noreferrer">NTP 时间同步：<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></h5>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629191006843.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629191006843.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629191006843.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629191006843.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629191006843.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629191006843.png"/></p>
<h5 id="cfarhttpszhuanlanzhihucomp269840008"><a href="https://zhuanlan.zhihu.com/p/269840008"target="_blank" rel="external nofollow noopener noreferrer">CFAR<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></h5>
<blockquote>
<p>全称是Constant False Alarm Rate Detector，恒定虚警概率下的检测器，是雷达目标检测的一种常见的手段。在含有噪声的情况下确定信号<strong>存在</strong>还是<strong>不存在</strong>。恒虚警检测器首先对输入的噪声进行处理后确定一个门限，将此门限与输入端信号相比，如输入端信号超过了此门限，则判为有目标，否则，判为无目标。一般信号由信号源发出，在传播的过程中受到各种干扰，到达接收机后经过处理，输出到检测器，然后检测器根据适当的准则对输入的信号做出判决。</p>
</blockquote>
<ul>
<li>噪声和信号同时存在： $x(t)=s(t)+n(t)$;</li>
<li>只有噪声存在： $x(t)=n(t)$</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629191850177.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629191850177.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629191850177.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629191850177.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629191850177.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629191850177.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629192052515.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629192052515.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629192052515.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629192052515.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629192052515.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629192052515.png"/></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-matlab" data-lang="matlab"><span style="display:flex;"><span><span style="color:#75715e">%--------------------------------------------------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">%   初始化</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">%--------------------------------------------------------------------------</span>
</span></span><span style="display:flex;"><span>clear;clc;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sig = randn(<span style="color:#ae81ff">1000</span>,<span style="color:#ae81ff">1</span>);                                                        <span style="color:#75715e">%构造噪声信号</span>
</span></span><span style="display:flex;"><span>sig(<span style="color:#ae81ff">300</span>) = <span style="color:#ae81ff">15</span>;                                                              <span style="color:#75715e">%构造目标信号</span>
</span></span><span style="display:flex;"><span>sig_pow = sig<span style="color:#f92672">.^</span><span style="color:#ae81ff">2</span>;                                                           <span style="color:#75715e">%信号平方</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>[detected,th] = rt.cfar_detector(sig_pow,[<span style="color:#ae81ff">1e-6</span> <span style="color:#ae81ff">1e-6</span>],[<span style="color:#ae81ff">8</span> <span style="color:#ae81ff">3</span> <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">3</span> <span style="color:#ae81ff">8</span>]);          <span style="color:#75715e">%CFAR检测器，输出检测结果</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">%--------------------------------------------------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">%   可视化</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">%--------------------------------------------------------------------------</span>
</span></span><span style="display:flex;"><span>figure(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>plot(sig_pow);hold on
</span></span><span style="display:flex;"><span>plot(th);
</span></span><span style="display:flex;"><span>plot( find(detected<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>),sig_pow(detected),<span style="color:#e6db74">&#39;ro&#39;</span>)
</span></span><span style="display:flex;"><span>grid on
</span></span><span style="display:flex;"><span>hold off
</span></span><span style="display:flex;"><span>legend(<span style="color:#e6db74">&#39;回波信号&#39;</span>,<span style="color:#e6db74">&#39;判决门限&#39;</span>,<span style="color:#e6db74">&#39;判决结果&#39;</span>)
</span></span></code></pre></div><p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629192251178.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629192251178.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629192251178.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629192251178.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629192251178.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629192251178.png"/></p>
<ul>
<li><a href="https://github.com/qwe14789cn/radar_tools"target="_blank" rel="external nofollow noopener noreferrer">radar tools/TOF camera tools/Optimization Tools工具箱<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
</ul>
<h5 id="dbscanhttpsblogcsdnnetu013181595articledetails80452914"><a href="https://blog.csdn.net/u013181595/article/details/80452914"target="_blank" rel="external nofollow noopener noreferrer">DBSCAN<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></h5>
<blockquote>
<p>DBSCAN:(Density-Based Spatial Clustering of Applications with Noise)是一个比较有代表性的<code>基于密度的聚类算法</code>。与划分和层次聚类方法不同，它将簇定义为密度相连的点的最大集合，能够把具有足够高密度的区域划分为簇，并可在噪声的空间数据库中发现任意形状的聚类。<a href="https://github.com/choffstein/dbscan"target="_blank" rel="external nofollow noopener noreferrer">code<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</blockquote>
<ul>
<li>Ε邻域：给定对象半径为Ε内的区域称为该对象的Ε邻域；</li>
<li>核心对象：如果给定<code>对象Ε领域内的样本点数大于等于MinPts，</code>则称该对象为核心对象；</li>
<li>直接密度可达：对于样本集合D，如果<code>样本点q在p的Ε领域内</code>，并且<code>p为核心对象</code>，那么对象q从对象p直接密度可达。</li>
<li>密度可达：对于样本集合D，给定一串样本点p1,p2….pn，p= p1,q= pn,假如对象pi从pi-1直接密度可达，那么对象q从对象p密度可达。</li>
<li>密度相连：存在样本集合D中的一点o，如果对象o到对象p和对象q都是密度可达的，那么p和q密度相联。</li>
</ul>
<p>　　可以发现，密度可达是直接密度可达的传递闭包，并且这种关系是非对称的。密度相连是对称关系。DBSCAN目的是找到密度相连对象的最大集合。</p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629193050758.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629193050758.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629193050758.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629193050758.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629193050758.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629193050758.png"/></p>
<h5 id="hungarian-algorithm"><strong>Hungarian algorithm</strong></h5>
<blockquote>
<p>匈牙利算法是一种在多项式时间内O(n3)求解任务分配问题的组合优化算法。它之所以被称作匈牙利算法，是因为算法很大一部分是基于以前匈牙利数学家的工作之上创建起来的。此后该算法被称为Kuhn–Munkres算法或Munkres分配算法（The Munkres Assignment Algorithm）。</p>
</blockquote>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629193522634.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629193522634.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629193522634.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629193522634.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629193522634.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210629193522634.png"/></p>
<blockquote>
<p>Li, Ziheng, et al. &ldquo;<code>ThuMouse</code>: A micro-gesture cursor input through mmWave radar-based interaction.&rdquo; <em>2020 IEEE International Conference on Consumer Electronics (<code>ICCE</code>)</em>. IEEE, 2020. 国际消费电子年会 B类  [<a href="https://ieeexplore.ieee.org/document/9043082"target="_blank" rel="external nofollow noopener noreferrer">pdf<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>] [<a href="https://github.com/ApocalyVec/mGesf/tree/21e0bf37a9d11a3cdde86a8d54e2f6c6a2211ab5"target="_blank" rel="external nofollow noopener noreferrer">code<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>] [<a href="https://drive.google.com/file/d/1wNtAK8W8OSPjI1Kx1LN0ByB2U8i-aJUJ/view"target="_blank" rel="external nofollow noopener noreferrer">video<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>]</p>
</blockquote>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712092918103.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712092918103.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712092918103.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712092918103.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712092918103.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712092918103.png"/></p>
<hr>
<h1 id="paper--thumouse">Paper:  ThuMouse</h1>
<!-- raw HTML omitted -->
<h4 id="summary-1">Summary</h4>
<ul>
<li>to create a gesture-based and touch-free cursor interaction that accurately tracks the motion of fingers in real-time; builds a foundation for designing <code>finer micro gesture-based interactions</code>.</li>
<li>presents the gesture <code>sensing pipeline</code>, with<code>regressive tracking</code>though deep neural networks, <code>data augmentation </code>for robustness, and <code>computer vision </code>as a training base;</li>
</ul>
<h4 id="contribution">Contribution</h4>
<ul>
<li>by leveraging the sensing ability powered by the signal processing chain from 13, we detect the spatial position of objects as well as their velocity, making it possible to track the finger gesture.</li>
<li>end-to-end gesture pipeline using the radar point cloud combined with several data augmentation methods to enrich the feature and build more robust models.</li>
<li>illustrate the implementation and evaluation of 3D Concv LSTM model the processed the radar point cloud data to achieve the motion tracking and gesture classification;</li>
<li>propose a dual-input training system utilizing computer vision to automate labeling the tracking information.</li>
</ul>
<h4 id="research-objective-1">Research Objective</h4>
<ul>
<li><strong>Purpose</strong>:  meet the demand for<code> mobile interaction</code>, with <code>hands-free gadgets</code> such as <code>virtual reality</code>, <code>augmented reality</code>;</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712123923396.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712123923396.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712123923396.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712123923396.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712123923396.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712123923396.png"/></p>
<h4 id="proble-statement-1">Proble Statement</h4>
<p><strong>previous work:</strong></p>
<ul>
<li>Sensing technology: pulse-band radar; Google ATAP&rsquo;s Project Soli;</li>
<li>Detecting different gestures models;</li>
</ul>
<h4 id="advantage-1">Advantage</h4>
<ul>
<li>Compared to <code>capacitive sensing</code> or <code>optical sensors</code>, mmWave radar<code> lacks spatial resolution</code> due to the fact the the <code>reflected signals are superimposed;</code> albeit this is offset by the high temporal/velocity resolution and highly sophisticated prediction model, <code>distinguishing similar gestures suffers</code> because the moving parts reside in close proximity to each other;</li>
<li>Current approaches <code>using raw analog-to-digital converter output</code> with minimal pre-processing, the resulting data profile is usually a<code> range-velocity image</code> of the object in front of radar, <code>vary across different platforms in their size and resolution</code>, but the image data from cameras possess much generality;<code> The features given by mmWave devices are relatively unique</code>;</li>
<li>due to high throughput of data, the<code> input accuracy mush give away for the real-time interaction</code>;</li>
</ul>
<h4 id="methods-1">Methods</h4>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712094958230.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712094958230.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712094958230.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712094958230.png 2x"
    data-sizes="auto"
    alt="image-20210712094958230"
    title="image-20210712094958230"/></p>
<h5 id="module-1-data-processing">【Module 1】 Data Processing</h5>
<ul>
<li>
<p><strong>Clustering</strong>: <code>dynamic noise removing</code></p>
<ul>
<li>using <code>Density-Based Clustering of Applications with Noise</code> to identifies high density areas and expose outliers;</li>
<li>defines there must be at least <code>3 points to from a cluster </code>and<code>two points need to be at most 20cm</code>apart to be considered as in the same cluster.</li>
</ul>
</li>
<li>
<p><strong>Voxelization:</strong></p>
<ul>
<li>create a bounding volume: $x,y,z\epsilon[-R_{bound},R_{bound}]$ the point cloud to filer out any points that lie outside the specified range of the radar, using bound to the extends parts, and using min-max normalization;</li>
<li>rasterize $P_{tfilterd}$ into (25<em>25</em>25) voxel, adn treated as the hear or color of each voxel;</li>
</ul>
</li>
<li>
<p><strong>Point Matrix</strong>:</p>
<ul>
<li>the output points are <code>clustered</code> and <code>filtered to focus only on the hand</code>, the filter points are then<code> rasterized in a 3D voxel space, forming a 3D feature</code>;</li>
<li>radar frame: consists of n detected points, defined as n*4 matrix, each row is the <code>Cartesian coordiantes </code>and <code>Doppler</code> of the detected points;</li>
</ul>
</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712102200001.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712102200001.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712102200001.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712102200001.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712102200001.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712102200001.png"/></p>
<h5 id="module-2-data-augmentation">【Module 2】 Data Augmentation</h5>
<ul>
<li>translation: changes the spatial coordinates of the detected points while adding small Gaussian noise;</li>
<li>scale: meant for simulating individuals with different shaped hands;</li>
<li>rotation: cover the case where participants may perform the gesture at varying tilted angle;</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712103805381.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712103805381.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712103805381.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712103805381.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712103805381.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712103805381.png"/></p>
<h5 id="module-3-model">【Module 3】 Model</h5>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712105642772.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712105642772.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712105642772.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712105642772.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712105642772.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712105642772.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712105709879.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712105709879.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712105709879.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712105709879.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712105709879.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712105709879.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712123847405.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712123847405.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712123847405.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712123847405.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712123847405.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712123847405.png"/></p>
<ul>
<li>
<p>user move his/her thumb against the planar surface of the index finger, the temporal displacement of the thumb is reflected in cursor movement; the index finger is emulating the mouse pad;</p>
</li>
<li>
<p>convolutional layers extracting the non-linear features of each radar frame;</p>
</li>
<li>
<p>LSTM cells retaining the features from the frames in a time regressive manner;  <code>20PFS;</code></p>
</li>
<li>
<p>dense layers as output that are adjustable based on given gesture scheme;</p>
</li>
<li>
<p><code>output the tracked position of the thumb tip in its spatial coordinates(x,y,z)</code>.</p>
</li>
<li>
<p>Ground truth: choose the camera&rsquo;s tracking as ground truth reference for radar&rsquo;s tracking;</p>
<ul>
<li>a Yolo model that identifies the position of the fingertip. (pre-trained with 750 images from 3 participants);</li>
<li>using two camera to get the location information of the fingertip;( <code>not detailed explained</code>, <code>time synchronization problem</code>)</li>
<li>according to times tamp, using linearly interpolate the position given by the two photos to get the location of the fingertip at the time when that radar frame is recorded;</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113422762.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113422762.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113422762.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113422762.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113422762.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113422762.png"/></p>
</li>
</ul>
<h4 id="evaluation-1">Evaluation</h4>
<ul>
<li><strong>Environment</strong>:</li>
</ul>
<blockquote>
<p>one above the hand to detect the x and y;  the other placed to detect the y and z, and feed into the Yolo framework to resolve the true x,y,z position of the thumb tip;</p>
<ul>
<li>all trials are carried out with the hand <code>at the same relative position to the top camera</code></li>
</ul>
</blockquote>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113537061.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113537061.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113537061.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113537061.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113537061.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113537061.png"/></p>
<ul>
<li><strong>Device:</strong> <code>IWR6843</code>; <code>IWR6843ISK</code> antenna module (long range on-board antenna with 108 azimuth field of view(FoV) and 44 inclination FoV);</li>
<li><strong>Quantitative Results</strong></li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113811623.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113811623.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113811623.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113811623.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113811623.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113811623.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113928275.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113928275.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113928275.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113928275.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113928275.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113928275.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113958109.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113958109.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113958109.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113958109.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113958109.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712113958109.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712114028065.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712114028065.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712114028065.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712114028065.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712114028065.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210712114028065.png"/></p>
<blockquote>
<p>Sengupta, Arindam, et al. &ldquo;mm-Pose: Real-time human skeletal posture estimation using mmWave radars and CNNs.&rdquo; <em>IEEE Sensors Journal</em> 20.17 (2020): 10032-10044.</p>
</blockquote>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718113700271.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718113700271.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718113700271.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718113700271.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718113700271.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718113700271.png"/></p>
<ul>
<li><strong><a href="https://scholar.google.com/citations?hl=en&amp;user=dQvEspMAAAAJ&amp;view_op=list_works&amp;sortby=pubdate"target="_blank" rel="external nofollow noopener noreferrer">Siyang Cao<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>:</strong> The <a href="https://scholar.google.com/citations?view_op=view_org&amp;hl=en&amp;org=12195049151929734221"target="_blank" rel="external nofollow noopener noreferrer">University of Arizona<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
<ul>
<li>Sengupta A, Jin F, Cao S.<code> NLP based Skeletal Pose Estimation using mmWave Radar Point-Cloud: A Simulation Approach</code>[C]//2020 IEEE Radar Conference (RadarConf20). IEEE, 2020: 1-6.</li>
<li>Cao S, Sengupta <code>A. Systems and methods of remote extraction of skeletal information using millimeter wave radar</code>: U.S. Patent Application 17/065,476[P]. 2021-04-08.</li>
<li>Jin F, Sengupta A, Cao S. <code>mmFall: Fall Detection Using 4-D mmWave Radar and a Hybrid Variational RNN AutoEncoder</code>[J]. IEEE Transactions on Automation Science and Engineering, 2020.</li>
<li>Zhang R, Cao S. <code>Robust and Adaptive Radar Elliptical Density-Based Spatial Clustering and labeling for mmWave Radar Point Cloud Data</code>[C]//2019 53rd Asilomar Conference on Signals, Systems, and Computers. IEEE, 2019: 919-924.</li>
<li>Sengupta, Arindam, et al. &ldquo;<code>mm-Pose: Real-time human skeletal posture estimation using mmWave radars and CNNs</code>.&rdquo; <em>IEEE Sensors Journal</em> 20.17 (2020): 10032-10044.</li>
<li>Zhang R, Cao S. <code>Real-time human motion behavior detection via CNN using mmWave radar</code>[J]. IEEE Sensors Letters, 2018, 3(2): 1-4.</li>
<li>Jin F, Zhang R, Sengupta A, et al. <code>Multiple patients behavior detection in real-time using mmWave radar and deep CNNs</code>[C]//2019 IEEE Radar Conference (RadarConf). IEEE, 2019: 1-6.</li>
<li>Sengupta A, Jin F, Cao S. A <code>Dnn-LSTM based target tracking approach using mmWave radar and camera sensor fusion</code>[C]//2019 IEEE National Aerospace and Electronics Conference (NAECON). IEEE, 2019: 688-693.</li>
<li>Jin F, Sengupta A, Cao S, et al. <code>Mmwave radar point cloud segmentation using gmm in multimodal traffic monitoring</code>[C]//2020 IEEE International Radar Conference (RADAR). IEEE, 2020: 732-737.</li>
</ul>
</li>
</ul>
<hr>
<h1 id="paper-mm-pose">Paper: mm-Pose</h1>
<!-- raw HTML omitted -->
<h4 id="summary-2">Summary</h4>
<ol>
<li>the first method to detect &gt;15 distinct skeletal joints using mmWave radar reflection signals for a single human scenario for four primary motions, walking, swinging left arm, swinging right arm, swinging both arms.</li>
<li></li>
</ol>
<h4 id="research-objective-2">Research Objective</h4>
<ul>
<li><strong>Application Area</strong>:</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718133527018.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718133527018.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718133527018.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718133527018.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718133527018.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718133527018.png"/></p>
<ul>
<li><strong>Radar-To-Image Data Representation</strong>
<ul>
<li>assign an RGB weighted pixel value to the points, resulting in a 3-D heatmap; maping the reflection power-levels,</li>
<li>gray-scale representation: <img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718134338740.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718134338740.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718134338740.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718134338740.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718134338740.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718134338740.png"/></li>
<li>solving the problem for extremely sparse data, and reduce the CNN size and parameters;</li>
</ul>
</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718133814943.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718133814943.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718133814943.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718133814943.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718133814943.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718133814943.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718134557183.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718134557183.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718134557183.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718134557183.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718134557183.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718134557183.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718135024044.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718135024044.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718135024044.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718135024044.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718135024044.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718135024044.png"/></p>
<h4 id="experiment">Experiment</h4>
<ul>
<li>Texas Instruments AWR 1462 boost mmWave radar transceiver;</li>
<li>using Microsoft Kinect to get 25 joint positoin as wel the UTC time-stamp;</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718135126473.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718135126473.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718135126473.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718135126473.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718135126473.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718135126473.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718135152715.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718135152715.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718135152715.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718135152715.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718135152715.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20210718135152715.png"/></p>
</div>
<div class="post-footer" id="post-footer">
  <div class="post-info">
    <div class="post-info-line">
      <div class="post-info-mod">
        <span title=2023-12-31&#32;16:10:48>更新于 2023-12-31&nbsp;</span>
      </div><div class="post-info-license">
          <span><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span>
        </div></div>
    <div class="post-info-line">
      <div class="post-info-md"><span><a href="/poserelative/index.md" title="阅读原始文档" class="link-to-markdown">阅读原始文档</a></span><span><a href="https://liudongdong1.github.io/edit/master/content/posts%5cAIOT%5cmmwave%5cbackground%5cPoseRelative.md" title="编辑此页"target="_blank" rel="external nofollow noopener noreferrer" class="link-to-edit">编辑此页</a></span></div>
      <div class="post-info-share">
        <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="https://liudongdong1.github.io/poserelative/" data-title="PoseRelative" data-hashtags="mmwave"><i class="fa-brands fa-twitter fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="https://liudongdong1.github.io/poserelative/" data-hashtag="mmwave"><i class="fa-brands fa-facebook-square fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="https://liudongdong1.github.io/poserelative/" data-title="PoseRelative" data-image="https://cdn.pixabay.com/photo/2021/05/10/14/48/rain-6243559__340.jpg"><i class="fa-brands fa-weibo fa-fw" aria-hidden="true"></i></a>
  </span>
      </div>
    </div>
  </div>

  <div class="post-info-more">
    <section class="post-tags"><i class="fa-solid fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/mmwave/">mmwave</a></section>
    <section>
      <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
    </section>
  </div>

  <div class="post-nav"><a href="/ssh_usage/" class="prev" rel="prev" title="SSH_usage"><i class="fa-solid fa-angle-left fa-fw" aria-hidden="true"></i>SSH_usage</a>
      <a href="/githubsearch/" class="next" rel="next" title="GithubSearch">GithubSearch<i class="fa-solid fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article></main><footer class="footer">
    <div class="footer-container"><div class="footer-line powered">由 <a href="https://gohugo.io/" target="_blank" rel="external nofollow noopener noreferrer" title="Hugo 0.118.2">Hugo</a> 强力驱动 | 主题 - <a href="https://github.com/hugo-fixit/FixIt" target="_blank" rel="external" title="FixIt v0.2.17-RC"><img class="fixit-icon" src="/fixit.min.svg" alt="FixIt logo" />&nbsp;FixIt</a>
        </div><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">2020 - 2023</span><span class="author" itemprop="copyrightHolder">
              <a href="https://liudongdong1.github.io/"target="_blank" rel="external nofollow noopener noreferrer">LiuDongdong</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div><div class="footer-line statistics"><span class="site-time" title='网站运行中 ...'><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden="true"></i>&nbsp;<span class="run-times">网站运行中 ...</span></span></div><div class="footer-line ibruce">
          <span id="busuanzi_container_site_uv" title='总访客数'><i class="fa-regular fa-user fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span><span id="busuanzi_container_site_pv" class="footer-divider" title='总访问量'><i class="fa-regular fa-eye fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span>
        </div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="回到顶部"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric">0%</span>
        </div></div><a href="https://liudongdong1.github.io/" title="在 GitHub 上查看源代码"target="_blank" rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><div id="mask"></div><div class="reading-progress-bar" style="left: 0;top: 0;--bg-progress: #0076ff;--bg-progress-dark: #fff;"></div><noscript>
    <div class="noscript-warning">FixIt 主题在启用 JavaScript 的情况下效果最佳。</div>
  </noscript>
</div><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script src="/lib/autocomplete/autocomplete.min.js" defer></script><script src="/lib/algoliasearch/algoliasearch-lite.umd.min.js" defer></script><script src="/lib/lazysizes/lazysizes.min.js" async defer></script><script src="/lib/sharer/sharer.min.js" async defer></script><script src="/lib/typeit/index.umd.js" defer></script><script src="/lib/katex/katex.min.js" defer></script><script src="/lib/katex/auto-render.min.js" defer></script><script src="/lib/katex/copy-tex.min.js" defer></script><script src="/lib/katex/mhchem.min.js" defer></script><script src="/lib/cookieconsent/cookieconsent.min.js" defer></script><script src="/lib/pangu/pangu.min.js" defer></script><script src="/lib/cell-watermark/watermark.min.js" defer></script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async defer></script><script>window.config={"code":{"copyTitle":"复制到剪贴板","editLockTitle":"锁定可编辑代码块","editUnLockTitle":"解锁可编辑代码块","editable":true,"maxShownLines":10},"comment":{"enable":false},"cookieconsent":{"content":{"dismiss":"同意","link":"了解更多","message":"本网站使用 Cookies 来改善您的浏览体验。"},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"data":{"typeit-header-subtitle-desktop":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e","typeit-header-subtitle-mobile":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e"},"enablePWA":true,"enablePangu":true,"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"2R1K9SKLQZ","algoliaIndex":"index.zh-cn","algoliaSearchKey":"4a226aa1c5c98d6859e4d1386adb2bc7","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"},"siteTime":"2020-12-18T16:15:22+08:00","typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"typeit-header-subtitle-desktop":["typeit-header-subtitle-desktop"],"typeit-header-subtitle-mobile":["typeit-header-subtitle-mobile"]},"duration":-1,"speed":100},"watermark":{"appendto":".wrapper\u003emain","colspacing":30,"content":"\u003cimg class=\"fixit-icon\" src=\"/fixit.min.svg\" alt=\"FixIt logo\" /\u003e FixIt 主题","enable":true,"fontfamily":"inherit","fontsize":0.85,"height":21,"opacity":0.0125,"rotate":15,"rowspacing":60,"width":150}};</script><script src="/js/theme.min.js" defer></script><script src="/js/custom.min.js" defer></script></body>
</html>
