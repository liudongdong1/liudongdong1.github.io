# DistributionTheory


- From: https://juejin.cn/post/6874599410802622472

### 1. 分布式架构系统回顾

#### .1. 分布式系统概念

> 分布式系统是一个`硬件或软件组件分布在不同的网络计算机上`，彼此之间仅`仅通过消息传递进行通信和协调`的系统。

> 所谓分布式系统，就`是一个业务拆分成多个子业务`，分布在不同的服务器节点，共同构成的系统称为分 布式系统，同一个分布式系统中的服务器节点在空间部署上是可以随意分布的，这些服务器可能放在不同的机柜 中，也可能在不同的机房中，甚至分布在不同的城市。

 ![](https://gitee.com/github-25970295/blogimgv2022/raw/master/987fa93db8c54d0fb426a7620a3d024b~tplv-k3u1fbpfcp-zoom-1.image)

分布式与集群的区别：

- 集群：多个人在一起作同样的事 。
- 分布式 ：多个人在一起作不同的事 。

![](https://gitee.com/github-25970295/blogimgv2022/raw/master/36d06b9545304b6186db256c441b4882~tplv-k3u1fbpfcp-zoom-1.image)

**分布式系统的特点：**

（1）分布性
（2）对等性
（3）并发性
（4）缺乏全局时钟
（5）故障总是会发生

#### .2. 分布式系统的发展

阿里巴巴发起的"去 IOE"运动 (IOE 指的是 IBM 小型机、Oracle 数据库、EMC 的高端存储)。阿里巴巴2009 年“去 IOE”战略技术总监透露，截止到 2013 年 5 月 17 日阿里巴巴最后一台 IBM 小型机在支付宝下线。

为什么要去IOE?

1. 升级单机处理能力的性价比越来越低
2. 单机处理能力存在瓶颈
3. 稳定性和可用性这两个指标很难达到

#### .3. 分布式架构的演变

- 阶段一：`单应用架构`

 ![](https://gitee.com/github-25970295/blogimgv2022/raw/master/c01255f6f4164762915894d083670728~tplv-k3u1fbpfcp-zoom-1.image)

- 阶段二：`应用服务器与数据库服务器分离 `

![](https://gitee.com/github-25970295/blogimgv2022/raw/master/f4884896dc5c442babaed0b0a5c255ce~tplv-k3u1fbpfcp-zoom-1.image)

- 阶段三：`应用服务器集群 `

![](https://gitee.com/github-25970295/blogimgv2022/raw/master/8ed6b99db92d4776bd00c935677c9ff6~tplv-k3u1fbpfcp-zoom-1.image)

- 阶段四：`应用服务器负载均衡 `

![](https://gitee.com/github-25970295/blogimgv2022/raw/master/6601cdadc33947e2b159949c3f73c0eb~tplv-k3u1fbpfcp-zoom-1.image)

- 阶段五：`数据库读写分离 `

![](https://gitee.com/github-25970295/blogimgv2022/raw/master/aa81ed11c97e48a29a2dbeb0dbff49ea~tplv-k3u1fbpfcp-zoom-1.image)

- 阶段六：`添加搜索引擎缓解读库的压力 `

![](https://gitee.com/github-25970295/blogimgv2022/raw/master/b73f1b7c42af4e708a012171680cfcee~tplv-k3u1fbpfcp-zoom-1.image)

- 阶段七：添加`缓存机制缓解数据库的压力`

 ![](https://gitee.com/github-25970295/blogimgv2022/raw/master/d93efb4b61b644ee93bdaffe7e2d06ce~tplv-k3u1fbpfcp-zoom-1.image)

- 阶段八：`数据库水平/垂直拆分 `

![](https://gitee.com/github-25970295/blogimgv2022/raw/master/57dfa0a0b5cc4e30bcc2e71ed1f4303f~tplv-k3u1fbpfcp-zoom-1.image)

- 阶段九：`应用拆分 `

![](https://gitee.com/github-25970295/blogimgv2022/raw/master/18210f6d74b54e1dbc0c38992f90a46a~tplv-k3u1fbpfcp-zoom-1.image)

- 阶段十：`服务化 `

![](https://gitee.com/github-25970295/blogimgv2022/raw/master/4a4cd47079c848d8b26ae8f073d30a63~tplv-k3u1fbpfcp-zoom-1.image)

### 2. 分布式系统面临的问题

#### .1. 通信异常

> 网络本身的不可靠性，因此每次网络通信都会伴随着网络不可用的风险（光纤、路由、DNS等硬件设备或系统的不 可用），都会导致最终分布式系统无法顺利进行一次网络通信，另外，即使分布式系统各节点之间的网络通信能够 正常执行，其延时也会大于单机操作，存在巨大的延时差别，也会影响消息的收发过程，因此`消息丢失和消息延迟` 变的非常普遍。

#### .2. 网络分区

> 网络之间出现了网络不连通，但各个子网络的内部网络是正常的，从而导致整个系统的网络环境被切分成了若干个 孤立的区域，分布式系统就会出现局部小集群，在极端情况下，这些小集群会独立完成原本需要整个分布式系统才 能完成的功能，包括数据的事务处理，这就对分布式一致性提出非常大的挑战。

#### .3. 节点故障

> 节点故障是分布式系统下另一个比较常见的问题，指的是组成分布式系统的服务器节点出现的宕机或"僵死"现象， 根据经验来说，每个节点都有可能出现故障，并且经常发生.

#### .4. 三态

**分布式系统每一次请求与响应存在特有的“三态”概念，即成功、失败和超时。**

分布式系统中，由于网络是不可靠的，虽然绝大部分情况下，网络通信能够接收到成功或失败的响应，但当网络出 现异常的情况下，就会出现超时现象，通常有以下两种情况：

- 由于网络原因，该请求并没有被成功的发送到接收方，而是在发送过程就发生了丢失现象。
- 该请求成功的被接收方接收后，并进行了处理，但在响应反馈给发送方过程中，发生了消息丢失现象。

### 3. 分布式理论：一致性

`分布式数据一致性，指的是数据在多份副本中存储时，各副本中的数据是一致的。`

#### .1.  副本一致性

分布式系统当中，数据往往会有多个**副本**。如果是一台数据库处理所有的数据请求，那么通过`ACID四原则`，基本 可以保证数据的一致性。而`多个副本`就需要保证数据会有`多份拷贝`。这就带来了同步的问题，因为我们几乎没有办 法保证可以`同时更新所有机器`当中的包括备份所有数据。 `网络延迟`，即使我在同一时间给所有机器发送了更新数据 的请求，也不能保证这些请求被响应的时间保持一致`存在时间差`，就会存在某些机器之间的`数据不一致`的情况。

![](https://gitee.com/github-25970295/blogimgv2022/raw/master/04507f96da334e5fb0b972d6ccddb87e~tplv-k3u1fbpfcp-zoom-1.image) 

总得来说，我们无法找到一种能够满足分布式系统所有系统属性的分布式一致性解决方案。因此，如何既保证数据 的一致性，同时又不影响系统运行的性能，是每一个分布式系统都需要重点考虑和权衡的。于是，一致性级别由此 诞生：

#### .2. 一致性分类

- **强一致性**: 这种一致性级别是最符合用户直觉的，它要求系统写入什么，读出来的也会是什么，用户体验好，但实现起来往往 对系统的性能影响大。但是强一致性很难实现。

- **弱一致性**: 这种一致性级别约束了系统在写入成功后，不承诺立即可以读到写入的值，也不承诺多久之后数据能够达到一致， 但会尽可能地保证到某个时间级别（比如秒级别）后，数据能够达到一致状态。

#### .3. 读写一致性

> 用户`读取自己写入结果的一致性`，保证用户永远能够第一时间看到自己更新的内容。 比如我们发一条朋友圈，朋友圈的内容是不是第一时间被朋友看见不重要，但是一定要显示在自己的列表上.

- 方案1：一种方案是对于一些特定的内容我们每次都去主库读取。 （问题主库压力大） 

- 方案2：我们设置一个`更新时间窗口`，在刚刚`更新的一段时间内，我们默认都从主库读取，过了这个窗口之后，我们会挑 选最近有过更新的从库进行读取 `

- 方案3：我们`直接记录用户更新的时间戳`，在请求的时候`把这个时间戳带上`，凡是最后更新时间小于这个时间戳的从库都 不予以响应。

#### .4. 单调读一致性

> `本次读到的数据不能比上次读到的旧`。 由于主从节点更新数据的时间不一致，导致用户在不停地刷新的时候，有时候能刷出来，再次刷新之后会发现数据不见 了，再刷新又可能再刷出来，就好像遇见灵异事件一样 

- 就是`根据用户ID计算一个hash值，再通过hash值映射到机器`。`同一个用户不管怎么刷新，都只会被映射到同 一台机器上`。这样就保证了不会读到其他从库的内容，带来用户体验不好的影响。

![](https://gitee.com/github-25970295/blogimgv2022/raw/master/66f22a9834064a469e2b75685de07b5a~tplv-k3u1fbpfcp-zoom-1.image)

#### .5. 因果一致性

> 指的是：如果节点 A 在更新完某个数据后通知了节点 B，那么节点 B 之后对该数据的访问和修改都是基于 A 更新后 的值。于此同时，和节点 A 无因果关系的节点 C 的数据访问则没有这样的限制。

#### .6. 最终一致性

> 最终一致性是所有分布式一致性模型当中最弱的。可以认为是没有任何优化的“最”弱一致性，它的意思是说，我不考虑 所有的中间状态的影响，`只保证当没有新的更新之后，经过一段时间之后，最终系统内所有副本的数据是正确的`。 它最大程度上保证了系统的并发能力，也因此，在高并发的场景下，它也是使用最广的一致性模型

![](https://gitee.com/github-25970295/blogimgv2022/raw/master/2b8a9df7b6744113bc1e50596ec3bb58~tplv-k3u1fbpfcp-zoom-1.image)

### 4. 分布式理论：CAP定理

> CAP 理论含义是，一个分布式系统不可能同时满足一致性（C:Consistency)，可用性（A: Availability）和分区容错 性（P：Partition tolerance）这三个基本需求，最多只能同时满足其中的2个。

| 选项         | 描述                                                         |
| ------------ | ------------------------------------------------------------ |
| C 一致性     | 分布式系统当中的一致性指的是`所有节点的数据一致，或者说是所有副本的数据一致` |
| A 可用性     | Reads and writes always succeed. 也就是说`系统一直可用`，而且`服务一直保持正常` |
| P 分区容错性 | 系统`在遇到一些节点或者网络分区故障的时候`，`仍然能够提供满足一致性和可用性的服务` |

![](https://gitee.com/github-25970295/blogimgv2022/raw/master/8ca1a9164ecd4767822a9e6c0e72e324~tplv-k3u1fbpfcp-zoom-1.image)

![](https://gitee.com/github-25970295/blogimgv2022/raw/master/b81767b5fc0843a08926d9683c37a73d~tplv-k3u1fbpfcp-zoom-1.image)

![](https://gitee.com/github-25970295/blogimgv2022/raw/master/654000662460482784b3f281eb2bce56~tplv-k3u1fbpfcp-zoom-1.image)

**假设有一个系统如下：** ![](https://gitee.com/github-25970295/blogimgv2022/raw/master/dd23bc24dd1148ef8969384f9e432f35~tplv-k3u1fbpfcp-zoom-1.image)

> 有用户向N1发送了请求更改了数据，将数据库从V0更新成了V1。由于网络断开，所以N2数据库依然是V0，如果这个时候 有一个请求发给了N2，但是N2并没有办法可以直接给出最新的结果V1，这个时候该怎么办呢？
>
> 这个时候无法两种方法，一种是将错就错，将错误的V0数据返回给用户。第二种是阻塞等待，等待网络通信恢复，N2中 的数据更新之后再返回给用户。显然前者牺牲了一致性，后者牺牲了可用性。
>
> 这个例子虽然简单，但是说明的内容却很重要。在分布式系统当中，CAP三个特性我们是无法同时满足的，必然要舍弃一 个。三者舍弃一个，显然排列组合一共有三种可能。

**1. 舍弃A(可用性)，保留CP(一致性和分区容错性)**

> 一个系统保证了一致性和分区容错性，舍弃可用性。也就是说在极端情况下，允许出现系统无法访问的情况出现，这个 时候往往会牺牲用户体验，让用户保持等待，一直到系统数据一致了之后，再恢复服务。
>
> 比如12306的时候，就让你重试就好了

**2. 舍弃C(一致性)，保留AP(可用性和分区容错性)**

> 这种是大部分的分布式系统的设计，保证高可用和分区容错，但是会牺牲一致性。
>
> 比如：更新个人状态时，并不是马上所有人都知道，而是等待一定时间，所有人才能收到

**3. 舍弃P(分区容错性)，保留CA(一致性和可用性)**

> 如果要舍弃P，那么就是要舍弃分布式系统，CAP也就无从谈起了。可以说P是分布式系统的前提，所以这种情况是不存在 的。

### 5. 分布式理论：BASE 理论

#### 1-Basically Available(基本可用)

基本可用是指分布式系统在出现不可预知故障的时候，`允许损失部分可用性`

但请注意，这`绝不等价于系统不可用`。以下就是两个"基本可用"的例子

- `响应时间上的损失`：正常情况下，一个在线搜索引擎需要在0.5秒之内返回给用户相应的查询结果，但由于出现故障（比如系统部分机房发生断电或断网故障），查询结果的响应时间增加到了1~2秒。
- `功能上的损失`：正常情况下，在一个电子商务网站（比如淘宝）上购物，消费者几乎能够顺利地完成每一笔订单。但在一些节日大促购物高峰的时候（比如双十一、双十二），由于消费者的购物行为激增，为了保护系统的稳定性（或者保证一致性），部分消费者可能会被引导到一个降级页面，如下 ![](https://gitee.com/github-25970295/blogimgv2022/raw/master/4b29aa951d224617b37dc046c710d410~tplv-k3u1fbpfcp-zoom-1.image)

#### 2-Soft state（软状态）

> 允许系统中的数据`存在中间状态`，并认为该状态`不影响系统的整体可用性`，即允许系统在多个不同节点的数据副本之间进行数据同步的过程中存在延迟。

#### 3-Eventually consistent（最终一致性）

最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，`最终能够达到一个一致的状态`。因此最终一致性的本质是需要系统保证最终数据能够达到一致，而`不需要实时保证`系统数据的强一致性。

### 6. 分布式事务

- **Atomicity（原子性）**

  是说事务是一个不可分割的整体，所有操作要么全做，要么全不做；只要事务中有一个操作出错，回滚到事务开始前的状态的话，那么之前已经执行的所有操作都是无效的，都应该回滚到开始前的状态。

- **Consistency（一致性）**

  是说事务执行前后，数据从一个状态到另一个状态必须是一致的，比如A向B转账（A、 B的总金额就是一个一致性状态），不可能出现A扣了钱，B却没收到的情况发生。

- **Isolation（隔离性）**

  多个并发事务之间相互隔离，不能互相干扰。关于事务的隔离性，可能不是特别好理解，这里的并发事务是指两个事务操作了同一份数据的情况；而对于并发事务操作同一份数据的隔离性问题，则是要求不能出现脏读、幻读的情况，即事务A不能读取事务B还没有提交的数据，或者在事务A读取数据进行更新操作时，不允许事务B率先更新掉这条数据。而为了解决这个问题，常用的手段就是加锁了，对于数据库来说就是通过数据库的相关锁机制来保证。

- **Durablity（持久性）** 事务完成后，对数据库的更改是永久保存的。

> 其实`分布式事务从实质上看与数据库事务的概念是一致的`，既然是事务也就需要满足事务的基本特性（ACID），只是分布式事务相对于本地事务而言其表现形式有很大的不同

### 7. 分布式理论：一致性协议 2PC

> 2PC （ Two-Phase Commit缩写）即两阶段提交协议，是`将整个事务流程分为两个阶段`，`准备阶段（Prepare phase）、提交阶段（commit phase）`，2是指两个阶段，P是指准备阶段，C是指提交阶段。在计算机中部分关系数据库如Oracle、MySQL支持两阶段提交协议.

![img](https://gitee.com/github-25970295/blogimgv2022/raw/master/2fb5b210091a4dd1b15eecd9c9bcc2e4~tplv-k3u1fbpfcp-zoom-1.image)

**准备阶段（Prepare phase）**：

- `事务管理器给每个参与者发送Prepare消息`
- 每个数据库参与者在本地执行事务，并`写本地的Undo/Redo日志`
- 此时事务没有提交。

`Undo日志是记录修改前的数据，用于数据库回滚，Redo日志是记录修改后的数据，用于提交事务后写入数据文件`

**提交阶段（commit phase）**:

- 如果`事务管理器收到了参与者的执行失败或者超时消息时，直接给每个参与者发送回滚(Rollback)消息；`
- 否则，`发送提交(Commit)消息`；参与者根据事务管理器的指令执行提交或者回滚操作，并释放事务处理过程中使用的锁资源。

`注意:必须在最后阶段释放锁资源。 `

![](https://gitee.com/github-25970295/blogimgv2022/raw/master/0a92f1aa17a74721af462f3d4caa1173~tplv-k3u1fbpfcp-zoom-1.image)

> 阶段一: 
> 1. 事务询问: 协调者向所有的参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待各参与者的响应。 
> 2. 执行事务 (写本地的Undo/Redo日志) 
> 3. 各参与者向协调者反馈事务询问的响应 
>
> 总结: 各个参与者进行投票是否让事务进行
>
> 阶段二: 
> 1. 发送提交请求： 协调者向所有参与者发出 commit 请求。 
> 2. 事务提交： 参与者收到 commit 请求后，会`正式执行事务提交操作`，并`在完成提交之后释放整个事务执行期间占用的事务资源。`
> 3. 反馈事务提交结果： 参与者在完成事务提交之后，向协调者发送 Ack 信息。 
> 4. 完成事务： 协调者接收到所有参与者反馈的 Ack 信息后，完成事务

**中断事务步骤如下：** 假如任何一个参与者向协调者`反馈了No响应，或者在等待超时`之后，协调者尚无法接收到所有参与者的反馈响 应，那么就会`中断事务 `

![](https://gitee.com/github-25970295/blogimgv2022/raw/master/80f7796ceab8473ba672f17f35657f8b~tplv-k3u1fbpfcp-zoom-1.image)

- **缺点**
  - 同步阻塞：二阶段提交协议存在最明显也是最大的一个问题就是`同步阻塞`，在二阶段提交的执行过程中，`所有参与该事务操作的逻辑都处于阻塞状态`，也就是说，各个参与者在等待其他参与者响应的过程中，`无法进行其他操作`。这种同步阻 塞极大的限制了分布式系统的性能。
  - 单点问题：协调者在整个二阶段提交过程中很重要，如果协调者在`提交阶段出现问题`，那么整个流程将`无法运转`，更重要的是：其他参与者将会处于`一直锁定事务资源`的状态中，而无法继续完成事务操作。
  - 数据不一致：假设当协调者向所有的参与者发送 commit 请求之后，发生了`局部网络异常`或者是协调者在尚未发送完所有commit 请求之前`自身发生了崩溃`，导致最终只有`部分参与者`收到了 commit 请求。这将导致严重的数据不一致问题。
  -  过于保守：如果在二阶段提交的提交询问阶段中，参与者出现故障而导致协调者始终无法获取到所有参与者的响应信息的话，这时协调者只能依靠`其自身的超时机制`来判断是否需要中断事务，显然，这种策略过于保守。换句话说，二阶段提 交协议`没有设计较为完善的容错机制`，任意一个节点失败都会导致`整个事务的失败。`

### 8. 分布式理论：一致性协议 3PC

> 3PC，全称 “three phase commit”，是 2PC 的改进版，将 2PC 的 “提交事务请求” 过程一分为二，共形成了由`CanCommit、PreCommit和doCommit三个阶段组成的事务处理协议。`

![](https://gitee.com/github-25970295/blogimgv2022/raw/master/fdbfe937597547f9950121a9f47951d7~tplv-k3u1fbpfcp-zoom-1.image)

#### 阶段一：CanCommit

- 事务询问: 协调者向`所有的参与者`发送一个包含事务内容的canCommit请求，询问是否可以执行事务提交操作，并开始`等待各参与者的响应`。
- 各参与者向协调者反馈事务询问的响应: 参与者在接收到来自协调者的包含了事务内容的`canCommit请求`后，正常情况下，如果自身认为可以顺利执行事务，则`反馈Yes响应`，并进入预备状态，否则`反馈No响应`

#### 阶段二：PreCommit

> 协调者在得到所有参与者的响应之后，会根据结果有2种执行操作的情况：`执行事务预提交`，或者`中断事务`, 假如`所有参与反馈的都是Yes，那么就会执行事务预提交。`

**(1)执行事务预提交分为 3 个步骤 **

1.  发送预提交请求：协调者向所有参与者节点发出preCommit请求，并进入prepared阶段。

2. 事务预提交：`参与者接收到preCommit请求后，会执行事务操作`，并将`Undo和Redo信息记录到事务日志中`

3.  各参与者向协调者反馈事务执行的结果: `若参与者成功执行了事务操作，那么反馈Ack`

> 若任一参与者反馈了No响应，或者在等待超时后，协调者尚无法接收到所有参与者反馈，则中断事务

**(2)中断事务也分为2个步骤：**

1. 发送中断请求：协调者向所有参与者发出abort请求。

2. 中断事务：无论是收到来自协调者的abort请求或者等待协调者请求过程中超时，参与者都会中断事务

#### 阶段三：do Commit

 该阶段做真正的事务提交或者完成事务回滚，所以就会出现两种情况：

> 执行事务提交

1- 发送提交请求：进入这一阶段，假设协调者处于正常工作状态，并且它接收到了来自所有参与者的Ack响应，那么他将从预提交状态转化为提交状态，并向所有的参与者发送doCommit请求。

2- 事务提交：参与者接收到doCommit请求后，会正式执行事务提交操作，并在完成提交之后释放整个事务执行过程中占用的事务资源。

3- 反馈事务提交结果：参与者在完成事务提交后，向协调者发送Ack响应。

4- 完成事务：协调者接收到所有参与者反馈的Ack消息后，完成事务。

> 中断事务

1-发送中断请求：协调者向所有的参与者节点发送abort请求。

2-事务回滚：参与者收到abort请求后，会根据记录的Undo信息来执行事务回滚，并在完成回滚之后释放整个事务执行期间占用的资源。

3-反馈事务回滚结果：参与者在完成事务回滚后，向协调者发送Ack消息。

4-中断事务：协调者接收到所有参与者反馈的Ack消息后，中断事务。

注意：一旦进入阶段三，可能会出现 2 种故障：

- 协调者出现问题
- 协调者和参与者之间的网络故障

> 如果出现了任一一种情况，最终都会导致参与者无法收到 doCommit 请求或者 abort 请求，针对这种情况，参与者都会在等待超时之后，继续进行事务提交

### 9. 2PC对比3PC

1. 首先对于协调者和参与者`都设置了超时机制`（在2PC中，只有协调者拥有超时机制，即如果在一定时间内没有收到参与者的消息则默认失败）,主要是避免了参与者在长时间无法与协调者节点通讯（协调者挂掉了）的情况下，无法释放资源的问题，`因为参与者自身拥有超时机制会在超时后，自动进行本地commit从而进行释放资源`。而这种机制也侧面降低了整个事务的阻塞时间和范围。
2. 通过CanCommit、PreCommit、DoCommit三个阶段的设计，相较于2PC而言，`多设置了一个缓冲阶段`保证了在最后提交阶段之前各参与节点的状态是一致的 。
3. PreCommit是一个缓冲，保证了在最后提交阶段之前各参与节点的状态是一致的。

问题：3PC协议并没有完全解决数据不一致问题。



---

> 作者: liudongdong1  
> URL: liudongdong1.github.io/distributiontheory/  

