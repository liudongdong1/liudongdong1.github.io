<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <head>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>AllenNLPIntroduce - DAY By DAY</title><meta name="author" content="LiuDongdong">
<meta name="author-link" content="https://liudongdong1.github.io/">
<meta name="description" content="you can write your own script to construct the dataset reader and model and run the training loop, or you can write a configuration file and use the allennlp train command 1. Text Classification Spam filtering Detect and filter spam emails Email Spam / Not spam Sentiment analysis Detect the polarity of text Tweet, review Positive / Negative Topic detection Detect the topic of text News article, blog post Business" /><meta name="keywords" content='Math&Model' /><meta itemprop="name" content="AllenNLPIntroduce">
<meta itemprop="description" content="you can write your own script to construct the dataset reader and model and run the training loop, or you can write a configuration file and use the allennlp train command 1. Text Classification Spam filtering Detect and filter spam emails Email Spam / Not spam Sentiment analysis Detect the polarity of text Tweet, review Positive / Negative Topic detection Detect the topic of text News article, blog post Business"><meta itemprop="datePublished" content="2020-10-20T07:56:09+00:00" />
<meta itemprop="dateModified" content="2023-12-31T14:33:15+08:00" />
<meta itemprop="wordCount" content="2062"><meta itemprop="image" content="https://liudongdong1.github.io/logo.png"/>
<meta itemprop="keywords" content="Math&amp;Model," /><meta property="og:title" content="AllenNLPIntroduce" />
<meta property="og:description" content="you can write your own script to construct the dataset reader and model and run the training loop, or you can write a configuration file and use the allennlp train command 1. Text Classification Spam filtering Detect and filter spam emails Email Spam / Not spam Sentiment analysis Detect the polarity of text Tweet, review Positive / Negative Topic detection Detect the topic of text News article, blog post Business" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://liudongdong1.github.io/allennlpintroduce/" /><meta property="og:image" content="https://liudongdong1.github.io/logo.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-10-20T07:56:09+00:00" />
<meta property="article:modified_time" content="2023-12-31T14:33:15+08:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://liudongdong1.github.io/logo.png"/>

<meta name="twitter:title" content="AllenNLPIntroduce"/>
<meta name="twitter:description" content="you can write your own script to construct the dataset reader and model and run the training loop, or you can write a configuration file and use the allennlp train command 1. Text Classification Spam filtering Detect and filter spam emails Email Spam / Not spam Sentiment analysis Detect the polarity of text Tweet, review Positive / Negative Topic detection Detect the topic of text News article, blog post Business"/>
<meta name="application-name" content="DAY By DAY">
<meta name="apple-mobile-web-app-title" content="DAY By DAY"><meta name="theme-color" data-light="#f8f8f8" data-dark="#252627" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://liudongdong1.github.io/allennlpintroduce/" /><link rel="prev" href="https://liudongdong1.github.io/wordembedding/" /><link rel="next" href="https://liudongdong1.github.io/pytorchsegmentcode/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "AllenNLPIntroduce",
    "inLanguage": "zh-CN",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https:\/\/liudongdong1.github.io\/allennlpintroduce\/"
    },"genre": "posts","keywords": "Math\u0026Model","wordcount":  2062 ,
    "url": "https:\/\/liudongdong1.github.io\/allennlpintroduce\/","datePublished": "2020-10-20T07:56:09+00:00","dateModified": "2023-12-31T14:33:15+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
      "@type": "Organization",
      "name": "LiuDongdong","logo": "https:\/\/liudongdong1.github.io\/images\/person.png"},"author": {
        "@type": "Person",
        "name": "liudongdong1"
      },"description": ""
  }
  </script></head>
  <body data-header-desktop="auto" data-header-mobile="auto"><script>(window.localStorage?.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('data-theme', 'dark');</script><div class="wrapper"><script type="text/javascript"
        async
        src="https://cdnjs.cloudflare.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>
<header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper" data-github-corner="right">
    <div class="header-title">
      <a href="/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="DAY By DAY"
    title="DAY By DAY"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-desktop" class="typeit header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a
                class="menu-link"
                href="/posts/"
                
                
              ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/categories/"
                
                
              ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/tags/"
                
                
              ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/friends/"
                title="友情链接"
                
              ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/about/"
                
                
              ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li class="menu-item delimiter"></li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <ul class="sub-menu"><li class="menu-item">没有更多翻译</li></ul>
          </li><li class="menu-item search" id="search-desktop">
            <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-desktop">
            <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
              <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
            </a>
            <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
              <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
            </a>
            <span class="search-button search-loading" id="search-loading-desktop">
              <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
            </span>
          </li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li>
      </ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="/fixit.min.svg"
    title="/fixit.min.svg"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-mobile" class="typeit header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li class="search-wrapper">
            <div class="search mobile" id="search-mobile">
              <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-mobile">
              <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
              </a>
              <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
              </a>
              <span class="search-button search-loading" id="search-loading-mobile">
                <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
              </span>
            </div>
            <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
              取消
            </a>
          </li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/posts/"
                  
                  
                ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/categories/"
                  
                  
                ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/tags/"
                  
                  
                ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/friends/"
                  title="友情链接"
                  
                ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/about/"
                  
                  
                ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li
              class="menu-item text-center"
            ><a
                  class="menu-link"
                  href="/"
                  title="GitHub"
                  
                ><i class='fa-brands fa-github fa-fw' aria-hidden='true'></i> </a></li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <select class="language-select" onchange="location = this.value;"><option disabled>没有更多翻译</option></select>
          </li></ul>
    </nav>
  </div>
</header><div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
  </div>
  <div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
  </div><main class="container" data-page-style="normal"><aside class="toc" id="toc-auto"><h2 class="toc-title">目录 <i class="toc-icon fa-solid fa-angle-down fa-fw"></i></h2>
      <div class="toc-content" id="toc-content-auto"></div></aside>

  <aside class="aside-custom" id="aside-sakana">
    

<div class="sakana-widget">
  <div class="sakana-item" id="takina-widget"></div>
  <div class="sakana-item" id="chisato-widget"></div>
</div>
<script>
  function initSakanaWidget() {
    const takina = SakanaWidget.getCharacter('takina')
    SakanaWidget.registerCharacter('takina-slow', takina);
    new SakanaWidget({
      character: 'takina-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#takina-widget');

    const chisato = SakanaWidget.getCharacter('chisato')
    SakanaWidget.registerCharacter('chisato-slow', chisato);
    new SakanaWidget({
      character: 'chisato-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#chisato-widget');
  }
</script>
<script async onload="initSakanaWidget()" src="https://cdn.jsdelivr.net/npm/sakana-widget@2.3.0/lib/sakana.min.js">
</script></aside>

  <article class="page single">
    <div class="header"><h1 class="single-title animate__animated animate__flipInX">
        <span>AllenNLPIntroduce</span>
      </h1></div><div class="post-meta">
      <div class="post-meta-line"><span class="post-author"><span class="author"><i class="fa-solid fa-user-circle" aria-hidden="true"></i>
      liudongdong1</span></span>
          <span class="post-category">收录于 <a href="/categories/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;Categories</a>&ensp;<a href="/categories/nlp/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;NLP</a></span></div>
      <div class="post-meta-line"><span title=2020-10-20&#32;07:56:09>
            <i class="fa-regular fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2020-10-20" >2020-10-20</time>
          </span>&nbsp;<i class="fa-solid fa-pencil-alt fa-fw"></i>&nbsp;约 2062 字&nbsp;
        <i class="fa-regular fa-clock fa-fw"></i>&nbsp;预计阅读 5 分钟&nbsp;<span id="busuanzi_container_page_pv" class="busuanzi_visitors comment-visitors" data-flag-title="AllenNLPIntroduce">
            <i class="fa-regular fa-eye fa-fw"></i>&nbsp;<span id="busuanzi_value_page_pv">-</span>&nbsp;次阅读
          </span>&nbsp;</div>
    </div><div class="featured-image"><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210501113113.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210501113113.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210501113113.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210501113113.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210501113113.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210501113113.png"/></div><div class="details toc" id="toc-static" kept="true">
        <div class="details-summary toc-title">
          <span>目录</span>
          <span><i class="details-icon fa-solid fa-angle-right"></i></span>
        </div>
        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#1-text-classification">1. Text Classification</a></li>
    <li><a href="#2-train-with-script">2. Train with script</a></li>
    <li><a href="#3-train-with-allennlp">3. Train with allennlp</a></li>
    <li><a href="#4-unlabeled-prediction">4. Unlabeled Prediction</a></li>
    <li><a href="#5-api">5. API</a>
      <ul>
        <li><a href="#51-datareading">5.1. DataReading</a></li>
        <li><a href="#52-text-representation">5.2. Text Representation</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
      </div><div
      class="content"
      id="content"
      
      
    ><blockquote>
<p>you can write your own script to construct the dataset reader and model and run the training loop, or you can write a configuration file and use the <code>allennlp train</code> command</p>
</blockquote>
<h2 id="1-text-classification">1. Text Classification</h2>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022211754511.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022211754511.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022211754511.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022211754511.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022211754511.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022211754511.png"/></p>
<table>
<thead>
<tr>
<th>Spam filtering</th>
<th>Detect and filter spam emails</th>
<th>Email</th>
<th>Spam / Not spam</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sentiment analysis</td>
<td>Detect the polarity of text</td>
<td>Tweet, review</td>
<td>Positive / Negative</td>
</tr>
<tr>
<td>Topic detection</td>
<td>Detect the topic of text</td>
<td>News article, blog post</td>
<td>Business / Tech / Sports</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Reading Data</strong></li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022212005872.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022212005872.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022212005872.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022212005872.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022212005872.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022212005872.png"/></p>
<ul>
<li><strong>Model</strong></li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022212412613.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022212412613.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022212412613.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022212412613.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022212412613.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022212412613.png"/></p>
<h2 id="2-train-with-script">2. Train with script</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> typing <span style="color:#f92672">import</span> Dict, Iterable, List
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.data <span style="color:#f92672">import</span> DatasetReader, Instance
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.data.fields <span style="color:#f92672">import</span> LabelField, TextField
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.data.token_indexers <span style="color:#f92672">import</span> TokenIndexer, SingleIdTokenIndexer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.data.tokenizers <span style="color:#f92672">import</span> Token, Tokenizer, WhitespaceTokenizer
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">ClassificationTsvReader</span>(DatasetReader):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self,
</span></span><span style="display:flex;"><span>                 lazy: bool <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>                 tokenizer: Tokenizer <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>,
</span></span><span style="display:flex;"><span>                 token_indexers: Dict[str, TokenIndexer] <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>,
</span></span><span style="display:flex;"><span>                 max_tokens: int <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__(lazy)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>tokenizer <span style="color:#f92672">=</span> tokenizer <span style="color:#f92672">or</span> WhitespaceTokenizer()  <span style="color:#75715e">##？？</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>token_indexers <span style="color:#f92672">=</span> token_indexers <span style="color:#f92672">or</span> {<span style="color:#e6db74">&#39;tokens&#39;</span>: SingleIdTokenIndexer()}  <span style="color:#75715e">##？？</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>max_tokens <span style="color:#f92672">=</span> max_tokens
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_read</span>(self, file_path: str) <span style="color:#f92672">-&gt;</span> Iterable[Instance]:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> open(file_path, <span style="color:#e6db74">&#39;r&#39;</span>) <span style="color:#66d9ef">as</span> lines:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> line <span style="color:#f92672">in</span> lines:
</span></span><span style="display:flex;"><span>                text, sentiment <span style="color:#f92672">=</span> line<span style="color:#f92672">.</span>strip()<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>                tokens <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>tokenizer<span style="color:#f92672">.</span>tokenize(text)   <span style="color:#75715e">##？？得到的是什么</span>
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>max_tokens:
</span></span><span style="display:flex;"><span>                    tokens <span style="color:#f92672">=</span> tokens[:self<span style="color:#f92672">.</span>max_tokens]
</span></span><span style="display:flex;"><span>                text_field <span style="color:#f92672">=</span> TextField(tokens, self<span style="color:#f92672">.</span>token_indexers)<span style="color:#75715e">##？？token_indexers 用来干什么</span>
</span></span><span style="display:flex;"><span>                label_field <span style="color:#f92672">=</span> LabelField(sentiment)
</span></span><span style="display:flex;"><span>                fields <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;text&#39;</span>: text_field, <span style="color:#e6db74">&#39;label&#39;</span>: label_field}
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">yield</span> Instance(fields)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dataset_reader <span style="color:#f92672">=</span> ClassificationTsvReader(max_tokens<span style="color:#f92672">=</span><span style="color:#ae81ff">64</span>)
</span></span><span style="display:flex;"><span>instances <span style="color:#f92672">=</span> dataset_reader<span style="color:#f92672">.</span>read(<span style="color:#e6db74">&#34;quick_start/data/movie_review/train.tsv&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> instance <span style="color:#f92672">in</span> instances[:<span style="color:#ae81ff">10</span>]:
</span></span><span style="display:flex;"><span>    print(instance)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">SimpleClassifier</span>(Model):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self,
</span></span><span style="display:flex;"><span>                 vocab: Vocabulary,
</span></span><span style="display:flex;"><span>                 embedder: TextFieldEmbedder,
</span></span><span style="display:flex;"><span>                 encoder: Seq2VecEncoder):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__(vocab)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>embedder <span style="color:#f92672">=</span> embedder
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>encoder <span style="color:#f92672">=</span> encoder
</span></span><span style="display:flex;"><span>        num_labels <span style="color:#f92672">=</span> vocab<span style="color:#f92672">.</span>get_vocab_size(<span style="color:#e6db74">&#34;labels&#34;</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>classifier <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Linear(encoder<span style="color:#f92672">.</span>get_output_dim(), num_labels)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self,
</span></span><span style="display:flex;"><span>                text: Dict[str, torch<span style="color:#f92672">.</span>Tensor],
</span></span><span style="display:flex;"><span>                label: torch<span style="color:#f92672">.</span>Tensor) <span style="color:#f92672">-&gt;</span> Dict[str, torch<span style="color:#f92672">.</span>Tensor]:
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Shape: (batch_size, num_tokens, embedding_dim)</span>
</span></span><span style="display:flex;"><span>        embedded_text <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>embedder(text)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Shape: (batch_size, num_tokens)</span>
</span></span><span style="display:flex;"><span>        mask <span style="color:#f92672">=</span> util<span style="color:#f92672">.</span>get_text_field_mask(text)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Shape: (batch_size, encoding_dim)</span>
</span></span><span style="display:flex;"><span>        encoded_text <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>encoder(embedded_text, mask)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Shape: (batch_size, num_labels)</span>
</span></span><span style="display:flex;"><span>        logits <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>classifier(encoded_text)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Shape: (batch_size, num_labels)</span>
</span></span><span style="display:flex;"><span>        probs <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>functional<span style="color:#f92672">.</span>softmax(logits, dim<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Shape: (1,)</span>
</span></span><span style="display:flex;"><span>        loss <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>functional<span style="color:#f92672">.</span>cross_entropy(logits, label)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> {<span style="color:#e6db74">&#39;loss&#39;</span>: loss, <span style="color:#e6db74">&#39;probs&#39;</span>: probs}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_dataset_reader</span>() <span style="color:#f92672">-&gt;</span> DatasetReader:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> ClassificationTsvReader()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">read_data</span>(
</span></span><span style="display:flex;"><span>    reader: DatasetReader
</span></span><span style="display:flex;"><span>) <span style="color:#f92672">-&gt;</span> Tuple[Iterable[Instance], Iterable[Instance]]:
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;Reading data&#34;</span>)
</span></span><span style="display:flex;"><span>    training_data <span style="color:#f92672">=</span> reader<span style="color:#f92672">.</span>read(<span style="color:#e6db74">&#34;quick_start/data/movie_review/train.tsv&#34;</span>)
</span></span><span style="display:flex;"><span>    validation_data <span style="color:#f92672">=</span> reader<span style="color:#f92672">.</span>read(<span style="color:#e6db74">&#34;quick_start/data/movie_review/dev.tsv&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> training_data, validation_data
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_vocab</span>(instances: Iterable[Instance]) <span style="color:#f92672">-&gt;</span> Vocabulary:
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;Building the vocabulary&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> Vocabulary<span style="color:#f92672">.</span>from_instances(instances)  <span style="color:#75715e">#？？ </span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_model</span>(vocab: Vocabulary) <span style="color:#f92672">-&gt;</span> Model:
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;Building the model&#34;</span>)
</span></span><span style="display:flex;"><span>    vocab_size <span style="color:#f92672">=</span> vocab<span style="color:#f92672">.</span>get_vocab_size(<span style="color:#e6db74">&#34;tokens&#34;</span>)
</span></span><span style="display:flex;"><span>    embedder <span style="color:#f92672">=</span> BasicTextFieldEmbedder(   <span style="color:#75715e">##？？</span>
</span></span><span style="display:flex;"><span>        {<span style="color:#e6db74">&#34;tokens&#34;</span>: Embedding(embedding_dim<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>, num_embeddings<span style="color:#f92672">=</span>vocab_size)})
</span></span><span style="display:flex;"><span>    encoder <span style="color:#f92672">=</span> BagOfEmbeddingsEncoder(embedding_dim<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)  <span style="color:#75715e">#？？</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> SimpleClassifier(vocab, embedder, encoder)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">run_training_loop</span>():
</span></span><span style="display:flex;"><span>    dataset_reader <span style="color:#f92672">=</span> build_dataset_reader()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># These are a subclass of pytorch Datasets, with some allennlp-specific</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># functionality added.</span>
</span></span><span style="display:flex;"><span>    train_data, dev_data <span style="color:#f92672">=</span> read_data(dataset_reader)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    vocab <span style="color:#f92672">=</span> build_vocab(train_data <span style="color:#f92672">+</span> dev_data)
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> build_model(vocab)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># This is the allennlp-specific functionality in the Dataset object;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># we need to be able convert strings in the data to integers, and this</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># is how we do it.</span>
</span></span><span style="display:flex;"><span>    train_data<span style="color:#f92672">.</span>index_with(vocab)   <span style="color:#75715e">#？？</span>
</span></span><span style="display:flex;"><span>    dev_data<span style="color:#f92672">.</span>index_with(vocab)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># These are again a subclass of pytorch DataLoaders, with an</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># allennlp-specific collate function, that runs our indexing and</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># batching code.</span>
</span></span><span style="display:flex;"><span>    train_loader, dev_loader <span style="color:#f92672">=</span> build_data_loaders(train_data, dev_data)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># You obviously won&#39;t want to create a temporary file for your training</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># results, but for execution in binder for this guide, we need to do this.</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> tempfile<span style="color:#f92672">.</span>TemporaryDirectory() <span style="color:#66d9ef">as</span> serialization_dir:
</span></span><span style="display:flex;"><span>        trainer <span style="color:#f92672">=</span> build_trainer(
</span></span><span style="display:flex;"><span>            model,
</span></span><span style="display:flex;"><span>            serialization_dir,
</span></span><span style="display:flex;"><span>            train_loader,
</span></span><span style="display:flex;"><span>            dev_loader
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;Starting training&#34;</span>)
</span></span><span style="display:flex;"><span>        trainer<span style="color:#f92672">.</span>train()
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;Finished training&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># The other `build_*` methods are things we&#39;ve seen before, so they are</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># in the setup section above.</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_data_loaders</span>(
</span></span><span style="display:flex;"><span>    train_data: torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>Dataset,
</span></span><span style="display:flex;"><span>    dev_data: torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>Dataset,
</span></span><span style="display:flex;"><span>) <span style="color:#f92672">-&gt;</span> Tuple[allennlp<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader, allennlp<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader]:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Note that DataLoader is imported from allennlp above, *not* torch.</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># We need to get the allennlp-specific collate function, which is</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># what actually does indexing and batching.</span>
</span></span><span style="display:flex;"><span>    train_loader <span style="color:#f92672">=</span> DataLoader(train_data, batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>, shuffle<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>    dev_loader <span style="color:#f92672">=</span> DataLoader(dev_data, batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>, shuffle<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> train_loader, dev_loader
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_trainer</span>(
</span></span><span style="display:flex;"><span>    model: Model,
</span></span><span style="display:flex;"><span>    serialization_dir: str,
</span></span><span style="display:flex;"><span>    train_loader: DataLoader,
</span></span><span style="display:flex;"><span>    dev_loader: DataLoader
</span></span><span style="display:flex;"><span>) <span style="color:#f92672">-&gt;</span> Trainer:
</span></span><span style="display:flex;"><span>    parameters <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>        [n, p]
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> n, p <span style="color:#f92672">in</span> model<span style="color:#f92672">.</span>named_parameters() <span style="color:#66d9ef">if</span> p<span style="color:#f92672">.</span>requires_grad
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>    optimizer <span style="color:#f92672">=</span> AdamOptimizer(parameters)
</span></span><span style="display:flex;"><span>    trainer <span style="color:#f92672">=</span> GradientDescentTrainer(
</span></span><span style="display:flex;"><span>        model<span style="color:#f92672">=</span>model,
</span></span><span style="display:flex;"><span>        serialization_dir<span style="color:#f92672">=</span>serialization_dir,
</span></span><span style="display:flex;"><span>        data_loader<span style="color:#f92672">=</span>train_loader,
</span></span><span style="display:flex;"><span>        validation_data_loader<span style="color:#f92672">=</span>dev_loader,
</span></span><span style="display:flex;"><span>        num_epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>,
</span></span><span style="display:flex;"><span>        optimizer<span style="color:#f92672">=</span>optimizer,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> trainer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>run_training_loop()
</span></span></code></pre></div><h2 id="3-train-with-allennlp">3. Train with allennlp</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> tempfile
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> json
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> typing <span style="color:#f92672">import</span> Dict, Iterable, List
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.data <span style="color:#f92672">import</span> DatasetReader, Instance, Vocabulary
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.data.fields <span style="color:#f92672">import</span> LabelField, TextField
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.data.token_indexers <span style="color:#f92672">import</span> TokenIndexer, SingleIdTokenIndexer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.data.tokenizers <span style="color:#f92672">import</span> Token, Tokenizer, WhitespaceTokenizer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.models <span style="color:#f92672">import</span> Model
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.modules <span style="color:#f92672">import</span> TextFieldEmbedder, Seq2VecEncoder
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.nn <span style="color:#f92672">import</span> util
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.training.metrics <span style="color:#f92672">import</span> CategoricalAccuracy
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">@DatasetReader.register</span>(<span style="color:#e6db74">&#34;classification-tsv&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">ClassificationTsvReader</span>(DatasetReader):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self,
</span></span><span style="display:flex;"><span>                 lazy: bool <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>                 tokenizer: Tokenizer <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>,
</span></span><span style="display:flex;"><span>                 token_indexers: Dict[str, TokenIndexer] <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>,
</span></span><span style="display:flex;"><span>                 max_tokens: int <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__(lazy)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>tokenizer <span style="color:#f92672">=</span> tokenizer <span style="color:#f92672">or</span> WhitespaceTokenizer()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>token_indexers <span style="color:#f92672">=</span> token_indexers <span style="color:#f92672">or</span> {<span style="color:#e6db74">&#39;tokens&#39;</span>: SingleIdTokenIndexer()}
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>max_tokens <span style="color:#f92672">=</span> max_tokens
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">text_to_instance</span>(self,
</span></span><span style="display:flex;"><span>                         tokens: List[Token],
</span></span><span style="display:flex;"><span>                         label: str <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>) <span style="color:#f92672">-&gt;</span> Instance:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>max_tokens:
</span></span><span style="display:flex;"><span>            tokens <span style="color:#f92672">=</span> tokens[:self<span style="color:#f92672">.</span>max_tokens]
</span></span><span style="display:flex;"><span>        text_field <span style="color:#f92672">=</span> TextField(tokens, self<span style="color:#f92672">.</span>token_indexers)
</span></span><span style="display:flex;"><span>        fields <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;text&#39;</span>: text_field}
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> label:
</span></span><span style="display:flex;"><span>            fields[<span style="color:#e6db74">&#39;label&#39;</span>] <span style="color:#f92672">=</span> LabelField(label)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> Instance(fields)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_read</span>(self, file_path: str) <span style="color:#f92672">-&gt;</span> Iterable[Instance]:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> open(file_path, <span style="color:#e6db74">&#39;r&#39;</span>) <span style="color:#66d9ef">as</span> lines:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> line <span style="color:#f92672">in</span> lines:
</span></span><span style="display:flex;"><span>                text, sentiment <span style="color:#f92672">=</span> line<span style="color:#f92672">.</span>strip()<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>                tokens <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>tokenizer<span style="color:#f92672">.</span>tokenize(text)
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">yield</span> self<span style="color:#f92672">.</span>text_to_instance(tokens, sentiment)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">@Model.register</span>(<span style="color:#e6db74">&#34;simple_classifier&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">SimpleClassifier</span>(Model):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self,
</span></span><span style="display:flex;"><span>                 vocab: Vocabulary,
</span></span><span style="display:flex;"><span>                 embedder: TextFieldEmbedder,
</span></span><span style="display:flex;"><span>                 encoder: Seq2VecEncoder):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__(vocab)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>embedder <span style="color:#f92672">=</span> embedder
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>encoder <span style="color:#f92672">=</span> encoder
</span></span><span style="display:flex;"><span>        num_labels <span style="color:#f92672">=</span> vocab<span style="color:#f92672">.</span>get_vocab_size(<span style="color:#e6db74">&#34;labels&#34;</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>classifier <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Linear(encoder<span style="color:#f92672">.</span>get_output_dim(), num_labels)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>accuracy <span style="color:#f92672">=</span> CategoricalAccuracy()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self,
</span></span><span style="display:flex;"><span>                text: Dict[str, torch<span style="color:#f92672">.</span>Tensor],
</span></span><span style="display:flex;"><span>                label: torch<span style="color:#f92672">.</span>Tensor <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>) <span style="color:#f92672">-&gt;</span> Dict[str, torch<span style="color:#f92672">.</span>Tensor]:
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;In model.forward(); printing here just because binder is so slow&#34;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Shape: (batch_size, num_tokens, embedding_dim)</span>
</span></span><span style="display:flex;"><span>        embedded_text <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>embedder(text)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Shape: (batch_size, num_tokens)</span>
</span></span><span style="display:flex;"><span>        mask <span style="color:#f92672">=</span> util<span style="color:#f92672">.</span>get_text_field_mask(text)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Shape: (batch_size, encoding_dim)</span>
</span></span><span style="display:flex;"><span>        encoded_text <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>encoder(embedded_text, mask)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Shape: (batch_size, num_labels)</span>
</span></span><span style="display:flex;"><span>        logits <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>classifier(encoded_text)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Shape: (batch_size, num_labels)</span>
</span></span><span style="display:flex;"><span>        probs <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>functional<span style="color:#f92672">.</span>softmax(logits)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Shape: (1,)</span>
</span></span><span style="display:flex;"><span>        output <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;probs&#39;</span>: probs}
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> label <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>accuracy(logits, label)
</span></span><span style="display:flex;"><span>            output[<span style="color:#e6db74">&#39;loss&#39;</span>] <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>functional<span style="color:#f92672">.</span>cross_entropy(logits, label)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> output
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_metrics</span>(self, reset: bool <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>) <span style="color:#f92672">-&gt;</span> Dict[str, float]:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> {<span style="color:#e6db74">&#34;accuracy&#34;</span>: self<span style="color:#f92672">.</span>accuracy<span style="color:#f92672">.</span>get_metric(reset)}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>config <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;dataset_reader&#34;</span> : {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;classification-tsv&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;token_indexers&#34;</span>: {
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;tokens&#34;</span>: {
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;single_id&#34;</span>
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    },
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;train_data_path&#34;</span>: <span style="color:#e6db74">&#34;quick_start/data/movie_review/train.tsv&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;validation_data_path&#34;</span>: <span style="color:#e6db74">&#34;quick_start/data/movie_review/dev.tsv&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;model&#34;</span>: {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;simple_classifier&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;embedder&#34;</span>: {
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;token_embedders&#34;</span>: {
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;tokens&#34;</span>: {
</span></span><span style="display:flex;"><span>                    <span style="color:#e6db74">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;embedding&#34;</span>,
</span></span><span style="display:flex;"><span>                    <span style="color:#e6db74">&#34;embedding_dim&#34;</span>: <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>                }
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>        },
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;encoder&#34;</span>: {
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;bag_of_embeddings&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;embedding_dim&#34;</span>: <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    },
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;data_loader&#34;</span>: {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;batch_size&#34;</span>: <span style="color:#ae81ff">8</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;shuffle&#34;</span>: <span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span>    },
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;trainer&#34;</span>: {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;optimizer&#34;</span>: <span style="color:#e6db74">&#34;adam&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;num_epochs&#34;</span>: <span style="color:#ae81ff">5</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> tempfile<span style="color:#f92672">.</span>TemporaryDirectory() <span style="color:#66d9ef">as</span> serialization_dir:
</span></span><span style="display:flex;"><span>    config_filename <span style="color:#f92672">=</span> serialization_dir <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;/training_config.json&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> open(config_filename, <span style="color:#e6db74">&#39;w&#39;</span>) <span style="color:#66d9ef">as</span> config_file:
</span></span><span style="display:flex;"><span>        json<span style="color:#f92672">.</span>dump(config, config_file)
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">from</span> allennlp.commands.train <span style="color:#f92672">import</span> train_model_from_file
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Instead of this python code, you would typically just call</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># allennlp train [config_file] -s [serialization_dir]</span>
</span></span><span style="display:flex;"><span>    train_model_from_file(config_filename,
</span></span><span style="display:flex;"><span>                          serialization_dir,
</span></span><span style="display:flex;"><span>                          file_friendly_logging<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>                          force<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e">#allennlp train my_text_classifier.jsonnet -s model --include-package my_text_classifier</span>
</span></span></code></pre></div><h2 id="4-unlabeled-prediction">4. Unlabeled Prediction</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> tempfile
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> typing <span style="color:#f92672">import</span> Dict, Iterable, List, Tuple
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> allennlp
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.common <span style="color:#f92672">import</span> JsonDict
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.data <span style="color:#f92672">import</span> DataLoader, DatasetReader, Instance
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.data <span style="color:#f92672">import</span> Vocabulary
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.data.fields <span style="color:#f92672">import</span> LabelField, TextField
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.data.token_indexers <span style="color:#f92672">import</span> TokenIndexer, SingleIdTokenIndexer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.data.tokenizers <span style="color:#f92672">import</span> Token, Tokenizer, WhitespaceTokenizer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.models <span style="color:#f92672">import</span> Model
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.modules <span style="color:#f92672">import</span> TextFieldEmbedder, Seq2VecEncoder
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.modules.text_field_embedders <span style="color:#f92672">import</span> BasicTextFieldEmbedder
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.modules.token_embedders <span style="color:#f92672">import</span> Embedding
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.modules.seq2vec_encoders <span style="color:#f92672">import</span> BagOfEmbeddingsEncoder
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.predictors <span style="color:#f92672">import</span> Predictor
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.nn <span style="color:#f92672">import</span> util
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.training.metrics <span style="color:#f92672">import</span> CategoricalAccuracy
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.training.trainer <span style="color:#f92672">import</span> Trainer, GradientDescentTrainer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> allennlp.training.optimizers <span style="color:#f92672">import</span> AdamOptimizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">ClassificationTsvReader</span>(DatasetReader):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self,
</span></span><span style="display:flex;"><span>                 lazy: bool <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>                 tokenizer: Tokenizer <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>,
</span></span><span style="display:flex;"><span>                 token_indexers: Dict[str, TokenIndexer] <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>,
</span></span><span style="display:flex;"><span>                 max_tokens: int <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__(lazy)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>tokenizer <span style="color:#f92672">=</span> tokenizer <span style="color:#f92672">or</span> WhitespaceTokenizer()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>token_indexers <span style="color:#f92672">=</span> token_indexers <span style="color:#f92672">or</span> {<span style="color:#e6db74">&#39;tokens&#39;</span>: SingleIdTokenIndexer()}
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>max_tokens <span style="color:#f92672">=</span> max_tokens
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">text_to_instance</span>(self, text: str, label: str <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>) <span style="color:#f92672">-&gt;</span> Instance:
</span></span><span style="display:flex;"><span>        tokens <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>tokenizer<span style="color:#f92672">.</span>tokenize(text)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>max_tokens:
</span></span><span style="display:flex;"><span>            tokens <span style="color:#f92672">=</span> tokens[:self<span style="color:#f92672">.</span>max_tokens]
</span></span><span style="display:flex;"><span>        text_field <span style="color:#f92672">=</span> TextField(tokens, self<span style="color:#f92672">.</span>token_indexers)
</span></span><span style="display:flex;"><span>        fields <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;text&#39;</span>: text_field}
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> label:
</span></span><span style="display:flex;"><span>            fields[<span style="color:#e6db74">&#39;label&#39;</span>] <span style="color:#f92672">=</span> LabelField(label)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> Instance(fields)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_read</span>(self, file_path: str) <span style="color:#f92672">-&gt;</span> Iterable[Instance]:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> open(file_path, <span style="color:#e6db74">&#39;r&#39;</span>) <span style="color:#66d9ef">as</span> lines:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> line <span style="color:#f92672">in</span> lines:
</span></span><span style="display:flex;"><span>                text, sentiment <span style="color:#f92672">=</span> line<span style="color:#f92672">.</span>strip()<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">yield</span> self<span style="color:#f92672">.</span>text_to_instance(text, sentiment)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">SimpleClassifier</span>(Model):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self,
</span></span><span style="display:flex;"><span>                 vocab: Vocabulary,
</span></span><span style="display:flex;"><span>                 embedder: TextFieldEmbedder,
</span></span><span style="display:flex;"><span>                 encoder: Seq2VecEncoder):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__(vocab)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>embedder <span style="color:#f92672">=</span> embedder
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>encoder <span style="color:#f92672">=</span> encoder
</span></span><span style="display:flex;"><span>        num_labels <span style="color:#f92672">=</span> vocab<span style="color:#f92672">.</span>get_vocab_size(<span style="color:#e6db74">&#34;labels&#34;</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>classifier <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Linear(encoder<span style="color:#f92672">.</span>get_output_dim(), num_labels)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>accuracy <span style="color:#f92672">=</span> CategoricalAccuracy()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self,
</span></span><span style="display:flex;"><span>                text: Dict[str, torch<span style="color:#f92672">.</span>Tensor],
</span></span><span style="display:flex;"><span>                label: torch<span style="color:#f92672">.</span>Tensor <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>) <span style="color:#f92672">-&gt;</span> Dict[str, torch<span style="color:#f92672">.</span>Tensor]:
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Shape: (batch_size, num_tokens, embedding_dim)</span>
</span></span><span style="display:flex;"><span>        embedded_text <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>embedder(text)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Shape: (batch_size, num_tokens)</span>
</span></span><span style="display:flex;"><span>        mask <span style="color:#f92672">=</span> util<span style="color:#f92672">.</span>get_text_field_mask(text)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Shape: (batch_size, encoding_dim)</span>
</span></span><span style="display:flex;"><span>        encoded_text <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>encoder(embedded_text, mask)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Shape: (batch_size, num_labels)</span>
</span></span><span style="display:flex;"><span>        logits <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>classifier(encoded_text)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Shape: (batch_size, num_labels)</span>
</span></span><span style="display:flex;"><span>        probs <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>functional<span style="color:#f92672">.</span>softmax(logits)
</span></span><span style="display:flex;"><span>        output <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;probs&#39;</span>: probs}
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> label <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>accuracy(logits, label)
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Shape: (1,)</span>
</span></span><span style="display:flex;"><span>            output[<span style="color:#e6db74">&#39;loss&#39;</span>] <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>functional<span style="color:#f92672">.</span>cross_entropy(logits, label)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> output
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_metrics</span>(self, reset: bool <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>) <span style="color:#f92672">-&gt;</span> Dict[str, float]:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> {<span style="color:#e6db74">&#34;accuracy&#34;</span>: self<span style="color:#f92672">.</span>accuracy<span style="color:#f92672">.</span>get_metric(reset)}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_metrics</span>(self, reset: bool <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>) <span style="color:#f92672">-&gt;</span> Dict[str, float]:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> {<span style="color:#e6db74">&#34;accuracy&#34;</span>: self<span style="color:#f92672">.</span>accuracy<span style="color:#f92672">.</span>get_metric(reset)}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_dataset_reader</span>() <span style="color:#f92672">-&gt;</span> DatasetReader:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> ClassificationTsvReader()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">read_data</span>(
</span></span><span style="display:flex;"><span>    reader: DatasetReader
</span></span><span style="display:flex;"><span>) <span style="color:#f92672">-&gt;</span> Tuple[Iterable[Instance], Iterable[Instance]]:
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;Reading data&#34;</span>)
</span></span><span style="display:flex;"><span>    training_data <span style="color:#f92672">=</span> reader<span style="color:#f92672">.</span>read(<span style="color:#e6db74">&#34;quick_start/data/movie_review/train.tsv&#34;</span>)
</span></span><span style="display:flex;"><span>    validation_data <span style="color:#f92672">=</span> reader<span style="color:#f92672">.</span>read(<span style="color:#e6db74">&#34;quick_start/data/movie_review/dev.tsv&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> training_data, validation_data
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_vocab</span>(instances: Iterable[Instance]) <span style="color:#f92672">-&gt;</span> Vocabulary:
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;Building the vocabulary&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> Vocabulary<span style="color:#f92672">.</span>from_instances(instances)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_model</span>(vocab: Vocabulary) <span style="color:#f92672">-&gt;</span> Model:
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;Building the model&#34;</span>)
</span></span><span style="display:flex;"><span>    vocab_size <span style="color:#f92672">=</span> vocab<span style="color:#f92672">.</span>get_vocab_size(<span style="color:#e6db74">&#34;tokens&#34;</span>)
</span></span><span style="display:flex;"><span>    embedder <span style="color:#f92672">=</span> BasicTextFieldEmbedder(
</span></span><span style="display:flex;"><span>        {<span style="color:#e6db74">&#34;tokens&#34;</span>: Embedding(embedding_dim<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>, num_embeddings<span style="color:#f92672">=</span>vocab_size)})
</span></span><span style="display:flex;"><span>    encoder <span style="color:#f92672">=</span> BagOfEmbeddingsEncoder(embedding_dim<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> SimpleClassifier(vocab, embedder, encoder)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_data_loaders</span>(
</span></span><span style="display:flex;"><span>    train_data: torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>Dataset,
</span></span><span style="display:flex;"><span>    dev_data: torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>Dataset,
</span></span><span style="display:flex;"><span>) <span style="color:#f92672">-&gt;</span> Tuple[allennlp<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader, allennlp<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader]:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Note that DataLoader is imported from allennlp above, *not* torch.</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># We need to get the allennlp-specific collate function, which is</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># what actually does indexing and batching.</span>
</span></span><span style="display:flex;"><span>    train_loader <span style="color:#f92672">=</span> DataLoader(train_data, batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>, shuffle<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>    dev_loader <span style="color:#f92672">=</span> DataLoader(dev_data, batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>, shuffle<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> train_loader, dev_loader
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_trainer</span>(
</span></span><span style="display:flex;"><span>    model: Model,
</span></span><span style="display:flex;"><span>    serialization_dir: str,
</span></span><span style="display:flex;"><span>    train_loader: DataLoader,
</span></span><span style="display:flex;"><span>    dev_loader: DataLoader
</span></span><span style="display:flex;"><span>) <span style="color:#f92672">-&gt;</span> Trainer:
</span></span><span style="display:flex;"><span>    parameters <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>        [n, p]
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> n, p <span style="color:#f92672">in</span> model<span style="color:#f92672">.</span>named_parameters() <span style="color:#66d9ef">if</span> p<span style="color:#f92672">.</span>requires_grad
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>    optimizer <span style="color:#f92672">=</span> AdamOptimizer(parameters)
</span></span><span style="display:flex;"><span>    trainer <span style="color:#f92672">=</span> GradientDescentTrainer(
</span></span><span style="display:flex;"><span>        model<span style="color:#f92672">=</span>model,
</span></span><span style="display:flex;"><span>        serialization_dir<span style="color:#f92672">=</span>serialization_dir,
</span></span><span style="display:flex;"><span>        data_loader<span style="color:#f92672">=</span>train_loader,
</span></span><span style="display:flex;"><span>        validation_data_loader<span style="color:#f92672">=</span>dev_loader,
</span></span><span style="display:flex;"><span>        num_epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>,
</span></span><span style="display:flex;"><span>        optimizer<span style="color:#f92672">=</span>optimizer,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> trainer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">run_training_loop</span>():
</span></span><span style="display:flex;"><span>    dataset_reader <span style="color:#f92672">=</span> build_dataset_reader()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># These are a subclass of pytorch Datasets, with some allennlp-specific</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># functionality added.</span>
</span></span><span style="display:flex;"><span>    train_data, dev_data <span style="color:#f92672">=</span> read_data(dataset_reader)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    vocab <span style="color:#f92672">=</span> build_vocab(train_data <span style="color:#f92672">+</span> dev_data)
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> build_model(vocab)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># This is the allennlp-specific functionality in the Dataset object;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># we need to be able convert strings in the data to integers, and this</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># is how we do it.</span>
</span></span><span style="display:flex;"><span>    train_data<span style="color:#f92672">.</span>index_with(vocab)
</span></span><span style="display:flex;"><span>    dev_data<span style="color:#f92672">.</span>index_with(vocab)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># These are again a subclass of pytorch DataLoaders, with an</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># allennlp-specific collate function, that runs our indexing and</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># batching code.</span>
</span></span><span style="display:flex;"><span>    train_loader, dev_loader <span style="color:#f92672">=</span> build_data_loaders(train_data, dev_data)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># You obviously won&#39;t want to create a temporary file for your training</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># results, but for execution in binder for this guide, we need to do this.</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> tempfile<span style="color:#f92672">.</span>TemporaryDirectory() <span style="color:#66d9ef">as</span> serialization_dir:
</span></span><span style="display:flex;"><span>        trainer <span style="color:#f92672">=</span> build_trainer(
</span></span><span style="display:flex;"><span>            model,
</span></span><span style="display:flex;"><span>            serialization_dir,
</span></span><span style="display:flex;"><span>            train_loader,
</span></span><span style="display:flex;"><span>            dev_loader
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        trainer<span style="color:#f92672">.</span>train()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> model, dataset_reader
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">SentenceClassifierPredictor</span>(Predictor):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">predict</span>(self, sentence: str) <span style="color:#f92672">-&gt;</span> JsonDict:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>predict_json({<span style="color:#e6db74">&#34;sentence&#34;</span>: sentence})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_json_to_instance</span>(self, json_dict: JsonDict) <span style="color:#f92672">-&gt;</span> Instance:
</span></span><span style="display:flex;"><span>        sentence <span style="color:#f92672">=</span> json_dict[<span style="color:#e6db74">&#34;sentence&#34;</span>]
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>_dataset_reader<span style="color:#f92672">.</span>text_to_instance(sentence)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># We&#39;ve copied the training loop from an earlier example, with updated model</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># code, above in the Setup section. We run the training loop to get a trained</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># model.</span>
</span></span><span style="display:flex;"><span>model, dataset_reader <span style="color:#f92672">=</span> run_training_loop()
</span></span><span style="display:flex;"><span>vocab <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>vocab
</span></span><span style="display:flex;"><span>predictor <span style="color:#f92672">=</span> SentenceClassifierPredictor(model, dataset_reader)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>output <span style="color:#f92672">=</span> predictor<span style="color:#f92672">.</span>predict(<span style="color:#e6db74">&#39;A good movie!&#39;</span>)
</span></span><span style="display:flex;"><span>print([(vocab<span style="color:#f92672">.</span>get_token_from_index(label_id, <span style="color:#e6db74">&#39;labels&#39;</span>), prob)
</span></span><span style="display:flex;"><span>       <span style="color:#66d9ef">for</span> label_id, prob <span style="color:#f92672">in</span> enumerate(output[<span style="color:#e6db74">&#39;probs&#39;</span>])])
</span></span><span style="display:flex;"><span>output <span style="color:#f92672">=</span> predictor<span style="color:#f92672">.</span>predict(<span style="color:#e6db74">&#39;This was a monstrous waste of time.&#39;</span>)
</span></span><span style="display:flex;"><span>print([(vocab<span style="color:#f92672">.</span>get_token_from_index(label_id, <span style="color:#e6db74">&#39;labels&#39;</span>), prob)
</span></span><span style="display:flex;"><span>       <span style="color:#66d9ef">for</span> label_id, prob <span style="color:#f92672">in</span> enumerate(output[<span style="color:#e6db74">&#39;probs&#39;</span>])])
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#部署到web应用</span>
</span></span><span style="display:flex;"><span>python allennlp<span style="color:#f92672">-</span>server<span style="color:#f92672">/</span>server_simple<span style="color:#f92672">.</span>py \
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">--</span>archive<span style="color:#f92672">-</span>path model<span style="color:#f92672">/</span>model<span style="color:#f92672">.</span>tar<span style="color:#f92672">.</span>gz \
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">--</span>predictor sentence_classifier \
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">--</span>field<span style="color:#f92672">-</span>name sentence
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">--</span>include<span style="color:#f92672">-</span>package my_text_classifier
</span></span></code></pre></div><h2 id="5-api">5. API</h2>
<h3 id="51-datareading">5.1. DataReading</h3>
<ul>
<li><strong>Field&amp;&amp;Instance</strong></li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022222221588.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022222221588.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022222221588.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022222221588.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022222221588.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022222221588.png"/></p>
<blockquote>
<p>A <code>Field</code> contains one piece of data for one example that is passed through your model. <code>Fields</code> get converted to tensors in a model, either as an input or an output, after being converted to IDs and batched &amp; padded.</p>
</blockquote>
<ul>
<li><strong>Dataset readers</strong></li>
</ul>
<blockquote>
<p><a href="https://github.com/allenai/allennlp/blob/master/allennlp/data/dataset_readers/text_classification_json.py"target="_blank" rel="external nofollow noopener noreferrer">Text classification<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<p><a href="https://github.com/allenai/allennlp/blob/master/allennlp/data/dataset_readers/sequence_tagging.py"target="_blank" rel="external nofollow noopener noreferrer">Sequence labeling<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<p><a href="https://github.com/allenai/allennlp-models/blob/master/allennlp_models/lm/dataset_readers/simple_language_modeling.py"target="_blank" rel="external nofollow noopener noreferrer">Language modeling<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<p><a href="https://github.com/allenai/allennlp-models/blob/master/allennlp_models/pair_classification/dataset_readers/snli.py"target="_blank" rel="external nofollow noopener noreferrer">Natural language inference<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<p><a href="https://github.com/allenai/allennlp-models/blob/master/allennlp_models/structured_prediction/dataset_readers/srl.py"target="_blank" rel="external nofollow noopener noreferrer">Semantic role labeling<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<p><a href="https://github.com/allenai/allennlp-models/blob/master/allennlp_models/generation/dataset_readers/seq2seq.py"target="_blank" rel="external nofollow noopener noreferrer">Seq2Seq tasks<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<p><a href="https://github.com/allenai/allennlp-models/blob/master/allennlp_models/structured_prediction/dataset_readers/penn_tree_bank.py"target="_blank" rel="external nofollow noopener noreferrer">Constituency parsing<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> and <a href="https://github.com/allenai/allennlp-models/blob/master/allennlp_models/structured_prediction/dataset_readers/universal_dependencies.py"target="_blank" rel="external nofollow noopener noreferrer">dependency parsing<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<p><a href="https://github.com/allenai/allennlp-models/tree/master/allennlp_models/rc/dataset_readers"target="_blank" rel="external nofollow noopener noreferrer">Reading comprehension<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<p><a href="https://github.com/allenai/allennlp-semparse"target="_blank" rel="external nofollow noopener noreferrer">Semantic parsing<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</blockquote>
<ul>
<li><strong>Vocabulary</strong></li>
</ul>
<blockquote>
<p><code>Vocabulary</code> manages different mappings using a concept called <em>namespaces</em>. Each namespace is a distinct mapping from strings to integers, so strings in different namespaces are treated separately.</p>
</blockquote>
<blockquote>
<p>create a <code>Vocabulary</code> object is to pass a collection of <code>Instances</code> to the <code>Vocabulary.from_instances()</code> method. This will count all strings in the <code>Instances</code> that need to be mapped to integers, then use those counts to decide what strings should be in the vocabulary.</p>
</blockquote>
<h3 id="52-text-representation">5.2. Text Representation</h3>
<blockquote>
<ul>
<li>GloVe or word2vec embeddings</li>
<li>Character CNNs</li>
<li>POS tag embeddings</li>
<li>Combination of GloVe and character CNNs</li>
<li>wordpieces and BERT</li>
</ul>
</blockquote>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022230601867.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022230601867.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022230601867.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022230601867.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022230601867.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022230601867.png"/></p>
<ul>
<li><strong>GloVe</strong></li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022230658192.png"
    data-srcset="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022230658192.png, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022230658192.png 1.5x, https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022230658192.png 2x"
    data-sizes="auto"
    alt="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022230658192.png"
    title="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/image-20201022230658192.png"/></p>
<blockquote>
<ol>
<li>Tokenizer (Text → Tokens)</li>
<li>TextField, TokenIndexer, and Vocabulary (Tokens → Ids)</li>
<li>TextFieldEmbedder (Ids → Vectors)</li>
</ol>
</blockquote>
<ul>
<li><strong>Tokenizers</strong></li>
</ul>
<blockquote>
<ul>
<li>Characters (“AllenNLP is great” → <code>[&quot;A&quot;, &quot;l&quot;, &quot;l&quot;, &quot;e&quot;, &quot;n&quot;, &quot;N&quot;, &quot;L&quot;, &quot;P&quot;, &quot; &quot;, &quot;i&quot;, &quot;s&quot;, &quot; &quot;, &quot;g&quot;, &quot;r&quot;, &quot;e&quot;, &quot;a&quot;, &quot;t&quot;]</code>)</li>
<li>Wordpieces (“AllenNLP is great” → <code>[&quot;Allen&quot;, &quot;##NL&quot;, &quot;##P&quot;, &quot;is&quot;, &quot;great&quot;]</code>)</li>
<li>Words (“AllenNLP is great” → <code>[&quot;AllenNLP&quot;, &quot;is&quot;, &quot;great&quot;]</code>)</li>
</ul>
</blockquote>
<ul>
<li><strong>TokenIndexers</strong></li>
</ul>
<blockquote>
<p>Each <code>TokenIndexer</code> knows how to convert a <code>Token</code> into a representation that can be encoded by a corresponding piece of the model. This could be just mapping the token to an index in some vocabulary, or it could be breaking up the token into characters or wordpieces and representing the token by a sequence of indexed characters</p>
</blockquote>
</div>
<div class="post-footer" id="post-footer">
  <div class="post-info">
    <div class="post-info-line">
      <div class="post-info-mod">
        <span title=2023-12-31&#32;14:33:15>更新于 2023-12-31&nbsp;</span>
      </div><div class="post-info-license">
          <span><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span>
        </div></div>
    <div class="post-info-line">
      <div class="post-info-md"><span><a href="/allennlpintroduce/index.md" title="阅读原始文档" class="link-to-markdown">阅读原始文档</a></span><span><a href="https://liudongdong1.github.io/edit/master/content/posts%5c%e8%87%aa%e7%84%b6%e8%af%ad%e8%a8%80%5cFramework%5cAllenNLPIntroduce.md" title="编辑此页"target="_blank" rel="external nofollow noopener noreferrer" class="link-to-edit">编辑此页</a></span></div>
      <div class="post-info-share">
        <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="https://liudongdong1.github.io/allennlpintroduce/" data-title="AllenNLPIntroduce" data-hashtags="Math&Model"><i class="fa-brands fa-twitter fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="https://liudongdong1.github.io/allennlpintroduce/" data-hashtag="Math&amp;Model"><i class="fa-brands fa-facebook-square fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="https://liudongdong1.github.io/allennlpintroduce/" data-title="AllenNLPIntroduce" data-image="https://lddpicture.oss-cn-beijing.aliyuncs.com/picture/20210501113113.png"><i class="fa-brands fa-weibo fa-fw" aria-hidden="true"></i></a>
  </span>
      </div>
    </div>
  </div>

  <div class="post-info-more">
    <section class="post-tags"><i class="fa-solid fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/mathmodel/">Math&amp;Model</a></section>
    <section>
      <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
    </section>
  </div>

  <div class="post-nav"><a href="/wordembedding/" class="prev" rel="prev" title="WordEmbedding"><i class="fa-solid fa-angle-left fa-fw" aria-hidden="true"></i>WordEmbedding</a>
      <a href="/pytorchsegmentcode/" class="next" rel="next" title="PytorchSegmentCode">PytorchSegmentCode<i class="fa-solid fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article></main><footer class="footer">
    <div class="footer-container"><div class="footer-line powered">由 <a href="https://gohugo.io/" target="_blank" rel="external nofollow noopener noreferrer" title="Hugo 0.118.2">Hugo</a> 强力驱动 | 主题 - <a href="https://github.com/hugo-fixit/FixIt" target="_blank" rel="external" title="FixIt v0.2.17-RC"><img class="fixit-icon" src="/fixit.min.svg" alt="FixIt logo" />&nbsp;FixIt</a>
        </div><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">2020 - 2024</span><span class="author" itemprop="copyrightHolder">
              <a href="https://liudongdong1.github.io/"target="_blank" rel="external nofollow noopener noreferrer">LiuDongdong</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div><div class="footer-line statistics"><span class="site-time" title='网站运行中 ...'><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden="true"></i>&nbsp;<span class="run-times">网站运行中 ...</span></span></div><div class="footer-line ibruce">
          <span id="busuanzi_container_site_uv" title='总访客数'><i class="fa-regular fa-user fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span><span id="busuanzi_container_site_pv" class="footer-divider" title='总访问量'><i class="fa-regular fa-eye fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span>
        </div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="回到顶部"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric">0%</span>
        </div></div><a href="https://liudongdong1.github.io/" title="在 GitHub 上查看源代码"target="_blank" rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><div id="mask"></div><div class="reading-progress-bar" style="left: 0;top: 0;--bg-progress: #0076ff;--bg-progress-dark: #fff;"></div><noscript>
    <div class="noscript-warning">FixIt 主题在启用 JavaScript 的情况下效果最佳。</div>
  </noscript>
</div><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script src="/lib/autocomplete/autocomplete.min.js" defer></script><script src="/lib/algoliasearch/algoliasearch-lite.umd.min.js" defer></script><script src="/lib/lazysizes/lazysizes.min.js" async defer></script><script src="/lib/sharer/sharer.min.js" async defer></script><script src="/lib/typeit/index.umd.js" defer></script><script src="/lib/katex/katex.min.js" defer></script><script src="/lib/katex/auto-render.min.js" defer></script><script src="/lib/katex/copy-tex.min.js" defer></script><script src="/lib/katex/mhchem.min.js" defer></script><script src="/lib/cookieconsent/cookieconsent.min.js" defer></script><script src="/lib/pangu/pangu.min.js" defer></script><script src="/lib/cell-watermark/watermark.min.js" defer></script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async defer></script><script>window.config={"code":{"copyTitle":"复制到剪贴板","editLockTitle":"锁定可编辑代码块","editUnLockTitle":"解锁可编辑代码块","editable":true,"maxShownLines":10},"comment":{"enable":false},"cookieconsent":{"content":{"dismiss":"同意","link":"了解更多","message":"本网站使用 Cookies 来改善您的浏览体验。"},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"data":{"typeit-header-subtitle-desktop":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e","typeit-header-subtitle-mobile":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e"},"enablePWA":true,"enablePangu":true,"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"2R1K9SKLQZ","algoliaIndex":"index.zh-cn","algoliaSearchKey":"4a226aa1c5c98d6859e4d1386adb2bc7","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"},"siteTime":"2020-12-18T16:15:22+08:00","typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"typeit-header-subtitle-desktop":["typeit-header-subtitle-desktop"],"typeit-header-subtitle-mobile":["typeit-header-subtitle-mobile"]},"duration":-1,"speed":100},"watermark":{"appendto":".wrapper\u003emain","colspacing":30,"content":"\u003cimg class=\"fixit-icon\" src=\"/fixit.min.svg\" alt=\"FixIt logo\" /\u003e FixIt 主题","enable":true,"fontfamily":"inherit","fontsize":0.85,"height":21,"opacity":0.0125,"rotate":15,"rowspacing":60,"width":150}};</script><script src="/js/theme.min.js" defer></script><script src="/js/custom.min.js" defer></script></body>
</html>
