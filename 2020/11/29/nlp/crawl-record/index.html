<!DOCTYPE HTML>
<html lang="en">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Crawl_record, AIOT,Space&amp;Temporal Sequence Analysis,SpringBoot,liudongdong1,cloud">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Crawl_record | DaybyDay</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="DaybyDay" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">DaybyDay</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>Tags</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">

      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/about">
          
          <i class="fas fa-user-circle" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>about</span>
        </a>
      </li>
      
      <li>
        <a href="/resume">
          
          <i class="fa fa-user-secret" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>resume</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>Friends</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/gallery" class="waves-effect waves-light">
      
      <i class="fas fa-camera" style="zoom: 0.6;"></i>
      
      <span>Galleries</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">DaybyDay</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			Tags
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-user-circle"></i>
			
			About
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/about " style="margin-left:75px">
				  
				   <i class="fa fas fa-user-circle" style="position: absolute;left:50px" ></i>
			      
		          <span>about</span>
                  </a>
                </li>
              
                <li>

                  <a href="/resume " style="margin-left:75px">
				  
				   <i class="fa fa fa-user-secret" style="position: absolute;left:50px" ></i>
			      
		          <span>resume</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			Friends
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/gallery" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-camera"></i>
			
			Galleries
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/liudongdong1" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/liudongdong1" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://gitee.com/github-25970295/blogImage/raw/master/img/2.jpeg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Crawl_record</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    .toc-fixed .toc-link::before{
        position: fixed!important;/*当toc的位置改为fixed时，.toc-link::before也要改为fixed*/
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/crawl/">
                                <span class="chip bg-color">crawl</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E8%A7%86%E8%A7%89AI/" class="post-category">
                                视觉AI
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2020-11-29
                </div>
                

                <!-- 
                    <i class="fa fa-pencil"></i> Author: liudongdong1
                  -->

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>Update Date:&nbsp;&nbsp;
                    2021-05-14
                </div>
                

                <!-- 
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>Word Count:&nbsp;&nbsp;
                    8.4k
                </div>
                 -->

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>Read Times:&nbsp;&nbsp;
                    40 Min
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>Read Count:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h3 id="1-HTMLParse"><a href="#1-HTMLParse" class="headerlink" title="1. HTMLParse"></a>1. HTMLParse</h3><h4 id="1-1-XML-方式"><a href="#1-1-XML-方式" class="headerlink" title="1.1. XML 方式"></a>1.1. XML 方式</h4><blockquote>
<p>lxml是python的一个解析库，支持HTML和XML的解析，支持XPath解析方式，而且解析效率非常高 XPath，全称XML Path Language，即XML路径语言，它是一门在XML文档中查找信息的语言，它最初是用来搜寻XML文档的，但是它同样适用于HTML文档的搜索 XPath的选择功能十分强大，它提供了非常简明的路径选择表达式，另外，它还提供了超过100个内建函数，用于字符串、数值、时间的匹配以及节点、序列的处理等，几乎所有我们想要定位的节点，都可以用XPath来选择</p>
</blockquote>
<h5 id="1-1-1-匹配规则"><a href="#1-1-1-匹配规则" class="headerlink" title="1.1.1. 匹配规则"></a>1.1.1. 匹配规则</h5><table>
<thead>
<tr>
<th align="left">表达式</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">nodename</td>
<td align="left">选取此节点的所有子节点</td>
</tr>
<tr>
<td align="left">/</td>
<td align="left">从当前节点选取直接子节点</td>
</tr>
<tr>
<td align="left">//</td>
<td align="left">从当前节点选取子孙节点</td>
</tr>
<tr>
<td align="left">.</td>
<td align="left">选取当前节点</td>
</tr>
<tr>
<td align="left">..</td>
<td align="left">选取当前节点的父节点</td>
</tr>
<tr>
<td align="left">@</td>
<td align="left">选取属性，[@id=”main”]，[@class=”job-list”]</td>
</tr>
<tr>
<td align="left">*</td>
<td align="left">通配符，选择所有元素节点与元素名</td>
</tr>
<tr>
<td align="left">@*</td>
<td align="left">选取所有属性</td>
</tr>
<tr>
<td align="left">[@attrib]</td>
<td align="left">选取具有给定属性的所有元素</td>
</tr>
<tr>
<td align="left">[@attrib=’value’]</td>
<td align="left">选取给定属性具有给定值的所有元素</td>
</tr>
<tr>
<td align="left">[tag]</td>
<td align="left">选取所有具有指定元素的直接子节点</td>
</tr>
<tr>
<td align="left">[tag=’text’]</td>
<td align="left">选取所有具有指定元素并且文本内容是text节点</td>
</tr>
</tbody></table>
<h5 id="1-1-2-文本html-解析输出"><a href="#1-1-2-文本html-解析输出" class="headerlink" title="1.1.2. 文本html 解析输出"></a>1.1.2. 文本html 解析输出</h5><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#可以通过浏览器复制xml路径或取</span></span><br><span class="line">html=etree.parse(<span class="string">'test.html'</span>,etree.HTMLParser()) <span class="comment">#指定解析器HTMLParser会根据文件修复HTML文件中缺失的如声明信息</span></span><br><span class="line"><span class="comment">#-----  或者</span></span><br><span class="line">html=etree.HTML(text) <span class="comment">#初始化生成一个XPath解析对象</span></span><br><span class="line">result=etree.tostring(html,encoding=<span class="string">'utf-8'</span>)   <span class="comment">#解析对象输出代码</span></span><br><span class="line">print(type(html))</span><br><span class="line">print(type(result))</span><br><span class="line">print(result.decode(<span class="string">'utf-8'</span>))</span><br><span class="line"><span class="comment"># -------  属性匹配</span></span><br><span class="line">html=etree.HTML(text,etree.HTMLParser())</span><br><span class="line"><span class="comment">#选取class为item-1的li节点</span></span><br><span class="line">result=html.xpath(<span class="string">'//li[@class="item-1"]'</span>)</span><br><span class="line"><span class="comment"># -------  文本获取</span></span><br><span class="line">result=html.xpath(<span class="string">'//li[@class="item-1"]/a/text()'</span>) <span class="comment">#获取a节点下的内容</span></span><br><span class="line"><span class="comment">#---------  属性获取</span></span><br><span class="line">result=html.xpath(<span class="string">'//li/a/@href'</span>)  <span class="comment">#获取a的href属性</span></span><br></pre></td></tr></tbody></table></figure>

<h5 id="1-1-3-属性多值匹配"><a href="#1-1-3-属性多值匹配" class="headerlink" title="1.1.3. 属性多值匹配"></a>1.1.3. 属性多值匹配</h5><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line">text1=<span class="string">'''</span></span><br><span class="line"><span class="string">&lt;div&gt;</span></span><br><span class="line"><span class="string">    &lt;ul&gt;</span></span><br><span class="line"><span class="string">         &lt;li class="aaa" name="item"&gt;&lt;a href="link1.html"&gt;第一个&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">         &lt;li class="aaa" name="fore"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">     &lt;/ul&gt;</span></span><br><span class="line"><span class="string"> &lt;/div&gt;</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">html=etree.HTML(text1,etree.HTMLParser())</span><br><span class="line">result=html.xpath(<span class="string">'//li[@class="aaa" and @name="fore"]/a/text()'</span>)</span><br><span class="line">result1=html.xpath(<span class="string">'//li[contains(@class,"aaa") and @name="fore"]/a/text()'</span>)</span><br><span class="line">print(result)</span><br><span class="line">print(result1)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">[<span class="string">'second item'</span>]</span><br><span class="line">[<span class="string">'second item'</span>]（<span class="number">11</span>）XPath中的运算符</span><br><span class="line"><span class="comment">#---------示例二</span></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line">text1=<span class="string">'''</span></span><br><span class="line"><span class="string">&lt;div&gt;</span></span><br><span class="line"><span class="string">    &lt;ul&gt;</span></span><br><span class="line"><span class="string">         &lt;li class="aaa" name="item"&gt;&lt;a href="link1.html"&gt;第一个&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">         &lt;li class="aaa" name="item"&gt;&lt;a href="link1.html"&gt;第二个&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">         &lt;li class="aaa" name="item"&gt;&lt;a href="link1.html"&gt;第三个&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">         &lt;li class="aaa" name="item"&gt;&lt;a href="link1.html"&gt;第四个&lt;/a&gt;&lt;/li&gt; </span></span><br><span class="line"><span class="string">     &lt;/ul&gt;</span></span><br><span class="line"><span class="string"> &lt;/div&gt;</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line">html=etree.HTML(text1,etree.HTMLParser())</span><br><span class="line"></span><br><span class="line">result=html.xpath(<span class="string">'//li[contains(@class,"aaa")]/a/text()'</span>) <span class="comment">#获取所有li节点下a节点的内容</span></span><br><span class="line">result1=html.xpath(<span class="string">'//li[1][contains(@class,"aaa")]/a/text()'</span>) <span class="comment">#获取第一个</span></span><br><span class="line">result2=html.xpath(<span class="string">'//li[last()][contains(@class,"aaa")]/a/text()'</span>) <span class="comment">#获取最后一个</span></span><br><span class="line">result3=html.xpath(<span class="string">'//li[position()&gt;2 and position()&lt;4][contains(@class,"aaa")]/a/text()'</span>) <span class="comment">#获取第一个</span></span><br><span class="line">result4=html.xpath(<span class="string">'//li[last()-2][contains(@class,"aaa")]/a/text()'</span>) <span class="comment">#获取倒数第三个</span></span><br></pre></td></tr></tbody></table></figure>

<h5 id="1-1-4-运算符"><a href="#1-1-4-运算符" class="headerlink" title="1.1.4.  运算符"></a>1.1.4.  运算符</h5><table>
<thead>
<tr>
<th align="left">运算符</th>
<th align="left">描述</th>
<th align="left">实例</th>
<th align="left">返回值</th>
</tr>
</thead>
<tbody><tr>
<td align="left">or</td>
<td align="left">或</td>
<td align="left">age=19 or age=20</td>
<td align="left">如果age等于19或者等于20则返回true反正返回false</td>
</tr>
<tr>
<td align="left">and</td>
<td align="left">与</td>
<td align="left">age&gt;19 and age&lt;21</td>
<td align="left">如果age等于20则返回true，否则返回false</td>
</tr>
<tr>
<td align="left">mod</td>
<td align="left">取余</td>
<td align="left">5 mod 2</td>
<td align="left">1</td>
</tr>
<tr>
<td align="left">|</td>
<td align="left">取两个节点的集合</td>
<td align="left">//book | //cd</td>
<td align="left">返回所有拥有book和cd元素的节点集合</td>
</tr>
<tr>
<td align="left">+</td>
<td align="left">加</td>
<td align="left">6+4</td>
<td align="left">10</td>
</tr>
<tr>
<td align="left">-</td>
<td align="left">减</td>
<td align="left">6-4</td>
<td align="left">2</td>
</tr>
<tr>
<td align="left">*</td>
<td align="left">乘</td>
<td align="left">6*4</td>
<td align="left">24</td>
</tr>
<tr>
<td align="left">div</td>
<td align="left">除法</td>
<td align="left">8 div 4</td>
<td align="left">2</td>
</tr>
<tr>
<td align="left">=</td>
<td align="left">等于</td>
<td align="left">age=19</td>
<td align="left">true</td>
</tr>
<tr>
<td align="left">!=</td>
<td align="left">不等于</td>
<td align="left">age!=19</td>
<td align="left">true</td>
</tr>
<tr>
<td align="left">&lt;</td>
<td align="left">小于</td>
<td align="left">age&lt;19</td>
<td align="left">true</td>
</tr>
<tr>
<td align="left">&lt;=</td>
<td align="left">小于或等于</td>
<td align="left">age&lt;=19</td>
<td align="left">true</td>
</tr>
<tr>
<td align="left">&gt;</td>
<td align="left">大于</td>
<td align="left">age&gt;19</td>
<td align="left">true</td>
</tr>
<tr>
<td align="left">&gt;=</td>
<td align="left">大于或等于</td>
<td align="left">age&gt;=19</td>
<td align="left">true</td>
</tr>
</tbody></table>
<h4 id="1-2-Json-方式"><a href="#1-2-Json-方式" class="headerlink" title="1.2. Json 方式"></a>1.2. Json 方式</h4><ul>
<li>使用工具<a href="https://www.sojson.com/" target="_blank" rel="noopener">https://www.sojson.com/</a> 查看json 格式，找到索引的key</li>
<li>或者直接把json 文件用vscode打开，注意后缀是.json;</li>
</ul>
<blockquote>
<p>JSON 的全称是 JavaScript Object Notation，即 JavaScript 对象符号，它是一种轻量级、跨平台、跨语言的数据交换格式，其设计意图是把所有事情都用设计的字符串来表示，这样既方便在互联网上传递信息，也方便人进行阅读。</p>
</blockquote>
<ul>
<li><p>json.dumps(): 对数据进行编码。</p>
</li>
<li><p>json.loads(): 对数据进行解码。</p>
</li>
<li><p><strong>编码类型转换</strong></p>
<ul>
<li><strong>JSON 解码为 Python 类型转换对应表</strong></li>
</ul>
<table>
<thead>
<tr>
<th align="left">JSON</th>
<th align="left">Python</th>
</tr>
</thead>
<tbody><tr>
<td align="left">object</td>
<td align="left">dict</td>
</tr>
<tr>
<td align="left">array</td>
<td align="left">list</td>
</tr>
<tr>
<td align="left">string</td>
<td align="left">str</td>
</tr>
<tr>
<td align="left">number (int)</td>
<td align="left">int</td>
</tr>
<tr>
<td align="left">number (real)</td>
<td align="left">float</td>
</tr>
<tr>
<td align="left">true</td>
<td align="left">True</td>
</tr>
<tr>
<td align="left">false</td>
<td align="left">False</td>
</tr>
<tr>
<td align="left">null</td>
<td align="left">None</td>
</tr>
</tbody></table>
<ul>
<li><strong>Python 编码为 JSON 类型转换对应表</strong>：</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th align="left">Python</th>
<th align="left">JSON</th>
</tr>
</thead>
<tbody><tr>
<td align="left">dict</td>
<td align="left">object</td>
</tr>
<tr>
<td align="left">list, tuple</td>
<td align="left">array</td>
</tr>
<tr>
<td align="left">str</td>
<td align="left">string</td>
</tr>
<tr>
<td align="left">int, float, int- &amp; float-derived Enums</td>
<td align="left">number</td>
</tr>
<tr>
<td align="left">True</td>
<td align="left">true</td>
</tr>
<tr>
<td align="left">False</td>
<td align="left">false</td>
</tr>
<tr>
<td align="left">None</td>
<td align="left">null</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="comment"># 创建字典类型Person</span></span><br><span class="line">person = {</span><br><span class="line">    <span class="string">'name'</span>: <span class="string">'知秋小梦'</span>,</span><br><span class="line">    <span class="string">'gender'</span>: <span class="string">'male'</span>,</span><br><span class="line">    <span class="string">'age'</span>: <span class="number">18</span></span><br><span class="line">}</span><br><span class="line"><span class="comment"># Python字典类型转换为JSON对象</span></span><br><span class="line">json_person = json.dumps(person)</span><br><span class="line">print(json_person)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 写入 JSON 数据</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'data.json'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    json.dump(data, f)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'data.json'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    data = json.load(f)</span><br></pre></td></tr></tbody></table></figure>

<h4 id="1-3-正则表达式"><a href="#1-3-正则表达式" class="headerlink" title="1.3. 正则表达式"></a>1.3. 正则表达式</h4><p><a href="https://www.runoob.com/regexp/regexp-syntax.html" target="_blank" rel="noopener">https://www.runoob.com/regexp/regexp-syntax.html</a></p>
<ul>
<li><p><strong>仅匹配精确短语</strong><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201029132849384.png" alt=""></p>
</li>
<li><p><strong>匹配列表中的字词或短语</strong><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201029132950911.png" alt=""></p>
</li>
<li><p><strong>匹配包含不同拼写或特殊字符的字词</strong><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201029133113269.png" alt=""></p>
</li>
<li><p><strong>匹配某个特定网域的所有电子邮件地址</strong><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201029133313415.png" alt="image-20201029133313415"></p>
</li>
</ul>
<h4 id="1-4-存储"><a href="#1-4-存储" class="headerlink" title="1.4. 存储"></a>1.4. 存储</h4><h5 id="1-4-1-panda-DataFrame"><a href="#1-4-1-panda-DataFrame" class="headerlink" title="1.4.1. panda.DataFrame"></a>1.4.1. <a href="https://pbpython.com/pandas-list-dict.html" target="_blank" rel="noopener">panda.DataFrame</a></h5><ul>
<li>数据存储，加载，参考<a href="https://pbpython.com/pandas-list-dict.html" target="_blank" rel="noopener">https://pbpython.com/pandas-list-dict.html</a></li>
</ul>
<blockquote>
<p>使用pandas的DataFrame to_csv方法实现csv文件输出，但是中文乱码，已验证的正确的方法是：</p>
<p>df.to_csv(“cnn_predict_result.csv”,<strong>encoding=”utf_8_sig”</strong>)</p>
<p>关于utf-8与<strong>utf_8_sig的区别：</strong></p>
<p>UTF-8以字节为编码单元，它的字节顺序在所有系统中都是一様的，没有字节序的问题，也因此它实际上并不需要BOM(“ByteOrder Mark”)。但是UTF-8 with BOM即utf-8-sig需要提供BOM。</p>
<p>1）程序输出中出现乱码的原因是因为python2中中文编码的问题，需要注意的是要将处理的中文文件的编码和python源文件的编码保持一致，这样不会出现中文乱码。可以参考这两篇文章<a href="http://blog.csdn.net/xw_classmate/article/details/51933904" target="_blank" rel="noopener">关于Python脚本开头两行的：#!/usr/bin/python和# -<em>- coding: utf-8 -</em>-的作用 – 指定</a>和<a href="http://blog.csdn.net/xw_classmate/article/details/51933851" target="_blank" rel="noopener">Python中用encoding声明的文件编码和文件的实际编码之间的关系</a></p>
<p>2）在程序中能够正常输出中文，但是导出到文件后使用excel打开是出现中文乱码是因为excel能够正确识别用gb2312、<strong>gbk</strong>、gb18030或<strong>utf_8 with BOM</strong> 编码的中文，如果是<strong>utf_8 no BOM</strong>编码的中文文件，excel打开会乱码。</p>
</blockquote>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">def parse_html(self, html):</span><br><span class="line">      '''</span><br><span class="line">          html: [{jobid},{job_href},{job_name},{jobwelf},{attribute_text},{providesalary_text},{company_name},{companysize_text},{companyind_text},{company_href},{degreefrom},{companytype_text},{workarea_text},{updatedate}]</span><br><span class="line">          解析一页中html文件，获得如上文件个数数据</span><br><span class="line">      '''</span><br><span class="line">      items = []   #python 列表的使用</span><br><span class="line">      for one in html:</span><br><span class="line">          item={}</span><br><span class="line">          item['jobid']=one['jobid']</span><br><span class="line">          item['job_href']=one['job_href']</span><br><span class="line">          item['job_name']=one['job_name']</span><br><span class="line">          item['job_welf']=one['jobwelf']</span><br><span class="line">          print(item['job_href'])</span><br><span class="line">          # 根据job介绍url地址 获取 职位要求，工作地点，公司信息</span><br><span class="line">          a,b,c=self.get_jobdetail(item['job_href'])</span><br><span class="line">          item['job_info']=a</span><br><span class="line">          item['job_work']=b</span><br><span class="line">          item['company_info']=c</span><br><span class="line">          item['attribute_text']=one['attribute_text']</span><br><span class="line">          item['providesalary_text']=one['providesalary_text']</span><br><span class="line">          item['company_name']=one['company_name']</span><br><span class="line">          item['companysize_text']=one['companysize_text']</span><br><span class="line">          item['companyind_text']=one['companyind_text']</span><br><span class="line">          item['company_href']=one['company_href']</span><br><span class="line">          item['degreefrom']=one['degreefrom']</span><br><span class="line">          item['companytype_text']=one['companytype_text']</span><br><span class="line">          item['workarea_text']=one['workarea_text']</span><br><span class="line">          item['updatedate']=one['updatedate']</span><br><span class="line">          items.append(item)</span><br><span class="line">      print("parse_one_page finished: size=",len(html),"开始存储")</span><br><span class="line">      df=pd.DataFrame(items)</span><br><span class="line">      df.to_csv("51job_data.csv",encoding="utf_8_sig",mode = 'a',columns=['jobid','job_href','job_name','job_welf','job_info','job_work','company_info',</span><br><span class="line">          'attribute_text','providesalary_text','company_name','companysize_text','companyind_text','company_href',</span><br><span class="line">          'degreefrom','companytype_text','workarea_text','updatedate'])</span><br></pre></td></tr></tbody></table></figure>



<h3 id="2-HTML-渲染模式"><a href="#2-HTML-渲染模式" class="headerlink" title="2. HTML 渲染模式"></a>2. HTML 渲染模式</h3><h4 id="2-1-静态网页"><a href="#2-1-静态网页" class="headerlink" title="2.1.  静态网页"></a>2.1.  静态网页</h4><p>静态网页是指存放在服务器文件系统中实实在在的HTML文件。当用户在浏览器中输入页面的URL，然后回车，浏览器就会将对应的html文件下载、渲染并呈现在窗口中。早期的网站通常都是由静态页面制作的。</p>
<p><strong>[特点]</strong></p>
<ul>
<li><p>静态网页每个网页都有一个固定的URL，且网页URL以.htm、.html、.shtml等常见形式为后缀，而不含有“?”；（动态网页中的“？”对搜索引擎检索存在一定的问题，搜索引擎一般不可能从一个网站的数据库中访问全部网页，或者出于技术方面的考虑，搜索蜘蛛不去抓取网址中“？”后面的内容。）</p>
</li>
<li><p>网页内容一经发布到网站服务器上，无论是否有用户访问，每个静态网页的内容都是保存在网站服务器上的，也就是说，静态网页是实实在在保存在服务器上的文件，每个网页都是一个独立的文件；</p>
</li>
<li><p>静态网页的内容相对稳定，因此容易被搜索引擎检索；</p>
</li>
<li><p>静态网页没有数据库的支持，在网站制作和维护方面工作量较大，因此当网站信息量很大时完全依靠静态网页制作方式比较困难；</p>
</li>
<li><p>静态网页的交互性较差，在功能方面有较大的限制。</p>
</li>
<li><p>页面浏览速度迅速，过程无需连接数据库，开启页面速度快于动态页面。</p>
</li>
<li><p>减轻了服务器的负担，工作量减少，也就降低了数据库的成本。</p>
</li>
<li><p>没得网络服务器或应用服务器，比如直接从CD-ROM（激光唱片-只读存储器）或USB闪存驱动器读取内容，可以通过网络浏览器直接访问。</p>
</li>
<li><p>网站更安全，HTML页面不会受Asp相关漏洞的影响；而且可以减少攻击，防SQL注入。数据库出错时，不影响网站正常访问。</p>
</li>
</ul>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201028223624298.png" alt=""></p>
<blockquote>
<p>所谓的动态网页，是指跟静态网页相对的一种网页编程技术。静态网页，随着html代码生成，页面的内容和显示效果就不会发生变化了。而动态网页则不然，其显示的页面则是经过Javascript处理数据后生成的结果，可以发生改变。<strong>这些数据的来源有多种，可能是经过Javascript计算生成的，也可能是通过Ajax加载的。</strong></p>
<p>动态加载网页的方式，一来是可以实现web开发的前后端分离，减少服务器直接渲染页面的压力；<strong>二来是可以作为反爬虫的一种手段。</strong></p>
</blockquote>
<h4 id="2-2-动态网页"><a href="#2-2-动态网页" class="headerlink" title="2.2. 动态网页"></a>2.2. 动态网页</h4><p>​        动态网页是相对于静态网页而言的。当浏览器请求服务器的某个页面时，服务器根据当前时间、环境参数、数据库操作等动态的生成HTML页面，然后在发送给浏览器（后面的处理就跟静态网页一样了）。很明显，动态网页中的“动态”是指服务器端页面的动态生成，相反，“静态”则指页面是实实在在的、独立的文件。</p>
<ul>
<li>HTML+JavaScript(Node.js)</li>
<li>HTML+PHP</li>
<li>HTML+ASP.NET(或ASP)</li>
<li>HTML+JSP</li>
<li>HTML+CGI(早期的动态网页技术)</li>
</ul>
<p>[<strong>动态网页</strong>]</p>
<ul>
<li><p>动态网页一般以数据库技术为基础，可以大大降低网站维护的工作量；</p>
</li>
<li><p>采用动态网页技术的网站可以实现更多的功能，如用户注册、用户登录、在线调查、用户管理、订单管理等等；</p>
</li>
<li><p>动态网页实际上并不是独立存在于服务器上的网页文件，只有当用户请求时服务器才返回一个完整的网页；</p>
</li>
<li><p>动态网页地址中的“?”对搜索引擎检索存在一定的问题，搜索引擎一般不可能从一个网站的数据库中访问全部网页，或者出于技术方面的考虑，搜索蜘蛛不去抓取网址中“?”后面的内容，因此采用动态网页的网站在进行搜索引擎推广时需要做一定的技术处理才能适应搜索引擎的要求。</p>
</li>
</ul>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201028223654422.png" alt=""></p>
<h4 id="2-3-伪静态网页"><a href="#2-3-伪静态网页" class="headerlink" title="2.3. 伪静态网页"></a>2.3. 伪静态网页</h4><p>实时的显示一些信息。或者还想运用动态脚本解决一些问题。不能用静态的方式来展示网站内容。但是这就损失了对搜索引擎的友好面。展示出来的是以html一类的静态页面形式，但其实是用ASP一类的动态脚本来处理的。</p>
<ul>
<li><a href="https://www.jianshu.com/p/649d2a0ebde5" target="_blank" rel="noopener">https://www.jianshu.com/p/649d2a0ebde5</a></li>
</ul>
<h3 id="3-动态网页爬取"><a href="#3-动态网页爬取" class="headerlink" title="3. 动态网页爬取"></a>3. 动态网页爬取</h3><blockquote>
<p>以 <a href="http://book.sina.com.cn/excerpt/" target="_blank" rel="noopener">新浪读书——书摘</a> 为例，介绍如何得到无法筛选出来的Ajax请求链接:在Chrome中打开网页，右键检查，会发现首页中书摘列表包含在一个id为subShowContent1_static的div中，而查看网页源代码会发现id为subShowContent1_static的div为空。</p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201029092325019.png" alt=""></p>
<p>并且点击更多书摘或下一页时，网页URL并没有发生变化。这与我们最前面所说的两种情况相同，说明这个网页就是使用 JS 动态加载数据的。</p>
<blockquote>
<p>F12打开调试工具，打开NetWork窗口，F5刷新，可以看到浏览器发送以及接收到的数据记录(我们可以点击上面的 XHR 或者 JS 对这些请求进行过滤)：</p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201029092647745.png" alt=""></p>
<h4 id="步骤一-根据id进行查找"><a href="#步骤一-根据id进行查找" class="headerlink" title="步骤一. 根据id进行查找"></a>步骤一. 根据id进行查找</h4><blockquote>
<p>js 操作页面的数据一定要进行定位，最常用的方法就是使用 id 定位，因为 id 在整个页面中是唯一的，那么我们第一步就是在所有的 js 文件中找和 subShowContent1_static 这个 id 相关的文件，于是我在 network 页面使用 ctrl+f 进行全局搜索。</p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201029093044283.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201029093403370.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201029095656616.png" alt=""></p>
<h4 id="步骤二：断点动态捕获"><a href="#步骤二：断点动态捕获" class="headerlink" title="步骤二：断点动态捕获"></a>步骤二：断点动态捕获</h4><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201029100221196.png" alt=""></p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#设置断点后 F5 刷新</span><br><span class="line">#根据断点信息构造 访问url</span><br><span class="line">http://feed.mix.sina.com.cn/api/roll/get?callback=xxxxxxxx&amp;pageid=96&amp;lid=560&amp;num=20&amp;page=1</span><br></pre></td></tr></tbody></table></figure>

<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201029100755169.png" alt=""></p>
<h3 id="4-反爬虫"><a href="#4-反爬虫" class="headerlink" title="4. 反爬虫"></a>4. 反爬虫</h3><p>1、<strong>Headers反爬虫</strong> ：Cookie、Referer、User-Agent</p>
<p> 解决方案: 通过F12获取headers,传给requests.get()方法</p>
<p>2、<strong>IP限制</strong> ：网站根据IP地址访问频率进行反爬,短时间内进制IP访问</p>
<p> 解决方案:</p>
<p>​    1、构造自己IP代理池,每次访问随机选择代理,经常更新代理池</p>
<p>​    2、购买开放代理或私密代理IP</p>
<p>​    3、降低爬取的速度</p>
<p>3、<strong>User-Agent限制</strong> ：类似于IP限制</p>
<p> 解决方案: 构造自己的User-Agent池,每次访问随机选择</p>
<p>5、<strong>对查询参数或Form表单数据认证(salt、sign)</strong></p>
<p> 解决方案: 找到JS文件,分析JS处理方法,用Python按同样方式处理</p>
<p>6、<strong>对响应内容做处理</strong></p>
<p> 解决方案: 打印并查看响应内容,用xpath或正则做处理</p>
<h3 id="5-爬虫练习"><a href="#5-爬虫练习" class="headerlink" title="5. 爬虫练习"></a>5. 爬虫练习</h3><blockquote>
<p>查看网页编码：在窗口console标签下，键入 “document.charset”</p>
</blockquote>
<h4 id="5-1-伪链接静态网页"><a href="#5-1-伪链接静态网页" class="headerlink" title="5.1.  伪链接静态网页"></a>5.1.  伪链接静态网页</h4><blockquote>
<p>目标: 抓取最新中华人民共和国县以上行政区划代码</p>
<p>URL: <a href="http://www.mca.gov.cn/article/sj/xzqh/2019/" target="_blank" rel="noopener">http://www.mca.gov.cn/article/sj/xzqh/2019/</a> - 民政数据 - 行政区划代码</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GovementSpider</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.url = <span class="string">'http://www.mca.gov.cn/article/sj/xzqh/2019/'</span></span><br><span class="line">        self.headers = {<span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0'</span>}</span><br><span class="line">        <span class="comment"># 创建2个对象</span></span><br><span class="line">        self.db = pymysql.connect(<span class="string">'127.0.0.1'</span>, <span class="string">'root'</span>, <span class="string">'123456'</span>, <span class="string">'govdb'</span>, charset=<span class="string">'utf8'</span>)</span><br><span class="line">        self.cursor = self.db.cursor()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取假链接</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_false_link</span><span class="params">(self)</span>:</span></span><br><span class="line">        html = requests.get(url=self.url, headers=self.headers).text</span><br><span class="line">        <span class="comment"># 此处隐藏了真实的二级页面的url链接，真实的在假的响应网页中，通过js脚本生成，</span></span><br><span class="line">        <span class="comment"># 假的链接在网页中可以访问，但是爬取到的内容却不是我们想要的</span></span><br><span class="line">        parse_html = etree.HTML(html)</span><br><span class="line">        a_list = parse_html.xpath(<span class="string">'//a[@class="artitlelist"]'</span>)</span><br><span class="line">        <span class="keyword">for</span> a <span class="keyword">in</span> a_list:</span><br><span class="line">            <span class="comment"># get()方法:获取某个属性的值</span></span><br><span class="line">            title = a.get(<span class="string">'title'</span>)</span><br><span class="line">            <span class="keyword">if</span> title.endswith(<span class="string">'代码'</span>):</span><br><span class="line">                <span class="comment"># 获取到第1个就停止即可，第1个永远是最新的链接</span></span><br><span class="line">                false_link = <span class="string">'http://www.mca.gov.cn'</span> + a.get(<span class="string">'href'</span>)</span><br><span class="line">                print(<span class="string">"二级“假”链接的网址为"</span>, false_link)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="comment"># 提取真链接</span></span><br><span class="line">        self.incr_spider(false_link)</span><br><span class="line">    <span class="comment"># 增量爬取函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">incr_spider</span><span class="params">(self, false_link)</span>:</span>   <span class="comment">#false_link: http://www.mca.gov.cn/article/sj/xzqh/2019/202002/20200200024708.shtml</span></span><br><span class="line">        self.cursor.execute(<span class="string">'select url from version where url=%s'</span>, [false_link])</span><br><span class="line">        <span class="comment"># fetchall: (('http://xxxx.html',),)</span></span><br><span class="line">        result = self.cursor.fetchall()</span><br><span class="line">        <span class="comment"># not result:代表数据库version表中无数据</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> result:</span><br><span class="line">            self.get_true_link(false_link)</span><br><span class="line">            <span class="comment"># 可选操作: 数据库version表中只保留最新1条数据</span></span><br><span class="line">            self.cursor.execute(<span class="string">"delete from version"</span>)</span><br><span class="line">            <span class="comment"># 把爬取后的url插入到version表中</span></span><br><span class="line">            self.cursor.execute(<span class="string">'insert into version values(%s)'</span>, [false_link])</span><br><span class="line">            self.db.commit()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">'数据已是最新,无须爬取'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取真链接</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_true_link</span><span class="params">(self, false_link)</span>:</span></span><br><span class="line">        <span class="comment"># 先获取假链接的响应,然后根据响应获取真链接</span></span><br><span class="line">        html = requests.get(url=false_link, headers=self.headers).text</span><br><span class="line">        <span class="comment"># 从二级页面的响应中提取真实的链接（此处为JS动态加载跳转的地址）</span></span><br><span class="line">        re_bds = <span class="string">r'window.location.href="(.*?)"'</span></span><br><span class="line">        pattern = re.compile(re_bds, re.S)</span><br><span class="line">        true_link = pattern.findall(html)[<span class="number">0</span>]</span><br><span class="line">        self.save_data(true_link)  <span class="comment"># 提取真链接的数据</span></span><br><span class="line">    <span class="comment"># 用xpath直接提取数据</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">save_data</span><span class="params">(self, true_link)</span>:</span></span><br><span class="line">        html = requests.get(url=true_link, headers=self.headers).text</span><br><span class="line">        <span class="comment"># 基准xpath,提取每个信息的节点列表对象</span></span><br><span class="line">        parse_html = etree.HTML(html)</span><br><span class="line">        tr_list = parse_html.xpath(<span class="string">'//tr[@height="19"]'</span>)</span><br><span class="line">        <span class="keyword">for</span> tr <span class="keyword">in</span> tr_list:</span><br><span class="line">            code = tr.xpath(<span class="string">'./td[2]/text()'</span>)[<span class="number">0</span>].strip()  <span class="comment"># 行政区划代码</span></span><br><span class="line">            name = tr.xpath(<span class="string">'./td[3]/text()'</span>)[<span class="number">0</span>].strip()  <span class="comment"># 单位名称</span></span><br><span class="line">            print(name, code)</span><br><span class="line">    <span class="comment"># 主函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.get_false_link()</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    spider = GovementSpider()</span><br><span class="line">    spider.main()</span><br></pre></td></tr></tbody></table></figure>

<h4 id="5-2-动态数据爬取"><a href="#5-2-动态数据爬取" class="headerlink" title="5.2. 动态数据爬取"></a>5.2. 动态数据爬取</h4><p><strong>特点</strong></p>
<blockquote>
<ol>
<li>右键 -&gt; 查看网页源码中没有具体数据</li>
<li>滚动鼠标滑轮或其他动作时加载</li>
</ol>
</blockquote>
<p><strong>抓取</strong></p>
<blockquote>
<ol>
<li>F12打开控制台，选择XHR异步加载数据包，找到页面动作抓取网络数据包</li>
<li>通过XHR–&gt;Header–&gt;General–&gt;Request URL，获取json文件URL地址</li>
<li>通过XHR–&gt;Header–&gt;Query String Parameters(查询参数)</li>
</ol>
</blockquote>
<h5 id="任务一：-豆瓣电影数据抓取案例"><a href="#任务一：-豆瓣电影数据抓取案例" class="headerlink" title="任务一： 豆瓣电影数据抓取案例"></a><strong>任务一： 豆瓣电影数据抓取案例</strong></h5><p>目标</p>
<ol>
<li>地址: 豆瓣电影 - 排行榜 - 剧情<ul>
<li><a href="https://movie.douban.com/typerank?type_name=剧情&amp;type=11&amp;interval_id=100:90&amp;action=" target="_blank" rel="noopener">https://movie.douban.com/typerank?</a></li>
<li><a href="https://movie.douban.com/typerank?type_name=剧情&amp;type=11&amp;interval_id=100:90&amp;action=" target="_blank" rel="noopener">type_name=%E5%89%A7%E6%83%85&amp;type=11&amp;interval_id=100:90&amp;action=</a></li>
</ul>
</li>
<li>目标: 爬取电影名称、电影评分</li>
</ol>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201029112020668.png" alt=""></p>
<blockquote>
<p>通过源代码找不到的情况下，可以在network那刷新，然后重新搜索。</p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201029111302563.png" alt=""></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubanSpider</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.base_url = <span class="string">'https://movie.douban.com/j/chart/top_list?'</span></span><br><span class="line">        self.i = <span class="number">0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_html</span><span class="params">(self, params)</span>:</span></span><br><span class="line">        headers = {<span class="string">'User-Agent'</span>: UserAgent().random}</span><br><span class="line">        res = requests.get(url=self.base_url, params=params, headers=headers)</span><br><span class="line">        res.encoding = <span class="string">'utf-8'</span></span><br><span class="line">        html = res.json()  <span class="comment"># 将json格式的字符串转为python数据类型</span></span><br><span class="line">        self.parse_html(html)  <span class="comment"># 直接调用解析函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_html</span><span class="params">(self, html)</span>:</span></span><br><span class="line">        <span class="comment"># html: [{电影1信息},{电影2信息},{}]</span></span><br><span class="line">        item = {}   <span class="comment">#python 列表的使用</span></span><br><span class="line">        <span class="keyword">for</span> one <span class="keyword">in</span> html:</span><br><span class="line">            item[<span class="string">'name'</span>] = one[<span class="string">'title'</span>]  <span class="comment"># 电影名</span></span><br><span class="line">            item[<span class="string">'score'</span>] = one[<span class="string">'score'</span>]  <span class="comment"># 评分</span></span><br><span class="line">            item[<span class="string">'time'</span>] = one[<span class="string">'release_date'</span>]  <span class="comment"># 打印测试</span></span><br><span class="line">            <span class="comment"># 打印显示</span></span><br><span class="line">            print(item)</span><br><span class="line">            self.i += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 获取电影总数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_total</span><span class="params">(self, typ)</span>:</span></span><br><span class="line">        <span class="comment"># 异步动态加载的数据 都可以在XHR数据抓包</span></span><br><span class="line">        url = <span class="string">'https://movie.douban.com/j/chart/top_list_count?type={}&amp;interval_id=100%3A90'</span>.format(typ)</span><br><span class="line">        ua = UserAgent()</span><br><span class="line">        html = requests.get(url=url, headers={<span class="string">'User-Agent'</span>: ua.random}).json()</span><br><span class="line">        total = html[<span class="string">'total'</span>]</span><br><span class="line">        <span class="keyword">return</span> total</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(self)</span>:</span></span><br><span class="line">        typ = input(<span class="string">'请输入电影类型(剧情|喜剧|动作):'</span>)</span><br><span class="line">        typ_dict = {<span class="string">'剧情'</span>: <span class="string">'11'</span>, <span class="string">'喜剧'</span>: <span class="string">'24'</span>, <span class="string">'动作'</span>: <span class="string">'5'</span>}</span><br><span class="line">        typ = typ_dict[typ]</span><br><span class="line">        total = self.get_total(typ)  <span class="comment"># 获取该类型电影总数量</span></span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">0</span>, int(total), <span class="number">20</span>):</span><br><span class="line">            params = {</span><br><span class="line">                <span class="string">'type'</span>: typ,</span><br><span class="line">                <span class="string">'interval_id'</span>: <span class="string">'100:90'</span>,</span><br><span class="line">                <span class="string">'action'</span>: <span class="string">''</span>,</span><br><span class="line">                <span class="string">'start'</span>: str(page),</span><br><span class="line">                <span class="string">'limit'</span>: <span class="string">'20'</span>}</span><br><span class="line">            self.get_html(params)</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">        print(<span class="string">'爬取的电影的数量:'</span>, self.i)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    spider = DoubanSpider()</span><br><span class="line">    spider.main()</span><br></pre></td></tr></tbody></table></figure>

<h5 id="任务二：腾讯招聘数据抓取-Ajax"><a href="#任务二：腾讯招聘数据抓取-Ajax" class="headerlink" title="任务二：腾讯招聘数据抓取(Ajax)"></a><strong>任务二：腾讯招聘数据抓取(Ajax)</strong></h5><p>确定URL地址及目标</p>
<ul>
<li>URL: 百度搜索腾讯招聘 - 查看工作岗位<a href="https://careers.tencent.com/search.html" target="_blank" rel="noopener">https://careers.tencent.com/search.html</a></li>
<li>目标: 职位名称、工作职责、岗位要求</li>
</ul>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201029112427977.png" alt=""></p>
<blockquote>
<p>确定所要数据所在页面： url 地址可以直接在header里面进行查看</p>
<p>职位名称：<a href="https://careers.tencent.com/tencentcareer/api/post/Query?timestamp=1603941718816&amp;countryId=&amp;cityId=&amp;bgIds=&amp;productId=&amp;categoryId=&amp;parentCategoryId=&amp;attrId=&amp;keyword=&amp;pageIndex=1&amp;pageSize=10&amp;language=zh-cn&amp;area=cn" target="_blank" rel="noopener">https://careers.tencent.com/tencentcareer/api/post/Query?timestamp=1603941718816&amp;countryId=&amp;cityId=&amp;bgIds=&amp;productId=&amp;categoryId=&amp;parentCategoryId=&amp;attrId=&amp;keyword=&amp;pageIndex=1&amp;pageSize=10&amp;language=zh-cn&amp;area=cn</a></p>
<p>工作职责、岗位要求： <a href="https://careers.tencent.com/jobdesc.html?postId=1290651460547125248" target="_blank" rel="noopener">https://careers.tencent.com/jobdesc.html?postId=1290651460547125248</a></p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> useragents <span class="keyword">import</span> ua_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TencentSpider</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.one_url = <span class="string">'https://careers.tencent.com/tencentcareer/api/post/Query?timestamp=1563912271089&amp;countryId=&amp;cityId=&amp;bgIds=&amp;productId=&amp;categoryId=&amp;parentCategoryId=&amp;attrId=&amp;keyword=&amp;pageIndex={}&amp;pageSize=10&amp;language=zh-cn&amp;area=cn'</span></span><br><span class="line">        self.two_url = <span class="string">'https://careers.tencent.com/tencentcareer/api/post/ByPostId?timestamp=1563912374645&amp;postId={}&amp;language=zh-cn'</span></span><br><span class="line">        self.f = open(<span class="string">'tencent.json'</span>, <span class="string">'a'</span>)  <span class="comment"># 打开文件</span></span><br><span class="line">        self.item_list = []  <span class="comment"># 存放抓取的item字典数据</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取响应内容函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_page</span><span class="params">(self, url)</span>:</span></span><br><span class="line">        headers = {<span class="string">'User-Agent'</span>: random.choice(ua_list)}</span><br><span class="line">        html = requests.get(url=url, headers=headers).text</span><br><span class="line">        html = json.loads(html)  <span class="comment"># json格式字符串转为Python数据类型</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> html</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 主线函数: 获取所有数据</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_page</span><span class="params">(self, one_url)</span>:</span></span><br><span class="line">        html = self.get_page(one_url)</span><br><span class="line">        item = {}</span><br><span class="line">        <span class="keyword">for</span> job <span class="keyword">in</span> html[<span class="string">'Data'</span>][<span class="string">'Posts'</span>]:</span><br><span class="line">            item[<span class="string">'name'</span>] = job[<span class="string">'RecruitPostName'</span>]  <span class="comment"># 名称</span></span><br><span class="line">            post_id = job[<span class="string">'PostId'</span>]  <span class="comment"># postId，拿postid为了拼接二级页面地址</span></span><br><span class="line">            <span class="comment"># 拼接二级地址,获取职责和要求</span></span><br><span class="line">            two_url = self.two_url.format(post_id)</span><br><span class="line">            item[<span class="string">'duty'</span>], item[<span class="string">'require'</span>] = self.parse_two_page(two_url)</span><br><span class="line">            print(item)</span><br><span class="line">            self.item_list.append(item)  <span class="comment"># 添加到大列表中</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 解析二级页面函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_two_page</span><span class="params">(self, two_url)</span>:</span></span><br><span class="line">        html = self.get_page(two_url)</span><br><span class="line">        duty = html[<span class="string">'Data'</span>][<span class="string">'Responsibility'</span>]  <span class="comment"># 工作责任</span></span><br><span class="line">        duty = duty.replace(<span class="string">'\r\n'</span>, <span class="string">''</span>).replace(<span class="string">'\n'</span>, <span class="string">''</span>)  <span class="comment"># 去掉换行</span></span><br><span class="line">        require = html[<span class="string">'Data'</span>][<span class="string">'Requirement'</span>]  <span class="comment"># 工作要求</span></span><br><span class="line">        require = require.replace(<span class="string">'\r\n'</span>, <span class="string">''</span>).replace(<span class="string">'\n'</span>, <span class="string">''</span>)  <span class="comment"># 去掉换行</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> duty, require</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取总页数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_numbers</span><span class="params">(self)</span>:</span></span><br><span class="line">        url = self.one_url.format(<span class="number">1</span>)</span><br><span class="line">        html = self.get_page(url)</span><br><span class="line">        numbers = int(html[<span class="string">'Data'</span>][<span class="string">'Count'</span>]) // <span class="number">10</span> + <span class="number">1</span>  <span class="comment"># 每页有10个推荐</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> numbers</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(self)</span>:</span></span><br><span class="line">        number = self.get_numbers()</span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">3</span>):</span><br><span class="line">            one_url = self.one_url.format(page)</span><br><span class="line">            self.parse_page(one_url)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 保存到本地json文件:json.dump</span></span><br><span class="line">        json.dump(self.item_list, self.f, ensure_ascii=<span class="literal">False</span>)</span><br><span class="line">        self.f.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    start = time.time()</span><br><span class="line">    spider = TencentSpider()</span><br><span class="line">    spider.main()</span><br><span class="line">    end = time.time()</span><br><span class="line">    print(<span class="string">'执行时间:%.2f'</span> % (end - start))</span><br></pre></td></tr></tbody></table></figure>

<h5 id="任务三：51job网站爬取"><a href="#任务三：51job网站爬取" class="headerlink" title="任务三：51job网站爬取"></a>任务三：51job网站爬取</h5><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201029205633909.png" alt=""></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> parse</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> xlwt     </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JobSpider</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.base_url = <span class="string">'https://movie.douban.com/j/chart/top_list?'</span></span><br><span class="line">        self.i = <span class="number">0</span>   <span class="comment">#记录计数器</span></span><br><span class="line">        <span class="comment">#self.wirte_sheet=self.init_xkwt()  </span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_xkwt</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">            初始化csv文件表头</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="comment">#新建表格空间</span></span><br><span class="line">        excel1 = xlwt.Workbook()</span><br><span class="line">        <span class="comment">#新建一个sheet,设置单元格格式,cell_overwrite_ok=True防止对一个单元格重复操作引发的错误</span></span><br><span class="line">        sheet1 = excel1.add_sheet(<span class="string">'Job'</span>, cell_overwrite_ok=<span class="literal">True</span>)</span><br><span class="line">        sheet1.write(<span class="number">0</span>, <span class="number">0</span>, <span class="string">'jobid'</span>)</span><br><span class="line">        sheet1.write(<span class="number">0</span>, <span class="number">1</span>, <span class="string">'job_href'</span>)</span><br><span class="line">        sheet1.write(<span class="number">0</span>, <span class="number">2</span>, <span class="string">'job_name'</span>)</span><br><span class="line">        sheet1.write(<span class="number">0</span>, <span class="number">3</span>, <span class="string">'jobwelf'</span>)</span><br><span class="line">        sheet1.write(<span class="number">0</span>, <span class="number">4</span>, <span class="string">'attribute_text'</span>)</span><br><span class="line">        sheet1.write(<span class="number">0</span>, <span class="number">5</span>, <span class="string">'providesalary_text'</span>)</span><br><span class="line">        sheet1.write(<span class="number">0</span>, <span class="number">6</span>, <span class="string">'company_name'</span>)</span><br><span class="line">        sheet1.write(<span class="number">0</span>, <span class="number">7</span>, <span class="string">'companysize_text'</span>)</span><br><span class="line">        sheet1.write(<span class="number">0</span>, <span class="number">8</span>, <span class="string">'companyind_text'</span>)</span><br><span class="line">        sheet1.write(<span class="number">0</span>, <span class="number">9</span>, <span class="string">'company_href'</span>)</span><br><span class="line">        sheet1.write(<span class="number">0</span>, <span class="number">10</span>,<span class="string">'degreefrom'</span>)</span><br><span class="line">        sheet1.write(<span class="number">0</span>, <span class="number">11</span>,<span class="string">'companytype_text'</span>)</span><br><span class="line">        sheet1.write(<span class="number">0</span>, <span class="number">12</span>,<span class="string">'workarea_text'</span>)</span><br><span class="line">        sheet1.write(<span class="number">0</span>, <span class="number">13</span>,<span class="string">'companytype_text'</span>)</span><br><span class="line">        sheet1.write(<span class="number">0</span>, <span class="number">14</span>,<span class="string">'updatedate'</span>)</span><br><span class="line">        sheet1.write(<span class="number">0</span>, <span class="number">15</span>,<span class="string">'job_info'</span>)</span><br><span class="line">        sheet1.write(<span class="number">0</span>, <span class="number">16</span>,<span class="string">'job_work'</span>)</span><br><span class="line">        sheet1.write(<span class="number">0</span>, <span class="number">17</span>,<span class="string">'company_info'</span>)</span><br><span class="line">        <span class="keyword">return</span> sheet1</span><br><span class="line">        <span class="comment">#sheet1.write(number,0,number)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_html</span><span class="params">(self, html)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">            html: [{jobid},{job_href},{job_name},{jobwelf},{attribute_text},{providesalary_text},{company_name},{companysize_text},{companyind_text},{company_href},{degreefrom},{companytype_text},{workarea_text},{updatedate}]</span></span><br><span class="line"><span class="string">            解析一页中html文件，获得如上文件个数数据</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        items = []   <span class="comment">#python 列表的使用</span></span><br><span class="line">        <span class="keyword">for</span> one <span class="keyword">in</span> html:</span><br><span class="line">            item={}</span><br><span class="line">            item[<span class="string">'jobid'</span>]=one[<span class="string">'jobid'</span>]</span><br><span class="line">            item[<span class="string">'job_href'</span>]=one[<span class="string">'job_href'</span>]</span><br><span class="line">            item[<span class="string">'job_name'</span>]=one[<span class="string">'job_name'</span>]</span><br><span class="line">            item[<span class="string">'job_welf'</span>]=one[<span class="string">'jobwelf'</span>]</span><br><span class="line">            <span class="comment">#print(item['job_href'])</span></span><br><span class="line">            <span class="comment"># 根据job介绍url地址 获取 职位要求，工作地点，公司信息</span></span><br><span class="line">            a,b,c=self.get_jobdetail(item[<span class="string">'job_href'</span>])</span><br><span class="line">            item[<span class="string">'job_info'</span>]=a</span><br><span class="line">            item[<span class="string">'job_work'</span>]=b</span><br><span class="line">            item[<span class="string">'company_info'</span>]=c</span><br><span class="line">            item[<span class="string">'attribute_text'</span>]=one[<span class="string">'attribute_text'</span>]</span><br><span class="line">            item[<span class="string">'providesalary_text'</span>]=one[<span class="string">'providesalary_text'</span>]</span><br><span class="line">            item[<span class="string">'company_name'</span>]=one[<span class="string">'company_name'</span>]</span><br><span class="line">            item[<span class="string">'companysize_text'</span>]=one[<span class="string">'companysize_text'</span>]</span><br><span class="line">            item[<span class="string">'companyind_text'</span>]=one[<span class="string">'companyind_text'</span>]</span><br><span class="line">            item[<span class="string">'company_href'</span>]=one[<span class="string">'company_href'</span>]</span><br><span class="line">            item[<span class="string">'degreefrom'</span>]=one[<span class="string">'degreefrom'</span>]</span><br><span class="line">            item[<span class="string">'companytype_text'</span>]=one[<span class="string">'companytype_text'</span>]</span><br><span class="line">            item[<span class="string">'workarea_text'</span>]=one[<span class="string">'workarea_text'</span>]</span><br><span class="line">            item[<span class="string">'updatedate'</span>]=one[<span class="string">'updatedate'</span>]</span><br><span class="line">            items.append(item)</span><br><span class="line">        print(<span class="string">"parse_one_page finished: size="</span>,len(html),<span class="string">"开始存储"</span>)</span><br><span class="line">        df=pd.DataFrame(items)</span><br><span class="line">        df.to_csv(<span class="string">"51job_data.csv"</span>,encoding=<span class="string">"utf_8_sig"</span>,mode = <span class="string">'a'</span>,columns=[<span class="string">'jobid'</span>,<span class="string">'job_href'</span>,<span class="string">'job_name'</span>,<span class="string">'job_welf'</span>,<span class="string">'job_info'</span>,<span class="string">'job_work'</span>,<span class="string">'company_info'</span>,</span><br><span class="line">            <span class="string">'attribute_text'</span>,<span class="string">'providesalary_text'</span>,<span class="string">'company_name'</span>,<span class="string">'companysize_text'</span>,<span class="string">'companyind_text'</span>,<span class="string">'company_href'</span>,</span><br><span class="line">            <span class="string">'degreefrom'</span>,<span class="string">'companytype_text'</span>,<span class="string">'workarea_text'</span>,<span class="string">'updatedate'</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_html</span><span class="params">(self, key,page)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">            根据key，page获取对应的html文件中对应的有效数据</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="comment">#伪装爬取头部，以防止被网站禁止</span></span><br><span class="line">        headers={<span class="string">'Host'</span>:<span class="string">'search.51job.com'</span>,</span><br><span class="line">                <span class="string">'Upgrade-Insecure-Requests'</span>:<span class="string">'1'</span>,</span><br><span class="line">                <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko)\</span></span><br><span class="line"><span class="string">                Chrome/63.0.3239.132 Safari/537.36'</span>}</span><br><span class="line">        headers = {<span class="string">'User-Agent'</span>: UserAgent().random}</span><br><span class="line">        url=<span class="string">'https://search.51job.com/list/050000%252c010000,000000,0100,00,9,99,{},2,{}.html'</span>.format(key,page)</span><br><span class="line">        html = requests.get(url=url, headers=headers).content.decode(<span class="string">'gbk'</span>)</span><br><span class="line">        pattern=re.compile(<span class="string">r'window.__SEARCH_RESULT__ =(.*?)&lt;/script&gt;'</span>)</span><br><span class="line">        data=pattern.findall(html)[<span class="number">0</span>]</span><br><span class="line">        data=json.loads(data)[<span class="string">"engine_search_result"</span>]</span><br><span class="line">        <span class="comment">#print("长度",len(data))</span></span><br><span class="line">        self.parse_html(data)  <span class="comment"># 直接调用解析函数</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_jobdetail</span><span class="params">(self,url)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">            https://jobs.51job.com/beijing-hdq/126533792.html?s=01&amp;t=0</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        headers = {<span class="string">'User-Agent'</span>: UserAgent().random}</span><br><span class="line">        html = requests.get(url=url, headers=headers).content.decode(<span class="string">'gbk'</span>)</span><br><span class="line">        parse_html = etree.HTML(html)</span><br><span class="line">        job_info=parse_html.xpath(<span class="string">'/html/body/div[3]/div[2]/div[3]/div[1]/div/p/text()'</span>)  <span class="comment">#/html/body/div[3]/div[2]/div[3]/div[1]/div/p[1]</span></span><br><span class="line">        job_work=parse_html.xpath(<span class="string">'/html/body/div[3]/div[2]/div[3]/div[2]/div/p/text()'</span>)</span><br><span class="line">        company_info=parse_html.xpath(<span class="string">'/html/body/div[3]/div[2]/div[3]/div[3]/div/text()'</span>)</span><br><span class="line">        <span class="comment">#print(job_info,job_work,company_info)</span></span><br><span class="line">        <span class="keyword">return</span> job_info,job_work,company_info</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取page 总数   #"total_page":"195"</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_total</span><span class="params">(self,key,page=<span class="number">1</span>)</span>:</span></span><br><span class="line">        url=<span class="string">'https://search.51job.com/list/000000,000000,0100,00,9,99,{},2,{}.html'</span>.format(key,page)</span><br><span class="line">        ua = UserAgent()</span><br><span class="line">        html = requests.get(url=url, headers={<span class="string">'User-Agent'</span>: ua.random}).content.decode(<span class="string">'gbk'</span>)</span><br><span class="line">        pattern=re.compile(<span class="string">r'window.__SEARCH_RESULT__ =(.*?)&lt;/script&gt;'</span>)</span><br><span class="line">        data=pattern.findall(html)[<span class="number">0</span>]</span><br><span class="line">        data=json.loads(data)</span><br><span class="line">        total =data[<span class="string">'total_page'</span>]</span><br><span class="line">        <span class="comment">#print("url:",url,"该职位总页数为：",total)</span></span><br><span class="line">        <span class="keyword">return</span> total</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#key = input('请输入职业类型(数据挖掘|喜剧|动作):')</span></span><br><span class="line">        key=[<span class="string">'数据挖掘'</span>,<span class="string">'人工智能'</span>,<span class="string">'语音识别'</span>,<span class="string">'物联网'</span>,<span class="string">'嵌入式'</span>,<span class="string">'java'</span>,<span class="string">'python'</span>,<span class="string">'c++'</span>,<span class="string">'android'</span>,<span class="string">'运维'</span>,<span class="string">'销售'</span>,<span class="string">'制造'</span>]</span><br><span class="line">        <span class="comment">#key=parse.quote(parse.quote(key))</span></span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> key:</span><br><span class="line">            key=parse.quote(parse.quote(item))</span><br><span class="line">            total = self.get_total(key)  <span class="comment"># 获取该类型电影总数量</span></span><br><span class="line">            print(<span class="string">"当前存储记录："</span>,self.i,<span class="string">"\t 即将爬取关键词："</span>,item,<span class="string">"\t 该关键词个数: "</span>,total)</span><br><span class="line">            <span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">1</span>, int(total)):</span><br><span class="line">                self.get_html(key,page)</span><br><span class="line">                time.sleep(random.random()*<span class="number">4</span>)</span><br><span class="line">        <span class="comment">#print('爬取的电影的数量:', self.i)</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    spider = JobSpider()</span><br><span class="line">    spider.main()</span><br><span class="line"></span><br><span class="line"><span class="comment">#https://search.51job.com/list/050000,000000,0100,00,9,99,%25E6%2595%25B0%25E6%258D%25AE%25E6%258C%2596%25E6%258E%2598,2,1.html?lang=c&amp;postchannel=0000&amp;workyear=99&amp;cotype=99&amp;degreefrom=99&amp;jobterm=99&amp;companysize=99&amp;ord_field=0&amp;dibiaoid=0&amp;line=&amp;welfare=</span></span><br><span class="line"><span class="comment">#https://search.51job.com/list/010000,000000,0100,00,9,99,%25E6%2595%25B0%25E6%258D%25AE%25E6%258C%2596%25E6%258E%2598,2,1.html?lang=c&amp;postchannel=0000&amp;workyear=99&amp;cotype=99&amp;degreefrom=99&amp;jobterm=99&amp;companysize=99&amp;ord_field=0&amp;dibiaoid=0&amp;line=&amp;welfare=</span></span><br><span class="line"><span class="comment">#010000-330000: 代表不同的省份，其中000000： 代表全国  ；%25E6%2595%25B0%25E6%258D%25AE%25E6%258C%2596%25E6%258E%2598 对应关键词编码； ,2: 代表页数</span></span><br></pre></td></tr></tbody></table></figure>

<h5 id="任务五：boss直聘爬虫"><a href="#任务五：boss直聘爬虫" class="headerlink" title="任务五：boss直聘爬虫"></a>任务五：boss直聘爬虫</h5><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># common imports</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> pymongo</span><br><span class="line"><span class="keyword">from</span> retrying <span class="keyword">import</span> retry</span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Selector </span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">import</span> xlwt</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---------------------</span></span><br><span class="line"><span class="comment"># 连接到MongoDB</span></span><br><span class="line">MONGO_URL = <span class="string">'localhost'</span></span><br><span class="line">MONGO_DB = <span class="string">'Graduation_project'</span></span><br><span class="line">MONGO_COLLECTION = <span class="string">'shanghai_discovery'</span></span><br><span class="line">client = pymongo.MongoClient(MONGO_URL, port=<span class="number">27017</span>)</span><br><span class="line">db = client[MONGO_DB]</span><br><span class="line"><span class="comment"># 页面获取函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_page</span><span class="params">(page, keyword)</span>:</span></span><br><span class="line">    header = {    </span><br><span class="line">        <span class="string">'user-agent'</span>: <span class="string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36"</span></span><br><span class="line">    }</span><br><span class="line">    print(<span class="string">'正在爬取第'</span>, page, <span class="string">'页'</span>)</span><br><span class="line">    url = <span class="string">'https://www.zhipin.com/c101020100/?query={k}&amp;page={page}&amp;ka=page-{page}'</span>.format(page=page, k=keyword)</span><br><span class="line">    response = requests.get(url, headers=header)</span><br><span class="line">    <span class="keyword">return</span> response.decode(<span class="string">"utf-8"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------</span></span><br><span class="line"><span class="meta">@retry(wait_fixed=8000)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">job_detail</span><span class="params">(link)</span>:</span></span><br><span class="line">    header = {</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '</span></span><br><span class="line">                      <span class="string">'Chrome/69.0.3497.12 Safari/537.36 '</span></span><br><span class="line">    }</span><br><span class="line">    response = requests.get(link, headers=header)</span><br><span class="line">    data = etree.HTML(response.text)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ---检验是否出现验证码</span></span><br><span class="line">    tips = data.xpath(<span class="string">'/html/head/title/text()'</span>)</span><br><span class="line">    tips_title = <span class="string">'BOSS直聘验证码'</span></span><br><span class="line">    <span class="keyword">if</span> tips[<span class="number">0</span>] == tips_title:</span><br><span class="line">        print(<span class="string">'检查是否弹出验证码'</span>)</span><br><span class="line">        <span class="comment"># 弹出验证码则引发IOError来进行循环</span></span><br><span class="line">        <span class="keyword">raise</span> IOError</span><br><span class="line">    <span class="comment"># ----------------------</span></span><br><span class="line">    job_desc = data.xpath(<span class="string">'//*[@id="main"]/div[3]/div/div[2]/div[3]/div[@class="job-sec"][1]/div/text()'</span>)</span><br><span class="line"></span><br><span class="line">    jd = <span class="string">""</span>.join(job_desc).strip()</span><br><span class="line">    <span class="keyword">return</span> jd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_page</span><span class="params">(html, keyword, page)</span>:</span></span><br><span class="line">    <span class="comment"># 观察数据结构可得</span></span><br><span class="line">    data = etree.HTML(html)</span><br><span class="line">    items = data.xpath(<span class="string">'//*[@id="main"]/div/div[2]/ul/li'</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        district = item.xpath(<span class="string">'./div/div[1]/p/text()[1]'</span>)[<span class="number">0</span>]</span><br><span class="line">        job_links = item.xpath(<span class="string">'./div/div[1]/h3/a/@href'</span>)[<span class="number">0</span>]</span><br><span class="line">        job_title = item.xpath(<span class="string">'./div/div[1]/h3/a/div[1]/text()'</span>)[<span class="number">0</span>]</span><br><span class="line">        job_salary = item.xpath(<span class="string">'./div/div[1]/h3/a/span/text()'</span>)[<span class="number">0</span>]</span><br><span class="line">        job_company = item.xpath(<span class="string">'./div/div[2]/div/h3/a/text()'</span>)[<span class="number">0</span>]</span><br><span class="line">        job_experience = item.xpath(<span class="string">'./div/div[1]/p/text()[2]'</span>)[<span class="number">0</span>]</span><br><span class="line">        job_degree = item.xpath(<span class="string">'./div/div[1]/p/text()[3]'</span>)[<span class="number">0</span>]</span><br><span class="line">        fin_status = item.xpath(<span class="string">'./div/div[2]/div/p/text()[2]'</span>)[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            company_scale = item.xpath(<span class="string">'./div/div[2]/div/p/text()[3]'</span>)[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">except</span> Exception:</span><br><span class="line">            company_scale = item.xpath(<span class="string">'./div/div[2]/div/p/text()[2]'</span>)[<span class="number">0</span>]</span><br><span class="line">        job_link = host + job_links</span><br><span class="line">        print(job_link)</span><br><span class="line">        <span class="comment"># 获取职位描述</span></span><br><span class="line">        detail = job_detail(job_link)</span><br><span class="line">        <span class="comment"># ---------------</span></span><br><span class="line">        job = {</span><br><span class="line">            <span class="string">'Keyword'</span>: keyword,</span><br><span class="line">            <span class="string">'地区'</span>: district,</span><br><span class="line">            <span class="string">'职位名称'</span>: job_title,</span><br><span class="line">            <span class="string">'职位薪资'</span>: job_salary,</span><br><span class="line">            <span class="string">'公司名称'</span>: job_company,</span><br><span class="line">            <span class="string">'工作经验'</span>: job_experience,</span><br><span class="line">            <span class="string">'学历要求'</span>: job_degree,</span><br><span class="line">            <span class="string">'公司规模'</span>: company_scale,</span><br><span class="line">            <span class="string">'融资情况'</span>: fin_status,</span><br><span class="line">            <span class="string">'职位描述'</span>: detail,</span><br><span class="line">        }</span><br><span class="line">        print(job)</span><br><span class="line">        save_to_mongo(job)</span><br><span class="line">        time.sleep(random.randint(<span class="number">6</span>, <span class="number">9</span>))</span><br><span class="line">        <span class="comment"># ---------------------------------------</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_mongo</span><span class="params">(data)</span>:</span></span><br><span class="line">    <span class="comment"># 保存到MongoDB中</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> db[MONGO_COLLECTION].insert(data):</span><br><span class="line">            print(<span class="string">'存储到 MongoDB 成功'</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception:</span><br><span class="line">        print(<span class="string">'存储到 MongoDB 失败'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#  header 通过浏览器检查， 网络， 点击对应的name在headers 属性下面；  选择某一个属性后可以通过 鼠标右击copy 复制xpath 路径。</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment">#url = r'https://list.jd.com/list.html?cat=670%2C671%2C2694&amp;ev=exbrand_%E5%BE%AE%E8%BD%AF%EF%BC%88Microsoft%EF%BC%89%5E1107_90246%5E244_116227%5E3753_76033%5E&amp;cid3=2694'</span></span><br><span class="line">    MAX_PAGE = <span class="number">10</span></span><br><span class="line">    host = <span class="string">'https://www.zhipin.com'</span></span><br><span class="line">    keywords = [<span class="string">'数据分析'</span>, <span class="string">'数据挖掘'</span>, <span class="string">'商业分析'</span>, <span class="string">'机器学习'</span>]</span><br><span class="line">    <span class="keyword">for</span> keyword <span class="keyword">in</span> keywords:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, MAX_PAGE + <span class="number">1</span>):</span><br><span class="line">            html = get_page(i, keyword)</span><br><span class="line">            <span class="comment"># ------------ 解析数据 ---------------</span></span><br><span class="line">            parse_page(html, keyword, i)</span><br><span class="line">            print(<span class="string">'-'</span> * <span class="number">100</span>)</span><br><span class="line">            <span class="comment"># -----------------</span></span><br><span class="line">            timewait = random.randint(<span class="number">15</span>, <span class="number">18</span>)</span><br><span class="line">            time.sleep(timewait)</span><br><span class="line">            print(<span class="string">'等待'</span>, timewait, <span class="string">'秒'</span>)</span><br></pre></td></tr></tbody></table></figure>

<h3 id="6-Scraw-框架"><a href="#6-Scraw-框架" class="headerlink" title="6. Scraw 框架"></a>6. Scraw 框架</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">pip install scrapy</span><br><span class="line"><span class="comment"># projectname为项目名称，可自定义</span></span><br><span class="line">scrapy startproject projectname</span><br><span class="line"><span class="comment">#文件结构</span></span><br><span class="line">projectname/</span><br><span class="line">    scrapy.cfg            <span class="comment"># 配置文件</span></span><br><span class="line">    projectname/             <span class="comment"># 爬虫模块文件夹</span></span><br><span class="line">        __init__.py</span><br><span class="line">        items.py          <span class="comment"># items定义文件,设置数据存储模板，用于结构化数据，如：Django的Model</span></span><br><span class="line">        middlewares.py    <span class="comment"># 中间件middlewares文件</span></span><br><span class="line">        pipelines.py      <span class="comment"># 项目管道pipelines文件,数据处理行为，如：一般结构化的数据持久化</span></span><br><span class="line">        settings.py       <span class="comment"># 设置settings文件</span></span><br><span class="line">        spiders/          <span class="comment"># 爬虫文件夹 爬虫目录，如：创建文件，编写爬虫规则</span></span><br><span class="line">            __init__.py</span><br></pre></td></tr></tbody></table></figure>

<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201030094148678.png" alt=""></p>
<ol>
<li>The <a href="https://doc.scrapy.org/en/latest/topics/architecture.html#component-engine" target="_blank" rel="noopener">Engine</a> gets the initial Requests to crawl from the <a href="https://doc.scrapy.org/en/latest/topics/architecture.html#component-spiders" target="_blank" rel="noopener">Spider</a>.</li>
<li>The <a href="https://doc.scrapy.org/en/latest/topics/architecture.html#component-engine" target="_blank" rel="noopener">Engine</a> schedules the Requests in the <a href="https://doc.scrapy.org/en/latest/topics/architecture.html#component-scheduler" target="_blank" rel="noopener">Scheduler</a> and asks for the next Requests to crawl.</li>
<li>The <a href="https://doc.scrapy.org/en/latest/topics/architecture.html#component-scheduler" target="_blank" rel="noopener">Scheduler</a> returns the next Requests to the <a href="https://doc.scrapy.org/en/latest/topics/architecture.html#component-engine" target="_blank" rel="noopener">Engine</a>.</li>
<li>The <a href="https://doc.scrapy.org/en/latest/topics/architecture.html#component-engine" target="_blank" rel="noopener">Engine</a> sends the Requests to the <a href="https://doc.scrapy.org/en/latest/topics/architecture.html#component-downloader" target="_blank" rel="noopener">Downloader</a>, passing through the <a href="https://doc.scrapy.org/en/latest/topics/architecture.html#component-downloader-middleware" target="_blank" rel="noopener">Downloader Middlewares</a> (see <a href="https://doc.scrapy.org/en/latest/topics/downloader-middleware.html#scrapy.downloadermiddlewares.DownloaderMiddleware.process_request" target="_blank" rel="noopener"><code>process_request()</code></a>).</li>
<li>Once the page finishes downloading the <a href="https://doc.scrapy.org/en/latest/topics/architecture.html#component-downloader" target="_blank" rel="noopener">Downloader</a> generates a Response (with that page) and sends it to the Engine, passing through the <a href="https://doc.scrapy.org/en/latest/topics/architecture.html#component-downloader-middleware" target="_blank" rel="noopener">Downloader Middlewares</a> (see <a href="https://doc.scrapy.org/en/latest/topics/downloader-middleware.html#scrapy.downloadermiddlewares.DownloaderMiddleware.process_response" target="_blank" rel="noopener"><code>process_response()</code></a>).</li>
<li>The <a href="https://doc.scrapy.org/en/latest/topics/architecture.html#component-engine" target="_blank" rel="noopener">Engine</a> receives the Response from the <a href="https://doc.scrapy.org/en/latest/topics/architecture.html#component-downloader" target="_blank" rel="noopener">Downloader</a> and sends it to the <a href="https://doc.scrapy.org/en/latest/topics/architecture.html#component-spiders" target="_blank" rel="noopener">Spider</a> for processing, passing through the <a href="https://doc.scrapy.org/en/latest/topics/architecture.html#component-spider-middleware" target="_blank" rel="noopener">Spider Middleware</a> (see <a href="https://doc.scrapy.org/en/latest/topics/spider-middleware.html#scrapy.spidermiddlewares.SpiderMiddleware.process_spider_input" target="_blank" rel="noopener"><code>process_spider_input()</code></a>).</li>
<li>The <a href="https://doc.scrapy.org/en/latest/topics/architecture.html#component-spiders" target="_blank" rel="noopener">Spider</a> processes the Response and returns scraped items and new Requests (to follow) to the <a href="https://doc.scrapy.org/en/latest/topics/architecture.html#component-engine" target="_blank" rel="noopener">Engine</a>, passing through the <a href="https://doc.scrapy.org/en/latest/topics/architecture.html#component-spider-middleware" target="_blank" rel="noopener">Spider Middleware</a> (see <a href="https://doc.scrapy.org/en/latest/topics/spider-middleware.html#scrapy.spidermiddlewares.SpiderMiddleware.process_spider_output" target="_blank" rel="noopener"><code>process_spider_output()</code></a>).</li>
<li>The <a href="https://doc.scrapy.org/en/latest/topics/architecture.html#component-engine" target="_blank" rel="noopener">Engine</a> sends processed items to <a href="https://doc.scrapy.org/en/latest/topics/architecture.html#component-pipelines" target="_blank" rel="noopener">Item Pipelines</a>, then send processed Requests to the <a href="https://doc.scrapy.org/en/latest/topics/architecture.html#component-scheduler" target="_blank" rel="noopener">Scheduler</a> and asks for possible next Requests to crawl.</li>
<li>The process repeats (from step 1) until there are no more requests from the <a href="https://doc.scrapy.org/en/latest/topics/architecture.html#component-scheduler" target="_blank" rel="noopener">Scheduler</a>.</li>
</ol>
<p><strong>【几个特殊的类】</strong></p>
<ul>
<li>scrapy.Spider 类</li>
</ul>
<blockquote>
<p>the place where you define the custom behaviour for crawling and parsing pages for a particular site (or, in some cases, a group of sites).</p>
<ol>
<li><p>You start by generating the initial Requests to crawl the first URLs, and specify a callback function to be called with the response downloaded from those requests.</p>
<p>The first requests to perform are obtained by calling the <a href="https://doc.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.Spider.start_requests" target="_blank" rel="noopener"><code>start_requests()</code></a> method which (by default) generates <a href="https://doc.scrapy.org/en/latest/topics/request-response.html#scrapy.http.Request" target="_blank" rel="noopener"><code>Request</code></a> for the URLs specified in the <a href="https://doc.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.Spider.start_urls" target="_blank" rel="noopener"><code>start_urls</code></a> and the <a href="https://doc.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.Spider.parse" target="_blank" rel="noopener"><code>parse</code></a> method as callback function for the Requests.</p>
</li>
<li><p>In the callback function, you parse the response (web page) and return <a href="https://doc.scrapy.org/en/latest/topics/items.html#topics-items" target="_blank" rel="noopener">item objects</a>, <a href="https://doc.scrapy.org/en/latest/topics/request-response.html#scrapy.http.Request" target="_blank" rel="noopener"><code>Request</code></a> objects, or an iterable of these objects. Those Requests will also contain a callback (maybe the same) and will then be downloaded by Scrapy and then their response handled by the specified callback.</p>
</li>
<li><p>In callback functions, you parse the page contents, typically using <a href="https://doc.scrapy.org/en/latest/topics/selectors.html#topics-selectors" target="_blank" rel="noopener">Selectors</a> (but you can also use BeautifulSoup, lxml or whatever mechanism you prefer) and generate items with the parsed data.</p>
</li>
<li><p>Finally, the items returned from the spider will be typically persisted to a database (in some <a href="https://doc.scrapy.org/en/latest/topics/item-pipeline.html#topics-item-pipeline" target="_blank" rel="noopener">Item Pipeline</a>) or written to a file using <a href="https://doc.scrapy.org/en/latest/topics/feed-exports.html#topics-feed-exports" target="_blank" rel="noopener">Feed exports</a>.</p>
</li>
</ol>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">    Spiders are classes that you define and that Scrapy uses to scrape information from a website (or a group of websites). They must subclass Spider and define the initial requests to make, optionally how to follow links in the pages, and how to parse the downloaded page content to extract data.</span></span><br><span class="line"><span class="string">    start_requests(): must return an iterable of Requests (you can return a list of requests or write a generator function) which the Spider will begin to crawl from. Subsequent requests will be generated successively from these initial requests.</span></span><br><span class="line"><span class="string">    parse(): a method that will be called to handle the response downloaded for each of the requests made. The response parameter is an instance of TextResponse that holds the page content and has further helpful methods to handle it.</span></span><br><span class="line"><span class="string">    The parse() method usually parses the response, extracting the scraped data as dicts and also finding new URLs to follow and creating new requests (Request) from them.</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment"># 注意一定要继承 scrapy.Spider 类</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ToScrapeSpiderXPath</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'toscrape-xpath'</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/'</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> response.xpath(<span class="string">'//div[@class="quote"]'</span>):</span><br><span class="line">            <span class="keyword">yield</span> {</span><br><span class="line">                <span class="string">'text'</span>: quote.xpath(<span class="string">'./span[@class="text"]/text()'</span>).extract_first(),</span><br><span class="line">                <span class="string">'author'</span>: quote.xpath(<span class="string">'.//small[@class="author"]/text()'</span>).extract_first(),</span><br><span class="line">                <span class="string">'tags'</span>: quote.xpath(<span class="string">'.//div[@class="tags"]/a[@class="tag"]/text()'</span>).extract()</span><br><span class="line">            }</span><br><span class="line"></span><br><span class="line">        next_page_url = response.xpath(<span class="string">'//li[@class="next"]/a/@href'</span>).extract_first()</span><br><span class="line">        <span class="keyword">if</span> next_page_url <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(response.urljoin(next_page_url))</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        urls = [</span><br><span class="line">            <span class="string">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class="line">            <span class="string">'http://quotes.toscrape.com/page/2/'</span>,</span><br><span class="line">        ]</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=url, callback=self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        page = response.url.split(<span class="string">"/"</span>)[<span class="number">-2</span>]</span><br><span class="line">        filename = <span class="string">f'quotes-<span class="subst">{page}</span>.html'</span></span><br><span class="line">        <span class="keyword">with</span> open(filename, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.body)</span><br><span class="line">        self.log(<span class="string">f'Saved file <span class="subst">{filename}</span>'</span>)</span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AuthorSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'author'</span></span><br><span class="line"></span><br><span class="line">    start_urls = [<span class="string">'http://quotes.toscrape.com/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        author_page_links = response.css(<span class="string">'.author + a'</span>)</span><br><span class="line">        <span class="keyword">yield</span> <span class="keyword">from</span> response.follow_all(author_page_links, self.parse_author)</span><br><span class="line"></span><br><span class="line">        pagination_links = response.css(<span class="string">'li.next a'</span>)</span><br><span class="line">        <span class="keyword">yield</span> <span class="keyword">from</span> response.follow_all(pagination_links, self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_author</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">extract_with_css</span><span class="params">(query)</span>:</span></span><br><span class="line">            <span class="keyword">return</span> response.css(query).get(default=<span class="string">''</span>).strip()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> {</span><br><span class="line">            <span class="string">'name'</span>: extract_with_css(<span class="string">'h3.author-title::text'</span>),</span><br><span class="line">            <span class="string">'birthdate'</span>: extract_with_css(<span class="string">'.author-born-date::text'</span>),</span><br><span class="line">            <span class="string">'bio'</span>: extract_with_css(<span class="string">'.author-description::text'</span>),</span><br><span class="line">        }</span><br></pre></td></tr></tbody></table></figure>

<ul>
<li><strong>Item</strong></li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#item 类型</span></span><br><span class="line"><span class="keyword">from</span> scrapy.item <span class="keyword">import</span> Item, Field</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomItem</span><span class="params">(Item)</span>:</span></span><br><span class="line">    one_field = Field()</span><br><span class="line">    another_field = Field()</span><br><span class="line"><span class="comment"># database 类型</span></span><br><span class="line"><span class="keyword">from</span> dataclasses <span class="keyword">import</span> dataclass</span><br><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomItem</span>:</span></span><br><span class="line">    one_field: str</span><br><span class="line">    another_field: int</span><br><span class="line"><span class="comment">#class 类型</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Product</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    name = scrapy.Field()</span><br><span class="line">    price = scrapy.Field()</span><br><span class="line">    stock = scrapy.Field()</span><br><span class="line">    tags = scrapy.Field()</span><br><span class="line">    last_updated = scrapy.Field(serializer=str)</span><br></pre></td></tr></tbody></table></figure>

<ul>
<li><strong>Item Loaders</strong></li>
</ul>
<blockquote>
<p>Item Loaders provide a convenient mechanism for populating scraped <a href="https://doc.scrapy.org/en/latest/topics/items.html#topics-items" target="_blank" rel="noopener">items</a>. Even though items can be populated directly, Item Loaders provide a much more convenient API for populating them from a scraping process, by automating some common tasks like parsing the raw extracted data before assigning it.</p>
<p>In other words, <a href="https://doc.scrapy.org/en/latest/topics/items.html#topics-items" target="_blank" rel="noopener">items</a> provide the <em>container</em> of scraped data, while Item Loaders provide the mechanism for <em>populating</em> that container.</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.loader <span class="keyword">import</span> ItemLoader</span><br><span class="line"><span class="keyword">from</span> myproject.items <span class="keyword">import</span> Product</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    l = ItemLoader(item=Product(), response=response)</span><br><span class="line">    l.add_xpath(<span class="string">'name'</span>, <span class="string">'//div[@class="product_name"]'</span>)</span><br><span class="line">    l.add_xpath(<span class="string">'name'</span>, <span class="string">'//div[@class="product_title"]'</span>)</span><br><span class="line">    l.add_xpath(<span class="string">'price'</span>, <span class="string">'//p[@id="price"]'</span>)</span><br><span class="line">    l.add_css(<span class="string">'stock'</span>, <span class="string">'p#stock]'</span>)</span><br><span class="line">    l.add_value(<span class="string">'last_updated'</span>, <span class="string">'today'</span>) <span class="comment"># you can also use literal values</span></span><br><span class="line">    <span class="keyword">return</span> l.load_item()</span><br><span class="line"><span class="comment">#when all data is collected, the ItemLoader.load_item() method is called which actually returns the item populated with the data previously extracted and collected with the add_xpath(), add_css(), and add_value() calls.</span></span><br></pre></td></tr></tbody></table></figure>

<ul>
<li><strong>Pipeline</strong></li>
</ul>
<blockquote>
<p>They receive an item and perform an action over it, also deciding if the item should continue through the pipeline or be dropped and no longer processed.Typical uses of item pipelines are:</p>
<ul>
<li><p>cleansing HTML data</p>
</li>
<li><p>validating scraped data (checking that the items contain certain fields)</p>
</li>
<li><p>checking for duplicates (and dropping them)</p>
</li>
<li><p>storing the scraped item in a database</p>
</li>
</ul>
<p><code>Process_item</code>(<em>self</em>, <em>item</em>, <em>spider</em>)</p>
<p>This method is called for every item pipeline component.</p>
<p>item is an <a href="https://doc.scrapy.org/en/latest/topics/items.html#item-types" target="_blank" rel="noopener">item object</a>, see <a href="https://doc.scrapy.org/en/latest/topics/items.html#supporting-item-types" target="_blank" rel="noopener">Supporting All Item Types</a>.</p>
<p><a href="https://doc.scrapy.org/en/latest/topics/item-pipeline.html#process_item" target="_blank" rel="noopener"><code>process_item()</code></a> must either: return an <a href="https://doc.scrapy.org/en/latest/topics/items.html#item-types" target="_blank" rel="noopener">item object</a>, return a <a href="https://twistedmatrix.com/documents/current/api/twisted.internet.defer.Deferred.html" target="_blank" rel="noopener"><code>Deferred</code></a> or raise a <a href="https://doc.scrapy.org/en/latest/topics/exceptions.html#scrapy.exceptions.DropItem" target="_blank" rel="noopener"><code>DropItem</code></a> exception.</p>
<p>Dropped items are no longer processed by further pipeline components.</p>
<ul>
<li><p>Parameters</p>
<p><strong>item</strong> (<a href="https://doc.scrapy.org/en/latest/topics/items.html#item-types" target="_blank" rel="noopener">item object</a>) – the scraped item<strong>spider</strong> (<a href="https://doc.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.Spider" target="_blank" rel="noopener"><code>Spider</code></a> object) – the spider which scraped the item</p>
</li>
<li><p>Activate the Pipeline</p>
</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = {</span><br><span class="line">    <span class="string">'myproject.pipelines.PricePipeline'</span>: <span class="number">300</span>,</span><br><span class="line">    <span class="string">'myproject.pipelines.JsonWriterPipeline'</span>: <span class="number">800</span>,</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#vaidation</span></span><br><span class="line"><span class="keyword">from</span> itemadapter <span class="keyword">import</span> ItemAdapter</span><br><span class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> DropItem</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PricePipeline</span>:</span></span><br><span class="line">    vat_factor = <span class="number">1.15</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        adapter = ItemAdapter(item)</span><br><span class="line">        <span class="keyword">if</span> adapter.get(<span class="string">'price'</span>):</span><br><span class="line">            <span class="keyword">if</span> adapter.get(<span class="string">'price_excludes_vat'</span>):</span><br><span class="line">                adapter[<span class="string">'price'</span>] = adapter[<span class="string">'price'</span>] * self.vat_factor</span><br><span class="line">            <span class="keyword">return</span> item</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> DropItem(<span class="string">f"Missing price in <span class="subst">{item}</span>"</span>)</span><br><span class="line"><span class="comment">#write to json</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> itemadapter <span class="keyword">import</span> ItemAdapter</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JsonWriterPipeline</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        self.file = open(<span class="string">'items.jl'</span>, <span class="string">'w'</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        self.file.close()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        line = json.dumps(ItemAdapter(item).asdict()) + <span class="string">"\n"</span></span><br><span class="line">        self.file.write(line)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"><span class="comment">#write to Mongodb</span></span><br><span class="line"><span class="keyword">import</span> pymongo</span><br><span class="line"><span class="keyword">from</span> itemadapter <span class="keyword">import</span> ItemAdapter</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MongoPipeline</span>:</span></span><br><span class="line">    collection_name = <span class="string">'scrapy_items'</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, mongo_uri, mongo_db)</span>:</span></span><br><span class="line">        self.mongo_uri = mongo_uri</span><br><span class="line">        self.mongo_db = mongo_db</span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls, crawler)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> cls(</span><br><span class="line">            mongo_uri=crawler.settings.get(<span class="string">'MONGO_URI'</span>),</span><br><span class="line">            mongo_db=crawler.settings.get(<span class="string">'MONGO_DATABASE'</span>, <span class="string">'items'</span>)</span><br><span class="line">        )</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        self.client = pymongo.MongoClient(self.mongo_uri)</span><br><span class="line">        self.db = self.client[self.mongo_db]</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        self.client.close()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        self.db[self.collection_name].insert_one(ItemAdapter(item).asdict())</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"><span class="comment">#duplicate</span></span><br><span class="line"><span class="keyword">from</span> itemadapter <span class="keyword">import</span> ItemAdapter</span><br><span class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> DropItem</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DuplicatesPipeline</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.ids_seen = set()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        adapter = ItemAdapter(item)</span><br><span class="line">        <span class="keyword">if</span> adapter[<span class="string">'id'</span>] <span class="keyword">in</span> self.ids_seen:</span><br><span class="line">            <span class="keyword">raise</span> DropItem(<span class="string">f"Duplicate item found: <span class="subst">{item!r}</span>"</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.ids_seen.add(adapter[<span class="string">'id'</span>])</span><br><span class="line">            <span class="keyword">return</span> item</span><br></pre></td></tr></tbody></table></figure>

<h3 id="7-数据可视化"><a href="#7-数据可视化" class="headerlink" title="7. 数据可视化"></a>7. 数据可视化</h3><p>使用pyechart </p>
<ul>
<li><a href="https://www.cnblogs.com/-wenli/p/10646261.html" target="_blank" rel="noopener">https://www.cnblogs.com/-wenli/p/10646261.html</a></li>
<li><a href="https://juejin.im/post/6844903861245722631" target="_blank" rel="noopener">https://juejin.im/post/6844903861245722631</a></li>
</ul>
<p>使用BI软件</p>
<p>使用Original2018 软件</p>
<h3 id="学习链接"><a href="#学习链接" class="headerlink" title=". 学习链接"></a>. 学习链接</h3><ul>
<li><a href="https://www.k0rz3n.com/2019/03/05/%E7%88%AC%E8%99%AB%E7%88%AC%E5%8F%96%E5%8A%A8%E6%80%81%E7%BD%91%E9%A1%B5%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F%E7%AE%80%E4%BB%8B/" target="_blank" rel="noopener">https://www.k0rz3n.com/2019/03/05/%E7%88%AC%E8%99%AB%E7%88%AC%E5%8F%96%E5%8A%A8%E6%80%81%E7%BD%91%E9%A1%B5%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F%E7%AE%80%E4%BB%8B/</a></li>
<li><a href="https://www.cnblogs.com/LXP-Never/p/11374795.html" target="_blank" rel="noopener">https://www.cnblogs.com/LXP-Never/p/11374795.html</a></li>
<li><a href="https://www.runoob.com/python3/python3-json.html" target="_blank" rel="noopener">https://www.runoob.com/python3/python3-json.html</a></li>
<li>crawl:<a href="https://doc.scrapy.org/en/latest/topics/architecture.html" target="_blank" rel="noopener">https://doc.scrapy.org/en/latest/topics/architecture.html</a></li>
<li>后续学习：<ul>
<li>crawl 框架</li>
<li>分布式反爬虫机制</li>
<li>crawllab 平台： <a href="https://github.com/crawlab-team/crawlab；" target="_blank" rel="noopener">https://github.com/crawlab-team/crawlab；</a> <a href="https://demo-pro.crawlab.cn/#/spiders/5f9ae48321225400243ed393" target="_blank" rel="noopener">https://demo-pro.crawlab.cn/#/spiders/5f9ae48321225400243ed393</a></li>
</ul>
</li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://liudongdong1.github.io" rel="external nofollow noreferrer">liudongdong1</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://liudongdong1.github.io/2020/11/29/nlp/crawl-record/">https://liudongdong1.github.io/2020/11/29/nlp/crawl-record/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint polocy. If reproduced, please indicate source
                    <a href="https://liudongdong1.github.io" target="_blank">liudongdong1</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/crawl/">
                                    <span class="chip bg-color">crawl</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="qq,qzone,wechat,weibo,douban" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/2020/11/30/yu-yan-kuang-jia/qian-duan/typescript/">
                    <div class="card-image">
                        
                        <img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201130202056402.png" class="responsive-img" alt="Typescript">
                        
                        <span class="card-title">Typescript</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
 TypeScript is a typed superset of JavaScript that compiles to plain JavaScript. TypeScript is pure object oriented wit
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2020-11-30
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E8%A7%86%E8%A7%89AI/" class="post-category">
                                    视觉AI
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Network/">
                        <span class="chip bg-color">Network</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2020/11/28/sheng-huo/photography/photutorial/">
                    <div class="card-image">
                        
                        <img src="https://gitee.com/github-25970295/blogImage/raw/master/img/20210501133627.png" class="responsive-img" alt="phoTutorial">
                        
                        <span class="card-title">phoTutorial</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            1. 清晨、中午、傍晚、夜晚

早晨

1.不适合做太风格化的调整，这是首要重点。
2.调整基础影调，加强质感。
3.色彩调整无需对色相作出太大改动。



中午：

1.强光下亮部容易出现过曝，后期需降低高光还原细节。
2.光影效果平淡，
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-11-28
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E7%94%9F%E6%B4%BB/" class="post-category">
                                    生活
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Photography/">
                        <span class="chip bg-color">Photography</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <!-- <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="463294659"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2019</span>
            <a href="https://liudongdong1.github.io" target="_blank">liudongdong</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">1206.4k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/liudongdong1/" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:3463264078@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>














    <a href="https://blog.csdn.net/liudongdong19/" class="tooltipped" target="_blank" data-tooltip="关注我的CSDN: https://blog.csdn.net/liudongdong19/" data-position="top" data-delay="50">
        <i class="fab fa-csdn">C</i>
    </a>





</div>
    </div>
</footer>

<div class="progress-bar"></div>
 -->

    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/search.xml", 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script type="text/javascript" src="/js/CFS.Snow.min.js"></script>
    <!-- 点击爆灯效果 -->
    <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas> 
    <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script> 
    <script type="text/javascript" src="/js/fireworks.js"></script>
    <!--动态线条背景-->
    <script type="text/javascript"
        color="122 103 238" opacity='0.7' zIndex="-2" count="200" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js">
    </script>
    <!-- 天气 -->
    <!-- weather -->
    <!-- weather -->
    <script type="text/javascript">
         WIDGET = {FID: 'knAMQaFanP'}
    </script>
    <script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"></script>
    <script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"></script>
    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    

    
    
    <script type="text/javascript" size="150" alpha='0.6'
        zIndex="-1" src="/libs/background/ribbon-refresh.min.js" async="async"></script>
    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    
    <!-- {% include '_custom/custom.swig' %} -->

</body>

</html>
