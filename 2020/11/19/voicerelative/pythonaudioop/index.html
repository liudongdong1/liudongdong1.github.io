<!DOCTYPE HTML>
<html lang="en">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="pythoAudioOp, AIOT,Space&amp;Temporal Sequence Analysis,SpringBoot,liudongdong1,cloud">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>pythoAudioOp | DaybyDay</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="DaybyDay" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">DaybyDay</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>Tags</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">

      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/about">
          
          <i class="fas fa-user-circle" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>about</span>
        </a>
      </li>
      
      <li>
        <a href="/resume">
          
          <i class="fa fa-user-secret" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>resume</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>Friends</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/gallery" class="waves-effect waves-light">
      
      <i class="fas fa-camera" style="zoom: 0.6;"></i>
      
      <span>Galleries</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">DaybyDay</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			Tags
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-user-circle"></i>
			
			About
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/about " style="margin-left:75px">
				  
				   <i class="fa fas fa-user-circle" style="position: absolute;left:50px" ></i>
			      
		          <span>about</span>
                  </a>
                </li>
              
                <li>

                  <a href="/resume " style="margin-left:75px">
				  
				   <i class="fa fa fa-user-secret" style="position: absolute;left:50px" ></i>
			      
		          <span>resume</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			Friends
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/gallery" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-camera"></i>
			
			Galleries
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/liudongdong1" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/liudongdong1" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://gitee.com/github-25970295/blogImage/raw/master/img/illuminated-bridge-and-city-at-night.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">pythoAudioOp</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    .toc-fixed .toc-link::before{
        position: fixed!important;/*当toc的位置改为fixed时，.toc-link::before也要改为fixed*/
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Voice/">
                                <span class="chip bg-color">Voice</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Voice/" class="post-category">
                                Voice
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2020-11-19
                </div>
                

                <!-- 
                    <i class="fa fa-pencil"></i> Author: liudongdong1
                  -->

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>Update Date:&nbsp;&nbsp;
                    2021-11-26
                </div>
                

                <!-- 
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>Word Count:&nbsp;&nbsp;
                    8.6k
                </div>
                 -->

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>Read Times:&nbsp;&nbsp;
                    35 Min
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>Read Count:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>语音信号有三个重要的参数：声道数、取样频率和量化位数。</p>
<ul>
<li><strong>声道数</strong>：可以是单声道或者是双声道</li>
<li><strong>采样频率</strong>：一秒内对声音信号的采集次数，44100Hz采样频率意味着每秒钟信号被分解成44100份。换句话说，每隔144100秒就会存储一次，如果采样率高，那么媒体播放音频时会感觉信号是连续的。</li>
<li><strong>量化位数</strong>：用多少bit表达一次采样所采集的数据，通常有8bit、16bit、24bit和32bit等几种</li>
</ul>
</blockquote>
<h3 id="1-文件读写"><a href="#1-文件读写" class="headerlink" title="1. 文件读写"></a>1. 文件读写</h3><h3 id="2-信号处理"><a href="#2-信号处理" class="headerlink" title="2. 信号处理"></a>2. 信号处理</h3><blockquote>
<p><code>语音信号是一个非平稳的时变信号</code>，但<code>语音信号是由声门的激励脉冲通过声道形成</code>的，而<code>声道(人的口腔、鼻腔)的肌肉运动是缓慢</code>的，所以<code>“短时间”(10~30ms)</code>内可以认为语音信号是<code>平稳时不变</code>的。由此构成了语音信号的<code>“短时分析技术”</code>。在短时分析中，将语音信号分为一段一段的语音帧，每一帧一般取10~30ms，我们的研究就建立在每一帧的语音特征分析上。提取的不同的语音特征参数对应着不同的语音信号分析方法：<code>时域分析、频域分析、倒谱域分析</code>…由于语音信号最重要的感知特性反映在<code>功率谱</code>上，而相位变化只起到很小的作用，所有语音频域分析更加重要。</p>
</blockquote>
<h4 id="2-0-预加重"><a href="#2-0-预加重" class="headerlink" title="2.0. 预加重"></a>2.0. 预加重</h4><blockquote>
<p>所谓预加重是指在信号发送之<code>前</code>，<code>先对模拟信号的高频部分进行适当的提升</code>，在接收到信号之<code>后</code>，进行<code>逆处理，即去加重</code>。预加重和去加重技术可以<code>使信号在传输中高频损耗的影响降低</code>，也可以是噪声的频谱发生变化，这是模拟降噪的原理。声道的终端是口和唇，<code>口唇辐射对低频影响比较小，但是对高频段影响比较大</code>，欲加重技术技术为了提升高频分辨率，欲加重的传递函数是$H(z)=1−aZ^{-1}$。</p>
</blockquote>
<h4 id="2-1-信号窗"><a href="#2-1-信号窗" class="headerlink" title="2.1. 信号窗"></a>2.1. 信号窗</h4><blockquote>
<p>通常对信号截断、分帧需要加窗，因为截断都有频域能量泄露，而窗函数可以减少截断带来的影响。<code>时域加窗会导致主瓣变宽而旁瓣得到明显降低，并且最大幅值也有所降低。</code></p>
<ul>
<li>傅里叶变换后主要的特征有频率、幅值和相位，加窗对相位的影响是线性的，所以一般不用考虑。</li>
<li>加窗对<code>频率和幅值的影响是关联的</code>，对于时域的单个频率信号，加窗之后的频谱就是将窗谱的谱峰位置平移到信号的频率处，然后进行垂直缩放。说明加窗的影响取决于窗的功率谱，也就容易理解为什么总常看到对窗特征主瓣、旁瓣等的描述。</li>
<li><code>主瓣变宽</code>就可能与附近的频率的谱相叠加，意味着<code>更难找到叠加后功率谱中最大的频率点</code>，即降低了频率分辨率，较难定位中心频率。<code>旁瓣多</code>意味着信号<code>功率泄露多，主瓣被削弱了，即幅值精度降低了</code>。</li>
</ul>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121163030377.png" alt=""></p>
<blockquote>
<p>通常时域上加窗更为普遍，时域截断效应带来了频谱的泄漏，窗函数是为了减小这个截断效应，被设计成一组加权系数w(n)。域加窗在时域上表现的是点乘，因此在频域上则表现为卷积。卷积可以被看成是一个平滑的过程，相当于一组具有特定函数形状的滤波器，因此，原始信号中在某一频率点上的能量会结合滤波器的形状表现出来，从而减小泄漏。</p>
<ul>
<li>对线性调频信号(LFM)的时域加窗会导致主瓣变宽而旁瓣得到明显降低，并且最大幅值也有所降低</li>
</ul>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211102110346914.png" alt="时域加窗"></p>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211102110541564.png" alt="频率加窗"></p>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121162806166.png" alt=""></p>
<blockquote>
<p>如果仅要求<code>精确读出主瓣频率，而不考虑幅值精度</code>，则可选用主瓣宽度比较窄而便于分辨的矩形窗，例如测量物体的自振频率等；如果分析窄带信号，且有较强的干扰噪声，则应选用旁瓣幅度小的窗函数，如汉宁窗、三角窗等；对于<code>随时间按指数衰减的函数</code>，可采用<code>指数窗</code>来提高信噪比。</p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121162342722.png" alt=""></p>
<h4 id="2-2-信号分帧"><a href="#2-2-信号分帧" class="headerlink" title="2.2. 信号分帧"></a>2.2. 信号分帧</h4><blockquote>
<p>在分帧中，相邻两帧之间会有一部分重叠，帧长(wlen) = 重叠(overlap)+帧移(inc)，如果相邻两帧之间不重叠，那么由于窗函数的形状，截取到的语音帧边缘会出现损失，所以要设置重叠部分。inc为帧移，表示后一帧第前一帧的偏移量，fs表示采样率，fn表示一段语音信号的分帧数。</p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121163426097.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121163512186.png" alt=""></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#没有加窗的语音分帧</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> wave</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment">#import math</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">enframe</span><span class="params">(signal, nw, inc)</span>:</span></span><br><span class="line">    <span class="string">'''将音频信号转化为帧。</span></span><br><span class="line"><span class="string">    参数含义：</span></span><br><span class="line"><span class="string">    signal:原始音频型号</span></span><br><span class="line"><span class="string">    nw:每一帧的长度(这里指采样点的长度，即采样频率乘以时间间隔)</span></span><br><span class="line"><span class="string">    inc:相邻帧的间隔（同上定义）</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    signal_length=len(signal) <span class="comment">#信号总长度</span></span><br><span class="line">    <span class="keyword">if</span> signal_length&lt;=nw: <span class="comment">#若信号长度小于一个帧的长度，则帧数定义为1</span></span><br><span class="line">        nf=<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>: <span class="comment">#否则，计算帧的总长度</span></span><br><span class="line">        nf=int(np.ceil((<span class="number">1.0</span>*signal_length-nw+inc)/inc))</span><br><span class="line">    pad_length=int((nf<span class="number">-1</span>)*inc+nw) <span class="comment">#所有帧加起来总的铺平后的长度</span></span><br><span class="line">    zeros=np.zeros((pad_length-signal_length,)) <span class="comment">#不够的长度使用0填补，类似于FFT中的扩充数组操作</span></span><br><span class="line">    pad_signal=np.concatenate((signal,zeros)) <span class="comment">#填补后的信号记为pad_signal</span></span><br><span class="line">    indices=np.tile(np.arange(<span class="number">0</span>,nw),(nf,<span class="number">1</span>))+np.tile(np.arange(<span class="number">0</span>,nf*inc,inc),(nw,<span class="number">1</span>)).T  <span class="comment">#相当于对所有帧的时间点进行抽取，得到nf*nw长度的矩阵</span></span><br><span class="line">    indices=np.array(indices,dtype=np.int32) <span class="comment">#将indices转化为矩阵</span></span><br><span class="line">    frames=pad_signal[indices] <span class="comment">#得到帧信号</span></span><br><span class="line"><span class="comment">#    win=np.tile(winfunc(nw),(nf,1))  #window窗函数，这里默认取1</span></span><br><span class="line"><span class="comment">#    return frames*win   #返回帧信号矩阵</span></span><br><span class="line">    <span class="keyword">return</span> frames</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">wavread</span><span class="params">(filename)</span>:</span></span><br><span class="line">    f = wave.open(filename,<span class="string">'rb'</span>)</span><br><span class="line">    params = f.getparams()</span><br><span class="line">    nchannels, sampwidth, framerate, nframes = params[:<span class="number">4</span>]</span><br><span class="line">    strData = f.readframes(nframes)<span class="comment">#读取音频，字符串格式</span></span><br><span class="line">    waveData = np.fromstring(strData,dtype=np.int16)<span class="comment">#将字符串转化为int</span></span><br><span class="line">    f.close()</span><br><span class="line">    waveData = waveData*<span class="number">1.0</span>/(max(abs(waveData)))<span class="comment">#wave幅值归一化</span></span><br><span class="line">    waveData = np.reshape(waveData,[nframes,nchannels]).T</span><br><span class="line">    <span class="keyword">return</span> waveData</span><br><span class="line"> </span><br><span class="line">filepath = <span class="string">"./data/"</span> <span class="comment">#添加路径</span></span><br><span class="line">dirname= os.listdir(filepath) <span class="comment">#得到文件夹下的所有文件名称 </span></span><br><span class="line">filename = filepath+dirname[<span class="number">0</span>]</span><br><span class="line">data = wavread(filename)</span><br><span class="line">nw = <span class="number">512</span></span><br><span class="line">inc = <span class="number">128</span></span><br><span class="line">Frame = enframe(data[<span class="number">0</span>], nw, inc) </span><br><span class="line"><span class="comment">#加窗的语音分帧</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">enframe</span><span class="params">(signal, nw, inc, winfunc)</span>:</span></span><br><span class="line">    <span class="string">'''将音频信号转化为帧。</span></span><br><span class="line"><span class="string">    参数含义：</span></span><br><span class="line"><span class="string">    signal:原始音频型号</span></span><br><span class="line"><span class="string">    nw:每一帧的长度(这里指采样点的长度，即采样频率乘以时间间隔)</span></span><br><span class="line"><span class="string">    inc:相邻帧的间隔（同上定义）</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    signal_length=len(signal) <span class="comment">#信号总长度</span></span><br><span class="line">    <span class="keyword">if</span> signal_length&lt;=nw: <span class="comment">#若信号长度小于一个帧的长度，则帧数定义为1</span></span><br><span class="line">        nf=<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>: <span class="comment">#否则，计算帧的总长度</span></span><br><span class="line">        nf=int(np.ceil((<span class="number">1.0</span>*signal_length-nw+inc)/inc))</span><br><span class="line">    pad_length=int((nf<span class="number">-1</span>)*inc+nw) <span class="comment">#所有帧加起来总的铺平后的长度</span></span><br><span class="line">    zeros=np.zeros((pad_length-signal_length,)) <span class="comment">#不够的长度使用0填补，类似于FFT中的扩充数组操作</span></span><br><span class="line">    pad_signal=np.concatenate((signal,zeros)) <span class="comment">#填补后的信号记为pad_signal</span></span><br><span class="line">    indices=np.tile(np.arange(<span class="number">0</span>,nw),(nf,<span class="number">1</span>))+np.tile(np.arange(<span class="number">0</span>,nf*inc,inc),(nw,<span class="number">1</span>)).T  <span class="comment">#相当于对所有帧的时间点进行抽取，得到nf*nw长度的矩阵</span></span><br><span class="line">    indices=np.array(indices,dtype=np.int32) <span class="comment">#将indices转化为矩阵</span></span><br><span class="line">    frames=pad_signal[indices] <span class="comment">#得到帧信号</span></span><br><span class="line">    win=np.tile(winfunc,(nf,<span class="number">1</span>))  <span class="comment">#window窗函数，这里默认取1</span></span><br><span class="line">    <span class="keyword">return</span> frames*win   <span class="comment">#返回帧信号矩阵</span></span><br></pre></td></tr></tbody></table></figure>

<h4 id="2-3-短时时域处理"><a href="#2-3-短时时域处理" class="headerlink" title="2.3.  短时时域处理"></a>2.3.  短时时域处理</h4><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121184731295.png" alt=""></p>
<ul>
<li><code>短时能量和短时平均幅度</code><ul>
<li><code>区分浊音和清音段</code>，因为浊音的短时能量E(i)比清音大很多；</li>
<li><code>区分声母和韵母的分界</code>和<code>无话段和有话段的分界</code></li>
</ul>
</li>
<li><code>短时平均过零率</code><ul>
<li>可以从<code>背景噪声中找出语音信号</code></li>
<li>可以用于判断<code>寂静无话段与有话段的起点和终止位置</code>。</li>
<li>在<code>背景噪声较小的时候，用平均能量识别较为有效</code>，在<code>背景噪声较大</code>的时候，用短时平均过零率识别较为有效。</li>
</ul>
</li>
<li>短时自相关函数: <ul>
<li>主要应用于<code>端点检测</code>和<code>基音的提取</code>，在韵母基因频率整数倍处将出现峰值特性，通常根据除R(0)外的第一峰值来估计基音，而在声母的短时自相关函数中看不到明显的峰值。</li>
</ul>
</li>
<li>短时平均幅度差函数:<ul>
<li>用于检测基音周期，而且在计算上比短时自相关函数更加简单。</li>
</ul>
</li>
</ul>
<h5 id="2-3-0-傅里叶变换"><a href="#2-3-0-傅里叶变换" class="headerlink" title="2.3.0.  傅里叶变换"></a>2.3.0.  傅里叶变换</h5><ul>
<li>frequency bin: 频点采用相等的间隔，这间隔通常frequency bin（频率窗口）或FFT bin表示。</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> numpy.fft <span class="keyword">as</span> fft</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">'font.sans-serif'</span>]=[<span class="string">'SimHei'</span>] <span class="comment">#用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">'axes.unicode_minus'</span>]=<span class="literal">False</span> <span class="comment">#用来正常显示符号</span></span><br><span class="line"></span><br><span class="line">Fs = <span class="number">1000</span>;            <span class="comment"># 采样频率</span></span><br><span class="line">T = <span class="number">1</span>/Fs;             <span class="comment"># 采样周期</span></span><br><span class="line">L = <span class="number">1000</span>;             <span class="comment"># 信号长度</span></span><br><span class="line">t = [i*T <span class="keyword">for</span> i <span class="keyword">in</span> range(L)]</span><br><span class="line">t = np.array(t)</span><br><span class="line"></span><br><span class="line">S = <span class="number">0.2</span>+<span class="number">0.7</span>*np.cos(<span class="number">2</span>*np.pi*<span class="number">50</span>*t+<span class="number">20</span>/<span class="number">180</span>*np.pi) + <span class="number">0.2</span>*np.cos(<span class="number">2</span>*np.pi*<span class="number">100</span>*t+<span class="number">70</span>/<span class="number">180</span>*np.pi) ;</span><br><span class="line"><span class="comment">#经过快速傅里叶变换得到一个复数数组，复数的模代表的是振幅，复数的辐角代表初相位</span></span><br><span class="line">complex_array = fft.fft(S)</span><br><span class="line">print(complex_array.shape)  <span class="comment"># (1000,) </span></span><br><span class="line">print(complex_array.dtype)  <span class="comment"># complex128 </span></span><br><span class="line">print(complex_array[<span class="number">1</span>])  <span class="comment"># (-2.360174309695419e-14+2.3825789764340993e-13j)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#################################</span></span><br><span class="line">plt.subplot(<span class="number">311</span>)</span><br><span class="line">plt.grid(linestyle=<span class="string">':'</span>)</span><br><span class="line">plt.plot(<span class="number">1000</span>*t[<span class="number">1</span>:<span class="number">51</span>], S[<span class="number">1</span>:<span class="number">51</span>], label=<span class="string">'S'</span>)  <span class="comment"># y是1000个相加后的正弦序列</span></span><br><span class="line">plt.xlabel(<span class="string">"t（毫秒）"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"S(t)幅值"</span>)</span><br><span class="line">plt.title(<span class="string">"叠加信号图"</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment">###################################</span></span><br><span class="line">plt.subplot(<span class="number">312</span>)</span><br><span class="line"><span class="comment">#复数数组 经过逆向傅里叶变换得到合成的函数值数组</span></span><br><span class="line">S_ifft = fft.ifft(complex_array)</span><br><span class="line"><span class="comment"># S_new是ifft变换后的序列</span></span><br><span class="line">plt.plot(<span class="number">1000</span>*t[<span class="number">1</span>:<span class="number">51</span>], S_ifft[<span class="number">1</span>:<span class="number">51</span>], label=<span class="string">'S_ifft'</span>, color=<span class="string">'orangered'</span>)</span><br><span class="line">plt.xlabel(<span class="string">"t（毫秒）"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"S_ifft(t)幅值"</span>)</span><br><span class="line">plt.title(<span class="string">"ifft变换图"</span>)</span><br><span class="line">plt.grid(linestyle=<span class="string">':'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment">###################################</span></span><br><span class="line"><span class="comment"># 得到分解波的频率序列</span></span><br><span class="line">freqs = fft.fftfreq(t.size, t[<span class="number">1</span>] - t[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 复数的模为信号的振幅（能量大小）</span></span><br><span class="line">pows = np.abs(complex_array)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">313</span>)</span><br><span class="line">plt.title(<span class="string">'FFT变换,频谱图'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Frequency 频率'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Power 功率'</span>)</span><br><span class="line">plt.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line">plt.grid(linestyle=<span class="string">':'</span>)</span><br><span class="line">plt.plot(freqs[freqs &gt; <span class="number">0</span>], pows[freqs &gt; <span class="number">0</span>], c=<span class="string">'orangered'</span>, label=<span class="string">'Frequency'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>

<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122000001935.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211102112057675.png" alt=""></p>
<blockquote>
<p>mel频率倒谱系数(MFCC)，线性预测系数(LPC)，线性预测倒谱系数(LPCC)，线谱频率(LSF)，离散小波变换(DWT)，感知线性预测(PLP)</p>
</blockquote>
<h5 id="2-3-1-短时傅里叶变换"><a href="#2-3-1-短时傅里叶变换" class="headerlink" title="2.3.1. 短时傅里叶变换"></a>2.3.1. 短时傅里叶变换</h5><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#绘制语音信号的频谱图</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.io <span class="keyword">import</span> wavfile</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">sampling_freq, audio = wavfile.read(<span class="string">r"C:\Windows\media\Windows Background.wav"</span>)   <span class="comment"># 读取文件</span></span><br><span class="line"></span><br><span class="line">audio = audio / np.max(audio)   <span class="comment"># 归一化，标准化</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 应用傅里叶变换</span></span><br><span class="line">fft_signal = np.fft.fft(audio)</span><br><span class="line">print(fft_signal)</span><br><span class="line"><span class="comment"># [-0.04022912+0.j         -0.04068997-0.00052721j -0.03933007-0.00448355j</span></span><br><span class="line"><span class="comment">#  ... -0.03947908+0.00298096j -0.03933007+0.00448355j -0.04068997+0.00052721j]</span></span><br><span class="line"></span><br><span class="line">fft_signal = abs(fft_signal)</span><br><span class="line">print(fft_signal)</span><br><span class="line"><span class="comment"># [0.04022912 0.04069339 0.0395848  ... 0.08001755 0.09203427 0.12889393]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立时间轴</span></span><br><span class="line">Freq = np.arange(<span class="number">0</span>, len(fft_signal))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制语音信号的</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(Freq, fft_signal, color=<span class="string">'blue'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Freq (in kHz)'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Amplitude'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">wav_to_frame</span><span class="params">(wave_data, win_len, win_shift)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    进行分帧操作</span></span><br><span class="line"><span class="string">    :param wave_data: 原始的数据</span></span><br><span class="line"><span class="string">    :param win_len: 滑动窗长</span></span><br><span class="line"><span class="string">    :param win_shift: 滑动间隔</span></span><br><span class="line"><span class="string">    :return: 分帧之后的结果，输出一个帧矩阵</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    num_frames = (len(wave_data) - win_len) // win_shift + <span class="number">1</span></span><br><span class="line">    results = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_frames):</span><br><span class="line">        results.append(wave_data[i*win_shift:i*win_shift + win_len])</span><br><span class="line">    <span class="keyword">return</span> np.array(results)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">spectrum_power</span><span class="params">(frames, NFFT)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    计算每一帧傅立叶变换以后的功率谱</span></span><br><span class="line"><span class="string">    参数说明：</span></span><br><span class="line"><span class="string">    frames:audio2frame函数计算出来的帧矩阵</span></span><br><span class="line"><span class="string">    NFFT:FFT的大小</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 功率谱等于每一点的幅度平方/NFFT</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span>/NFFT * np.square(spectrum_magnitude(frames, NFFT))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">spectrum_magnitude</span><span class="params">(frames, NFFT)</span>:</span></span><br><span class="line">    <span class="string">"""计算每一帧经过FFT变幻以后的频谱的幅度，若frames的大小为N*L,则返回矩阵的大小为N*NFFT</span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">    frames:即audio2frame函数中的返回值矩阵，帧矩阵</span></span><br><span class="line"><span class="string">    NFFT:FFT变换的数组大小,如果帧长度小于NFFT，则帧的其余部分用0填充铺满</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    complex_spectrum = np.fft.rfft(frames, NFFT)    <span class="comment"># 对frames进行FFT变换</span></span><br><span class="line">    <span class="comment"># 返回频谱的幅度值</span></span><br><span class="line">    <span class="keyword">return</span> np.absolute(complex_spectrum)</span><br></pre></td></tr></tbody></table></figure>

<h5 id="2-3-2-梅尔频率倒谱系数"><a href="#2-3-2-梅尔频率倒谱系数" class="headerlink" title="2.3.2 梅尔频率倒谱系数"></a>2.3.2 梅尔频率倒谱系数</h5><blockquote>
<p><strong>梅尔频率倒谱系数</strong>(MFCC)，MFCC首先计算信号的功率谱，然后用滤波器组和离散余弦变换的组合来提取特征。人耳在接收声音时呈现非线性状态，对高频的更不敏感，因此<code>Mel刻度在低频区分辨度较高</code>，在高频区分辨度较低，<code>与频率之间的换算</code>关系。滤波器组中的每个滤波器都是三角形的，<code>中心频率为f(m)</code> ，中心频率处的响应为1，并向0线性减小，直到达到两个相邻滤波器的中心频率，其中响应为0，<code>各f(m)之间的间隔随着m值的增大而增宽</code>。</p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121215912320.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121221407705.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121221423367.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121215252948.png" alt=""></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">import</span> scipy.io.wavfile</span><br><span class="line"><span class="keyword">from</span> scipy.fftpack <span class="keyword">import</span> dct</span><br><span class="line"></span><br><span class="line">sample_rate, signal = scipy.io.wavfile.read(<span class="string">'OSR_us_000_0010_8k.wav'</span>) </span><br><span class="line">signal = signal[<span class="number">0</span>:int(<span class="number">3.5</span> * sample_rate)]  <span class="comment"># 我们只取前3.5s</span></span><br><span class="line"><span class="comment"># 欲加重处理</span></span><br><span class="line">emphasized_signal = numpy.append(signal[<span class="number">0</span>], signal[<span class="number">1</span>:] - pre_emphasis * signal[:<span class="number">-1</span>])</span><br><span class="line"><span class="comment"># 分帧</span></span><br><span class="line">frame_length, frame_step = frame_size * sample_rate, frame_stride * sample_rate  <span class="comment"># 从秒转换为采样点</span></span><br><span class="line">signal_length = len(emphasized_signal)</span><br><span class="line">frame_length = int(round(frame_length))</span><br><span class="line">frame_step = int(round(frame_step))</span><br><span class="line"><span class="comment"># 确保我们至少有1帧</span></span><br><span class="line">num_frames = int(numpy.ceil(float(numpy.abs(signal_length - frame_length)) / frame_step))  </span><br><span class="line"></span><br><span class="line">pad_signal_length = num_frames * frame_step + frame_length</span><br><span class="line">z = numpy.zeros((pad_signal_length - signal_length))</span><br><span class="line"><span class="comment"># 填充信号，确保所有帧的采样数相等，而不从原始信号中截断任何采样</span></span><br><span class="line">pad_signal = numpy.append(emphasized_signal, z) </span><br><span class="line"></span><br><span class="line">indices = numpy.tile(numpy.arange(<span class="number">0</span>, frame_length), (num_frames, <span class="number">1</span>)) + numpy.tile(numpy.arange(<span class="number">0</span>, num_frames * frame_step, frame_step), (frame_length, <span class="number">1</span>)).T</span><br><span class="line">frames = pad_signal[indices.astype(numpy.int32, copy=<span class="literal">False</span>)]</span><br><span class="line"><span class="comment"># 加窗处理</span></span><br><span class="line">frames *= numpy.hamming(frame_length)</span><br><span class="line"><span class="comment"># FFT 变换</span></span><br><span class="line">mag_frames = numpy.absolute(numpy.fft.rfft(frames, NFFT))   <span class="comment"># fft的幅度(magnitude)</span></span><br><span class="line"><span class="comment"># 计算功率谱</span></span><br><span class="line">pow_frames = ((<span class="number">1.0</span> / NFFT) * ((mag_frames) ** <span class="number">2</span>))  <span class="comment"># 功率谱</span></span><br><span class="line">nfilt = <span class="number">40</span></span><br><span class="line">low_freq_mel = <span class="number">0</span></span><br><span class="line">high_freq_mel = (<span class="number">2595</span> * np.log10(<span class="number">1</span> + (sample_rate / <span class="number">2</span>) / <span class="number">700</span>))  <span class="comment"># 将Hz转换为Mel</span></span><br><span class="line"><span class="comment"># 我们要做40个滤波器组，为此需要42个点，这意味着在们需要low_freq_mel和high_freq_mel之间线性间隔40个点</span></span><br><span class="line">mel_points = np.linspace(low_freq_mel, high_freq_mel, nfilt + <span class="number">2</span>)  <span class="comment"># 使得Mel scale间距相等</span></span><br><span class="line">hz_points = (<span class="number">700</span> * (<span class="number">10</span> ** (mel_points / <span class="number">2595</span>) - <span class="number">1</span>))  <span class="comment"># 将Mel转换回-Hz</span></span><br><span class="line"><span class="comment"># bin = sample_rate/NFFT    # frequency bin的计算公式</span></span><br><span class="line"><span class="comment"># bins = hz_points/bin=hz_points*NFFT/ sample_rate    # 得出每个hz_point中有多少frequency bin</span></span><br><span class="line">bins = np.floor((NFFT + <span class="number">1</span>) * hz_points / sample_rate)</span><br><span class="line"></span><br><span class="line">fbank = np.zeros((nfilt, int(np.floor(NFFT / <span class="number">2</span> + <span class="number">1</span>))))</span><br><span class="line"><span class="keyword">for</span> m <span class="keyword">in</span> range(<span class="number">1</span>, nfilt + <span class="number">1</span>):</span><br><span class="line">    f_m_minus = int(bins[m - <span class="number">1</span>])  <span class="comment"># 左</span></span><br><span class="line">    f_m = int(bins[m])  <span class="comment"># 中</span></span><br><span class="line">    f_m_plus = int(bins[m + <span class="number">1</span>])  <span class="comment"># 右</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(f_m_minus, f_m):</span><br><span class="line">        fbank[m - <span class="number">1</span>, k] = (k - bins[m - <span class="number">1</span>]) / (bins[m] - bins[m - <span class="number">1</span>])</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(f_m, f_m_plus):</span><br><span class="line">        fbank[m - <span class="number">1</span>, k] = (bins[m + <span class="number">1</span>] - k) / (bins[m + <span class="number">1</span>] - bins[m])</span><br><span class="line">filter_banks = np.dot(pow_frames, fbank.T)</span><br><span class="line">filter_banks = np.where(filter_banks == <span class="number">0</span>, np.finfo(float).eps, filter_banks)  <span class="comment"># 数值稳定性</span></span><br><span class="line">filter_banks = <span class="number">20</span> * np.log10(filter_banks)  <span class="comment"># dB</span></span><br><span class="line"><span class="comment">#梅尔频率倒谱系数（MFCCs）</span></span><br><span class="line">mfcc = dct(filter_banks, type=<span class="number">2</span>, axis=<span class="number">1</span>, norm=<span class="string">'ortho'</span>)[:, <span class="number">1</span> : (num_ceps + <span class="number">1</span>)] <span class="comment"># 保持在2-13</span></span><br><span class="line"><span class="comment"># 均值归一化处理</span></span><br><span class="line">mfcc -= (numpy.mean(mfcc, axis=<span class="number">0</span>) + <span class="number">1e-8</span>)</span><br></pre></td></tr></tbody></table></figure>

<h5 id="2-3-3-频谱图"><a href="#2-3-3-频谱图" class="headerlink" title="2.3.3. 频谱图"></a>2.3.3. 频谱图</h5><blockquote>
<p><strong>频谱图</strong>表示语音信号的功率随频率变化的规律，<code>信号频率与能量的关系</code>用频谱表示，频谱图的<strong>横轴为频率</strong>，变化为采样率的一半（奈奎斯特采样定理），<strong>纵轴为频率的强度（功率），</strong>以分贝（dB）为单位</p>
</blockquote>
<blockquote>
<p><strong>语谱图</strong>： 横坐标是时间<strong>，</strong><code>纵坐标是频率</code><strong>，</strong>坐标点值为语音数据能量<strong>，</strong><code>能量值的大小是通过颜色来表示的</code>，颜色越深表示该点的能量越强。<code>一条条横方向的条纹，称为“声纹”</code>。</p>
</blockquote>
<figure class="highlight matlab"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[Y,FS]=audioread(<span class="string">'p225_355_wb.wav'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% specgram(Y,2048,44100,2048,1536);</span></span><br><span class="line">    <span class="comment">%Y1为波形数据</span></span><br><span class="line">    <span class="comment">%FFT帧长2048点(在44100Hz频率时约为46ms)</span></span><br><span class="line">    <span class="comment">%采样频率44.1KHz</span></span><br><span class="line">    <span class="comment">%加窗长度，一般与帧长相等</span></span><br><span class="line">    <span class="comment">%帧重叠长度，此处取为帧长的3/4</span></span><br><span class="line">specgram(Y,<span class="number">2048</span>,FS,<span class="number">2048</span>,<span class="number">1536</span>);</span><br><span class="line">xlabel(<span class="string">'时间(s)'</span>)</span><br><span class="line">ylabel(<span class="string">'频率(Hz)'</span>)</span><br><span class="line">title(<span class="string">'“概率”语谱图'</span>)</span><br></pre></td></tr></tbody></table></figure>

<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121234847152.png" alt="功率谱计算"></p>
<h5 id="2-3-4-Librosa-库使用"><a href="#2-3-4-Librosa-库使用" class="headerlink" title="2.3.4. Librosa 库使用"></a>2.3.4. <a href="https://www.cnblogs.com/LXP-Never/p/11561355.html" target="_blank" rel="noopener">Librosa 库使用</a></h5><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> librosa</span><br><span class="line"><span class="keyword">import</span> librosa.display</span><br><span class="line"></span><br><span class="line">y, sr = librosa.load(<span class="string">'./train_wb.wav'</span>, sr=<span class="number">16000</span>)</span><br><span class="line"><span class="comment"># 提取 MFCC feature</span></span><br><span class="line">mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=<span class="number">40</span>)</span><br><span class="line"><span class="comment"># 提取 mel spectrogram feature</span></span><br><span class="line">melspec = librosa.feature.melspectrogram(y, sr, n_fft=<span class="number">1024</span>, hop_length=<span class="number">512</span>, n_mels=<span class="number">128</span>)</span><br><span class="line">logmelspec = librosa.power_to_db(melspec)       <span class="comment"># 转换为对数刻度</span></span><br><span class="line"><span class="comment"># 绘制 mel 频谱图</span></span><br><span class="line">plt.figure()</span><br><span class="line">librosa.display.specshow(logmelspec, sr=sr, x_axis=<span class="string">'time'</span>, y_axis=<span class="string">'mel'</span>, cmp=<span class="string">"jet"</span>)</span><br><span class="line">plt.colorbar(format=<span class="string">'%+2.0f dB'</span>)        <span class="comment"># 右边的色度条</span></span><br><span class="line">plt.title(<span class="string">'Beat wavform'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>

<h5 id="2-3-5-线性预测系数-LPC"><a href="#2-3-5-线性预测系数-LPC" class="headerlink" title="2.3.5.  线性预测系数(LPC)"></a>2.3.5.  线性预测系数(LPC)</h5><blockquote>
<p><code>共振峰出现的频率称为共振峰频率</code>。因此，使用这种技术，<code>通过计算滑动窗口上的线性预测系数</code>，并在<code>随后的线性预测滤波器[17]的频谱中找到峰值</code>，可以预测语音信号中共振峰的位置。LPC有助于在低比特率下对高质量语音进行编码[13,26,27]。从线性预测倒谱系数(LPCC)、对数面积比(LAR)、反射系数(RC)、线谱频率(LSF)和反正弦系数(Arcus Sine coefficients)[13]可以推导出LPC的其他特征。<code>有效地从给定的语音[16]中选择声道信息</code>。</p>
</blockquote>
<h5 id="2-3-6-线性预测倒谱系数-LPCC"><a href="#2-3-6-线性预测倒谱系数-LPCC" class="headerlink" title="2.3.6. 线性预测倒谱系数(LPCC)"></a>2.3.6. 线性预测倒谱系数(LPCC)</h5><blockquote>
<p>横轴是时间轴，纵轴是振幅轴, 高频语音信号的倒谱分析给出了低频域[29]的小源滤波器可分性。低阶倒谱系数对谱斜率敏感，而高阶倒谱系数对噪声[15]敏感。</p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201122095224766.png" alt=""></p>
<h5 id="2-3-7-线谱频率-LSF"><a href="#2-3-7-线谱频率-LSF" class="headerlink" title="2.3.7. 线谱频率(LSF)"></a>2.3.7. 线谱频率(LSF)</h5><blockquote>
<p>LSF图能够在不影响合成语音质量的前提下，<code>将传输线性预测信息的比特率降低25% ~ 30%</code>。除量子化外，预测器的LSF图也适用于插值。从理论上讲，将lsf域平方量化误差与感知相关的对数谱相联系的灵敏度矩阵是对角的[41,42], LSF在语音压缩领域的应用最为突出，并扩展到说话人识别和语音识别领域。LSF还被应用于动物噪音识别、个人工具识别和金融市场分析。LSF的优点包括其对光谱灵敏度的定位能力，它们可以表征带宽和共振位置，并强调了谱峰定位的重要方面。</p>
</blockquote>
<h5 id="2-3-8-小波变换"><a href="#2-3-8-小波变换" class="headerlink" title="2.3.8. 小波变换"></a>2.3.8. 小波变换</h5><blockquote>
<p>小波变换是一种信号处理技术，可以<code>高效地表示现实生活中的非平稳信号</code>。它能够在时域和频域同时从瞬态信号中挖掘信息。<code>小波变换将信号分解成一组称为小波的基本函数</code>。小波由一个称为母波的原型小波通过扩展和移位得到。小波变换的主要特点是利用可变窗口扫描频谱，提高了分析的时间分辨率.DWT确实为有效的语音分析[51]提供了足够的频带数。由于输入信号的长度是有限的，由于边界[50]处的不连续性，使得小波系数在边界处的变化非常大。</p>
</blockquote>
<h5 id="2-3-9-感知线性预测-PLP"><a href="#2-3-9-感知线性预测-PLP" class="headerlink" title="2.3.9. 感知线性预测(PLP)"></a>2.3.9. 感知线性预测(PLP)</h5><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122101238672.png" alt=""></p>
<table>
<thead>
<tr>
<th></th>
<th>滤波器系数</th>
<th>滤波器的形状</th>
<th>建模方法</th>
<th>速度的计算</th>
<th>系数类型</th>
<th>抗噪声能力</th>
<th>对量化/附加噪声的灵敏度</th>
<th>可靠性</th>
<th>捕获频率</th>
</tr>
</thead>
<tbody><tr>
<td>Mel倒频谱系数(MFCC)</td>
<td>Mel</td>
<td>三角形</td>
<td>人类听觉系统</td>
<td>高</td>
<td>倒频谱</td>
<td>中等</td>
<td>中等</td>
<td>高</td>
<td>低</td>
</tr>
<tr>
<td>线性预测系数(LPC)</td>
<td>线性预测</td>
<td>线性</td>
<td>人类声道</td>
<td>高</td>
<td>自相关系数</td>
<td>高</td>
<td>高</td>
<td>高</td>
<td>低</td>
</tr>
<tr>
<td>线性预测倒谱系数(LPCC)</td>
<td>线性预测</td>
<td>线性</td>
<td>人类声道</td>
<td>中等</td>
<td>倒频谱</td>
<td>高</td>
<td>高</td>
<td>中等</td>
<td>低&amp;中等</td>
</tr>
<tr>
<td>谱线频率(LSF)</td>
<td>线性预测</td>
<td>线性</td>
<td>人类声道</td>
<td>中等</td>
<td>频谱</td>
<td>高</td>
<td>高</td>
<td>中等</td>
<td>低&amp;中等</td>
</tr>
<tr>
<td>离散小波变换(DWT)</td>
<td>低通&amp;高通</td>
<td>-</td>
<td>-</td>
<td>高</td>
<td>小波</td>
<td>中等</td>
<td>中等</td>
<td>中等</td>
<td>低&amp;中等</td>
</tr>
<tr>
<td>感知线性预测(PLP)</td>
<td>Bark</td>
<td>梯形</td>
<td>人类听觉系统</td>
<td>中等</td>
<td>倒频谱&amp;自相关</td>
<td>中等</td>
<td>中等</td>
<td>中等</td>
<td>低&amp;中等</td>
</tr>
</tbody></table>
<h4 id="2-4-采样-amp-下采样"><a href="#2-4-采样-amp-下采样" class="headerlink" title="2.4. 采样&amp;下采样"></a>2.4. 采样&amp;下采样</h4><blockquote>
<p><code>奈奎斯特采样定理</code>，只有采样频率高于声音信号最高<strong>频率</strong>的两倍时，才能把数字信号表示的声音还原成为原来的声音。<code>带宽</code>：采样频率的一半，最高频率等于采样频率的一半。</p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121223210707.png" alt=""></p>
<h5 id="2-4-1-插值法"><a href="#2-4-1-插值法" class="headerlink" title="2.4.1. 插值法"></a>2.4.1. 插值法</h5><blockquote>
<p>Volodymyr Kuleshov的论文中使用抗混叠滤波器对语音信号进行下采样，再通过三次样条插值把下采样信号上采样到相同的长度。</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.signal <span class="keyword">import</span> decimate</span><br><span class="line"><span class="keyword">import</span> librosa </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> interpolate</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">upsample</span><span class="params">(x_lr, r)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    上采样，每隔一步去掉语音波形的r个点，然后用三次样条插值的方法把去掉的点补回来，有机会可以画图看看</span></span><br><span class="line"><span class="string">    :param x_lr:    音频数据</span></span><br><span class="line"><span class="string">    :param r:       样条插值前个数</span></span><br><span class="line"><span class="string">    :return:        样条插值后的音频信号</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    x_lr = x_lr.flatten()                   <span class="comment"># 把x_lr数组折叠成一维的数组</span></span><br><span class="line">    x_hr_len = len(x_lr) * r</span><br><span class="line">    i_lr = np.arange(x_hr_len, step=r)</span><br><span class="line">    i_hr = np.arange(x_hr_len)</span><br><span class="line"></span><br><span class="line">    f = interpolate.splrep(i_lr, x_lr)      <span class="comment"># 样条曲线插值系数</span></span><br><span class="line">    x_sp = interpolate.splev(i_hr, f)       <span class="comment"># 给定样条表示的节点和系数，返回在节点处的样条值</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x_sp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">yt, wav_fs = librosa.load(<span class="string">"./48k/p225_001.wav"</span>, sr=<span class="number">16000</span>, mono=<span class="literal">True</span>)</span><br><span class="line">x_lr = decimate(yt, <span class="number">2</span>)          <span class="comment"># 应用抗混叠滤波器后对信号进行下采样，获得低分辨率音频，下采样因子scale=2</span></span><br><span class="line"></span><br><span class="line">print(len(yt))</span><br><span class="line">print(len(x_lr))</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">plt.specgram(yt, Fs=<span class="number">16000</span>, scale_by_freq=<span class="literal">True</span>, sides=<span class="string">'default'</span>)</span><br><span class="line"></span><br><span class="line">x_lr = upsample(x_lr, <span class="number">2</span>)       <span class="comment"># 上采样</span></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">plt.specgram(x_lr, Fs=<span class="number">16000</span>, scale_by_freq=<span class="literal">True</span>, sides=<span class="string">'default'</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>

<h5 id="2-4-2-重采样（下采样）"><a href="#2-4-2-重采样（下采样）" class="headerlink" title="2.4.2. 重采样（下采样）"></a>2.4.2. 重采样（下采样）</h5><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> librosa </span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> signal</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">y, wav_fs = librosa.load(<span class="string">"./48k/p225_001.wav"</span>, sr=<span class="number">16000</span>, mono=<span class="literal">True</span>) </span><br><span class="line"><span class="comment">#沿给定轴使用傅立叶方法重新采样x到num个样本</span></span><br><span class="line">f = signal.resample(y, len(y)//<span class="number">2</span>)</span><br><span class="line">f = signal.resample(f, len(y))</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">plt.specgram(y, Fs=<span class="number">16000</span>, scale_by_freq=<span class="literal">True</span>, sides=<span class="string">'default'</span>)</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">plt.specgram(f, Fs=<span class="number">16000</span>, scale_by_freq=<span class="literal">True</span>, sides=<span class="string">'default'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">#         方法二</span></span><br><span class="line"><span class="keyword">import</span> librosa </span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> signal</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">y, wav_fs = librosa.load(<span class="string">"./48k/p225_001.wav"</span>, sr=<span class="number">16000</span>, mono=<span class="literal">True</span>) </span><br><span class="line">audio8k = librosa.core.resample(y, wav_fs, wav_fs/<span class="number">2</span>)            <span class="comment"># 下采样率 16000--&gt;8000</span></span><br><span class="line">audio8k = librosa.core.resample(audio8k, wav_fs/<span class="number">2</span>, wav_fs)    <span class="comment"># 上采样率 8000--&gt;16000，并不恢复高频部分</span></span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">plt.specgram(y, Fs=<span class="number">16000</span>, scale_by_freq=<span class="literal">True</span>, sides=<span class="string">'default'</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">plt.specgram(audio8k, Fs=<span class="number">16000</span>, scale_by_freq=<span class="literal">True</span>, sides=<span class="string">'default'</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>



<h4 id="2-5-滤波"><a href="#2-5-滤波" class="headerlink" title="2.5. 滤波"></a>2.5. 滤波</h4><p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201121231447009.png" alt=""></p>
<h5 id="2-5-1-butterworth低通滤波器"><a href="#2-5-1-butterworth低通滤波器" class="headerlink" title="2.5.1. butterworth低通滤波器"></a>2.5.1. butterworth低通滤波器</h5><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121231628339.png" alt=""></p>
<h5 id="2-5-2-切比雪夫I形状滤波器"><a href="#2-5-2-切比雪夫I形状滤波器" class="headerlink" title="2.5.2. 切比雪夫I形状滤波器"></a>2.5.2. 切比雪夫I形状滤波器</h5><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121231833697.png" alt=""></p>
<h5 id="2-5-3-切比雪夫2形状滤波器"><a href="#2-5-3-切比雪夫2形状滤波器" class="headerlink" title="2.5.3. 切比雪夫2形状滤波器"></a>2.5.3. 切比雪夫2形状滤波器</h5><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121231923712.png" alt=""></p>
<h5 id="2-5-4-椭圆低通滤波器"><a href="#2-5-4-椭圆低通滤波器" class="headerlink" title="2.5.4. 椭圆低通滤波器"></a>2.5.4. 椭圆低通滤波器</h5><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121232013593.png" alt=""></p>
<h5 id="2-5-5-频域滤波"><a href="#2-5-5-频域滤波" class="headerlink" title="2.5.5.  频域滤波"></a>2.5.5.  频域滤波</h5><blockquote>
<p>含噪信号是高能信号与低能噪声叠加的信号，可以通过傅里叶变换的频域滤波实现降噪。<a href="https://github.com/LXP-Neve/data/blob/master/machine_learning_date/noised.wav" target="_blank" rel="noopener">https://github.com/LXP-Neve/data/blob/master/machine_learning_date/noised.wav</a></p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> numpy.fft <span class="keyword">as</span> nf</span><br><span class="line"><span class="keyword">import</span> scipy.io.wavfile <span class="keyword">as</span> wf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取音频文件</span></span><br><span class="line">sample_rate, noised_sigs = wf.read(<span class="string">'./da_data/noised.wav'</span>)</span><br><span class="line">print(sample_rate)  <span class="comment"># sample_rate：采样率44100</span></span><br><span class="line">print(noised_sigs.shape)    <span class="comment"># noised_sigs:存储音频中每个采样点的采样位移(220500,)</span></span><br><span class="line">times = np.arange(noised_sigs.size) / sample_rate</span><br><span class="line"></span><br><span class="line">plt.figure(<span class="string">'Filter'</span>)</span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.title(<span class="string">'Time Domain'</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Signal'</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line">plt.grid(linestyle=<span class="string">':'</span>)</span><br><span class="line">plt.plot(times[:<span class="number">178</span>], noised_sigs[:<span class="number">178</span>], c=<span class="string">'orangered'</span>, label=<span class="string">'Noised'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 傅里叶变换后，绘制频域图像</span></span><br><span class="line">freqs = nf.fftfreq(times.size, times[<span class="number">1</span>] - times[<span class="number">0</span>])</span><br><span class="line">complex_array = nf.fft(noised_sigs)</span><br><span class="line">pows = np.abs(complex_array)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.title(<span class="string">'Frequency Domain'</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Power'</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line">plt.grid(linestyle=<span class="string">':'</span>)</span><br><span class="line"><span class="comment"># 指数增长坐标画图</span></span><br><span class="line">plt.semilogy(freqs[freqs &gt; <span class="number">0</span>], pows[freqs &gt; <span class="number">0</span>], c=<span class="string">'limegreen'</span>, label=<span class="string">'Noised'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 寻找能量最大的频率值</span></span><br><span class="line">fund_freq = freqs[pows.argmax()]</span><br><span class="line"><span class="comment"># where函数寻找那些需要抹掉的复数的索引</span></span><br><span class="line">noised_indices = np.where(freqs != fund_freq)</span><br><span class="line"><span class="comment"># 复制一个复数数组的副本，避免污染原始数据</span></span><br><span class="line">filter_complex_array = complex_array.copy()</span><br><span class="line">filter_complex_array[noised_indices] = <span class="number">0</span></span><br><span class="line">filter_pows = np.abs(filter_complex_array)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Frequency'</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Power'</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line">plt.grid(linestyle=<span class="string">':'</span>)</span><br><span class="line">plt.plot(freqs[freqs &gt;= <span class="number">0</span>], filter_pows[freqs &gt;= <span class="number">0</span>], c=<span class="string">'dodgerblue'</span>, label=<span class="string">'Filter'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">filter_sigs = nf.ifft(filter_complex_array).real</span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Time'</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Signal'</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line">plt.grid(linestyle=<span class="string">':'</span>)</span><br><span class="line">plt.plot(times[:<span class="number">178</span>], filter_sigs[:<span class="number">178</span>], c=<span class="string">'hotpink'</span>, label=<span class="string">'Filter'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">wf.write(<span class="string">'./da_data/filter.wav'</span>, sample_rate, filter_sigs)</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>

<h4 id="2-6-信号增强"><a href="#2-6-信号增强" class="headerlink" title="2.6. 信号增强"></a>2.6. 信号增强</h4><h5 id="2-6-1-加噪声"><a href="#2-6-1-加噪声" class="headerlink" title="2.6.1. 加噪声"></a>2.6.1. 加噪声</h5><ul>
<li>控制噪声因子</li>
</ul>
<blockquote>
<p>添加的噪声为均值为0，标准差为1的高斯白噪声，有两种方法对数据进行加噪。</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_noise1</span><span class="params">(x, w=<span class="number">0.004</span>)</span>:</span></span><br><span class="line">    <span class="comment"># w：噪声因子</span></span><br><span class="line">    output = x + w * np.random.normal(loc=<span class="number">0</span>, scale=<span class="number">1</span>, size=len(x))</span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">Augmentation = add_noise1(x=wav_data, w=<span class="number">0.004</span>)</span><br></pre></td></tr></tbody></table></figure>

<ul>
<li>控制信噪比</li>
</ul>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121233538338.png" alt=""></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_noise2</span><span class="params">(x, snr)</span>:</span></span><br><span class="line">    <span class="comment"># snr：生成的语音信噪比</span></span><br><span class="line">    P_signal = np.sum(abs(x) ** <span class="number">2</span>) / len(x)  <span class="comment"># 信号功率</span></span><br><span class="line">    P_noise = P_signal / <span class="number">10</span> ** (snr / <span class="number">10.0</span>)  <span class="comment"># 噪声功率</span></span><br><span class="line">    <span class="keyword">return</span> x + np.random.randn(len(x)) * np.sqrt(P_noise)</span><br><span class="line"></span><br><span class="line">Augmentation = add_noise2(x=wav_data, snr=<span class="number">50</span>)</span><br></pre></td></tr></tbody></table></figure>

<h5 id="2-6-2-波形位移"><a href="#2-6-2-波形位移" class="headerlink" title="2.6.2. 波形位移"></a>2.6.2. 波形位移</h5><blockquote>
<p>语音波形移动使用numpy.roll函数向右移动shift距离</p>
<p>numpy.roll(a, shift, axis=None)</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">time_shift</span><span class="params">(x, shift)</span>:</span></span><br><span class="line">    <span class="comment"># shift：移动的长度</span></span><br><span class="line">    <span class="keyword">return</span> np.roll(x, int(shift))</span><br><span class="line"></span><br><span class="line">Augmentation = time_shift(wav_data, shift=fs//<span class="number">2</span>)</span><br></pre></td></tr></tbody></table></figure>

<h5 id="2-6-3-波形拉伸"><a href="#2-6-3-波形拉伸" class="headerlink" title="2.6.3. 波形拉伸"></a>2.6.3. 波形拉伸</h5><blockquote>
<p>在不影响音高的情况下改变声音的速度 / 持续时间。这可以使用librosa的time_stretch函数来实现。</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">time_stretch</span><span class="params">(x, rate)</span>:</span></span><br><span class="line">    <span class="comment"># rate：拉伸的尺寸，</span></span><br><span class="line">    <span class="comment"># rate &gt; 1 加快速度</span></span><br><span class="line">    <span class="comment"># rate &lt; 1 放慢速度</span></span><br><span class="line">    <span class="keyword">return</span> librosa.effects.time_stretch(x, rate)</span><br><span class="line">Augmentation = time_stretch(wav_data, rate=<span class="number">2</span>)</span><br></pre></td></tr></tbody></table></figure>

<h5 id="2-6-4-音高修正"><a href="#2-6-4-音高修正" class="headerlink" title="2.6.4. 音高修正"></a>2.6.4. 音高修正</h5><blockquote>
<p>音高修正只改变音高而不影响音速，我发现-5到5之间的步数更合适。</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pitch_shifting</span><span class="params">(x, sr, n_steps, bins_per_octave=<span class="number">12</span>)</span>:</span></span><br><span class="line">    <span class="comment"># sr: 音频采样率</span></span><br><span class="line">    <span class="comment"># n_steps: 要移动多少步</span></span><br><span class="line">    <span class="comment"># bins_per_octave: 每个八度音阶(半音)多少步</span></span><br><span class="line">    <span class="keyword">return</span> librosa.effects.pitch_shift(x, sr, n_steps, bins_per_octave=bins_per_octave)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 向上移三音（如果bins_per_octave为12，则六步）</span></span><br><span class="line">Augmentation = pitch_shifting(wav_data, sr=fs, n_steps=<span class="number">6</span>, bins_per_octave=<span class="number">12</span>)</span><br><span class="line"><span class="comment"># 向上移三音（如果bins_per_octave为24，则3步）</span></span><br><span class="line">Augmentation = pitch_shifting(wav_data, sr=fs, n_steps=<span class="number">3</span>, bins_per_octave=<span class="number">24</span>)</span><br><span class="line"><span class="comment"># 向下移三音（如果bins_per_octave为12，则六步）</span></span><br><span class="line">Augmentation = pitch_shifting(wav_data, sr=fs, n_steps=<span class="number">-6</span>, bins_per_octave=<span class="number">12</span>)</span><br></pre></td></tr></tbody></table></figure>

<h4 id="2-7-语音度量"><a href="#2-7-语音度量" class="headerlink" title="2.7. 语音度量"></a>2.7. 语音度量</h4><h5 id="2-7-1-信噪比SNR"><a href="#2-7-1-信噪比SNR" class="headerlink" title="2.7.1. 信噪比SNR"></a>2.7.1. 信噪比SNR</h5><blockquote>
<p>有用信号功率与噪声功率的比（此处功率为平均功率），也等于幅度比的平方。</p>
</blockquote>
<h5 id="2-7-2-峰值信噪比（PSNR）"><a href="#2-7-2-峰值信噪比（PSNR）" class="headerlink" title="2.7.2. 峰值信噪比（PSNR）"></a>2.7.2. 峰值信噪比（PSNR）</h5><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122001115395.png" alt=""></p>
<h5 id="2-7-3-分段信噪比（SegSNR）"><a href="#2-7-3-分段信噪比（SegSNR）" class="headerlink" title="2.7.3. 分段信噪比（SegSNR）"></a>2.7.3. 分段信噪比（SegSNR）</h5><blockquote>
<p>由于语音信号是一种缓慢变化的短时平稳信号，因而在不同时间段上的信噪比也应不一样。为了改善上面的问题，可以采用分段信噪比。<code>分段信噪比</code>即是<code>先对语音进行分帧</code>，然后<code>对每一帧语音求信噪比，最好求均值</code>。</p>
</blockquote>
<h3 id="3-语音识别"><a href="#3-语音识别" class="headerlink" title="3. 语音识别"></a>3. 语音识别</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy.io.wavfile <span class="keyword">as</span> wf</span><br><span class="line"><span class="keyword">import</span> python_speech_features <span class="keyword">as</span> sf</span><br><span class="line"><span class="keyword">import</span> hmmlearn.hmm <span class="keyword">as</span> hl</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 读取training文件夹中的训练音频样本，每个音频对应一个mfcc矩阵，每个mfcc都有一个类别(apple...)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">search_file</span><span class="params">(directory)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    :param directory: 训练音频的路径</span></span><br><span class="line"><span class="string">    :return: 字典{'apple':[url, url, url ... ], 'banana':[...]}</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 使传过来的directory匹配当前操作系统</span></span><br><span class="line">    directory = os.path.normpath(directory)</span><br><span class="line">    objects = {}</span><br><span class="line">    <span class="comment"># curdir：当前目录</span></span><br><span class="line">    <span class="comment"># subdirs: 当前目录下的所有子目录</span></span><br><span class="line">    <span class="comment"># files: 当前目录下的所有文件名</span></span><br><span class="line">    <span class="keyword">for</span> curdir, subdirs, files <span class="keyword">in</span> os.walk(directory):</span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">            <span class="keyword">if</span> file.endswith(<span class="string">'.wav'</span>):</span><br><span class="line">                label = curdir.split(os.path.sep)[<span class="number">-1</span>]  <span class="comment"># os.path.sep为路径分隔符</span></span><br><span class="line">                <span class="keyword">if</span> label <span class="keyword">not</span> <span class="keyword">in</span> objects:</span><br><span class="line">                    objects[label] = []</span><br><span class="line">                <span class="comment"># 把路径添加到label对应的列表中</span></span><br><span class="line">                path = os.path.join(curdir, file)</span><br><span class="line">                objects[label].append(path)</span><br><span class="line">    <span class="keyword">return</span> objects</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取训练集数据</span></span><br><span class="line">train_samples = search_file(<span class="string">'../machine_learning_date/speeches/training'</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">2. 把所有类别为apple的mfcc合并在一起，形成训练集。</span></span><br><span class="line"><span class="string">    训练集:</span></span><br><span class="line"><span class="string">    train_x：[mfcc1,mfcc2,mfcc3,...],[mfcc1,mfcc2,mfcc3,...]...</span></span><br><span class="line"><span class="string">    train_y：[apple],[banana]...</span></span><br><span class="line"><span class="string">由上述训练集样本可以训练一个用于匹配apple的HMM。"""</span></span><br><span class="line"></span><br><span class="line">train_x, train_y = [], []</span><br><span class="line"><span class="comment"># 遍历字典</span></span><br><span class="line"><span class="keyword">for</span> label, filenames <span class="keyword">in</span> train_samples.items():</span><br><span class="line">    <span class="comment"># [('apple', ['url1,,url2...'])</span></span><br><span class="line">    <span class="comment"># [("banana"),("url1,url2,url3...")]...</span></span><br><span class="line">    mfccs = np.array([])</span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> filenames:</span><br><span class="line">        sample_rate, sigs = wf.read(filename)</span><br><span class="line">        mfcc = sf.mfcc(sigs, sample_rate)</span><br><span class="line">        <span class="keyword">if</span> len(mfccs) == <span class="number">0</span>:</span><br><span class="line">            mfccs = mfcc</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mfccs = np.append(mfccs, mfcc, axis=<span class="number">0</span>)</span><br><span class="line">    train_x.append(mfccs)</span><br><span class="line">    train_y.append(label)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.训练模型，有7个句子，创建了7个模型</span></span><br><span class="line">models = {}</span><br><span class="line"><span class="keyword">for</span> mfccs, label <span class="keyword">in</span> zip(train_x, train_y):</span><br><span class="line">    model = hl.GaussianHMM(n_components=<span class="number">4</span>, covariance_type=<span class="string">'diag'</span>, n_iter=<span class="number">1000</span>)</span><br><span class="line">    models[label] = model.fit(mfccs)  <span class="comment"># # {'apple':object, 'banana':object ...}</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">4. 读取testing文件夹中的测试样本，</span></span><br><span class="line"><span class="string">    测试集数据：</span></span><br><span class="line"><span class="string">        test_x  [mfcc1, mfcc2, mfcc3...]</span></span><br><span class="line"><span class="string">        test_y  [apple, banana, lime]</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">test_samples = search_file(<span class="string">'../machine_learning_date/speeches/testing'</span>)</span><br><span class="line"></span><br><span class="line">test_x, test_y = [], []</span><br><span class="line"><span class="keyword">for</span> label, filenames <span class="keyword">in</span> test_samples.items():</span><br><span class="line">    mfccs = np.array([])</span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> filenames:</span><br><span class="line">        sample_rate, sigs = wf.read(filename)</span><br><span class="line">        mfcc = sf.mfcc(sigs, sample_rate)</span><br><span class="line">        <span class="keyword">if</span> len(mfccs) == <span class="number">0</span>:</span><br><span class="line">            mfccs = mfcc</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mfccs = np.append(mfccs, mfcc, axis=<span class="number">0</span>)</span><br><span class="line">    test_x.append(mfccs)</span><br><span class="line">    test_y.append(label)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.测试模型</span></span><br><span class="line"><span class="comment">#    1. 分别使用7个HMM模型，对测试样本计算score得分。</span></span><br><span class="line"><span class="comment">#    2. 取7个模型中得分最高的模型所属类别作为预测类别。</span></span><br><span class="line">pred_test_y = []</span><br><span class="line"><span class="keyword">for</span> mfccs <span class="keyword">in</span> test_x:</span><br><span class="line">    <span class="comment"># 判断mfccs与哪一个HMM模型更加匹配</span></span><br><span class="line">    best_score, best_label = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    <span class="comment"># 遍历7个模型</span></span><br><span class="line">    <span class="keyword">for</span> label, model <span class="keyword">in</span> models.items():</span><br><span class="line">        score = model.score(mfccs)</span><br><span class="line">        <span class="keyword">if</span> (best_score <span class="keyword">is</span> <span class="literal">None</span>) <span class="keyword">or</span> (best_score &lt; score):</span><br><span class="line">            best_score = score</span><br><span class="line">            best_label = label</span><br><span class="line">    pred_test_y.append(best_label)</span><br><span class="line"></span><br><span class="line">print(test_y)   <span class="comment"># ['apple', 'banana', 'kiwi', 'lime', 'orange', 'peach', 'pineapple']</span></span><br><span class="line">print(pred_test_y)  <span class="comment"># ['apple', 'banana', 'kiwi', 'lime', 'orange', 'peach', 'pineapple']</span></span><br></pre></td></tr></tbody></table></figure>

<h3 id="4-主动降噪（ANC）"><a href="#4-主动降噪（ANC）" class="headerlink" title="4. 主动降噪（ANC）"></a>4. 主动降噪（ANC）</h3><blockquote>
<p>通过降噪系统产生与外界噪音相等的反向声波，将噪声中和，从而实现降噪的效果。所有的声音都由一定的频谱组成，如果可找到一种声音，其频率、振幅与所要消除的噪声完全一样，只是相位刚好相反(相差$180^o$)就可以将这噪声完全抵消。ANC降噪对2KHZ以下的信号噪声降噪效果比较好，<strong>对高频噪声降噪效果很差</strong>。原因为高频信号波长短，对相位偏差也比较敏感，导致ANC对高频噪声降噪效果差。<strong>一般高频噪声可以被耳机物理的遮蔽屏蔽掉</strong>，这种降噪被称为被动降噪。</p>
</blockquote>
<blockquote>
<p>被动降噪：被动式降噪也就是物理降噪，被动式降噪是指利用物理特性将外部噪声与耳朵隔绝开，主要通过耳机的头梁设计得紧一些、耳罩腔体进行声学优化、耳罩内部放上吸声材料……等等来实现耳机的物理隔音。被动降噪对高频率声音（如人声）的隔绝非常有效，一般可使噪声降低大约为15-20dB。</p>
</blockquote>
<h4 id="4-1-ENC降噪"><a href="#4-1-ENC降噪" class="headerlink" title="4.1. ENC降噪"></a>4.1. ENC降噪</h4><blockquote>
<p>ENC（Environmental Noise Cancellation，环境降噪技术），能有效抑制90%的反向环境噪声，由此降低环境噪声最高可达35dB以上，让游戏玩家可以更加自由的语音沟通。通过双麦克风阵列，精准计算通话者说话的方位，在保护主方向目标语音的同时，去除环境中的各种干扰噪声。</p>
</blockquote>
<h4 id="4-2-DSP降噪"><a href="#4-2-DSP降噪" class="headerlink" title="4.2. DSP降噪"></a>4.2. DSP降噪</h4><blockquote>
<p>DSP是英文(digital signal processing)的简写。主要是针对高、低频噪声。工作原理是<code>麦克风收集外部环境噪音</code>，然后系统<code>复制一个与外界环境噪音相等的反向声波，将噪音抵消</code>，从而达到更好的降噪效果。DSP降噪的原理和ANC降噪相似。但DSP降噪正反向噪音直接在系统内部相互中和抵消。</p>
</blockquote>
<h4 id="4-3-CVC降噪"><a href="#4-3-CVC降噪" class="headerlink" title="4.3. CVC降噪"></a>4.3. CVC降噪</h4><blockquote>
<p>CVC（Clear Voice Capture）是通话软件降噪技术。主要针对通话过程中产生的回声。通过全双工麦克风消噪软件，提供通话的回声和环境噪音消除功能，是目前蓝牙通话耳机中最先进的降噪技术。</p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122102106150.png" alt=""></p>
<h3 id="5-声源定位"><a href="#5-声源定位" class="headerlink" title="5. 声源定位"></a>5. 声源定位</h3><blockquote>
<p>FRIDA和MUSIC算法的鲁棒性较好，其次是SRP-PHAT和TOPS，再次WAVES和CSSM算法。</p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122140742280.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122134459424.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122134526910.png" alt=""></p>
<h4 id="5-1-GCC-SRP"><a href="#5-1-GCC-SRP" class="headerlink" title="5.1. GCC-SRP"></a>5.1. GCC-SRP</h4><blockquote>
<p>互相关方法具有计算量小，实时性好而被大多数系统中使用，其<code>基于阵元之间的差异时间差</code>(Time-Delay/Frequency-Delay)进而<code>提取出声源距离阵元的位置信息</code>，根据不同的麦克风对就可以在三维空间中唯一确定一个声源. 基本思想是在可能的空间点中做波束合成，然后根据合成后的各个方向上的功率最大值认为是声源方法。用GCC-PHAT方法得到具有陡峭峰值互相关函数，找到互相关最大时的点，结合采样频率Fs与与麦克风间距dFs与与麦克风间距d，就可以得到方向信息。</p>
</blockquote>
<ul>
<li>互相关可以用来描述两个信号之间的相似性;离散信号xk,yk的互相关函数定义为:<img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122140953113.png" alt=""></li>
<li>取使得互相关系数最大的延时值作为TDOA的估计:<img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122141017679.png" alt=""></li>
<li><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122141236829.png" alt="">)<img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122141341097.png" alt=""></li>
</ul>
<h4 id="5-2-Music"><a href="#5-2-Music" class="headerlink" title="5.2. Music"></a>5.2. Music</h4><h4 id="5-3-TOPS"><a href="#5-3-TOPS" class="headerlink" title="5.3. TOPS"></a>5.3. TOPS</h4><blockquote>
<p>通过信号和噪声子空间多个频率成分的正交关系估计声源方位，TOPS可用于一维和二维阵列.    </p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122142655944.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122142715490.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201122142737407.png" alt=""></p>
<ul>
<li>窄带编辑</li>
</ul>
<blockquote>
<p><strong>窄带意味着信号在阵列上的延迟比信号的时域宽度小得多，从而信号包络沿这列的延迟可以忽略不计，故阵列孔径内的各振元复包络不变。反之，若复包络有变化，则通常认为是宽带信号。</strong></p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122142946919.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143322461.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143400195.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143441337.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143700814.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122144036148.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143945998.png" alt=""></p>
<h4 id="5-4-FRIDA"><a href="#5-4-FRIDA" class="headerlink" title="5.4. FRIDA"></a>5.4. FRIDA</h4><h3 id="6-声源分离"><a href="#6-声源分离" class="headerlink" title="6. 声源分离"></a>6. 声源分离</h3><h4 id="6-1-ML-based"><a href="#6-1-ML-based" class="headerlink" title="6.1. ML based"></a>6.1. ML based</h4><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122145237780.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031150702720.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122145545772.png" alt=""></p>
<p>波束形成技术(BF, beamforming) 2.盲源分离技术(BSS, blind source seperation) 3.时频掩码技术(T-F masking, time-frequency masking)</p>
<blockquote>
<p>一般使用理想二值掩蔽方法来生产mask，对于时频表示的语音信号，输出有几个信号就会生成几个mask矩阵，以两个说话人为例，在每个时频点比较两个说话人语音能量的大小，将能量大的一方的mask矩阵对应位置的值设为1，另一个mask矩阵的对应位置设为0。</p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031152021286.png" alt=""></p>
<h4 id="6-2-Deep-Clustering"><a href="#6-2-Deep-Clustering" class="headerlink" title="6.2.  Deep Clustering"></a>6.2.  Deep Clustering</h4><blockquote>
<p>Deep Clustering算法训练神经网络为输入特征中的每个元素生成一个具有区分性的嵌入向量（embedding），之后利用聚类算法，如K-means，对生产的embedding进行聚类，得出不同类别即是不同说话人的信号分离结果图。Deep Clustering性能和泛化性能(训练在英文，测试在中文等情况)都比较好，但缺点是它不是一个end to end的方法，因为聚类方法不能训练。</p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031152325894.png" alt=""></p>
<blockquote>
<p>TasNet（Time-domain Audio Separation Network）是时域的方法(直接输入混合语音，不经过STFT等变化得到声音特征)，由编码器、分离网络、解码组成，与频域方法相比，编码过程不是固定的而是网络学到的(论文中认为对于语音而言STFT并不一定是最佳编码方式，有两点证实了此观点，论文中对编码器输出增加非负的约束会使模型变差，对编解码器增加互逆的关联约束使模型变差，即同一信号经过编码器再经过解码器得到同一信号)，通过分离网络得到两个mask，学到的mask与编码器输出相乘再经过解码器得分离的声音，训练过程使用前文提到的PIT方法，编解码器都是一维卷积（相当于全连接层线性变换），实验结果展示幅度和相位信息都被编码器学习到了特征之中。</p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031152501949.png" alt=""></p>
<ul>
<li><a href="https://www.youtube.com/watch?v=n7y2rLAnd5I" target="_blank" rel="noopener">Lightweight and Optimized Sound Source Localization and Tracking Methods for Open and Closed Microphone Array Configurations</a></li>
</ul>
<p>学习链接：</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/77275353" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/77275353</a></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://liudongdong1.github.io" rel="external nofollow noreferrer">liudongdong1</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://liudongdong1.github.io/2020/11/19/voicerelative/pythonaudioop/">https://liudongdong1.github.io/2020/11/19/voicerelative/pythonaudioop/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint polocy. If reproduced, please indicate source
                    <a href="https://liudongdong1.github.io" target="_blank">liudongdong1</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Voice/">
                                    <span class="chip bg-color">Voice</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="qq,qzone,wechat,weibo,douban" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/2020/11/19/aiot/mmwave/background/devicesurvey/">
                    <div class="card-image">
                        
                        <img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201124211750356.png" class="responsive-img" alt="DeviceSurvey">
                        
                        <span class="card-title">DeviceSurvey</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
Millimeter wave (mmWave) is a special class of radar technology that uses shortwavelength electromagnetic waves. Radar 
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2020-11-19
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/AIOT/" class="post-category">
                                    AIOT
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/mmwave/">
                        <span class="chip bg-color">mmwave</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2020/11/15/nlp/recommandation/">
                    <div class="card-image">
                        
                        <img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201129142519025.png" class="responsive-img" alt="Recommandation">
                        
                        <span class="card-title">Recommandation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
Recommendation Summary

User 数据（用户的基础属性数据，如性别、年龄、关系链、兴趣偏好等）


对于用户兴趣偏好，一般简单地采用文本 embedding 方法来得到各标签的 embedding 向量，然后根据用
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-11-15
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/NLP/" class="post-category">
                                    NLP
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Semantic-Parsing/">
                        <span class="chip bg-color">Semantic Parsing</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <!-- <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="463294659"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2019</span>
            <a href="https://liudongdong1.github.io" target="_blank">liudongdong</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">1206.4k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/liudongdong1/" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:3463264078@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>














    <a href="https://blog.csdn.net/liudongdong19/" class="tooltipped" target="_blank" data-tooltip="关注我的CSDN: https://blog.csdn.net/liudongdong19/" data-position="top" data-delay="50">
        <i class="fab fa-csdn">C</i>
    </a>





</div>
    </div>
</footer>

<div class="progress-bar"></div>
 -->

    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/search.xml", 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script type="text/javascript" src="/js/CFS.Snow.min.js"></script>
    <!-- 点击爆灯效果 -->
    <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas> 
    <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script> 
    <script type="text/javascript" src="/js/fireworks.js"></script>
    <!--动态线条背景-->
    <script type="text/javascript"
        color="122 103 238" opacity='0.7' zIndex="-2" count="200" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js">
    </script>
    <!-- 天气 -->
    <!-- weather -->
    <!-- weather -->
    <script type="text/javascript">
         WIDGET = {FID: 'knAMQaFanP'}
    </script>
    <script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"></script>
    <script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"></script>
    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    

    
    
    <script type="text/javascript" size="150" alpha='0.6'
        zIndex="-1" src="/libs/background/ribbon-refresh.min.js" async="async"></script>
    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    
    <!-- {% include '_custom/custom.swig' %} -->

</body>

</html>
