<!DOCTYPE HTML>
<html lang="en">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="DataSet_Record, AIOT,Space&amp;Temporal Sequence Analysis,SpringBoot,liudongdong1,cloud">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>DataSet_Record | DaybyDay</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="DaybyDay" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">DaybyDay</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>Tags</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">

      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/about">
          
          <i class="fas fa-user-circle" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>about</span>
        </a>
      </li>
      
      <li>
        <a href="/resume">
          
          <i class="fa fa-user-secret" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>resume</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>Friends</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/gallery" class="waves-effect waves-light">
      
      <i class="fas fa-camera" style="zoom: 0.6;"></i>
      
      <span>Galleries</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">DaybyDay</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			Tags
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-user-circle"></i>
			
			About
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/about " style="margin-left:75px">
				  
				   <i class="fa fas fa-user-circle" style="position: absolute;left:50px" ></i>
			      
		          <span>about</span>
                  </a>
                </li>
              
                <li>

                  <a href="/resume " style="margin-left:75px">
				  
				   <i class="fa fa fa-user-secret" style="position: absolute;left:50px" ></i>
			      
		          <span>resume</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			Friends
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/gallery" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-camera"></i>
			
			Galleries
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/liudongdong1" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/liudongdong1" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://gitee.com/github-25970295/blogImage/raw/master/img/33.jpeg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">DataSet_Record</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    .toc-fixed .toc-link::before{
        position: fixed!important;/*当toc的位置改为fixed时，.toc-link::before也要改为fixed*/
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Dataset/">
                                <span class="chip bg-color">Dataset</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E8%A7%86%E8%A7%89AI/" class="post-category">
                                视觉AI
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2020-07-13
                </div>
                

                <!-- 
                    <i class="fa fa-pencil"></i> Author: liudongdong1
                  -->

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>Update Date:&nbsp;&nbsp;
                    2022-11-07
                </div>
                

                <!-- 
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>Word Count:&nbsp;&nbsp;
                    4.3k
                </div>
                 -->

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>Read Times:&nbsp;&nbsp;
                    17 Min
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>Read Count:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>在以数据驱动的人工智能时代，本文用于平时学习或者阅读论文中所涉及到的开源数据集积累。<a href="https://lod-cloud.net/" target="_blank" rel="noopener">dataset知识图谱</a></p>
</blockquote>
<p>More:<a href="https://www.codetd.com/article/7219369" target="_blank" rel="noopener">https://www.codetd.com/article/7219369</a></p>
<ul>
<li><p>Dataset: <a href="https://www.cnblogs.com/xiaojianliu/p/9446358.html" target="_blank" rel="noopener">https://www.cnblogs.com/xiaojianliu/p/9446358.html</a></p>
</li>
<li><p><a href="https://facescape.nju.edu.cn/" target="_blank" rel="noopener"><strong>FaceScape</strong></a></p>
</li>
</ul>
<blockquote>
<p>一个大规模高质量的3D人脸数据集，包括18760张高质量3D人脸模型，对938名志愿者实现20种表情采集，该数据训练可以实现对单张图像预测3D人脸的细节。</p>
</blockquote>
<ul>
<li><a href="https://oasis.cs.princeton.edu/" target="_blank" rel="noopener">OASIS</a></li>
</ul>
<blockquote>
<p>开放的单图表面标注，是大规模的单图三维表面数据集。该数据集采用了14万张的互联网图像，人工标注实现了三维表面像素级重建。该数据集可以在深度估算、三维表面重建、边缘检测、实例分割等方向上帮助研究者。</p>
</blockquote>
<ul>
<li><a href="https://waymo.com/open" target="_blank" rel="noopener">Waymo</a></li>
</ul>
<blockquote>
<p>Waymo开源的大规模、高质量、自动驾驶数据集。该数据包含大量高质量手动标注的3D与2D图像，包含了1150个场景，涵盖雷达与相机导航数据，城市与乡村道路。</p>
</blockquote>
<ul>
<li><a href="https://github.com/cvdfoundation/google-landmark" target="_blank" rel="noopener">人脸landmark 数据</a></li>
</ul>
<blockquote>
<p>Google Landmarks Dataset v2，一个大规模的图像检索与识别基准数据集。采集了20W人的500W的数据。</p>
</blockquote>
<ul>
<li><a href="https://sdolivia.github.io/FineGym/" target="_blank" rel="noopener">FineGym</a></li>
</ul>
<blockquote>
<p>基于细粒度动作理解的层次化视频数据集，主要为了动作识别领域的研究需要，由港中大开发的大规模、高质量的动作细粒度识别数据集。数据集在动作和子动作两个层次上实现标注，具有三个层次的语义，具有多个不同层次的语义。</p>
</blockquote>
<ul>
<li><a href="https://github.com/zhixuany/HUMBI" target="_blank" rel="noopener">HUMBI</a></li>
</ul>
<blockquote>
<p>一个新的大规模多视角人体表达数据集，包含多个视角的自然衣着状态下的人体表达，这个数据集的主要目的是帮助更加有效的学习与重建人体，它是MPII-Gaze, Multi-PIE, Human3.6M, and Panoptic Studio datasets这些数据集的补充。</p>
</blockquote>
<ul>
<li><a href="https://github.com/jimmy646/violin" target="_blank" rel="noopener">VIOLIN</a></li>
</ul>
<blockquote>
<p>视频与语言推理，一个新的大规模数据集，总计15887个视频片段包含95322个视频假设对，超过582个小时的视频，这些视频内容丰富，时间跨度大。主要来自流行的电视剧、电影剪切片段、油管。</p>
</blockquote>
<h2 id="1-Image-Analysis"><a href="#1-Image-Analysis" class="headerlink" title="1. Image Analysis"></a>1. Image Analysis</h2><table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody><tr>
<td>Flickr30k</td>
<td>图片描述</td>
<td>31,783 images，每张图片5个语句标注</td>
<td><a href="http://web.engr.illinois.edu/~bplumme2/Flickr30kEntities/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Microsoft COCO</td>
<td>图片描述</td>
<td>330,000 images,每张图片至少5个语句标注</td>
<td><a href="http://cocodataset.org/#download" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>ESP Game</td>
<td>多标签定义图像</td>
<td>20,770 images，268 tags，诸如bed, light man,music</td>
<td><a href="https://www.kaggle.com/c/challenges-in-representation-learning-multi-modal-learning/data" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>IAPRTC-12</td>
<td>多标签定义图像</td>
<td>19,452 images,291 tags</td>
<td><a href="http://www.imageclef.org/photodata" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>NUS-WIDE</td>
<td>多标签定义图像</td>
<td>269,648 images,several tags (2-5 on average) per image</td>
<td><a href="http://lms.comp.nus.edu.sg/research/NUS-WIDE.htm" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>CUHK-PEDES</td>
<td>以文搜图</td>
<td>34,054 images，每张图片2条描述</td>
<td><a href="http://cuhk-pedes.shuanglee.me/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>VRD</td>
<td>视觉关系检测</td>
<td>5,000 images, 100目录，37,993对关系</td>
<td><a href="https://cs.stanford.edu/people/ranjaykrishna/vrd/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>sVG</td>
<td>视觉关系检测</td>
<td>108,000 images, 998,000对关系</td>
<td><a href="https://drive.google.com/file/d/0B5RJWjAhdT04SXRfVHBKZ0dOTzQ/view" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Visual Genome Dataset</td>
<td>图像属性检测</td>
<td>108,077 images, 5.4 M 区域块，2.8 M 属性，2.3 M 关系</td>
<td><a href="https://visualgenome.org/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>VQA</td>
<td>问答系统</td>
<td>1,105,904问题，11,059,040 回答</td>
<td><a href="http://www.visualqa.org/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Visual7W</td>
<td>问答系统</td>
<td>327,939 问答对</td>
<td><a href="http://web.stanford.edu/~yukez/visual7w/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>TID2013</td>
<td>图像质量评价</td>
<td>25张参考图像，24个失真类型</td>
<td><a href="http://www.ponomarenko.info/tid2013.htm" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>CSIQ</td>
<td>图像质量评价</td>
<td>30张参考图像，6个失真类型</td>
<td><a href="http://vision.eng.shizuoka.ac.jp/mod/page/view.php?id=23" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>LIVE</td>
<td>图像质量评价</td>
<td>29张参考图像，5个失真类型</td>
<td><a href="http://live.ece.utexas.edu/research/quality/subjective.htm" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>WATERLOO</td>
<td>图像质量评价</td>
<td>4744张参考图像，20个失真类型</td>
<td><a href="https://ece.uwaterloo.ca/~k29ma/exploration/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>photo.net</td>
<td>图像美观评价</td>
<td>20,278张图像，打分[0,10]</td>
<td><a href="http://ritendra.weebly.com/aesthetics-datasets.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>DPChallenge.com</td>
<td>图像美观评价</td>
<td>16,509张图像，打分[0,10]</td>
<td><a href="http://ritendra.weebly.com/aesthetics-datasets.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>CUHK</td>
<td>图像美观评价</td>
<td>28,410张图像，只分高质量和低质量</td>
<td><a href="http://mmlab.ie.cuhk.edu.hk/archive/CUHKPQ/Dataset.htm" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>AVA</td>
<td>图像美观评价</td>
<td>255,500张图像，打分[0,10]</td>
<td><a href="https://github.com/mtobeiyf/ava_downloader" target="_blank" rel="noopener">链接</a></td>
</tr>
</tbody></table>
<h2 id="2-Image-Motion-amp-amp-Tracking"><a href="#2-Image-Motion-amp-amp-Tracking" class="headerlink" title="2. Image Motion&amp;&amp;Tracking"></a>2. Image Motion&amp;&amp;Tracking</h2><table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody><tr>
<td>CUHK03</td>
<td>Person re-identification(人重识别)</td>
<td>image num:13164 person num:1360 camera num:10( 5 pairs)</td>
<td><a href="http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>CUHK02</td>
<td>Person re-identification(人重识别)</td>
<td>image num:7264 person num:1816 camera num:10( 5 pairs)</td>
<td><a href="http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>CUHK01</td>
<td>Person re-identification(人重识别)</td>
<td>image num:3884 person num:971 camera num: 2</td>
<td><a href="http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>VIPeR</td>
<td>Person re-identification(人重识别)</td>
<td>image num:1264 person num:632 camera num:2</td>
<td><a href="https://vision.soe.ucsc.edu/node/178" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>ETH1,2,3</td>
<td>Person re-identification(人重识别)</td>
<td>image num:8580 person num:83,35,28 camera num:1</td>
<td><a href="http://homepages.dcc.ufmg.br/~william/datasets.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>PRID2011</td>
<td>Person re-identification(人重识别)</td>
<td>image num:24541 person num:934 camera num:2</td>
<td><a href="https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/PRID11/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MARS</td>
<td>Person re-identification(人重识别)</td>
<td>image num:11910031 person num:1261 camera num:6</td>
<td><a href="http://www.liangzheng.com.cn/Project/project_mars.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Market1501</td>
<td>Person re-identification(人重识别)</td>
<td>image num:32217 person num:1501 camera num:6</td>
<td><a href="http://www.liangzheng.org/Project/project_reid.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Epic Fail (EF) dataset</td>
<td>Risk Assessment(风险评估)</td>
<td>video num:3000</td>
<td><a href="https://vision.soe.ucsc.edu/?q=node/178" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Street Accident (SA) dataset</td>
<td>Risk Assessment(风险评估)</td>
<td>video num:1733</td>
<td><a href="https://vision.soe.ucsc.edu/?q=node/178" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>OTB-50</td>
<td>visual tracking(跟踪)</td>
<td>video num:50</td>
<td><a href="http://www.visual-tracking.net/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>OTB-100</td>
<td>visual tracking(跟踪)</td>
<td>video num:100</td>
<td><a href="http://www.visual-tracking.net/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>VOT2015</td>
<td>visual tracking(跟踪)</td>
<td>video num:60</td>
<td><a href="http://www.votchallenge.net/vot2015/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>ALOV300</td>
<td>visual tracking(跟踪)</td>
<td>video num:314</td>
<td><a href="http://alov300pp.joomlafree.it/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MOT</td>
<td>visual tracking(跟踪)</td>
<td>video num:train:11 test:11</td>
<td><a href="https://motchallenge.net/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>THUMOS</td>
<td>Temporal action localization(动作定位)</td>
<td>video num:<del>3K activities class:20 instances:</del>3K</td>
<td><a href="http://crcv.ucf.edu/THUMOS14/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>ActivityNet</td>
<td>Temporal action localization(动作定位)</td>
<td>video num:20k activities class:200 instances:7.6K</td>
<td><a href="http://activity-net.org/challenges/2016/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Mexaction2</td>
<td>Temporal action localization(动作定位)</td>
<td>activities class:2 instances:1975</td>
<td><a href="http://mexculture.cnam.fr/xwiki/bin/view/Datasets/Mex+action+dataset" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>FlyingChairs dataset</td>
<td>optical flow(光流)</td>
<td>image pairs：22k</td>
<td><a href="https://lmb.informatik.uni-freiburg.de/resources/datasets/FlyingChairs.en.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>FlyingThings3D</td>
<td>optical flow(光流)</td>
<td>image pairs：22k</td>
<td><a href="https://lmb.informatik.uni-freiburg.de/resources/datasets/SceneFlowDatasets.en.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>KITTI benchmark suite</td>
<td>optical flow(光流)</td>
<td>image pairs：1600</td>
<td><a href="http://www.cvlibs.net/datasets/kitti/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MPI Sintel</td>
<td>optical flow(光流)</td>
<td>image pairs：1064</td>
<td><a href="http://sintel.is.tue.mpg.de/" target="_blank" rel="noopener">链接</a></td>
</tr>
</tbody></table>
<h2 id="3-Video-Analysis-amp-Scene-Understanding"><a href="#3-Video-Analysis-amp-Scene-Understanding" class="headerlink" title="3. Video Analysis &amp; Scene Understanding"></a>3. Video Analysis &amp; Scene Understanding</h2><table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody><tr>
<td>UCF101</td>
<td>动作行为识别</td>
<td>13320 video,101类动作，主要是五大类：1)人-物交互；2)肢体运动；3)人-人交互；4)弹奏乐器；5)运动</td>
<td><a href="http://crcv.ucf.edu/data/UCF101.php" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>HMDB51</td>
<td>动作行为识别</td>
<td>7000 videos,51类，包括人脸表情动作，身体动作，人与人交互等</td>
<td><a href="http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/#Downloads" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Moments-in-Time</td>
<td>动作行为识别</td>
<td>1,000,000 videos,339类</td>
<td><a href="http://moments.csail.mit.edu/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>ActivityNet 1.3</td>
<td>动作行为识别</td>
<td>20,000 videos,200类</td>
<td><a href="http://activity-net.org/challenges/2016/guidelines.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Kinetics</td>
<td>动作行为识别</td>
<td>300,000 videos，400类</td>
<td><a href="https://deepmind.com/research/open-source/open-source-datasets/kinetics/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>AVA</td>
<td>动作行为识别</td>
<td>57,600 videos，80类</td>
<td><a href="https://research.google.com/ava/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Collective Activity Dataset</td>
<td>群体活动行为识别</td>
<td>44 videos,穿叉、行走、等待、交谈和排队 五类</td>
<td><a href="http://vhosts.eecs.umich.edu/vision//activity-dataset.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Choi’s New Dataset</td>
<td>群体活动行为识别</td>
<td>32 videos，聚会，谈话，分开，一起走，追逐和排队 六类</td>
<td>None</td>
</tr>
<tr>
<td>ActivityNet 1.3</td>
<td>检测动作事件的起始时间和终止时间</td>
<td>20,000 videos,200类动作的起始时间和终止时间</td>
<td><a href="http://activity-net.org/challenges/2016/guidelines.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>THUMOS</td>
<td>检测动作事件的起始时间和终止时间</td>
<td>15,000 videos，101类动作的起始时间和终止时间</td>
<td><a href="http://www.thumos.info/download.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MED</td>
<td>事件检测</td>
<td>32,744 videos,20个事件</td>
<td><a href="http://www-nlpir.nist.gov/projects/tv2017/data/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>EventNet</td>
<td>事件检测</td>
<td>90,000 videos，500个事件</td>
<td><a href="http://eventnet.ee.columbia.edu/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Columbia Consumer Video</td>
<td>事件检测</td>
<td>9,317 videos，20个事件</td>
<td><a href="http://www.ee.columbia.edu/ln/dvmm/CCV/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>ADE20K</td>
<td>事件检测</td>
<td>20,210 videos，900个事件</td>
<td><a href="http://sceneparsing.csail.mit.edu/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>DAVIS</td>
<td>视频主物体分割</td>
<td>50 videos，分割标注</td>
<td><a href="http://davischallenge.org/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>FBMS</td>
<td>视频主物体分割</td>
<td>59 videos，分割标注</td>
<td><a href="https://lmb.informatik.uni-freiburg.de/resources/datasets/moseg.en.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>IJB-C</td>
<td>视频人脸识别</td>
<td>11,000 videos，</td>
<td><a href="https://www.nist.gov/programs-projects/face-challenges" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>YouTube Faces</td>
<td>视频人脸识别</td>
<td>3,425 videos，1595 人</td>
<td><a href="https://www.cs.tau.ac.il/~wolf/ytfaces/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MS-Celeb-1M</td>
<td>视频人脸识别</td>
<td>1,000,000 images，21,000人</td>
<td><a href="http://www.msceleb.org/download/sampleset" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MSVD</td>
<td>视频描述</td>
<td>1,970 videos</td>
<td><a href="http://www.cs.utexas.edu/users/ml/clamp/videoDescription/YouTubeClips.tar" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MSR-VTT-10K</td>
<td>视频描述</td>
<td>10，000 videos</td>
<td><a href="http://ms-multimedia-challenge.com/2017/dataset" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MSR-VTT-10K</td>
<td>视频描述</td>
<td>无</td>
<td><a href="https://sites.google.com/site/describingmovies/lsmdc-2016/download" target="_blank" rel="noopener">链接</a></td>
</tr>
</tbody></table>
<h2 id="4-3D-Computer-Vision"><a href="#4-3D-Computer-Vision" class="headerlink" title="4. 3D Computer Vision"></a>4. 3D Computer Vision</h2><table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody><tr>
<td>photoface database</td>
<td>基于光度立体视觉的二维和三维人脸识别数据库</td>
<td>总共7356张图像，包含1839个session和261个subjects</td>
<td>None</td>
</tr>
<tr>
<td>NYU Depth V2 dataset</td>
<td>关于RGBD 图像场景理解的数据库</td>
<td>提供1449张深度图片和他们的密集2d点类标注</td>
<td><a href="https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>SUN RGBD dataset</td>
<td>是上面的NYU Depth V2 dataset的超集，多了3D bounding boxes和room layouts的标注。</td>
<td>有10,000张RGB-D图片，有58,657个3D包围框和146,617 个2d包围框。</td>
<td><a href="http://rgbd.cs.princeton.edu/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>PASCAL3D+</td>
<td>新的三维物体检测和姿态估计数据集，从PASCAL VOC 演化而来，包含图像，注解，和3D CAD模型</td>
<td>总共12个类，平均每个类别有3000多个实例</td>
<td><a href="http://cvgl.stanford.edu/projects/pascal3d.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>IKEA</td>
<td>包含典型室内场景的三维模型的数据库，例如桌子椅子等</td>
<td>包含大约759张图片和219个3D模型</td>
<td><a href="http://ikea.csail.mit.edu/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>New Tsukuba Dataset</td>
<td>包含了很多立体物体对的数据库，用于立体物体匹配</td>
<td>总共1800个立体物体对，以及每立体对的立体视差图、遮挡图和不连续图</td>
<td><a href="https://cvlab-home.blogspot.jp/2012/05/h2fecha-2581457116665894170-displaynone.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Oxford RobotCar Dataset</td>
<td>关于户外自动驾驶的数据集。</td>
<td>包含在驾驶汽车过程从6个摄像头收集的2000w张图片，和当时的激光雷达，GPS和地面实况标注。</td>
<td><a href="http://robotcar-dataset.robots.ox.ac.uk/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Middlebury V3</td>
<td>包含高分辨率物体立体视差标注的数据库</td>
<td>包含33个类，没有明说每类有多少数据</td>
<td><a href="http://vision.middlebury.edu/stereo/eval3/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>ShapeNet</td>
<td>包含3D模型，和3d模型的类别标注的数据集，覆盖了常用的3D数据集PASCAL 3D+。</td>
<td>它涵盖55个常见的对象类别，有大约51,300个3D模型</td>
<td><a href="https://www.shapenet.org/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MICC dataset</td>
<td>包含了3D人脸扫描和在不同分辨率，条件和缩放级别下的几个视频序列的数据库。</td>
<td>有53个人的立体人脸数据</td>
<td><a href="https://www.micc.unifi.it/resources/datasets/florence-3d-faces/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>CMU MoCap Dataset</td>
<td>包含了3D人体关键点标注和骨架移动标注的数据集。</td>
<td>有6个类别和23个子类别，总共2605个数据。</td>
<td><a href="http://mocap.cs.cmu.edu/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>DTU dataset</td>
<td>关于3D场景的数据集。</td>
<td>有124个场景，每场景有49/64个位置的RGB图像和结构光标注。</td>
<td><a href="http://roboimagedata.compute.dtu.dk/?page_id=36" target="_blank" rel="noopener">链接</a></td>
</tr>
</tbody></table>
<h2 id="5-Analyzing-Humans-in-Images"><a href="#5-Analyzing-Humans-in-Images" class="headerlink" title="5. Analyzing Humans in Images"></a>5. Analyzing Humans in Images</h2><table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody><tr>
<td>MSR-Action3D</td>
<td>包含深度的动作识别数据集，</td>
<td>有20个动作，总共557个序列。</td>
<td><a href="http://users.eecs.northwestern.edu/~jwa368/my_data.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Florence-3D</td>
<td>包含深度的动作识别数据集，</td>
<td>有9个动作，总共215个动作序列。</td>
<td><a href="https://www.micc.unifi.it/resources/datasets/florence-3d-actions-dataset/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Berkeley MHAD</td>
<td>包含深度的动作识别数据集，</td>
<td>有11个动作，产生660个动作序列。</td>
<td><a href="http://tele-immersion.citris-uc.org/berkeley_mhad" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Online Action Detection</td>
<td>包含深度的动作识别数据集，</td>
<td>数据集包含59个长序列，包含10种不同的日常生活行为。</td>
<td><a href="http://homes.esat.kuleuven.be/~rdegeest/OnlineActionDetection.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>ChaLearn LAP IsoGD Dataset</td>
<td>RGB-D图像的手势识别的数据集。</td>
<td>包括47933个RGB-D手势视频，有249个手势标签。Training有35878视频，Validation有5784个，test有6271个</td>
<td><a href="http://gesture.chalearn.org/2016-looking-at-people-cvpr-challenge/isogd-and-congd-datasets" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MAFA dataset</td>
<td>关于面部遮挡问题的数据集</td>
<td>有30, 811张人脸和35806张有遮挡的脸组成。</td>
<td><a href="http://www.escience.cn/people/geshiming/mafa.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MSRC-12 Kinect Gesture Dataset</td>
<td>手势识别数据集</td>
<td>有4900张图片，包含12个不同手势，</td>
<td><a href="https://www.microsoft.com/en-us/download/details.aspx?id=52283" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>2013 Chalearn Gesture Challenge dataset</td>
<td>手势识别数据集</td>
<td>有11000张图片，包含20个不同手势，</td>
<td><a href="http://gesture.chalearn.org/2013-multi-modal-challenge" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>WIDER FACE</td>
<td>人脸检测数据集</td>
<td>有 32,203 张图片，标注了393703个人脸。</td>
<td><a href="http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>FDDB</td>
<td>人脸检测数据集</td>
<td>2845张图片，标注了5171张人脸。</td>
<td><a href="http://vis-www.cs.umass.edu/fddb/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>300-VW dataset</td>
<td>面部表情数据集</td>
<td>包含114个视频和总计218,595帧。</td>
<td><a href="https://ibug.doc.ic.ac.uk/resources/300-VW/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>HMDB51</td>
<td>人类行为识别的数据集</td>
<td>包含51个动作，总共有6766个视频剪辑</td>
<td><a href="http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MPII Cooking Activities Dataset</td>
<td>人类行为识别的数据集</td>
<td>包含65个动作，有5609个视频</td>
<td><a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/human-activity-recognition/mpii-cooking-activities-dataset/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>UCF101</td>
<td>人类行为识别的数据集</td>
<td>包含101个动作，有13320个视频</td>
<td><a href="http://crcv.ucf.edu/data/UCF101.php" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>IJB-A dataset</td>
<td>包含视频和图片人脸识别的数据集</td>
<td>包含5712个图像和2085个视频</td>
<td><a href="https://www.nist.gov/programs-projects/face-challenges" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>YouTube celebrities</td>
<td>视频人脸识别的数据集</td>
<td>包含47位名人的1910个视频</td>
<td><a href="https://www.cs.tau.ac.il/~wolf/ytfaces/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>COX</td>
<td>视频人脸识别的数据集</td>
<td>包含1000个主题的4000个视频</td>
<td><a href="http://vipl.ict.ac.cn/view_database.php?id=3" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Human3.6M</td>
<td>人体姿态估计的数据集</td>
<td>360万张3D照片，11名受试者在4个视点下执行15个了不同的动作</td>
<td><a href="http://vision.imar.ro/human3.6m/description.php" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>iLIDS</td>
<td>行人重识别的数据集</td>
<td>476 张图像，包含119个人</td>
<td><a href="http://www.eecs.qmul.ac.uk/~xiatian/downloads_qmul_iLIDS-VID_ReID_dataset.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>VIPeR</td>
<td>行人重识别的数据集</td>
<td>632个行人图片对（由两个相机拍摄）</td>
<td><a href="https://iiw.kuleuven.be/onderzoek/eavise/viper/dataset" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>CUHK01</td>
<td>行人重识别的数据集</td>
<td>包含971行人, 3884张图片</td>
<td><a href="http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>CUHK03</td>
<td>行人重识别的数据集</td>
<td>包含1360行人, 13164张图片</td>
<td><a href="http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>RWTH-PHOENIX-Weather multi-signer 2014</td>
<td>手语识别的数据集</td>
<td>包含了5672个德语手语的句子，有65,227个手语姿势和799,006帧</td>
<td><a href="https://www-i6.informatik.rwth-aachen.de/~forster/database-rwth-phoenix.php" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>AFLW</td>
<td>人类面部关键点的数据集</td>
<td>总共约有25k张脸，每幅图像标注了大约21个位置。</td>
<td><a href="https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/aflw" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>CMU mocap database</td>
<td>动作识别的数据集</td>
<td>2235个数据，包含144个不同的动作。</td>
<td><a href="http://mocap.cs.cmu.edu/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Georgia Tech (GT) database</td>
<td>人脸识别数据库</td>
<td>50个人每人15张人脸。</td>
<td><a href="http://www.anefian.com/research/face_reco.htm" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>ORL</td>
<td>人脸识别数据库</td>
<td>40个人每个人10张图。</td>
<td><a href="https://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html" target="_blank" rel="noopener">链接</a></td>
</tr>
</tbody></table>
<h2 id="6-Application"><a href="#6-Application" class="headerlink" title="6. Application"></a>6. Application</h2><table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody><tr>
<td>DogCentric Activity Dataset</td>
<td>第一视角的狗和人之间的相互行为的数据集（视频）</td>
<td>总共有10类，具体数据量没有明说，y是动作类别</td>
<td><a href="http://robotics.ait.kyushu-u.ac.jp/yumi/db/first_dog.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>JPL First-Person Interaction Dataset</td>
<td>第一视角观察动作的数据集</td>
<td>57个视频，8个大类，y是动作类别</td>
<td><a href="http://michaelryoo.com/jpl-interaction.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>NUS-WIDE</td>
<td>关于图像文本匹配的数据集</td>
<td>269,648个图像和对应的标签</td>
<td><a href="http://lms.comp.nus.edu.sg/research/NUS-WIDE.htm" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>LabelMe Dataset</td>
<td>关于图像文本匹配的数据集</td>
<td>3825个图像和对应标签</td>
<td><a href="http://labelme.csail.mit.edu/Release3.0/browserTools/php/dataset.php" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Pascal Dataset</td>
<td>关于图像文本匹配的数据集</td>
<td>5011张训练图像和4952张测试图像</td>
<td>)</td>
</tr>
<tr>
<td>ICDAR 2015</td>
<td>关于文本检测的数据集</td>
<td>1500张训练，1000张测试，y为四边形的四个顶点。</td>
<td><a href="http://rrc.cvc.uab.es/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>COCO-Text</td>
<td>关于文本检测的数据集</td>
<td>63686张图片，其中43686张被选为训练集，剩下的2万用于测试。</td>
<td><a href="https://vision.cornell.edu/se3/coco-text-2/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MSRA-TD500</td>
<td>关于文本检测的数据集</td>
<td>300个训练，200个测试图像</td>
<td><a href="http://www.iapr-tc11.org/mediawiki/index.php/MSRA_Text_Detection_500_Database_(MSRA-TD500)" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Microsoft 7-Scenes Dataset</td>
<td>室内人体运动的数据集</td>
<td>有7种不同室内环境，每包含500-1000张图像视频序列。</td>
<td><a href="https://www.microsoft.com/en-us/research/project/rgb-d-dataset-7-scenes/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Oxford RobotCar</td>
<td>户外自动驾驶数据集</td>
<td>包含图像，激光扫描结果和GPS数据。</td>
<td><a href="http://robotcar-dataset.robots.ox.ac.uk/" target="_blank" rel="noopener">链接</a></td>
</tr>
</tbody></table>
<h2 id="7-Low-amp-Mid-Level-Vision"><a href="#7-Low-amp-Mid-Level-Vision" class="headerlink" title="7. Low- &amp; Mid-Level Vision"></a>7. Low- &amp; Mid-Level Vision</h2><table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody><tr>
<td>Deep Video Deblurring for Hand-held Cameras</td>
<td>video/image deblurring(图像去模糊)</td>
<td>video num:71 video time: 3-5s blurry and sharp pair image num:6708</td>
<td><a href="https://www.cs.ubc.ca/labs/imager/tr/2017/DeepVideoDeblurring/#dataset" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>GOPRO dataset</td>
<td>video/image deblurring(图像去模糊)</td>
<td>blurry and sharp pair image num:3214 train num:2103 test num:1111</td>
<td><a href="https://github.com/SeungjunNah/DeepDeblur_release" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>BSD68</td>
<td>image restoration(图像修复)/高斯降噪</td>
<td>image num:68</td>
<td><a href="https://www.robots.ox.ac.uk/~vgg/data/dtd/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>BSD100</td>
<td>“image restoration(图像修复)super resolution超分辨率重建”</td>
<td>image num:100</td>
<td><a href="https://github.com/jbhuang0604/SelfExSR/tree/master/data" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Set5</td>
<td>“image restoration(图像修复)super resolution超分辨率重建”</td>
<td>image num:5</td>
<td><a href="https://github.com/jbhuang0604/SelfExSR/tree/master/data" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Set14</td>
<td>“image restoration(图像修复)super resolution超分辨率重建”</td>
<td>image num:14</td>
<td><a href="https://github.com/jbhuang0604/SelfExSR/tree/master/data" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Urban100</td>
<td>“image restoration(图像修复)super resolution超分辨率重建”</td>
<td>image num:100</td>
<td><a href="https://github.com/jbhuang0604/SelfExSR/tree/master/data" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>NYU v2 dataset</td>
<td>“image restoration(图像修复)depth super resolution深度超分辨率重建”</td>
<td>image num:1449</td>
<td><a href="https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Middlebury dataset</td>
<td>“image restoration(图像修复)depth super resolution深度超分辨率重建”</td>
<td>image pair num: 33</td>
<td><a href="http://vision.middlebury.edu/stereo/data/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>alpha matting benchmark</td>
<td>Natural image matting(抠图)</td>
<td>“train num:27,test num:8”</td>
<td><a href="http://www.alphamatting.com/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>real image benchmark</td>
<td>Natural image matting(抠图)</td>
<td>“train num:49300,test num:1000”</td>
<td><a href="https://sites.google.com/view/deepimagematting" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MSRA10K/MSRA-B</td>
<td>Image saliency detection(显著性区域检测)</td>
<td>image num(MSRA10K):10000 image num(MSRA-B):5000</td>
<td><a href="https://mmcheng.net/zh/msra10k/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>ECSSD</td>
<td>Image saliency detection(显著性区域检测)</td>
<td>image num:1000</td>
<td><a href="http://www.cse.cuhk.edu.hk/leojia/projects/hsaliency/dataset.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>DUT-OMRON</td>
<td>Image saliency detection(显著性区域检测)</td>
<td>image num:5168</td>
<td><a href="http://saliencydetection.net/dut-omron/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>PASCAL-S</td>
<td>Image saliency detection(显著性区域检测)</td>
<td>image num:850</td>
<td><a href="http://cbi.gatech.edu/salobj/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>HKU-IS</td>
<td>Image saliency detection(显著性区域检测)</td>
<td>image num:4447</td>
<td><a href="http://i.cs.hku.hk/~gbli/deep_saliency.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>SOD</td>
<td>Image saliency detection(显著性区域检测)</td>
<td>image num:300</td>
<td><a href="http://i.cs.hku.hk/~gbli/deep_saliency.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Describable Textures Dataset</td>
<td>texture synthesis(纹理合成)</td>
<td>image num:5640 category num:47 split train:val:test = 1:1:1</td>
<td><a href="https://www.robots.ox.ac.uk/~vgg/data/dtd/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>CVPPP leaf segmentation</td>
<td>Instance segmentation(样例分割)</td>
<td>image num: 161 train num: 128 test num: 33</td>
<td><a href="https://www.plant-phenotyping.org/CVPPP2014-dataset" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>KITTI car segmentation</td>
<td>Instance segmentation(样例分割)</td>
<td>image num: 3976 train num: 3712 test num: 144 val:120</td>
<td><a href="http://www.cvlibs.net/datasets/kitti/eval_semantics.php" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Cityscapes</td>
<td>Instance segmentation(样例分割)</td>
<td>image num: 5000 train num: 2975 test num: 1525 val:500</td>
<td><a href="https://www.cityscapes-dataset.com/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>SYMMAX</td>
<td>Symmetry Detection(对称性检测)</td>
<td>image num: train:200 test:100</td>
<td><a href="https://github.com/KevinKecc/SRN" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>WHSYMMAX</td>
<td>Symmetry Detection(对称性检测)</td>
<td>image num: train:228 test:100 object num: 1</td>
<td><a href="https://github.com/KevinKecc/SRN" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>SK506</td>
<td>Symmetry Detection(对称性检测)</td>
<td>image num: train:300 test:206 object num: 16</td>
<td><a href="https://github.com/KevinKecc/SRN" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Sym-PASCAL</td>
<td>Symmetry Detection(对称性检测)</td>
<td>image num: train:648 test:787 object num: 14</td>
<td><a href="https://github.com/KevinKecc/SRN" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Color Checker Dataset</td>
<td>Color constancy(颜色恒定)</td>
<td>image num: 568</td>
<td><a href="http://www.eecs.harvard.edu/~ayanc/oldcc/dbs.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>NUS 8-Camera Dataset</td>
<td>Color constancy(颜色恒定)</td>
<td>image num: 1736</td>
<td><a href="http://www.comp.nus.edu.sg/~whitebal/illuminant/illuminant.html" target="_blank" rel="noopener">链接</a></td>
</tr>
</tbody></table>
<h2 id="8-Text"><a href="#8-Text" class="headerlink" title="8. Text"></a>8. Text</h2><table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody><tr>
<td>Stanford Sentiment Treebank</td>
<td>文本情感分析</td>
<td>11855个句子划分为239231个短语，每个短语有个概率值，越小越负面，越大越正面</td>
<td><a href="https://nlp.stanford.edu/sentiment/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>IMDB</td>
<td>文本情感分析</td>
<td>100,000句子，正面负面两类</td>
<td><a href="http://ai.stanford.edu/~amaas/data/sentiment/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Yelp</td>
<td>文本情感分析</td>
<td>无</td>
<td><a href="https://www.yelp.com/dataset/challenge" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Multi-Domain Sentiment Dataset(Amazon product)</td>
<td>文本情感分析</td>
<td>100,000+句子，正面负面2类或强正面、弱正面、中立、弱负面、强负面5类</td>
<td><a href="http://www.cs.jhu.edu/~mdredze/datasets/sentiment/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>SemEval</td>
<td>文本情感分析</td>
<td>20,632句子，三类（正面、负面、中立）</td>
<td><a href="http://alt.qcri.org/semeval2017/task4/index.php?id=data-and-tools" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Sentiment140(STS)</td>
<td>文本情感分析</td>
<td>1,600,000句子,三类（正面、负面、中立）</td>
<td><a href="https://drive.google.com/uc?id=0B04GJPshIjmPRnZManQwWEdTZjg&export=download" target="_blank" rel="noopener">链接</a></td>
</tr>
</tbody></table>
<p>人脸数据集：<a href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html" target="_blank" rel="noopener">http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html</a></p>
<p><strong>From:</strong> <a href="https://www.cnblogs.com/xiaojianliu/p/9446358.html" target="_blank" rel="noopener">https://www.cnblogs.com/xiaojianliu/p/9446358.html</a></p>
<p>​        <a href="https://blog.csdn.net/weixin_41036461/article/details/80667690" target="_blank" rel="noopener">https://blog.csdn.net/weixin_41036461/article/details/80667690</a></p>
<h2 id="9-Car-Relative"><a href="#9-Car-Relative" class="headerlink" title="9. Car Relative"></a>9. Car Relative</h2><ul>
<li>江苏数林数据标注公司</li>
</ul>
<blockquote>
<p>江苏数林数据标注公司近期自主采集了30000名驾驶员动作行为数据集，类别含有12种：</p>
<p>抽烟，喝水，打电话，玩手机，回头拿东西，调广播，打瞌睡，连续眨眼挤眼睛，打哈欠，头连续转动，聊天，正常行驶，总共396万段视频，包括白天和晚上的。</p>
<p>标注类别 </p>
<ol>
<li>人脸关键点</li>
<li>手持物体框</li>
<li>人脸、人体框</li>
</ol>
</blockquote>

            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://liudongdong1.github.io" rel="external nofollow noreferrer">liudongdong1</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://liudongdong1.github.io/2020/07/13/shi-jue-yun-dong/dataset-record/">https://liudongdong1.github.io/2020/07/13/shi-jue-yun-dong/dataset-record/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint polocy. If reproduced, please indicate source
                    <a href="https://liudongdong1.github.io" target="_blank">liudongdong1</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Dataset/">
                                    <span class="chip bg-color">Dataset</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="qq,qzone,wechat,weibo,douban" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/2020/07/13/zi-ran-yu-yan/framework/nlp-pyspark/">
                    <div class="card-image">
                        
                        <img src="https://gitee.com/github-25970295/blogImage/raw/master/img/traffic-lights-in-city-at-night.jpg" class="responsive-img" alt="NLP_pyspark">
                        
                        <span class="card-title">NLP_pyspark</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            

1. Concept1.1. Estimators
The Estimators have a method called fit() which secures and trains a piece of data to such a
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2020-07-13
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/NLP/" class="post-category">
                                    NLP
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/pyspark/">
                        <span class="chip bg-color">pyspark</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2020/07/13/shen-jing-wang-luo/model/siamesenetwork/">
                    <div class="card-image">
                        
                        <img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201129135707833.png" class="responsive-img" alt="SiameseNetwork">
                        
                        <span class="card-title">SiameseNetwork</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
Siamese Network 是一种神经网络的框架，用于评估两个输入样本的相似度，而不是具体的某种网络，就像seq2seq一样，具体实现上可以使用RNN也可以使用CNN。

1. Siamese Network1.Paperlevel:
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-07-13
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Model/" class="post-category">
                                    Model
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Similarity/">
                        <span class="chip bg-color">Similarity</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <!-- <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="463294659"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2019</span>
            <a href="https://liudongdong1.github.io" target="_blank">liudongdong</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">1314.9k</span>&nbsp;字
            
            
            
            
            
            
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/liudongdong1/" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:3463264078@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>














    <a href="https://blog.csdn.net/liudongdong19/" class="tooltipped" target="_blank" data-tooltip="关注我的CSDN: https://blog.csdn.net/liudongdong19/" data-position="top" data-delay="50">
        <i class="fab fa-csdn">C</i>
    </a>





</div>
    </div>
</footer>

<div class="progress-bar"></div>
 -->

    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/search.xml", 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script type="text/javascript" src="/js/CFS.Snow.min.js"></script>
    <!-- 点击爆灯效果 -->
    <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas> 
    <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script> 
    <script type="text/javascript" src="/js/fireworks.js"></script>
    <!--动态线条背景-->
    <script type="text/javascript"
        color="122 103 238" opacity='0.7' zIndex="-2" count="200" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js">
    </script>
    <!-- 天气 -->
    <!-- weather -->
    <!-- weather -->
    <script type="text/javascript">
         WIDGET = {FID: 'knAMQaFanP'}
    </script>
    <script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"></script>
    <script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"></script>
    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    

    
    
    <script type="text/javascript" size="150" alpha='0.6'
        zIndex="-1" src="/libs/background/ribbon-refresh.min.js" async="async"></script>
    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    
    <!-- {% include '_custom/custom.swig' %} -->

</body>

</html>
