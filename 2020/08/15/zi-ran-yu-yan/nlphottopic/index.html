<!DOCTYPE HTML>
<html lang="en">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="NLPHotTopic, AIOT,Space&amp;Temporal Sequence Analysis,SpringBoot,liudongdong1,cloud">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>NLPHotTopic | DaybyDay</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="DaybyDay" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">DaybyDay</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>Tags</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">

      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/about">
          
          <i class="fas fa-user-circle" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>about</span>
        </a>
      </li>
      
      <li>
        <a href="/resume">
          
          <i class="fa fa-user-secret" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>resume</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>Friends</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/gallery" class="waves-effect waves-light">
      
      <i class="fas fa-camera" style="zoom: 0.6;"></i>
      
      <span>Galleries</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">DaybyDay</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			Tags
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-user-circle"></i>
			
			About
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/about " style="margin-left:75px">
				  
				   <i class="fa fas fa-user-circle" style="position: absolute;left:50px" ></i>
			      
		          <span>about</span>
                  </a>
                </li>
              
                <li>

                  <a href="/resume " style="margin-left:75px">
				  
				   <i class="fa fa fa-user-secret" style="position: absolute;left:50px" ></i>
			      
		          <span>resume</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			Friends
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/gallery" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-camera"></i>
			
			Galleries
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/liudongdong1" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/liudongdong1" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://gitee.com/github-25970295/blogImage/raw/master/img/20210501113138.png')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">NLPHotTopic</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    .toc-fixed .toc-link::before{
        position: fixed!important;/*当toc的位置改为fixed时，.toc-link::before也要改为fixed*/
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Semantic-Parsing/">
                                <span class="chip bg-color">Semantic Parsing</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/" class="post-category">
                                自然语言
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2020-08-15
                </div>
                

                <!-- 
                    <i class="fa fa-pencil"></i> Author: liudongdong1
                  -->

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>Update Date:&nbsp;&nbsp;
                    2021-06-21
                </div>
                

                <!-- 
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>Word Count:&nbsp;&nbsp;
                    3k
                </div>
                 -->

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>Read Times:&nbsp;&nbsp;
                    16 Min
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>Read Count:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>This week i get a summary knowledge of NLP, and learn some direction for further learning. And in this blog, i will record what i learned this weak by searching some information on Internet, the content is organized as follows: the Preparatory knowledge which need to be master in the following years, and some direction in NLP areas from model sides, application sides and the scene task, and some paper and learning resource recording.</p>
</blockquote>
<h3 id="0-Preparatory-knowledge"><a href="#0-Preparatory-knowledge" class="headerlink" title="0.  Preparatory knowledge"></a>0.  Preparatory knowledge</h3><ul>
<li>Probability&amp; Statistics</li>
</ul>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201008165645446.png" alt=""></p>
<ul>
<li><p><strong>Machine Learning</strong><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/ml.png" alt=""></p>
</li>
<li><p><strong>Text Mining</strong></p>
</li>
</ul>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/textmining.png" alt=""></p>
<ul>
<li><strong>NLP</strong></li>
</ul>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/prob.png" alt=""></p>
<h3 id="1-Model-sides"><a href="#1-Model-sides" class="headerlink" title="1. Model sides"></a>1. Model sides</h3><h4 id="1-1-Transformers-and-pre-trained-language-models"><a href="#1-1-Transformers-and-pre-trained-language-models" class="headerlink" title="1.1. Transformers and pre-trained language models"></a>1.1. Transformers and pre-trained language models</h4><ul>
<li>“Attention is all you need” (<a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">Vaswani et al., 2017</a>)</li>
<li>“BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding” (<a href="https://arxiv.org/abs/1810.04805" target="_blank" rel="noopener">Devlin et al., 2018</a>)</li>
</ul>
<blockquote>
<p><strong>Theory-proving side:</strong>  (<a href="https://arxiv.org/abs/2002.06622" target="_blank" rel="noopener">Shi et al., 2020</a>; <a href="https://arxiv.org/abs/1908.04211" target="_blank" rel="noopener">Brunner et al., 2020</a>; <a href="https://arxiv.org/abs/1912.10077" target="_blank" rel="noopener">Yun et al., 2019</a>; <a href="https://arxiv.org/abs/1911.03584" target="_blank" rel="noopener">Cordonnier et al., 2019</a>).</p>
</blockquote>
<blockquote>
<p><strong>improving the task performances of Transformers and pre-trained language models:</strong>(<a href="https://arxiv.org/abs/1908.04577" target="_blank" rel="noopener">Wang et al. 2019</a>; <a href="https://arxiv.org/abs/1909.11299" target="_blank" rel="noopener">Lee et al., 2019</a>).</p>
</blockquote>
<blockquote>
<p><strong>Reducing the size of models or the time of training:</strong>(<a href="https://arxiv.org/abs/2004.11886" target="_blank" rel="noopener">Wu et al., 2020</a>; <a href="https://arxiv.org/abs/1909.11942" target="_blank" rel="noopener">Lan et al., 2019</a>; <a href="https://arxiv.org/abs/2001.04451" target="_blank" rel="noopener">Kitaev et al., 2020</a>; <a href="https://arxiv.org/abs/2003.10555" target="_blank" rel="noopener">Clark et al., 2020</a>; <a href="https://arxiv.org/abs/1911.05507" target="_blank" rel="noopener">Rae et al., 2019</a>; <a href="https://arxiv.org/abs/1909.11556" target="_blank" rel="noopener">Fan et al., 2019</a>; <a href="https://arxiv.org/abs/1904.00962" target="_blank" rel="noopener">You et al., 2019</a>).</p>
<ul>
<li>Model Compression/Pruning (<a href="https://arxiv.org/abs/1912.00120" target="_blank" rel="noopener">Zhang et al., 2019</a>)</li>
</ul>
</blockquote>
<h4 id="1-2-Multilingual-Cross-lingual-tasks"><a href="#1-2-Multilingual-Cross-lingual-tasks" class="headerlink" title="1.2. Multilingual/Cross-lingual tasks:"></a>1.2. Multilingual/Cross-lingual tasks:</h4><ul>
<li>(<a href="https://arxiv.org/abs/1912.07840" target="_blank" rel="noopener">Karthikeyan et al., 2019</a>; <a href="https://openreview.net/forum?id=HyeYTgrFPB" target="_blank" rel="noopener">Berend 2020</a>; <a href="https://arxiv.org/abs/2002.03518" target="_blank" rel="noopener">Cao et al., 2020</a>; <a href="https://arxiv.org/abs/1910.04708" target="_blank" rel="noopener">Wang et al., 2019</a>)</li>
<li>Multimodal models(<a href="https://arxiv.org/abs/1908.08530" target="_blank" rel="noopener">Su et al., 2019</a>)</li>
<li><a href="https://openreview.net/forum?id=HJeT3yrtDr" target="_blank" rel="noopener"><strong>Cross-Lingual Ability of Multilingual BERT: An Empirical Study</strong></a></li>
<li><a href="https://openreview.net/forum?id=HJlnC1rKPB" target="_blank" rel="noopener"><strong>On the Relationship between Self-Attention and Convolutional Layers</strong></a></li>
</ul>
<h4 id="1-3-Reinforcement-learning-and-NLP"><a href="#1-3-Reinforcement-learning-and-NLP" class="headerlink" title="1.3. Reinforcement learning and NLP"></a>1.3. Reinforcement learning and NLP</h4><ul>
<li>(<a href="https://arxiv.org/abs/1906.02768" target="_blank" rel="noopener">Yu et al., 2019</a>; <a href="https://arxiv.org/abs/1909.00668" target="_blank" rel="noopener">Clift et al., 2019</a>)</li>
</ul>
<blockquote>
<p><strong>Session 4：The Machine Learning in NLP</strong></p>
<ul>
<li><p>Learning Sparse Sharing Architectures for Multiple Tasks</p>
</li>
<li><p>Reinforcement Learning from Imperfect Demonstrations under Soft Expert Guidance</p>
</li>
<li><p>Shapley Q-value: A Local Reward Approach to Solve Global Reward Games</p>
</li>
<li><p>Measuring and relieving the over-smoothing problem in graph neural networks from the topological view</p>
</li>
<li><p>Neighborhood Cognition Consistent Multi-Agent Reinforcement Learning</p>
</li>
<li><p>Neural Snowball for Few-Shot Relation Learning</p>
</li>
<li><p>Multi-Task Self-Supervised Learning for Disfluency Detection</p>
</li>
<li><p>Constructing Multiple Tasks for Augmentation: Improving Neural Image Classification With K-means Features</p>
</li>
<li><p>Graph-propagation based correlation learning for fine-grained image classification</p>
</li>
<li><p>End-to-End Bootstrapping Neural Network for Entity Set Expansion</p>
</li>
</ul>
</blockquote>
<h3 id="2-Application-sides"><a href="#2-Application-sides" class="headerlink" title="2. Application sides"></a>2. Application sides</h3><h4 id="2-1-Natural-language-generation"><a href="#2-1-Natural-language-generation" class="headerlink" title="2.1. Natural language generation"></a>2.1. Natural language generation</h4><ul>
<li>Generation of realistic, rhymed and theme based poetry (creative writing)</li>
<li>Generation of theme based short stories (creative writing)</li>
<li>Generation of theme based novels (creative writing)</li>
<li>Generation of news / short articles based on numerical / audio / video data</li>
<li>Generation of research papers based on a topic. </li>
</ul>
<h4 id="2-2-Natural-language-understanding"><a href="#2-2-Natural-language-understanding" class="headerlink" title="2.2. Natural language understanding"></a>2.2. Natural language understanding</h4><ul>
<li><strong>Sentiment Analysis</strong> </li>
</ul>
<blockquote>
<p>Deriving sentiments in sentences (positive, negative, neutral), and also in articles (though that will be more appropriate like bag of sentence sentiments). The future is to include emotions (attributes) in that, like the attributes now on Facebook posts - Love, Like, Angry, Surprised, Sad, Hilarious. These attributes make a lot more sense for sentiments going forward.</p>
</blockquote>
<ul>
<li><strong>Text Summarization（汇总）</strong></li>
</ul>
<blockquote>
<p>Summarizing a single or many articles according to a particular theme.</p>
</blockquote>
<ul>
<li><strong>Textual entailment（语篇蕴涵）</strong></li>
</ul>
<blockquote>
<p> Inferring directional causal relationships between textual fragments. This can be challenging in a long article.</p>
<ul>
<li>Towards Building a Multilingual Sememe Knowledge Base: Predicting Sememes for BabelNet Synsets</li>
<li>Multi-Scale Self-Attention for Text Classification</li>
<li>Learning Multi-level Dependencies for Robust Word Recognition</li>
</ul>
</blockquote>
<ul>
<li><strong>Information Extraction</strong> or <strong>Relationship Extraction</strong> or <strong>Knowledge Graph</strong></li>
</ul>
<blockquote>
<p>Find structured information from unstructured data, like entities, relationships, co-reference resolution. This at a basic level is very useful for algorithmic trading. An extension of this is a global form of extracting logic structures (first order and higher order).</p>
</blockquote>
<ul>
<li><strong>Topic Segmentation</strong></li>
</ul>
<blockquote>
<p>Topic Extraction (with regions). Normally, there will be overlapping regions.</p>
</blockquote>
<ul>
<li><font color="red"><strong>Question Answering</strong> or <strong>NLP-based voice assistant</strong></font></li>
</ul>
<blockquote>
<p>Answer the questions to both closed (specific) and open questions (subjective). Answers to subjective questions is the main challenge for the likes of realistic Virtual Assistants.</p>
<ul>
<li>Modeling Fluency and Faithfulness for Diverse Neural Machine Translation</li>
<li>Minimizing the Bag-of-Ngrams Difference for Non-Autoregressive Neural Machine Translation</li>
<li>Neural Machine Translation with Joint Representation</li>
<li>Task-Oriented Dialog Systems that Consider Multiple Appropriate Responses under the Same Context</li>
<li>A pre-training based personalized dialogue generation model with persona-sparse data</li>
<li>Knowledge Graph Grounded Goal Planning for Open-Domain Conversation Generation</li>
</ul>
</blockquote>
<ul>
<li><strong>Parsing</strong></li>
</ul>
<blockquote>
<p>Parsing natural language generally in the form a tree. This involves hierarchical segmentation of the language involving the grammar rules.</p>
</blockquote>
<ul>
<li><strong>Prediction</strong></li>
</ul>
<blockquote>
<p>Given a short text, predict what happens next. The prediction problem is beginning to be targeted in vision, but it has never ever gained paths for realistic products. For closed and deterministic prediction (not innovative else that would fall under the paradigm of creative writing), this can be a useful task for prediction of future events based on past evidences and analysis. This can be then very useful for finance sectors.</p>
</blockquote>
<ul>
<li><strong>Part of Speech Tagging(词性标注)</strong></li>
</ul>
<blockquote>
<p>Tagging words whether they are nouns, verbs or adjectives.</p>
</blockquote>
<ul>
<li><strong>Translation</strong></li>
</ul>
<blockquote>
<p>Translate one language to another. This can be very challenging given the nature of the language, and the grammar. Normally, under probabilistic models, this assumes that the underlying grammar is mostly the same, and thus, models normally fail for Sanskrit.</p>
</blockquote>
<ul>
<li><strong>Query Expansion</strong></li>
</ul>
<blockquote>
<p>Expand query in possible ways for making the search results more meaningful. This is normally an issue with search engines, where people do not know what all keywords (or query sentences) to include to cover the entire gamut of relevancy.</p>
</blockquote>
<ul>
<li><strong>Argumentation Mining(论证分析挖掘）</strong></li>
</ul>
<blockquote>
<p>Evolving field of NLP, where one wants to analyse discussions and arguments.</p>
</blockquote>
<ul>
<li><strong>Interestingness(趣味性挖掘）</strong></li>
</ul>
<h4 id="2-3-NLP-and-CV"><a href="#2-3-NLP-and-CV" class="headerlink" title="2. 3. NLP and CV"></a>2. 3. NLP and CV</h4><ul>
<li><strong>Visual Question Answering</strong></li>
<li><strong>Automated Image Captioning（自动图像字幕）</strong></li>
<li><strong>OCR</strong></li>
</ul>
<blockquote>
<ul>
<li>DualVD: An Adaptive Dual Encoding Model for Deep Visual  Understanding  in Visual Dialogue</li>
<li>Storytelling from an Image Stream Using Scene Graphs</li>
</ul>
</blockquote>
<h4 id="2-4-Voice-and-NLP"><a href="#2-4-Voice-and-NLP" class="headerlink" title="2.4. Voice and NLP"></a>2.4. Voice and NLP</h4><ul>
<li><strong>speech to text</strong></li>
</ul>
<blockquote>
<p>Analysts predict speech recognition technologies will be substantially improved in the near future thanks to natural language processing. This will involve minimization of errors, recognition of what several individuals are saying despite different accents and a noisy environment. </p>
</blockquote>
<h3 id="3-Scene-task"><a href="#3-Scene-task" class="headerlink" title="3. Scene task"></a>3. Scene task</h3><ul>
<li><p>Integrated Chatbot</p>
</li>
<li><p>Human-to-machine Interaction</p>
</li>
</ul>
<blockquote>
<p>conversing with a machine is as simple as conversing with a human. </p>
</blockquote>
<ul>
<li>Company monitoring</li>
</ul>
<blockquote>
<p>Banks and other monetary organizations can utilize NLP to find and parse client sentiment by checking social media and analyzing discussions about their services and strategies. With the capacity to get to significant, separated data, financial services analysts can compose increasingly definite reports and give better advice to customers and internal decision makers.</p>
</blockquote>
<ul>
<li>Business intelligence</li>
</ul>
<blockquote>
<p>getting business intelligence from raw business information, including product information, marketing and sales information, customer service, brand notoriety and the present talent pool of a company. This implies NLP will be the way to moving numerous legacy organizations from data-driven to intelligence-driven platforms, helping humankind rapidly get the insights to make decisions.</p>
</blockquote>
<blockquote>
<ul>
<li><p>搜索是NLP技术最早得到大规模应用的技术，例如百度搜索、知乎话题搜索以及各大互联网公司的query搜索技术，都涉及到语义匹配或文本分类技术。此外，大型的搜索引擎，知识图谱的搭建是必须的。</p>
</li>
<li><p>推荐系统在一定层面来说是跟搜索场景相反的。搜索是基于用户的意图，在文本库中寻找匹配项；推荐则相反，通常基于积累的用户信息，给用户推荐可能感兴趣的内容。推荐系统常常涉及用户画像、标签定义等过程，需要一定程度的依赖NLP技术。</p>
</li>
<li><p>聊天机器人是目前NLP技术应用最多的场景，基于NLP技术构建一个能够替代客服、销售、办公文员是这一任务的终极目标。目前，聊天机器人已经以各种形态出现在人们面前，有站在银行门口迎接顾客的迎宾机器人，有放在卧室床头的智能音箱，有呆在各个APP首页的助手机器人等等。在聊天机器人中，运用了文本分类、语义匹配、对话管理、实体识别等大量的NLP技术。要做好是一件难度大、超复杂的任务。</p>
</li>
<li><p>知识图谱是AI时代一个非常重要基础设施，大规模结构化的知识网络的搭建，能够重塑很多的智能场景。</p>
</li>
</ul>
</blockquote>
<h3 id="4-Paper-amp-Relative-Article"><a href="#4-Paper-amp-Relative-Article" class="headerlink" title="4. Paper &amp; Relative Article"></a>4. Paper &amp; Relative Article</h3><p><strong>4.1. Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context</strong></p>
<blockquote>
<p><strong>About:</strong> In this paper, researchers from Carnegie Mellon University and Google Brain proposed a novel neural architecture known as Transformer-XL that enables learning dependency beyond a fixed-length without disrupting temporal coherence. According to the researchers, TransformerXL learns dependency that is 80% longer than RNNs and 450% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation.</p>
</blockquote>
<p><strong>4.2. Bridging The Gap Between Training &amp; Inference For Neural Machine Translation</strong> </p>
<blockquote>
<p><strong>About:</strong> This paper is one of the top <a href="https://analyticsindiamag.com/6-top-nlp-papers-from-acl-2019-you-should-read/" target="_blank" rel="noopener">NLP papers</a> from the premier conference, Association for Computational Linguistics (ACL). This paper talks about the error accumulation during Neural Machine Translation. The researchers addressed such problems by sampling context words, not only from the ground truth sequence but also from the predicted sequence by the model during training, where the predicted sequence is selected with a sentence-level optimum. According to the researchers, this approach can achieve significant improvements in multiple datasets. </p>
</blockquote>
<p><strong>4.3. BERT: Pre-training Of Deep Bidirectional Transformers For Language Understanding</strong></p>
<blockquote>
<p>BERT by Google AI is one of the most popular language representation models. Several organisations, including Facebook as well as academia, have been researching NLP using this transformer model. BERT stands for Bidirectional Encoder Representations from Transformers and is designed to pre-train deep bidirectional representations from the unlabeled text by jointly conditioning on both left and right context in all layers. The model obtained new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5%, MultiNLI accuracy to 86.7%, and much more.</p>
</blockquote>
<p><strong>4.4. Emotion-Cause Pair Extraction: A New Task To Emotion Analysis In Texts</strong></p>
<blockquote>
<p>Emotion cause extraction (ECE) is a task that is aimed at extracting the potential causes behind certain emotions in text. In this paper, researchers from China proposed a new task known as emotion-cause pair extraction (ECPE), which aims to extract the potential pairs of emotions and corresponding causes in a document. The experimental results on a benchmark emotion cause corpus that prove the feasibility of the ECPE task as well as the effectiveness of this approach. </p>
</blockquote>
<p><strong>4.5. Improving Language Understanding By Generative Pre-Training</strong></p>
<blockquote>
<p>This paper is published by OpenAI, where the researchers talked about natural language understanding and how it can be challenging for discriminatively trained models to perform adequately. The researchers demonstrated the effectiveness of the approach on a wide range of benchmarks for natural language understanding. They proposed a general task-agnostic model, which outperformed discriminatively trained models that use architectures specifically crafted for each task, significantly improving upon state-of-the art in 9 out of the 12 tasks studied. </p>
</blockquote>
<p><strong>4.6. Neural Approaches To Conversational AI</strong> </p>
<blockquote>
<p> This research paper by Microsoft Research surveys neural approaches to conversational AI that have been developed in the last few years. In this paper, the researchers grouped conversational systems into three categories, which are question answering agents, task-oriented dialogue agents, and chatbots. For each category, a review of state-of-the-art neural approaches is presented, drawing the connection between them and traditional approaches, as well as discussing the progress that has been made and challenges still being faced, using specific systems and models as case studies.</p>
</blockquote>
<p><strong>Session 1：翻译、对话与文本生成</strong></p>
<p>(1) Modeling Fluency and Faithfulness for Diverse Neural Machine Translation</p>
<p>(2) Minimizing the Bag-of-Ngrams Difference for Non-Autoregressive Neural Machine Translation</p>
<p>(3) Task-Oriented Dialog Systems that Consider Multiple Appropriate Responses under the Same Context</p>
<p>(4) A pre-training based personalized dialogue generation model with persona-sparse data</p>
<p>(5) Synchronous Speech Recognition and Speech-to-Text Translation with Interactive Decoding</p>
<p>(6) SPARQA: Skeleton-based Semantic Parsing for Complex Questions over Knowledge Bases</p>
<p>(7) Knowledge Graph Grounded Goal Planning for Open-Domain Conversation Generation</p>
<p>(8) Neural Machine Translation with Joint Representation </p>
<p><strong>Session 2：文本分析与内容挖掘</strong></p>
<p>(9) Multi-Scale Self-Attention for Text Classification</p>
<p>(10) Learning Multi-level Dependencies for Robust Word Recognition</p>
<p>(11) Towards Building a Multilingual Sememe Knowledge Base: Predicting Sememes for BabelNet Synsets</p>
<p>(12) Cross-Lingual Low-Resource Set-to-Description Retrieval for Global E-Commerce</p>
<p>(13) Integrating Relation Constraints with Neural Relation Extractors</p>
<p>(14) Capturing Sentence Relations for Answer Sentence Selection with Multi-Perspective Graph Encoding</p>
<p>(15) Replicate, Walk, and Stop on Syntax: an Effective Neural Network Model for Aspect-Level Sentiment Classification</p>
<p>(16) Cross-Lingual Natural Language Generation via Pre-Training</p>
<p><strong>Session 3：知识理解与NLP应用</strong></p>
<p>(17) Hyperbolic Interaction Model For Hierarchical Multi-Label Classification</p>
<p>(18) Multi-channel Reverse Dictionary Model</p>
<p>(19) Discovering New Intents via Constrained Deep Adaptive Clustering with Cluster Refinement</p>
<p>(20) Logo-2K+: A Large-Scale Logo Dataset for Scalable Logo Classification</p>
<p>(21) DMRM: A Dual-channel Multi-hop Reasoning Model for Visual Dialog</p>
<p>(22) DualVD: An Adaptive Dual Encoding Model for Deep Visual  Understanding  in Visual Dialogue</p>
<p>(23) Storytelling from an Image Stream Using Scene Graphs</p>
<p>(24) Draft and Edit: Automatic Storytelling Through Multi-Pass Hierarchical Conditional Variational Autoencoder </p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649035757%26idx%3D1%26sn%3Dcaaf1d3f78e65a4df46fcffa0720f931%26chksm%3D8712ad90b065248603f8db9fbdc18a19ee2af5900bcc55ddc381833467ff1cb7e15120d504c1%26scene%3D21%23wechat_redirect">【NLP-词向量】词向量的由来及本质</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649035906%26idx%3D1%26sn%3D24df0e979ad2761a763c4f073ea92ac2%26chksm%3D8712aaffb06523e933148d4146cc343e12275ae91ea81710b4e2bab3bb6435e8d35b13223445%26scene%3D21%23wechat_redirect">【NLP-词向量】从模型结构到损失函数详解word2vec</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649034734%26idx%3D1%26sn%3D78b209c04b3f69387240efa1a904278e%26chksm%3D8712b193b0653885b808090c5c8e96ba4c7dac75fa013b1e4f72ef0027b6035155baae41c397%26scene%3D21%23wechat_redirect">【NLP】 聊聊NLP中的attention机制</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649034901%26idx%3D2%26sn%3D5a12aff786df3f305a5a05595fb6b8b8%26chksm%3D8712aee8b06527fee9a62c070313c47067e2bc00cb1a39b19401b4bf8d0e364eb88e28826667%26scene%3D21%23wechat_redirect">【NLP】 理解NLP中网红特征抽取器Tranformer</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649035055%26idx%3D1%26sn%3Dc49f6919ec8d0fef269f751680819edf%26chksm%3D8712af52b06526443ed01d2ec3bb9d8621ec4ef714b132dfa88020bbda268fdc22ab2e598f78%26scene%3D21%23wechat_redirect">【NLP】 深入浅出解析BERT原理及其表征的内容</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649035554%26idx%3D2%26sn%3D61cbd0046aa055b16dd2e74f6a625a4d%26chksm%3D8712ad5fb06524495d663310836fd222c9e89c002ff778cba7996c90c27ca4f41b85a050cd6b%26scene%3D21%23wechat_redirect">【NLP】GPT：第一个引入Transformer的预训练模型</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649035407%26idx%3D2%26sn%3De84f0f9f2c7458658514bf9a4e934324%26chksm%3D8712acf2b06525e41d82fbc5a9b60efeca91a0eec1a1f4c96f44800b30d2fe08fb0bf5f67917%26scene%3D21%23wechat_redirect">【NLP】XLnet：GPT和BERT的合体，博采众长，所以更强</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649036099%26idx%3D1%26sn%3D7671dfd7c4f748c3aa0d12f57956fabf%26chksm%3D8712ab3eb065222862a03a0f18ec62cce6a6a8166656a3477c7c2f492c9749b7b68b75679693%26scene%3D21%23wechat_redirect">【NLP-NER】什么是命名实体识别？</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649036142%26idx%3D1%26sn%3D00b0a2588b0e4eb1f67f4e0997562c53%26chksm%3D8712ab13b0652205517ecf622982410ab81dd22ff7bc23f0eed2c89525ce95d8cf851000efff%26scene%3D21%23wechat_redirect">【NLP-NER】命名实体识别中最常用的两种深度学习模型</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649036272%26idx%3D1%26sn%3D3ce6800462c6ea8d911909489bef4ed0%26chksm%3D8712ab8db065229bc8ea68f94332be9e03a06eb54b84c42d7e1ce8dc3d366a7e03035d0e3ae1%26scene%3D21%23wechat_redirect">【NLP-NER】如何使用BERT来做命名实体识别</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649036559%26idx%3D1%26sn%3D97bd5d699ceffd7f5f98b831cc26ec1b%26chksm%3D8712a972b065206481a853852939ba4c7f4e8a713197ca4f2c3b55e98fbeb405af339ea3644c%26scene%3D21%23wechat_redirect">【NLP实战系列】Tensorflow命名实体识别实战</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649035102%26idx%3D2%26sn%3D75957ee0aec259c1ada9b9015fc93828%26chksm%3D8712af23b0652635c255bd3e1c58d998e6b01cbd1513d8ce4e40e0a4dc0841560b1710699c54%26scene%3D21%23wechat_redirect">【每周NLP论文推荐】 NLP中命名实体识别从机器学习到深度学习的代表性研究</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649036470%26idx%3D1%26sn%3Dcc44bc3babdb25b959fb644975382156%26chksm%3D8712a8cbb06521dd17e2848a567b69b91b42baa4d0527186a64e0cbd059576bd99ee40e7ac86%26scene%3D21%23wechat_redirect">【NLP实战系列】朴素贝叶斯文本分类实战</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649036836%26idx%3D1%26sn%3Da4e0b73a4ed227b53c305494b848e094%26chksm%3D8712a659b0652f4fab5613d0c2a85da6ee898159d1648e13d5be4fc8484692334bced37d0dd7%26scene%3D21%23wechat_redirect">【NLP实战】基于ALBERT的文本相似度计算</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649037438%26idx%3D1%26sn%3Dc68e8734c19bade085f7a5a23a5401a7%26chksm%3D8712a403b0652d15b3c5d8a721c6a3a838e100118116a53c5d6a443daf05c9d285f950ce956c%26scene%3D21%23wechat_redirect">【文本信息抽取与结构化】目前NLP领域最有应用价值的子任务之一</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649037522%26idx%3D2%26sn%3D4c3b77627fd6a879d34781476bfd194f%26chksm%3D8712a4afb0652db964a5f7e1de3c927eb99ec0e9f5fad6588d4d1243f356392b4232ac3fc001%26scene%3D21%23wechat_redirect">【文本信息抽取与结构化】详聊文本的结构化【上】</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649037655%26idx%3D2%26sn%3Dd83d62d87227e34d9324faeb6d536cd1%26chksm%3D8712a52ab0652c3c6f28e08456ef9f740f2fbd42b4f46ca5f71914103a20b28a8bc88ad2497e%26scene%3D21%23wechat_redirect">【文本信息抽取与结构化】详聊文本的结构化【下】</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649037990%26idx%3D2%26sn%3D76b2b4c32f72aaddfec60a3a04dac90a%26chksm%3D8712a2dbb0652bcd9ae280267ca62bbe1f2c62430fca96534eb853db298efa1dc43f73e8a7bd%26scene%3D21%23wechat_redirect">【文本信息抽取与结构化】详聊如何用BERT实现关系抽取</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649035654%26idx%3D2%26sn%3Df9f8020da1faa66390c424c5faec3260%26chksm%3D8712adfbb06524ed14db1a5e35a62cb1db9ed7cf1b3298771969cf95731b1410ac08740891e2%26scene%3D21%23wechat_redirect">【每周NLP论文推荐】 掌握实体关系抽取必读的文章</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649036303%26idx%3D1%26sn%3D15d4cd20640fae64535ef5bff08ca1fa%26chksm%3D8712a872b065216466b0be4f44567c8470746c673f4113da0269a14f5342044f93a9b07d3e76%26scene%3D21%23wechat_redirect">【NLP-ChatBot】我们熟悉的聊天机器人都有哪几类？</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649036396%26idx%3D1%26sn%3D55370a63f225ae9d734fdc31dad5869f%26chksm%3D8712a811b0652107ef7152df9ee001cc90aafb4db332b88bcb29a5f3ca2c0da04b30250ecbb7%26scene%3D21%23wechat_redirect">【NLP-ChatBot】搜索引擎的最终形态之问答系统（FAQ）详述</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649036508%26idx%3D1%26sn%3Dddd9a454497b7a766ca7246448fe2eb2%26chksm%3D8712a8a1b06521b789ca66143391efef8ba88e243d306ce6a45040213ff31fb2493635f93994%26scene%3D21%23wechat_redirect">【NLP-ChatBot】能干活的聊天机器人-对话系统概述</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649036142%26idx%3D2%26sn%3Df3ce4c20b0827b9f08babfd225a93aa9%26chksm%3D8712ab13b065220512ebf7339b58395e04634081904e6e6fe3a20237051ef6c2a846972f1fb5%26scene%3D21%23wechat_redirect">【每周NLP论文推荐】 对话管理中的标志性论文介绍</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649035491%26idx%3D2%26sn%3D4ec519ce322949e9d5117bbfc7bd074e%26chksm%3D8712ac9eb0652588b7218a396140563553dc399e00136b6cd5403d675f852ef5a56616da3535%26scene%3D21%23wechat_redirect">【每周NLP论文推荐】 开发聊天机器人必读的重要论文</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649036786%26idx%3D1%26sn%3Dbf010d6a8c561b80d163f5c51598030f%26chksm%3D8712a98fb06520991297e3ac2b710643ce91d881d38d01cd9ba8ed80055826a1fcc9c14c0383%26scene%3D21%23wechat_redirect">【知识图谱】人工智能技术最重要基础设施之一，知识图谱你该学习的东西</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649036864%26idx%3D1%26sn%3D78c14394b20f80d481004cca5156a776%26chksm%3D8712a63db0652f2b513810ce6190c5bf1a7c98746f7d1188710cfa44d6249272a66aef893451%26scene%3D21%23wechat_redirect">【知识图谱】知识表示：知识图谱如何表示结构化的知识？</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649036959%26idx%3D1%26sn%3Ddce0df28080545324e40cabcb5c9e1e6%26chksm%3D8712a6e2b0652ff488e691c1db605570d6f4d888ac516548e843c9324e95e2ad42cb8fc7fe34%26scene%3D21%23wechat_redirect">【知识图谱】如何构建知识体系：知识图谱搭建的第一步</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649037188%26idx%3D1%26sn%3D2ac2099c02c1fadd2455a71601d3921f%26chksm%3D8712a7f9b0652eefaa14d21f186bfd0609ae220ed1a30dfc36a9dcc1fea26d4791ef47776553%26scene%3D21%23wechat_redirect">【知识图谱】获取到知识后，如何进行存储和便捷的检索？</a></p>
<p><a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649037252%26idx%3D1%26sn%3D668affc58c11e731ad2f2488311c3df4%26chksm%3D8712a7b9b0652eaf980bc40311cd20370e93f49904e08d788a20f51ab2878220a69bd84b3627%26scene%3D21%23wechat_redirect">【知识图谱】知识推理，知识图谱里最“人工智能”的一段</a></p>
<h3 id="5-Reference-amp-Learning-Resource"><a href="#5-Reference-amp-Learning-Resource" class="headerlink" title="5. Reference&amp;Learning Resource"></a>5. Reference&amp;Learning Resource</h3><ul>
<li><p><a href="https://github.com/graykode/nlp-roadmap" target="_blank" rel="noopener">https://github.com/graykode/nlp-roadmap</a></p>
</li>
<li><p><font color="red"><a href="https://github.com/ivan-bilan/The-NLP-Pandect" target="_blank" rel="noopener">A comprehensive reference for all topics related to Natural Language Processing</a></font></p>
</li>
<li><p><a href="https://github.com/keon/awesome-nlp" target="_blank" rel="noopener">A curated list of resources dedicated to Natural Language Processing</a></p>
</li>
<li><p><a href="https://github.com/yandexdataschool/nlp_course" target="_blank" rel="noopener">YSDA course in Natural Language Processing</a></p>
</li>
<li><p><a href="https://github.com/makcedward/nlp" target="_blank" rel="noopener">NLP Learning journey.</a></p>
</li>
<li><p><a href="https://github.com/lyeoni/nlp-tutorial" target="_blank" rel="noopener">NLP(Natural Language Processing) tutorials Pytorch example</a></p>
</li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://liudongdong1.github.io" rel="external nofollow noreferrer">liudongdong1</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://liudongdong1.github.io/2020/08/15/zi-ran-yu-yan/nlphottopic/">https://liudongdong1.github.io/2020/08/15/zi-ran-yu-yan/nlphottopic/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint polocy. If reproduced, please indicate source
                    <a href="https://liudongdong1.github.io" target="_blank">liudongdong1</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Semantic-Parsing/">
                                    <span class="chip bg-color">Semantic Parsing</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="qq,qzone,wechat,weibo,douban" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/2020/08/15/zi-ran-yu-yan/nlprelative/">
                    <div class="card-image">
                        
                        <img src="https://gitee.com/github-25970295/blogImage/raw/master/img/79.jpeg" class="responsive-img" alt="NLPRelative">
                        
                        <span class="card-title">NLPRelative</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
Semantic Parsing: aims to translate a natural languages sentence into its corresponding executable programming language
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2020-08-15
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/" class="post-category">
                                    自然语言
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Semantic-Parsing/">
                        <span class="chip bg-color">Semantic Parsing</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2020/08/15/zi-ran-yu-yan/framework/stanfordnlp-record/">
                    <div class="card-image">
                        
                        <img src="https://gitee.com/github-25970295/blogImage/raw/master/img/82.jpeg" class="responsive-img" alt="Standfordnlp">
                        
                        <span class="card-title">Standfordnlp</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
NLTK 是一款著名的 Python 自然语言处理(Natural Language Processing, NLP)工具包，在其收集的大量公开数据集、模型上提供了全面、易用的接口，涵盖了分词、词性标注(Part-Of-Speech ta
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-08-15
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/NLP/" class="post-category">
                                    NLP
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Stanfordnlp/">
                        <span class="chip bg-color">Stanfordnlp</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <!-- <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="463294659"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2019</span>
            <a href="https://liudongdong1.github.io" target="_blank">liudongdong</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">1413.5k</span>&nbsp;字
            
            
            
            
            
            
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/liudongdong1/" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:3463264078@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>














    <a href="https://blog.csdn.net/liudongdong19/" class="tooltipped" target="_blank" data-tooltip="关注我的CSDN: https://blog.csdn.net/liudongdong19/" data-position="top" data-delay="50">
        <i class="fab fa-csdn">C</i>
    </a>





</div>
    </div>
</footer>

<div class="progress-bar"></div>
 -->

    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/search.xml", 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script type="text/javascript" src="/js/CFS.Snow.min.js"></script>
    <!-- 点击爆灯效果 -->
    <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas> 
    <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script> 
    <script type="text/javascript" src="/js/fireworks.js"></script>
    <!--动态线条背景-->
    <script type="text/javascript"
        color="122 103 238" opacity='0.7' zIndex="-2" count="200" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js">
    </script>
    <!-- 天气 -->
    <!-- weather -->
    <!-- weather -->
    <script type="text/javascript">
         WIDGET = {FID: 'knAMQaFanP'}
    </script>
    <script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"></script>
    <script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"></script>
    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    

    
    
    <script type="text/javascript" size="150" alpha='0.6'
        zIndex="-1" src="/libs/background/ribbon-refresh.min.js" async="async"></script>
    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    
    <!-- {% include '_custom/custom.swig' %} -->

</body>

</html>
