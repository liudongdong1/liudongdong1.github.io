<!DOCTYPE HTML>
<html lang="en">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Standfordnlp, AIOT，Space&amp;Temporal Sequence Analysis，SpringBoot，liudongdong1 .etc">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Standfordnlp | DaybyDay</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="DaybyDay" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">DaybyDay</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>Tags</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">

      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/about">
          
          <i class="fas fa-user-circle" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>about</span>
        </a>
      </li>
      
      <li>
        <a href="/resume">
          
          <i class="fa fa-user-secret" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>resume</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>Friends</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">DaybyDay</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			Tags
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-user-circle"></i>
			
			About
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/about " style="margin-left:75px">
				  
				   <i class="fa fas fa-user-circle" style="position: absolute;left:50px" ></i>
			      
		          <span>about</span>
                  </a>
                </li>
              
                <li>

                  <a href="/resume " style="margin-left:75px">
				  
				   <i class="fa fa fa-user-secret" style="position: absolute;left:50px" ></i>
			      
		          <span>resume</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			Friends
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/liudongdong1" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/liudongdong1" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://gitee.com/github-25970295/blogImage/raw/master/img/82.jpeg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Standfordnlp</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    .toc-fixed .toc-link::before{
        position: fixed!important;/*当toc的位置改为fixed时，.toc-link::before也要改为fixed*/
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Stanfordnlp/">
                                <span class="chip bg-color">Stanfordnlp</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/" class="post-category">
                                自然语言
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2020-08-15
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>Update Date:&nbsp;&nbsp;
                    2021-06-21
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>Word Count:&nbsp;&nbsp;
                    5.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>Read Times:&nbsp;&nbsp;
                    24 Min
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>Read Count:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>NLTK 是一款著名的 Python 自然语言处理(Natural Language Processing, NLP)工具包，在其收集的大量公开数据集、模型上提供了全面、易用的接口，涵盖了分词、词性标注(Part-Of-Speech tag, POS-tag)、命名实体识别(Named Entity Recognition, NER)、句法分析(Syntactic Parse)等各项 NLP 领域的功能。</p>
</blockquote>
<blockquote>
<p>Stanford NLP 是由斯坦福大学的 NLP 小组开源的 Java 实现的 NLP 工具包，同样对 NLP 领域的各个问题提供了解决办法。斯坦福大学的 NLP 小组是世界知名的研究小组，如果能将 NLTK 和 Stanford NLP 这两个工具包结合起来使用，那自然是极好的！在 2004 年 Steve Bird 在 NLTK 中加上了对 Stanford NLP 工具包的支持，通过调用外部的 jar 文件来使用 Stanford NLP 工具包的功能。现在的 NLTK 中，通过封装提供了 Stanford NLP 中的以下几个功能:</p>
<ol>
<li>分词</li>
<li>词性标注</li>
<li>命名实体识别</li>
<li>句法分析</li>
<li>依存句法分析</li>
</ol>
</blockquote>
<h3 id="1-命名实体识别"><a href="#1-命名实体识别" class="headerlink" title="1. 命名实体识别"></a>1. 命名实体识别</h3><blockquote>
<p>命名实体识别（Named Entity Recognition，简称NER）是信息提取、问答系统、句法分析、机器翻译等应用领域的重要基础工具，在自然语言处理技术走向实用化的过程中占有重要地位。一般来说，<strong>命名实体识别的任务就是识别出待处理文本中三大类（实体类、时间类和数字类）、七小类（人名、机构名、地名、时间、日期、货币和百分比）命名实体。</strong></p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116085824037.png" alt=""></p>
<h3 id="1-1-NLTK"><a href="#1-1-NLTK" class="headerlink" title="1.1. NLTK"></a>1.1. NLTK</h3><pre class=" language-python"><code class="language-python">pip install nltk
<span class="token keyword">import</span> nltk
nltk<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116094247020.png" alt=""></p>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116094708285.png" alt=""></p>
<h4 id="1-1-1-语料库"><a href="#1-1-1-语料库" class="headerlink" title="1.1.1. 语料库"></a>1.1.1. 语料库</h4><table>
<thead>
<tr>
<th><strong>语料库</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>gutenberg</strong></td>
<td><strong>一个有若干万部的小说语料库，多是古典作品</strong></td>
</tr>
<tr>
<td><strong>webtext</strong></td>
<td><strong>收集的网络广告等内容</strong></td>
</tr>
<tr>
<td><strong>nps_chat</strong></td>
<td><strong>有上万条聊天消息语料库，即时聊天消息为主</strong></td>
</tr>
<tr>
<td><strong>brown</strong></td>
<td><strong>一个百万词级的英语语料库，按文体进行分类</strong></td>
</tr>
<tr>
<td><strong>reuters</strong></td>
<td><strong>路透社语料库，上万篇新闻方档，约有1百万字，分90个主题，并分为训练集和测试集两组</strong></td>
</tr>
<tr>
<td><strong>inaugural</strong></td>
<td><strong>演讲语料库，几十个文本，都是总统演说</strong></td>
</tr>
</tbody></table>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> nltk<span class="token punctuation">.</span>corpus <span class="token keyword">import</span> brown
<span class="token keyword">print</span><span class="token punctuation">(</span>brown<span class="token punctuation">.</span>categories<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#输出brown语料库的类别</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>len<span class="token punctuation">(</span>brown<span class="token punctuation">.</span>sents<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#输出brown语料库的句子数量</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>len<span class="token punctuation">(</span>brown<span class="token punctuation">.</span>words<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#输出brown语料库的词数量</span>

<span class="token triple-quoted-string string">'''
结果为：
['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 
'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 
'science_fiction']
57340
1161192
'''</span></code></pre>
<h4 id="1-1-2-词频统计-frequency"><a href="#1-1-2-词频统计-frequency" class="headerlink" title="1.1.2. 词频统计(frequency)"></a>1.1.2. 词频统计(frequency)</h4><table>
<thead>
<tr>
<th><strong>方法</strong></th>
<th><strong>作用</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>B()</strong></td>
<td><strong>返回词典的长度</strong></td>
</tr>
<tr>
<td><strong>plot(title,cumulative=False)</strong></td>
<td><strong>绘制频率分布图，若cumu为True，则是累积频率分布图</strong></td>
</tr>
<tr>
<td><strong>tabulate()</strong></td>
<td><strong>生成频率分布的表格形式</strong></td>
</tr>
<tr>
<td><strong>most_common()</strong></td>
<td><strong>返回出现次数最频繁的词与频度</strong></td>
</tr>
<tr>
<td><strong>hapaxes()</strong></td>
<td><strong>返回只出现过一次的词</strong></td>
</tr>
</tbody></table>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> nltk
tokens<span class="token operator">=</span><span class="token punctuation">[</span> <span class="token string">'my'</span><span class="token punctuation">,</span><span class="token string">'dog'</span><span class="token punctuation">,</span><span class="token string">'has'</span><span class="token punctuation">,</span><span class="token string">'flea'</span><span class="token punctuation">,</span><span class="token string">'problems'</span><span class="token punctuation">,</span><span class="token string">'help'</span><span class="token punctuation">,</span><span class="token string">'please'</span><span class="token punctuation">,</span>
         <span class="token string">'maybe'</span><span class="token punctuation">,</span><span class="token string">'not'</span><span class="token punctuation">,</span><span class="token string">'take'</span><span class="token punctuation">,</span><span class="token string">'him'</span><span class="token punctuation">,</span><span class="token string">'to'</span><span class="token punctuation">,</span><span class="token string">'dog'</span><span class="token punctuation">,</span><span class="token string">'park'</span><span class="token punctuation">,</span><span class="token string">'stupid'</span><span class="token punctuation">,</span>
         <span class="token string">'my'</span><span class="token punctuation">,</span><span class="token string">'dalmation'</span><span class="token punctuation">,</span><span class="token string">'is'</span><span class="token punctuation">,</span><span class="token string">'so'</span><span class="token punctuation">,</span><span class="token string">'cute'</span><span class="token punctuation">,</span><span class="token string">'I'</span><span class="token punctuation">,</span><span class="token string">'love'</span><span class="token punctuation">,</span><span class="token string">'him'</span>  <span class="token punctuation">]</span>
<span class="token comment" spellcheck="true">#统计词频</span>
freq <span class="token operator">=</span> nltk<span class="token punctuation">.</span>FreqDist<span class="token punctuation">(</span>tokens<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#输出词和相应的频率</span>
<span class="token keyword">for</span> key<span class="token punctuation">,</span>val <span class="token keyword">in</span> freq<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span> <span class="token punctuation">(</span>str<span class="token punctuation">(</span>key<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">':'</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>val<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#可以把最常用的5个单词拿出来</span>
standard_freq<span class="token operator">=</span>freq<span class="token punctuation">.</span>most_common<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>standard_freq<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#绘图函数为这些词频绘制一个图形</span>
freq<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> cumulative<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></code></pre>
<h4 id="1-1-3-停用分词-stopwords"><a href="#1-1-3-停用分词-stopwords" class="headerlink" title="1.1.3. 停用分词(stopwords)"></a>1.1.3. 停用分词(stopwords)</h4><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#英文停用分词</span>
<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>corpus <span class="token keyword">import</span> stopwords
tokens<span class="token operator">=</span><span class="token punctuation">[</span> <span class="token string">'my'</span><span class="token punctuation">,</span><span class="token string">'dog'</span><span class="token punctuation">,</span><span class="token string">'has'</span><span class="token punctuation">,</span><span class="token string">'flea'</span><span class="token punctuation">,</span><span class="token string">'problems'</span><span class="token punctuation">,</span><span class="token string">'help'</span><span class="token punctuation">,</span><span class="token string">'please'</span><span class="token punctuation">,</span>
         <span class="token string">'maybe'</span><span class="token punctuation">,</span><span class="token string">'not'</span><span class="token punctuation">,</span><span class="token string">'take'</span><span class="token punctuation">,</span><span class="token string">'him'</span><span class="token punctuation">,</span><span class="token string">'to'</span><span class="token punctuation">,</span><span class="token string">'dog'</span><span class="token punctuation">,</span><span class="token string">'park'</span><span class="token punctuation">,</span><span class="token string">'stupid'</span><span class="token punctuation">,</span>
         <span class="token string">'my'</span><span class="token punctuation">,</span><span class="token string">'dalmation'</span><span class="token punctuation">,</span><span class="token string">'is'</span><span class="token punctuation">,</span><span class="token string">'so'</span><span class="token punctuation">,</span><span class="token string">'cute'</span><span class="token punctuation">,</span><span class="token string">'I'</span><span class="token punctuation">,</span><span class="token string">'love'</span><span class="token punctuation">,</span><span class="token string">'him'</span>  <span class="token punctuation">]</span>
clean_tokens<span class="token operator">=</span>tokens<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
stwords<span class="token operator">=</span>stopwords<span class="token punctuation">.</span>words<span class="token punctuation">(</span><span class="token string">'english'</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> token <span class="token keyword">in</span> tokens<span class="token punctuation">:</span>
    <span class="token keyword">if</span> token <span class="token keyword">in</span> stwords<span class="token punctuation">:</span>
        clean_tokens<span class="token punctuation">.</span>remove<span class="token punctuation">(</span>token<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>clean_tokens<span class="token punctuation">)</span></code></pre>
<h4 id="1-1-4-分词-amp-amp-分句-tokenize"><a href="#1-1-4-分词-amp-amp-分句-tokenize" class="headerlink" title="1.1.4. 分词&amp;&amp;分句(tokenize)"></a>1.1.4. 分词&amp;&amp;分句(tokenize)</h4><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#--- 分句</span>
<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>tokenize <span class="token keyword">import</span> sent_tokenize
mytext <span class="token operator">=</span> <span class="token string">"Hello Adam, how are you? I hope everything is going well. Today is a good day, see you dude."</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>sent_tokenize<span class="token punctuation">(</span>mytext<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#--- 分词</span>
<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>tokenize <span class="token keyword">import</span> word_tokenize
mytext <span class="token operator">=</span> <span class="token string">"Hello Mr. Adam, how are you? I hope everything is going well. Today is a good day, see you dude."</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>word_tokenize<span class="token punctuation">(</span>mytext<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<h4 id="1-1-5-词干提取（Stemming"><a href="#1-1-5-词干提取（Stemming" class="headerlink" title="1.1.5. 词干提取（Stemming)"></a>1.1.5. 词干提取（Stemming)</h4><blockquote>
<p>单词词干提取就是<code>从单词中去除词缀并返回词根</code>。（<code>比方说 working 的词干是 work。</code>）搜索引擎在索引页面的时候使用这种技术，所以很多人通过同一个单词的不同形式进行搜索，返回的都是相同的，有关这个词干的页面。词干提取的算法有很多，但最常用的算法是 <strong>Porter 提取算法</strong>。NLTK 有一个 PorterStemmer 类，使用的就是 Porter 提取算法。</p>
</blockquote>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#    PorterStemmer算法</span>
<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>stem <span class="token keyword">import</span> PorterStemmer
porter_stemmer <span class="token operator">=</span> PorterStemmer<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>porter_stemmer<span class="token punctuation">.</span>stem<span class="token punctuation">(</span><span class="token string">'working'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#结果为：work </span>
<span class="token comment" spellcheck="true">#    LancasterStemmer算法</span>
<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>stem <span class="token keyword">import</span> LancasterStemmer
lancaster_stemmer <span class="token operator">=</span> LancasterStemmer<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>lancaster_stemmer<span class="token punctuation">.</span>stem<span class="token punctuation">(</span><span class="token string">'working'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#结果为：work </span></code></pre>
<h4 id="1-1-6-词干还原（Lemmatization）"><a href="#1-1-6-词干还原（Lemmatization）" class="headerlink" title="1.1.6. 词干还原（Lemmatization）"></a>1.1.6. 词干还原（Lemmatization）</h4><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#词形还原与词干提取类似， 但不同之处在于词干提取经常可能创造出不存在的词汇，词形还原的结果是一个真正的词汇</span>
<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>stem <span class="token keyword">import</span> WordNetLemmatizer
lemmatizer <span class="token operator">=</span> WordNetLemmatizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>lemmatizer<span class="token punctuation">.</span>lemmatize<span class="token punctuation">(</span><span class="token string">'playing'</span><span class="token punctuation">,</span> pos<span class="token operator">=</span><span class="token string">"v"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>lemmatizer<span class="token punctuation">.</span>lemmatize<span class="token punctuation">(</span><span class="token string">'playing'</span><span class="token punctuation">,</span> pos<span class="token operator">=</span><span class="token string">"n"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>lemmatizer<span class="token punctuation">.</span>lemmatize<span class="token punctuation">(</span><span class="token string">'playing'</span><span class="token punctuation">,</span> pos<span class="token operator">=</span><span class="token string">"a"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>lemmatizer<span class="token punctuation">.</span>lemmatize<span class="token punctuation">(</span><span class="token string">'playing'</span><span class="token punctuation">,</span> pos<span class="token operator">=</span><span class="token string">"r"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">'''
结果为：
play
playing
playing
playing
'''</span></code></pre>
<h4 id="1-1-7-词性标注（PosTag）"><a href="#1-1-7-词性标注（PosTag）" class="headerlink" title="1.1.7. 词性标注（PosTag）"></a>1.1.7. 词性标注（PosTag）</h4><blockquote>
<p><strong>词性标注是把一个句子中的单词标注为名词，形容词，动词等。</strong></p>
</blockquote>
<table>
<thead>
<tr>
<th><strong>标记（Tag）</strong></th>
<th><strong>含义（Meaning）</strong></th>
<th><strong>例子（Examples）</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>ADJ</strong></td>
<td><strong>形容词（adjective）</strong></td>
<td><strong>new，good，high，special，big</strong></td>
</tr>
<tr>
<td><strong>ADV</strong></td>
<td><strong>副词（adverb）</strong></td>
<td><strong>really,，already，still，early，now</strong></td>
</tr>
<tr>
<td><strong>CNJ</strong></td>
<td><strong>连词（conjunction）</strong></td>
<td><strong>and，or，but，if，while</strong></td>
</tr>
<tr>
<td><strong>DET</strong></td>
<td><strong>限定词（determiner）</strong></td>
<td><strong>the，a，some，most，every</strong></td>
</tr>
<tr>
<td><strong>EX</strong></td>
<td><strong>存在量词（existential）</strong></td>
<td><strong>there，there’s</strong></td>
</tr>
<tr>
<td><strong>FW</strong></td>
<td><strong>外来词（foreign word）</strong></td>
<td><strong>dolce，ersatz，esprit，quo，maitre</strong></td>
</tr>
<tr>
<td><strong>MOD</strong></td>
<td><strong>情态动词（modal verb）</strong></td>
<td><strong>will，can，would，may，must</strong></td>
</tr>
<tr>
<td><strong>N</strong></td>
<td><strong>名词（noun）</strong></td>
<td><strong>year，home，costs，time</strong></td>
</tr>
<tr>
<td><strong>NP</strong></td>
<td><strong>专有名词（proper noun）</strong></td>
<td><strong>Alison，Africa，April，Washington</strong></td>
</tr>
<tr>
<td><strong>NUM</strong></td>
<td><strong>数词（number）</strong></td>
<td><strong>twenty-four，fourth，1991，14:24</strong></td>
</tr>
<tr>
<td><strong>PRO</strong></td>
<td><strong>代词（pronoun）</strong></td>
<td><strong>he，their，her，its，my，I，us</strong></td>
</tr>
<tr>
<td><strong>P</strong></td>
<td><strong>介词（preposition）</strong></td>
<td><strong>on，of，at，with，by，into，under</strong></td>
</tr>
<tr>
<td><strong>TO</strong></td>
<td><strong>词 to（the word to）</strong></td>
<td><strong>to</strong></td>
</tr>
<tr>
<td><strong>UH</strong></td>
<td><strong>感叹词（interjection）</strong></td>
<td><strong>ah，bang，ha，whee，hmpf，oops</strong></td>
</tr>
<tr>
<td><strong>V</strong></td>
<td><strong>动词（verb）</strong></td>
<td><strong>is，has，get，do，make，see，run</strong></td>
</tr>
<tr>
<td><strong>VD</strong></td>
<td><strong>过去式（past tense）</strong></td>
<td><strong>said，took，told，made，asked</strong></td>
</tr>
<tr>
<td><strong>VG</strong></td>
<td><strong>现在分词（present participle）</strong></td>
<td><strong>making，going，playing，working</strong></td>
</tr>
<tr>
<td><strong>VN</strong></td>
<td><strong>过去分词（past participle）</strong></td>
<td><strong>given，taken，begun，sung</strong></td>
</tr>
<tr>
<td><strong>WH</strong></td>
<td><strong>wh限定词（wh determiner）</strong></td>
<td><strong>who，which，when，what，where</strong></td>
</tr>
</tbody></table>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> nltk
text<span class="token operator">=</span>nltk<span class="token punctuation">.</span>word_tokenize<span class="token punctuation">(</span><span class="token string">'what does the fox say'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>nltk<span class="token punctuation">.</span>pos_tag<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">'''
结果为：
['what', 'does', 'the', 'fox', 'say']
输出是元组列表，元组中的第一个元素是单词，第二个元素是词性标签
[('what', 'WDT'), ('does', 'VBZ'), ('the', 'DT'), ('fox', 'NNS'), ('say', 'VBP')]
'''</span></code></pre>
<h4 id="1-1-8-wordnet"><a href="#1-1-8-wordnet" class="headerlink" title="1.1.8. wordnet"></a>1.1.8. wordnet</h4><blockquote>
<p><strong>wordnet</strong> 是为自然语言处理构建的数据库。它包括部分词语的一个同义词组和一个简短的定义和反义词。</p>
</blockquote>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> nltk<span class="token punctuation">.</span>corpus <span class="token keyword">import</span> wordnet
syn <span class="token operator">=</span> wordnet<span class="token punctuation">.</span>synsets<span class="token punctuation">(</span><span class="token string">"pain"</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#获取“pain”的同义词集</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>syn<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>definition<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#定义</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>syn<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>examples<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 例句</span>

synonyms <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> syn <span class="token keyword">in</span> wordnet<span class="token punctuation">.</span>synsets<span class="token punctuation">(</span><span class="token string">'Computer'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> lemma <span class="token keyword">in</span> syn<span class="token punctuation">.</span>lemmas<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        synonyms<span class="token punctuation">.</span>append<span class="token punctuation">(</span>lemma<span class="token punctuation">.</span>name<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#同义词</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>synonyms<span class="token punctuation">)</span>


<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>corpus <span class="token keyword">import</span> wordnet
antonyms <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> syn <span class="token keyword">in</span> wordnet<span class="token punctuation">.</span>synsets<span class="token punctuation">(</span><span class="token string">"small"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> l <span class="token keyword">in</span> syn<span class="token punctuation">.</span>lemmas<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> l<span class="token punctuation">.</span>antonyms<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>   <span class="token comment" spellcheck="true">#判断是否是正确的反义词</span>
            antonyms<span class="token punctuation">.</span>append<span class="token punctuation">(</span>l<span class="token punctuation">.</span>antonyms<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>name<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>antonyms<span class="token punctuation">)</span></code></pre>
<h4 id="1-1-9-命名实体识别"><a href="#1-1-9-命名实体识别" class="headerlink" title="1.1.9.  命名实体识别"></a>1.1.9.  命名实体识别</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> re
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> nltk

<span class="token keyword">def</span> <span class="token function">parse_document</span><span class="token punctuation">(</span>document<span class="token punctuation">)</span><span class="token punctuation">:</span>
   document <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">,</span> document<span class="token punctuation">)</span>
   <span class="token keyword">if</span> isinstance<span class="token punctuation">(</span>document<span class="token punctuation">,</span> str<span class="token punctuation">)</span><span class="token punctuation">:</span>
       document <span class="token operator">=</span> document
   <span class="token keyword">else</span><span class="token punctuation">:</span>
       <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Document is not string!'</span><span class="token punctuation">)</span>
   document <span class="token operator">=</span> document<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
   sentences <span class="token operator">=</span> nltk<span class="token punctuation">.</span>sent_tokenize<span class="token punctuation">(</span>document<span class="token punctuation">)</span>
   sentences <span class="token operator">=</span> <span class="token punctuation">[</span>sentence<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> sentence <span class="token keyword">in</span> sentences<span class="token punctuation">]</span>
   <span class="token keyword">return</span> sentences

<span class="token comment" spellcheck="true"># sample document</span>
text <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
FIFA was founded in 1904 to oversee international competition among the national associations of Belgium, 
Denmark, France, Germany, the Netherlands, Spain, Sweden, and Switzerland. Headquartered in Zürich, its 
membership now comprises 211 national associations. Member countries must each also be members of one of 
the six regional confederations into which the world is divided: Africa, Asia, Europe, North &amp; Central America 
and the Caribbean, Oceania, and South America.
"""</span>

<span class="token comment" spellcheck="true"># tokenize sentences</span>
sentences <span class="token operator">=</span> parse_document<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
tokenized_sentences <span class="token operator">=</span> <span class="token punctuation">[</span>nltk<span class="token punctuation">.</span>word_tokenize<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span> <span class="token keyword">for</span> sentence <span class="token keyword">in</span> sentences<span class="token punctuation">]</span>
<span class="token comment" spellcheck="true"># tag sentences and use nltk's Named Entity Chunker</span>
tagged_sentences <span class="token operator">=</span> <span class="token punctuation">[</span>nltk<span class="token punctuation">.</span>pos_tag<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span> <span class="token keyword">for</span> sentence <span class="token keyword">in</span> tokenized_sentences<span class="token punctuation">]</span>
ne_chunked_sents <span class="token operator">=</span> <span class="token punctuation">[</span>nltk<span class="token punctuation">.</span>ne_chunk<span class="token punctuation">(</span>tagged<span class="token punctuation">)</span> <span class="token keyword">for</span> tagged <span class="token keyword">in</span> tagged_sentences<span class="token punctuation">]</span>
<span class="token comment" spellcheck="true"># extract all named entities</span>
named_entities <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> ne_tagged_sentence <span class="token keyword">in</span> ne_chunked_sents<span class="token punctuation">:</span>
   <span class="token keyword">for</span> tagged_tree <span class="token keyword">in</span> ne_tagged_sentence<span class="token punctuation">:</span>
       <span class="token comment" spellcheck="true"># extract only chunks having NE labels</span>
       <span class="token keyword">if</span> hasattr<span class="token punctuation">(</span>tagged_tree<span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
           entity_name <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>c<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> tagged_tree<span class="token punctuation">.</span>leaves<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#get NE name</span>
           entity_type <span class="token operator">=</span> tagged_tree<span class="token punctuation">.</span>label<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># get NE category</span>
           named_entities<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>entity_name<span class="token punctuation">,</span> entity_type<span class="token punctuation">)</span><span class="token punctuation">)</span>
           <span class="token comment" spellcheck="true"># get unique named entities</span>
           named_entities <span class="token operator">=</span> list<span class="token punctuation">(</span>set<span class="token punctuation">(</span>named_entities<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># store named entities in a data frame</span>
entity_frame <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>named_entities<span class="token punctuation">,</span> columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Entity Name'</span><span class="token punctuation">,</span> <span class="token string">'Entity Type'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># display results</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>entity_frame<span class="token punctuation">)</span></code></pre>
<ul>
<li>NLTK 中集成了standordnlp</li>
</ul>
<blockquote>
<p>StanfordNERTagger(‘./stanford-ner/classifiers/english.muc.7class.distsim.crf.ser.gz’,<br>                       path_to_jar=’./stanford-ner/stanford-ner.jar’)</p>
</blockquote>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> re
<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>tag <span class="token keyword">import</span> StanfordNERTagger
<span class="token keyword">import</span> os
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> nltk

<span class="token keyword">def</span> <span class="token function">parse_document</span><span class="token punctuation">(</span>document<span class="token punctuation">)</span><span class="token punctuation">:</span>
   document <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">,</span> document<span class="token punctuation">)</span>
   <span class="token keyword">if</span> isinstance<span class="token punctuation">(</span>document<span class="token punctuation">,</span> str<span class="token punctuation">)</span><span class="token punctuation">:</span>
       document <span class="token operator">=</span> document
   <span class="token keyword">else</span><span class="token punctuation">:</span>
       <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Document is not string!'</span><span class="token punctuation">)</span>
   document <span class="token operator">=</span> document<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
   sentences <span class="token operator">=</span> nltk<span class="token punctuation">.</span>sent_tokenize<span class="token punctuation">(</span>document<span class="token punctuation">)</span>
   sentences <span class="token operator">=</span> <span class="token punctuation">[</span>sentence<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> sentence <span class="token keyword">in</span> sentences<span class="token punctuation">]</span>
   <span class="token keyword">return</span> sentences

<span class="token comment" spellcheck="true"># sample document</span>
text <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
FIFA was founded in 1904 to oversee international competition among the national associations of Belgium, 
Denmark, France, Germany, the Netherlands, Spain, Sweden, and Switzerland. Headquartered in Zürich, its 
membership now comprises 211 national associations. Member countries must each also be members of one of 
the six regional confederations into which the world is divided: Africa, Asia, Europe, North &amp; Central America 
and the Caribbean, Oceania, and South America.
"""</span>
<span class="token comment" spellcheck="true">#C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Intel\Shared Libraries\redist\intel64\compiler;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\Git\cmd;C:\Users\dell\Anaconda3;C:\Users\dell\Anaconda3\Scripts;C:\Users\dell\Anaconda3\Library\bin;C:\Program Files\nodejs\;C:\Program Files (x86)\Microsoft SQL Server\110\Tools\Binn\;C:\Program Files\Microsoft SQL Server\110\Tools\Binn\;C:\Program Files\Microsoft SQL Server\110\DTS\Binn\;C:\Users\dell\AppData\Local\Android\Sdk\tools\;C:\Users\dell\AppData\Local\Android\Sdk\platform-tools\;D:\latex\texlive\2020\bin\win32;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\MATLAB\R2015b\runtime\win64;C:\Program Files\MATLAB\R2015b\bin;C:\Program Files\MATLAB\R2015b\polyspace\bin;C:\msys64\usr\bin;C:\Users\dell\Downloads\Programs\bazel-3.4.1-windows-x86_64_2.exe;</span>
sentences <span class="token operator">=</span> parse_document<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
tokenized_sentences <span class="token operator">=</span> <span class="token punctuation">[</span>nltk<span class="token punctuation">.</span>word_tokenize<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span> <span class="token keyword">for</span> sentence <span class="token keyword">in</span> sentences<span class="token punctuation">]</span>

<span class="token comment" spellcheck="true"># set java path in environment variables</span>
java_path <span class="token operator">=</span> r<span class="token string">'C:\Program Files (x86)\Common Files\Oracle\Java\javapath\java.exe'</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'JAVAHOME'</span><span class="token punctuation">]</span> <span class="token operator">=</span> java_path
<span class="token comment" spellcheck="true"># load stanford NER</span>
sn <span class="token operator">=</span> StanfordNERTagger<span class="token punctuation">(</span><span class="token string">'./stanford-ner/classifiers/english.muc.7class.distsim.crf.ser.gz'</span><span class="token punctuation">,</span>
                       path_to_jar<span class="token operator">=</span><span class="token string">'./stanford-ner/stanford-ner.jar'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># tag sentences</span>
ne_annotated_sentences <span class="token operator">=</span> <span class="token punctuation">[</span>sn<span class="token punctuation">.</span>tag<span class="token punctuation">(</span>sent<span class="token punctuation">)</span> <span class="token keyword">for</span> sent <span class="token keyword">in</span> tokenized_sentences<span class="token punctuation">]</span>
<span class="token comment" spellcheck="true"># extract named entities</span>
named_entities <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> sentence <span class="token keyword">in</span> ne_annotated_sentences<span class="token punctuation">:</span>
   temp_entity_name <span class="token operator">=</span> <span class="token string">''</span>
   temp_named_entity <span class="token operator">=</span> None
   <span class="token keyword">for</span> term<span class="token punctuation">,</span> tag <span class="token keyword">in</span> sentence<span class="token punctuation">:</span>
       <span class="token comment" spellcheck="true"># get terms with NE tags</span>
       <span class="token keyword">if</span> tag <span class="token operator">!=</span> <span class="token string">'O'</span><span class="token punctuation">:</span>
           temp_entity_name <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>temp_entity_name<span class="token punctuation">,</span> term<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#get NE name</span>
           temp_named_entity <span class="token operator">=</span> <span class="token punctuation">(</span>temp_entity_name<span class="token punctuation">,</span> tag<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># get NE and its category</span>
       <span class="token keyword">else</span><span class="token punctuation">:</span>
           <span class="token keyword">if</span> temp_named_entity<span class="token punctuation">:</span>
               named_entities<span class="token punctuation">.</span>append<span class="token punctuation">(</span>temp_named_entity<span class="token punctuation">)</span>
               temp_entity_name <span class="token operator">=</span> <span class="token string">''</span>
               temp_named_entity <span class="token operator">=</span> None

<span class="token comment" spellcheck="true"># get unique named entities</span>
named_entities <span class="token operator">=</span> list<span class="token punctuation">(</span>set<span class="token punctuation">(</span>named_entities<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># store named entities in a data frame</span>
entity_frame <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>named_entities<span class="token punctuation">,</span> columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Entity Name'</span><span class="token punctuation">,</span> <span class="token string">'Entity Type'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># display results</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>entity_frame<span class="token punctuation">)</span></code></pre>
<h4 id="1-1-10-文本分类"><a href="#1-1-10-文本分类" class="headerlink" title="1.1.10. 文本分类"></a>1.1.10. 文本分类</h4><h4 id="1-1-11-情感分类"><a href="#1-1-11-情感分类" class="headerlink" title="1.1.11. 情感分类"></a>1.1.11. 情感分类</h4><ul>
<li><a href="http://ir.dlut.edu.cn/EmotionOntologyDownload" target="_blank" rel="noopener">http://ir.dlut.edu.cn/EmotionOntologyDownload</a> </li>
</ul>
<h4 id="1-1-12-事件抽取"><a href="#1-1-12-事件抽取" class="headerlink" title="1.1.12. 事件抽取"></a>1.1.12. 事件抽取</h4><ul>
<li><a href="https://github.com/twjiang/fact_triple_extraction" target="_blank" rel="noopener">https://github.com/twjiang/fact_triple_extraction</a></li>
</ul>
<h2 id="2-StanfordNlp"><a href="#2-StanfordNlp" class="headerlink" title="2.StanfordNlp"></a>2.StanfordNlp</h2><blockquote>
<p>斯坦福 NER 标记器的一大优势是，为我们提供了几种不同的模型来提取命名实体。我们可以使用以下任何一个：</p>
<ul>
<li>三类模型，用于识别位置，人员和组织</li>
<li>四类模型，用于识别位置，人员，组织和杂项实体</li>
<li>七类模型，识别位置，人员，组织，时间，金钱，百分比和日期</li>
</ul>
</blockquote>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#!/usr/bin/env python</span>
<span class="token keyword">from</span> __future__ <span class="token keyword">import</span> print_function
<span class="token keyword">import</span> os
<span class="token keyword">import</span> pickle
<span class="token keyword">from</span> argparse <span class="token keyword">import</span> ArgumentParser
<span class="token keyword">from</span> platform <span class="token keyword">import</span> system
<span class="token keyword">from</span> subprocess <span class="token keyword">import</span> Popen
<span class="token keyword">from</span> sys <span class="token keyword">import</span> argv
<span class="token keyword">from</span> sys <span class="token keyword">import</span> stderr

<span class="token comment" spellcheck="true">#IS_WINDOWS = True if system() == 'Windows' else False</span>
JAVA_BIN_PATH <span class="token operator">=</span> <span class="token string">'java.exe'</span> <span class="token keyword">if</span> IS_WINDOWS <span class="token keyword">else</span> <span class="token string">'java'</span>
STANFORD_NER_FOLDER <span class="token operator">=</span> <span class="token string">'stanford-ner'</span>
<span class="token keyword">def</span> <span class="token function">arg_parse</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    arg_p <span class="token operator">=</span> ArgumentParser<span class="token punctuation">(</span><span class="token string">'Stanford NER Python Wrapper'</span><span class="token punctuation">)</span>
    arg_p<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'-f'</span><span class="token punctuation">,</span> <span class="token string">'--filename'</span><span class="token punctuation">,</span> type<span class="token operator">=</span>str<span class="token punctuation">,</span> default<span class="token operator">=</span>None<span class="token punctuation">)</span>
    arg_p<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'-v'</span><span class="token punctuation">,</span> <span class="token string">'--verbose'</span><span class="token punctuation">,</span> action<span class="token operator">=</span><span class="token string">'store_true'</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> arg_p
<span class="token keyword">def</span> <span class="token function">debug_print</span><span class="token punctuation">(</span>log<span class="token punctuation">,</span> verbose<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> verbose<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>log<span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">process_entity_relations</span><span class="token punctuation">(</span>entity_relations_str<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># format is ollie.</span>
    entity_relations <span class="token operator">=</span> list<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> s <span class="token keyword">in</span> entity_relations_str<span class="token punctuation">:</span>
        entity_relations<span class="token punctuation">.</span>append<span class="token punctuation">(</span>s<span class="token punctuation">[</span>s<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">"("</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span>s<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">")"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">';'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> entity_relations


<span class="token keyword">def</span> <span class="token function">stanford_ner</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> absolute_path<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
    out <span class="token operator">=</span> <span class="token string">'out.txt'</span>

    command <span class="token operator">=</span> <span class="token string">''</span>
    <span class="token keyword">if</span> absolute_path <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>
        command <span class="token operator">=</span> <span class="token string">'cd {};'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>absolute_path<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        filename <span class="token operator">=</span> <span class="token string">'../{}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>filename<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#java -mx1g -cp "*:lib/*" edu.stanford.nlp.ie.NERClassifierCombiner -textFile sample.txt -ner.model classifiers/english.all.3class.distsim.crf.ser.gz,classifiers/english.conll.4class.distsim.crf.ser.gz,classifiers/english.muc.7class.distsim.crf.ser.gz</span>
    command <span class="token operator">+=</span> <span class="token string">'cd {}; {} -mx1g -cp "*:lib/*" edu.stanford.nlp.ie.NERClassifierCombiner '</span> \
               <span class="token string">'-ner.model classifiers/english.all.3class.distsim.crf.ser.gz '</span> \
               <span class="token string">'-outputFormat tabbedEntities -textFile {} > ../{}'</span> \
        <span class="token punctuation">.</span>format<span class="token punctuation">(</span>STANFORD_NER_FOLDER<span class="token punctuation">,</span> JAVA_BIN_PATH<span class="token punctuation">,</span> filename<span class="token punctuation">,</span> out<span class="token punctuation">)</span>

    <span class="token keyword">if</span> verbose<span class="token punctuation">:</span>
        debug_print<span class="token punctuation">(</span><span class="token string">'Executing command = {}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>command<span class="token punctuation">)</span><span class="token punctuation">,</span> verbose<span class="token punctuation">)</span>
        java_process <span class="token operator">=</span> Popen<span class="token punctuation">(</span>command<span class="token punctuation">,</span> stdout<span class="token operator">=</span>stderr<span class="token punctuation">,</span> shell<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        java_process <span class="token operator">=</span> Popen<span class="token punctuation">(</span>command<span class="token punctuation">,</span> stdout<span class="token operator">=</span>stderr<span class="token punctuation">,</span> stderr<span class="token operator">=</span>open<span class="token punctuation">(</span>os<span class="token punctuation">.</span>devnull<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> shell<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    java_process<span class="token punctuation">.</span>wait<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">assert</span> <span class="token operator">not</span> java_process<span class="token punctuation">.</span>returncode<span class="token punctuation">,</span> <span class="token string">'ERROR: Call to stanford_ner exited with a non-zero code status.'</span>

    <span class="token keyword">if</span> absolute_path <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>
        out <span class="token operator">=</span> absolute_path <span class="token operator">+</span> out

    <span class="token keyword">with</span> open<span class="token punctuation">(</span>out<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> output_file<span class="token punctuation">:</span>
        results_str <span class="token operator">=</span> output_file<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
    os<span class="token punctuation">.</span>remove<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

    results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> res <span class="token keyword">in</span> results_str<span class="token punctuation">:</span>
        <span class="token keyword">if</span> len<span class="token punctuation">(</span>res<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
            split_res <span class="token operator">=</span> res<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span>
            entity_name <span class="token operator">=</span> split_res<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            entity_type <span class="token operator">=</span> split_res<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
            <span class="token keyword">if</span> len<span class="token punctuation">(</span>entity_name<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span> <span class="token operator">and</span> len<span class="token punctuation">(</span>entity_type<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
                results<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>entity_name<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> entity_type<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> verbose<span class="token punctuation">:</span>
        pickle<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>results_str<span class="token punctuation">,</span> open<span class="token punctuation">(</span><span class="token string">'out.pkl'</span><span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        debug_print<span class="token punctuation">(</span><span class="token string">'wrote to out.pkl'</span><span class="token punctuation">,</span> verbose<span class="token punctuation">)</span>
    <span class="token keyword">return</span> results
<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>
    arg_p <span class="token operator">=</span> arg_parse<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    filename <span class="token operator">=</span> arg_p<span class="token punctuation">.</span>filename
    verbose <span class="token operator">=</span> arg_p<span class="token punctuation">.</span>verbose
    debug_print<span class="token punctuation">(</span>arg_p<span class="token punctuation">,</span> verbose<span class="token punctuation">)</span>
    <span class="token keyword">if</span> filename <span class="token keyword">is</span> None<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'please provide a text file containing your input. Program will exit.'</span><span class="token punctuation">)</span>
        exit<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> verbose<span class="token punctuation">:</span>
        debug_print<span class="token punctuation">(</span><span class="token string">'filename = {}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">,</span> verbose<span class="token punctuation">)</span>
    entities <span class="token operator">=</span> stanford_ner<span class="token punctuation">(</span>filename<span class="token punctuation">,</span> verbose<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>entity<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>ljust<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'\t'</span> <span class="token operator">+</span> entity<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> entity <span class="token keyword">in</span> entities<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    exit<span class="token punctuation">(</span>main<span class="token punctuation">(</span>argv<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<h2 id="3-jieba-分词"><a href="#3-jieba-分词" class="headerlink" title="3. jieba 分词"></a>3. jieba 分词</h2><pre class=" language-shell"><code class="language-shell">pip3 install jieba
import jieba</code></pre>
<h3 id="3-1-分词"><a href="#3-1-分词" class="headerlink" title="3.1. 分词"></a>3.1. 分词</h3><blockquote>
<h5 id="jieba-cut-和jieba-lcut；-lcut-将返回的对象转化为list对象返回·"><a href="#jieba-cut-和jieba-lcut；-lcut-将返回的对象转化为list对象返回·" class="headerlink" title="jieba.cut 和jieba.lcut；  lcut 将返回的对象转化为list对象返回·"></a>jieba.cut 和jieba.lcut；  <code>lcut</code> 将返回的对象转化为<code>list对象</code>返回·</h5></blockquote>
<pre><code>def cut(self, sentence, cut_all=False, HMM=True, use_paddle=False):
# sentence: 需要分词的字符串;
# cut_all: 参数用来控制是否采用全模式；
# HMM: 参数用来控制是否使用 HMM 模型;
# use_paddle: 参数用来控制是否使用paddle模式下的分词模式，paddle模式采用延迟加载方式，通过enable_paddle接口安装paddlepaddle-tiny</code></pre><h6 id="1）精准模式（默认）"><a href="#1）精准模式（默认）" class="headerlink" title="1）精准模式（默认）:"></a>1）精准模式（默认）:</h6><blockquote>
<p>试图将句子最精确地切开，适合文本分析</p>
</blockquote>
<pre class=" language-python"><code class="language-python">seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span><span class="token string">"我来到北京清华大学"</span><span class="token punctuation">,</span> cut_all<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"精准模式: "</span> <span class="token operator">+</span> <span class="token string">"/ "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>seg_list<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 精确模式</span>
<span class="token comment" spellcheck="true"># -----output-----</span>
精准模式<span class="token punctuation">:</span> 我<span class="token operator">/</span> 来到<span class="token operator">/</span> 北京<span class="token operator">/</span> 清华大学</code></pre>
<h6 id="2）全模式"><a href="#2）全模式" class="headerlink" title="2）全模式:"></a>2）全模式:</h6><blockquote>
<p>把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义；</p>
</blockquote>
<pre class=" language-python"><code class="language-python">seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span><span class="token string">"我来到北京清华大学"</span><span class="token punctuation">,</span> cut_all<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"全模式: "</span> <span class="token operator">+</span> <span class="token string">"/ "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>seg_list<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 全模式</span>
<span class="token comment" spellcheck="true"># -----output-----</span>
全模式<span class="token punctuation">:</span> 我<span class="token operator">/</span> 来到<span class="token operator">/</span> 北京<span class="token operator">/</span> 清华<span class="token operator">/</span> 清华大学<span class="token operator">/</span> 华大<span class="token operator">/</span> 大学</code></pre>
<h6 id="3）paddle模式"><a href="#3）paddle模式" class="headerlink" title="3）paddle模式"></a>3）paddle模式</h6><blockquote>
<p>利用PaddlePaddle深度学习框架，训练序列标注（双向GRU）网络模型实现分词。同时支持词性标注。<br>paddle模式使用需安装paddlepaddle-tiny，pip install paddlepaddle-tiny==1.6.1。<br>目前paddle模式支持jieba v0.40及以上版本。<br>jieba v0.40以下版本，请升级jieba，pip installjieba –upgrade。 <a href="https://www.paddlepaddle.org.cn/" target="_blank" rel="noopener">PaddlePaddle官网</a></p>
</blockquote>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> jieba
<span class="token comment" spellcheck="true"># 通过enable_paddle接口安装paddlepaddle-tiny，并且import相关代码；</span>
jieba<span class="token punctuation">.</span>enable_paddle<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 初次使用可以自动安装并导入代码</span>
seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>str<span class="token punctuation">,</span> use_paddle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Paddle模式: '</span> <span class="token operator">+</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>list<span class="token punctuation">(</span>seg_list<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># -----output-----</span>
Paddle模式<span class="token punctuation">:</span> 我<span class="token operator">/</span>来到<span class="token operator">/</span>北京清华大学</code></pre>
<h3 id="3-2-搜索引擎模式"><a href="#3-2-搜索引擎模式" class="headerlink" title="3.2. 搜索引擎模式"></a>3.2. 搜索引擎模式</h3><blockquote>
<p>在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词</p>
</blockquote>
<pre class=" language-python"><code class="language-python">seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut_for_search<span class="token punctuation">(</span><span class="token string">"小明硕士毕业于中国科学院计算所，后在日本京都大学深造"</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 搜索引擎模式</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">", "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>seg_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># -----output-----</span>
小明<span class="token punctuation">,</span> 硕士<span class="token punctuation">,</span> 毕业<span class="token punctuation">,</span> 于<span class="token punctuation">,</span> 中国<span class="token punctuation">,</span> 科学<span class="token punctuation">,</span> 学院<span class="token punctuation">,</span> 科学院<span class="token punctuation">,</span> 中国科学院<span class="token punctuation">,</span> 计算<span class="token punctuation">,</span> 计算所<span class="token punctuation">,</span> ，<span class="token punctuation">,</span> 后<span class="token punctuation">,</span> 在<span class="token punctuation">,</span> 日本<span class="token punctuation">,</span> 京都<span class="token punctuation">,</span> 大学<span class="token punctuation">,</span> 日本京都大学<span class="token punctuation">,</span> 深造</code></pre>
<h5 id="1-jieba-Tokenizer-dictionary-DEFAULT-DICT"><a href="#1-jieba-Tokenizer-dictionary-DEFAULT-DICT" class="headerlink" title="1) jieba.Tokenizer(dictionary=DEFAULT_DICT)"></a>1) jieba.Tokenizer(dictionary=DEFAULT_DICT)</h5><blockquote>
<p>新建自定义分词器，可用于同时使用不同词典。jieba.dt 为默认分词器，所有全局分词相关函数都是该分词器的映射。</p>
</blockquote>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> jieba
test_sent <span class="token operator">=</span> <span class="token string">"永和服装饰品有限公司"</span>
<span class="token comment" spellcheck="true"># jieba.load_userdict(dict_path)    # dict_path为文件类对象或自定义词典的路径。</span>
result <span class="token operator">=</span> jieba<span class="token punctuation">.</span>tokenize<span class="token punctuation">(</span>test_sent<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">##Tokenize：返回词语在原文的起始位置</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span>
<span class="token keyword">for</span> tk <span class="token keyword">in</span> result<span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># print ("word %s\t\t start: %d \t\t end:%d" % (tk[0],tk[1],tk[2])    )</span>
    <span class="token keyword">print</span> <span class="token punctuation">(</span>tk<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># -----output-----</span>
<span class="token operator">&lt;</span>generator object Tokenizer<span class="token punctuation">.</span>tokenize at <span class="token number">0x7f6b68a69d58</span><span class="token operator">></span>
<span class="token punctuation">(</span><span class="token string">'永和'</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#词语、词频（可省略）、词性（可省略）</span>
<span class="token punctuation">(</span><span class="token string">'服装'</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token string">'饰品'</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token string">'有限公司'</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    </code></pre>
<h6 id="2）使用自定义词典文件"><a href="#2）使用自定义词典文件" class="headerlink" title="2）使用自定义词典文件"></a>2）使用自定义词典文件</h6><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> jieba

test_sent <span class="token operator">=</span> <span class="token string">"中信建投投资公司投资了一款游戏,中信也投资了一个游戏公司"</span>
jieba<span class="token punctuation">.</span>load_userdict<span class="token punctuation">(</span><span class="token string">"userdict.txt"</span><span class="token punctuation">)</span>
words <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>test_sent<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>list<span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#-----output------</span>
<span class="token punctuation">[</span><span class="token string">'中信建投'</span><span class="token punctuation">,</span> <span class="token string">'投资公司'</span><span class="token punctuation">,</span> <span class="token string">'投资'</span><span class="token punctuation">,</span> <span class="token string">'了'</span><span class="token punctuation">,</span> <span class="token string">'一款'</span><span class="token punctuation">,</span> <span class="token string">'游戏'</span><span class="token punctuation">,</span> <span class="token string">','</span><span class="token punctuation">,</span> <span class="token string">'中信'</span><span class="token punctuation">,</span> <span class="token string">'也'</span><span class="token punctuation">,</span> <span class="token string">'投资'</span><span class="token punctuation">,</span> <span class="token string">'了'</span><span class="token punctuation">,</span> <span class="token string">'一个'</span><span class="token punctuation">,</span> <span class="token string">'游戏'</span><span class="token punctuation">,</span> <span class="token string">'公司'</span><span class="token punctuation">]</span></code></pre>
<h6 id="3）使用-jieba-在程序中动态修改词典"><a href="#3）使用-jieba-在程序中动态修改词典" class="headerlink" title="3）使用 jieba 在程序中动态修改词典"></a>3）使用 jieba 在程序中动态修改词典</h6><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> jieba

<span class="token comment" spellcheck="true"># 定义示例句子</span>
test_sent <span class="token operator">=</span> <span class="token string">"中信建投投资公司投资了一款游戏,中信也投资了一个游戏公司"</span>
<span class="token comment" spellcheck="true">#添加词</span>
jieba<span class="token punctuation">.</span>add_word<span class="token punctuation">(</span><span class="token string">'中信建投'</span><span class="token punctuation">)</span>
jieba<span class="token punctuation">.</span>add_word<span class="token punctuation">(</span><span class="token string">'投资公司'</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 删除词</span>
jieba<span class="token punctuation">.</span>del_word<span class="token punctuation">(</span><span class="token string">'中信建投'</span><span class="token punctuation">)</span>
words <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>test_sent<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>list<span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#-----output------</span>
<span class="token punctuation">[</span><span class="token string">'中信'</span><span class="token punctuation">,</span> <span class="token string">'建投'</span><span class="token punctuation">,</span> <span class="token string">'投资公司'</span><span class="token punctuation">,</span> <span class="token string">'投资'</span><span class="token punctuation">,</span> <span class="token string">'了'</span><span class="token punctuation">,</span> <span class="token string">'一款'</span><span class="token punctuation">,</span> <span class="token string">'游戏'</span><span class="token punctuation">,</span> <span class="token string">','</span><span class="token punctuation">,</span> <span class="token string">'中信'</span><span class="token punctuation">,</span> <span class="token string">'也'</span><span class="token punctuation">,</span> <span class="token string">'投资'</span><span class="token punctuation">,</span> <span class="token string">'了'</span><span class="token punctuation">,</span> <span class="token string">'一个'</span><span class="token punctuation">,</span> <span class="token string">'游戏'</span><span class="token punctuation">,</span> <span class="token string">'公司'</span><span class="token punctuation">]</span></code></pre>
<h3 id="3-3-关键词提取"><a href="#3-3-关键词提取" class="headerlink" title="3.3. 关键词提取"></a>3.3. 关键词提取</h3><h6 id="1）TF-IDF接口和示例"><a href="#1）TF-IDF接口和示例" class="headerlink" title="1）TF-IDF接口和示例"></a>1）TF-IDF接口和示例</h6><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> jieba<span class="token punctuation">.</span>analyse</code></pre>
<ul>
<li><p>jieba.analyse.extract_tags(sentence, topK=20, withWeight=False,allowPOS=())</p>
<p>其中需要说明的是：</p>
<ul>
<li>1.sentence 为待提取的文本</li>
<li>2.topK 为返回几个 TF/IDF 权重最大的关键词，默认值为 20</li>
<li>3.withWeight 为是否一并返回关键词权重值，默认值为 False</li>
<li>4.allowPOS 仅包括指定词性的词，默认值为空，即不筛选</li>
</ul>
</li>
<li><p>jieba.analyse.TFIDF(idf_path=None) 新建 TFIDF 实例，idf_path 为 IDF 频率文件</p>
</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> jieba
<span class="token keyword">import</span> jieba<span class="token punctuation">.</span>analyse
<span class="token comment" spellcheck="true">#读取文件,返回一个字符串，使用utf-8编码方式读取，该文档位于此python同以及目录下</span>
content  <span class="token operator">=</span> open<span class="token punctuation">(</span><span class="token string">'data.txt'</span><span class="token punctuation">,</span><span class="token string">'r'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>
tags <span class="token operator">=</span> jieba<span class="token punctuation">.</span>analyse<span class="token punctuation">.</span>extract_tags<span class="token punctuation">(</span>content<span class="token punctuation">,</span>topK<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>withWeight<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>allowPOS<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">"nr"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
<span class="token keyword">print</span><span class="token punctuation">(</span>tags<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># ----output-------</span>
<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'虚竹'</span><span class="token punctuation">,</span> <span class="token number">0.20382572423643955</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'丐帮'</span><span class="token punctuation">,</span> <span class="token number">0.07839419568792882</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'什么'</span><span class="token punctuation">,</span> <span class="token number">0.07287469641815765</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'自己'</span><span class="token punctuation">,</span> <span class="token number">0.05838617200768695</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'师父'</span><span class="token punctuation">,</span> <span class="token number">0.05459680087740782</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'内力'</span><span class="token punctuation">,</span> <span class="token number">0.05353758008018405</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'大理'</span><span class="token punctuation">,</span> <span class="token number">0.04885277765801372</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'咱们'</span><span class="token punctuation">,</span> <span class="token number">0.04458784837687502</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'星宿'</span><span class="token punctuation">,</span> <span class="token number">0.04412126568280158</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'少林'</span><span class="token punctuation">,</span> <span class="token number">0.04207588649463058</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token number">123456789</span></code></pre>
<h6 id="2）Stop-Words"><a href="#2）Stop-Words" class="headerlink" title="2）Stop Words"></a>2）Stop Words</h6><ul>
<li>用法： jieba.analyse.set_stop_words(file_name) # file_name为自定义语料库的路径</li>
<li>自定义语料库示例：</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> jieba
<span class="token keyword">import</span> jieba<span class="token punctuation">.</span>analyse
<span class="token comment" spellcheck="true">#读取文件,返回一个字符串，使用utf-8编码方式读取，该文档位于此python同以及目录下</span>
content  <span class="token operator">=</span> open<span class="token punctuation">(</span>u<span class="token string">'data.txt'</span><span class="token punctuation">,</span><span class="token string">'r'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>
jieba<span class="token punctuation">.</span>analyse<span class="token punctuation">.</span>set_stop_words<span class="token punctuation">(</span><span class="token string">"stopwords.txt"</span><span class="token punctuation">)</span>
tags <span class="token operator">=</span> jieba<span class="token punctuation">.</span>analyse<span class="token punctuation">.</span>extract_tags<span class="token punctuation">(</span>content<span class="token punctuation">,</span> topK<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>tags<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<h3 id="3-4-词性标注"><a href="#3-4-词性标注" class="headerlink" title="3.4. 词性标注"></a>3.4. 词性标注</h3><ul>
<li>jieba.posseg.POSTokenizer(tokenizer=None) 新建自定义分词器，tokenizer参数可指定内部使用的 jieba.Tokenizer 分词器。 jieba.posseg.dt 为默认词性标注分词器。</li>
<li>标注句子分词后每个词的词性，采用和 ictclas 兼容的标记法。</li>
<li>用法示例</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> jieba<span class="token punctuation">.</span>posseg <span class="token keyword">as</span> pseg
words <span class="token operator">=</span> pseg<span class="token punctuation">.</span>cut<span class="token punctuation">(</span><span class="token string">"我爱北京天安门"</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> word<span class="token punctuation">,</span> flag <span class="token keyword">in</span> words<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'%s %s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>word<span class="token punctuation">,</span> flag<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># ----output--------</span>
我 r
爱 v
北京 ns
天安门 ns</code></pre>
<p><img src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201116165024512.png" alt=""></p>
<h2 id="4-nlp-pyltp"><a href="#4-nlp-pyltp" class="headerlink" title="4. nlp-pyltp"></a>4. nlp-pyltp</h2><blockquote>
<p>LTP 是哈工大社会计算与信息检索研究中心历时十年开发的一整套中文语言处理系统。LTP 制定了基于 XML 的语言处理结果表示，并在此基础上提供了一整套自底向上的丰富而且高效的中文语言处理模块 （包括词法、句法、语义等6项中文处理核心技术），以及基于动态链接库（Dynamic Link Library, DLL）的应用程序接口，可视化工具，并且能够以网络服务（Web Service）的形式进行使用。</p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116214442582.png" alt=""></p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 分句子</span>
<span class="token keyword">from</span> pyltp <span class="token keyword">import</span> SentenceSplitter
sents <span class="token operator">=</span> SentenceSplitter<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'元芳你怎么看？我就趴窗口上看呗！'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 分句</span>
<span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>sents<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#---- 分词</span>
<span class="token keyword">import</span> os
<span class="token keyword">from</span> pyltp <span class="token keyword">import</span> Segmentor
LTP_DATA_DIR <span class="token operator">=</span> <span class="token string">'./ltp_data_v3.4.0'</span>  <span class="token comment" spellcheck="true"># ltp模型目录的路径</span>
cws_model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>LTP_DATA_DIR<span class="token punctuation">,</span> <span class="token string">'cws.model'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 分词模型路径，模型名称为`cws.model`</span>
segmentor <span class="token operator">=</span> Segmentor<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 初始化实例</span>
segmentor<span class="token punctuation">.</span>load<span class="token punctuation">(</span>cws_model_path<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 加载模型</span>
word1 <span class="token operator">=</span> segmentor<span class="token punctuation">.</span>segment<span class="token punctuation">(</span><span class="token string">'中信建投证券投资有限公司'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 分词</span>
word2 <span class="token operator">=</span> segmentor<span class="token punctuation">.</span>segment<span class="token punctuation">(</span><span class="token string">'中信今天投资了一款游戏'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 分词</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>word1<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>word1<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>word2<span class="token punctuation">)</span><span class="token punctuation">)</span>
segmentor<span class="token punctuation">.</span>release<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 释放模型</span></code></pre>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 词性标注</span>
<span class="token keyword">import</span> os
LTP_DATA_DIR <span class="token operator">=</span> <span class="token string">'./ltp_data_v3.4.0'</span>  <span class="token comment" spellcheck="true"># ltp模型目录的路径</span>
pos_model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>LTP_DATA_DIR<span class="token punctuation">,</span> <span class="token string">'pos.model'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 词性标注模型路径，模型名称为`pos.model`</span>

<span class="token keyword">from</span> pyltp <span class="token keyword">import</span> Postagger
postagger <span class="token operator">=</span> Postagger<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 初始化实例</span>
postagger<span class="token punctuation">.</span>load<span class="token punctuation">(</span>pos_model_path<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 加载模型</span>

word1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"中信建投"</span><span class="token punctuation">,</span><span class="token string">"证券"</span><span class="token punctuation">,</span><span class="token string">"投资"</span><span class="token punctuation">,</span><span class="token string">"有限公司"</span><span class="token punctuation">]</span>
word2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"中信"</span><span class="token punctuation">,</span><span class="token string">"    今天"</span><span class="token punctuation">,</span><span class="token string">"投资"</span><span class="token punctuation">,</span><span class="token string">"了"</span><span class="token punctuation">,</span><span class="token string">"一款"</span><span class="token punctuation">,</span><span class="token string">"游戏"</span><span class="token punctuation">]</span>

postags1 <span class="token operator">=</span> postagger<span class="token punctuation">.</span>postag<span class="token punctuation">(</span>word1<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 词性标注</span>
postags2 <span class="token operator">=</span> postagger<span class="token punctuation">.</span>postag<span class="token punctuation">(</span>word2<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 词性标注</span>

<span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>postags1<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>postags2<span class="token punctuation">)</span><span class="token punctuation">)</span>

postagger<span class="token punctuation">.</span>release<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 释放模型</span></code></pre>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#--   命名实体识别</span>
<span class="token keyword">import</span> os
LTP_DATA_DIR <span class="token operator">=</span> <span class="token string">'./ltp_data_v3.4.0'</span>  <span class="token comment" spellcheck="true"># ltp模型目录的路径</span>
ner_model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>LTP_DATA_DIR<span class="token punctuation">,</span> <span class="token string">'ner.model'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 命名实体识别模型路径，模型名称为`pos.model`</span>
<span class="token keyword">from</span> pyltp <span class="token keyword">import</span> NamedEntityRecognizer
recognizer <span class="token operator">=</span> NamedEntityRecognizer<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 初始化实例</span>
recognizer<span class="token punctuation">.</span>load<span class="token punctuation">(</span>ner_model_path<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 加载模型</span>
word1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"中信建投"</span><span class="token punctuation">,</span><span class="token string">"证券"</span><span class="token punctuation">,</span><span class="token string">"投资"</span><span class="token punctuation">,</span><span class="token string">"有限公司"</span><span class="token punctuation">]</span>
word2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"中信"</span><span class="token punctuation">,</span><span class="token string">"今天"</span><span class="token punctuation">,</span><span class="token string">"投资"</span><span class="token punctuation">,</span><span class="token string">"了"</span><span class="token punctuation">,</span><span class="token string">"一款"</span><span class="token punctuation">,</span><span class="token string">"游戏"</span><span class="token punctuation">]</span>
postags1  <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"j"</span><span class="token punctuation">,</span><span class="token string">"n"</span><span class="token punctuation">,</span><span class="token string">"v"</span><span class="token punctuation">,</span><span class="token string">"n"</span><span class="token punctuation">]</span>
postags2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"j"</span><span class="token punctuation">,</span><span class="token string">"nt"</span><span class="token punctuation">,</span><span class="token string">"v"</span><span class="token punctuation">,</span><span class="token string">"u"</span><span class="token punctuation">,</span><span class="token string">"m"</span><span class="token punctuation">,</span><span class="token string">"n"</span><span class="token punctuation">]</span>
netags1 <span class="token operator">=</span> recognizer<span class="token punctuation">.</span>recognize<span class="token punctuation">(</span>word1<span class="token punctuation">,</span> postags1<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 命名实体识别</span>
netags2 <span class="token operator">=</span> recognizer<span class="token punctuation">.</span>recognize<span class="token punctuation">(</span>word2<span class="token punctuation">,</span> postags2<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 命名实体识别</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>netags1<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>netags2<span class="token punctuation">)</span><span class="token punctuation">)</span>
recognizer<span class="token punctuation">.</span>release<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 释放模型</span></code></pre>
<blockquote>
<p><code>依存句法</code> (Dependency Parsing, DP) 通过分析语言单位内成分之间的依存关系揭示其句法结构。 直观来讲，依存句法分析识别句子中的<code>“主谓宾”、“定状补”</code>这些语法成分，并分析<code>各成分之间的关 系</code>。</p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116215205218.png" alt=""></p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 1）依存句法分析</span>
<span class="token keyword">import</span> os
LTP_DATA_DIR <span class="token operator">=</span> <span class="token string">'./ltp_data_v3.4.0'</span>  <span class="token comment" spellcheck="true"># ltp模型目录的路径</span>
par_model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>LTP_DATA_DIR<span class="token punctuation">,</span> <span class="token string">'parser.model'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 依存句法分析模型路径，模型名称为`parser.model`</span>

<span class="token keyword">from</span> pyltp <span class="token keyword">import</span> Parser
parser <span class="token operator">=</span> Parser<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 初始化实例</span>
parser<span class="token punctuation">.</span>load<span class="token punctuation">(</span>par_model_path<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 加载模型</span>

words <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'中信建投'</span><span class="token punctuation">,</span> <span class="token string">'证券'</span><span class="token punctuation">,</span> <span class="token string">'投资'</span><span class="token punctuation">,</span> <span class="token string">'有限公司'</span><span class="token punctuation">,</span><span class="token string">"今天"</span><span class="token punctuation">,</span><span class="token string">"投资"</span><span class="token punctuation">,</span><span class="token string">"了"</span><span class="token punctuation">,</span><span class="token string">"一款"</span><span class="token punctuation">,</span><span class="token string">"雷人"</span><span class="token punctuation">,</span><span class="token string">"游戏"</span><span class="token punctuation">]</span>
postags <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"j"</span><span class="token punctuation">,</span><span class="token string">"n"</span><span class="token punctuation">,</span><span class="token string">"v"</span><span class="token punctuation">,</span><span class="token string">"n"</span><span class="token punctuation">,</span><span class="token string">"nt"</span><span class="token punctuation">,</span><span class="token string">"v"</span><span class="token punctuation">,</span><span class="token string">"u"</span><span class="token punctuation">,</span><span class="token string">"m"</span><span class="token punctuation">,</span><span class="token string">"n"</span><span class="token punctuation">,</span><span class="token string">"n"</span><span class="token punctuation">]</span>
arcs <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse<span class="token punctuation">(</span>words<span class="token punctuation">,</span> postags<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 句法分析</span>
<span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">"%d:%s"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>arc<span class="token punctuation">.</span>head<span class="token punctuation">,</span> arc<span class="token punctuation">.</span>relation<span class="token punctuation">)</span> <span class="token keyword">for</span> arc <span class="token keyword">in</span> arcs<span class="token punctuation">)</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>release<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 释放模型</span>

<span class="token comment" spellcheck="true"># 2）语义角色标注</span>
<span class="token keyword">import</span> os
LTP_DATA_DIR <span class="token operator">=</span> <span class="token string">'./ltp_data_v3.4.0'</span>  <span class="token comment" spellcheck="true"># ltp模型目录的路径</span>
srl_model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>LTP_DATA_DIR<span class="token punctuation">,</span> <span class="token string">'pisrl.model'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 语义角色标注模型目录路径，模型目录为`srl`。注意该模型路径是一个目录，而不是一个文件。</span>
<span class="token keyword">from</span> pyltp <span class="token keyword">import</span> SementicRoleLabeller
labeller <span class="token operator">=</span> SementicRoleLabeller<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 初始化实例</span>
labeller<span class="token punctuation">.</span>load<span class="token punctuation">(</span>srl_model_path<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 加载模型</span>
words <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'中信建投'</span><span class="token punctuation">,</span> <span class="token string">'证券'</span><span class="token punctuation">,</span> <span class="token string">'投资'</span><span class="token punctuation">,</span> <span class="token string">'有限公司'</span><span class="token punctuation">,</span><span class="token string">"今天"</span><span class="token punctuation">,</span><span class="token string">"投资"</span><span class="token punctuation">,</span><span class="token string">"了"</span><span class="token punctuation">,</span><span class="token string">"一款"</span><span class="token punctuation">,</span><span class="token string">"雷人"</span><span class="token punctuation">,</span><span class="token string">"游戏"</span><span class="token punctuation">]</span>
postags <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"j"</span><span class="token punctuation">,</span><span class="token string">"n"</span><span class="token punctuation">,</span><span class="token string">"v"</span><span class="token punctuation">,</span><span class="token string">"n"</span><span class="token punctuation">,</span><span class="token string">"nt"</span><span class="token punctuation">,</span><span class="token string">"v"</span><span class="token punctuation">,</span><span class="token string">"u"</span><span class="token punctuation">,</span><span class="token string">"m"</span><span class="token punctuation">,</span><span class="token string">"n"</span><span class="token punctuation">,</span><span class="token string">"n"</span><span class="token punctuation">]</span>
<span class="token comment" spellcheck="true"># arcs 使用依存句法分析的结果</span>
roles <span class="token operator">=</span> labeller<span class="token punctuation">.</span>label<span class="token punctuation">(</span>words<span class="token punctuation">,</span> postags<span class="token punctuation">,</span> arcs<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 语义角色标注</span>
<span class="token comment" spellcheck="true"># 打印结果</span>
<span class="token keyword">for</span> role <span class="token keyword">in</span> roles<span class="token punctuation">:</span>
    <span class="token keyword">print</span> <span class="token punctuation">(</span>role<span class="token punctuation">.</span>index<span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"%s:(%d,%d)"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>arg<span class="token punctuation">.</span>name<span class="token punctuation">,</span> arg<span class="token punctuation">.</span>range<span class="token punctuation">.</span>start<span class="token punctuation">,</span> arg<span class="token punctuation">.</span>range<span class="token punctuation">.</span>end<span class="token punctuation">)</span> <span class="token keyword">for</span> arg <span class="token keyword">in</span> role<span class="token punctuation">.</span>arguments<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
labeller<span class="token punctuation">.</span>release<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 释放模型</span></code></pre>
<blockquote>
<p><code>语义角色标注 (Semantic Role Labeling, SRL)</code>是一种浅层的语义分析技术，标注句子中某些短语为给定谓词的论元 (语义角色) ，如施事、受事、时间和地点等。其能够对问答系统、信息抽取和机器翻译等应用产生推动作用。</p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116215730714.png" alt=""></p>
<blockquote>
<p><code>语义依存分析 (Semantic Dependency Parsing, SDP)</code>，分析句子各个语言单位之间的语义关联，并将语义关联以依存结构呈现。 使用语义依存刻画句子语义，好处在于不需要去抽象词汇本身，而是通过词汇所承受的语义框架来描述该词汇，而论元的数目相对词汇来说数量总是少了很多的。语义依存分析目标是跨越句子表层句法结构的束缚，直接获取深层的语义信息。</p>
</blockquote>
<p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201116220050224.png" alt=""></p>
<h2 id="5-学习链接"><a href="#5-学习链接" class="headerlink" title="5. 学习链接"></a>5. 学习链接</h2><ul>
<li><p><a href="http://www.ltp-cloud.com/intro#dp_how" target="_blank" rel="noopener">http://www.ltp-cloud.com/intro#dp_how</a></p>
</li>
<li><p><a href="http://www.ltp-cloud.com/document2#api2_python_interface" target="_blank" rel="noopener">http://www.ltp-cloud.com/document2#api2_python_interface</a></p>
</li>
<li><p><a href="http://www.ltp-cloud.com/blog/" target="_blank" rel="noopener">技术博客</a></p>
</li>
<li><p><a href="http://nlp.stanford.edu:8080/ner/process" target="_blank" rel="noopener">Stanfordnlp</a></p>
</li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://liudongdong1.github.io" rel="external nofollow noreferrer">liudongdong1</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://liudongdong1.github.io/2020/08/15/nlp/framework/stanfordnlp-record/">https://liudongdong1.github.io/2020/08/15/nlp/framework/stanfordnlp-record/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint polocy. If reproduced, please indicate source
                    <a href="https://liudongdong1.github.io" target="_blank">liudongdong1</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Stanfordnlp/">
                                    <span class="chip bg-color">Stanfordnlp</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="qq,qzone,wechat,weibo,douban" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/2020/08/15/nlp/nlprelative/">
                    <div class="card-image">
                        
                        <img src="https://gitee.com/github-25970295/blogImage/raw/master/img/79.jpeg" class="responsive-img" alt="NLPRelative">
                        
                        <span class="card-title">NLPRelative</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
Semantic Parsing: aims to translate a natural languages sentence into its corresponding executable programming language
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2020-08-15
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/" class="post-category">
                                    自然语言
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Semantic-Parsing/">
                        <span class="chip bg-color">Semantic Parsing</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2020/08/14/ruan-jian-gong-ju/picturecompress/">
                    <div class="card-image">
                        
                        <img src="https://gitee.com/github-25970295/blogImage/raw/master/img/13.jpeg" class="responsive-img" alt="PictureCompress">
                        
                        <span class="card-title">PictureCompress</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
1. 鲁班图片压缩算法from PIL import Image
import os
from shutil import copyfile
from math import ceil
class Luban(object):
    d
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-08-14
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/" class="post-category">
                                    软件工具
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Compress/">
                        <span class="chip bg-color">Compress</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <!-- <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="463294659"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2019</span>
            <a href="https://liudongdong1.github.io" target="_blank">liudongdong</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">923.3k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/liudongdong1" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:3463264078@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>


    <a href="https://blog.csdn.net/liudongdong19/" class="tooltipped" target="_blank" data-tooltip="关注我的CSDN: https://blog.csdn.net/liudongdong19/" data-position="top" data-delay="50">
        <i class="fab fa-csdn">C</i>
    </a>





</div>
    </div>
</footer>

<div class="progress-bar"></div>
 -->

    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/search.xml", 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script type="text/javascript" src="/js/CFS.Snow.min.js"></script>
    <!-- 点击爆灯效果 -->
    <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas> 
    <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script> 
    <script type="text/javascript" src="/js/fireworks.js"></script>
    <!--动态线条背景-->
    <script type="text/javascript"
        color="122 103 238" opacity='0.7' zIndex="-2" count="200" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js">
    </script>
    <!-- 天气 -->
    <!-- weather -->
    <!-- weather -->
    <script type="text/javascript">
         WIDGET = {FID: 'knAMQaFanP'}
    </script>
    <script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"></script>
    <script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"></script>
    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    

    
    
    <script type="text/javascript" size="150" alpha='0.6'
        zIndex="-1" src="/libs/background/ribbon-refresh.min.js" async="async"></script>
    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
