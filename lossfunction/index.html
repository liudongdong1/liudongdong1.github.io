<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>LossFunction - DAY By DAY</title><meta name=author content="LiuDongdong"><meta name=author-link content="https://liudongdong1.github.io/"><meta name=description content="1. logSoftmax CLASStorch.nn.``LogSoftmax(dim=None) Input: (*)(∗) where * means, any number of additional dimensions Output: (*)(∗) , same shape as the input dim (int) – A dimension along which LogSoftmax will be computed. 参数dim=1表示对每一行求softmax，那么每一行的"><meta name=keywords content="Model"><meta itemprop=name content="LossFunction"><meta itemprop=description content="1. logSoftmax CLASStorch.nn.``LogSoftmax(dim=None) Input: (*)(∗) where * means, any number of additional dimensions Output: (*)(∗) , same shape as the input dim (int) – A dimension along which LogSoftmax will be computed. 参数dim=1表示对每一行求softmax，那么每一行的"><meta itemprop=dateModified content="2023-09-28T22:17:28+08:00"><meta itemprop=wordCount content="881"><meta itemprop=image content="/logo.png"><meta itemprop=keywords content="Model,"><meta property="og:title" content="LossFunction"><meta property="og:description" content="1. logSoftmax CLASStorch.nn.``LogSoftmax(dim=None) Input: (*)(∗) where * means, any number of additional dimensions Output: (*)(∗) , same shape as the input dim (int) – A dimension along which LogSoftmax will be computed. 参数dim=1表示对每一行求softmax，那么每一行的"><meta property="og:type" content="article"><meta property="og:url" content="liudongdong1.github.io/lossfunction/"><meta property="og:image" content="/logo.png"><meta property="article:section" content="posts"><meta property="article:modified_time" content="2023-09-28T22:17:28+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="/logo.png"><meta name=twitter:title content="LossFunction"><meta name=twitter:description content="1. logSoftmax CLASStorch.nn.``LogSoftmax(dim=None) Input: (*)(∗) where * means, any number of additional dimensions Output: (*)(∗) , same shape as the input dim (int) – A dimension along which LogSoftmax will be computed. 参数dim=1表示对每一行求softmax，那么每一行的"><meta name=application-name content="DAY By DAY"><meta name=apple-mobile-web-app-title content="DAY By DAY"><meta name=theme-color data-light=#f8f8f8 data-dark=#252627 content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=liudongdong1.github.io/lossfunction/><link rel=prev href=liudongdong1.github.io/magneticpapaers/><link rel=next href=liudongdong1.github.io/logicpaper/><link rel=stylesheet href=/liudongdong1.github.io/css/style.min.css><link rel=stylesheet href=/liudongdong1.github.io/lib/fontawesome-free/all.min.css><link rel=stylesheet href=/liudongdong1.github.io/lib/animate/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"LossFunction","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"liudongdong1.github.io\/lossfunction\/"},"genre":"posts","keywords":"Model","wordcount":881,"url":"liudongdong1.github.io\/lossfunction\/","dateModified":"2023-09-28T22:17:28+08:00","license":"This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher":{"@type":"Organization","name":"LiuDongdong","logo":"\/images\/person.png"},"author":{"@type":"Person","name":"liudongdong1"},"description":""}</script></head><body data-header-desktop=auto data-header-mobile=auto><script>(window.localStorage?.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("data-theme","dark")</script><div class=wrapper><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper data-github-corner=right><div class=header-title><a href=liudongdong1.github.io/ title="DAY By DAY"><img class="lazyload logo" src=/liudongdong1.github.io/svg/loading.min.svg data-src=/fixit.min.svg data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x" data-sizes=auto alt="DAY By DAY" title="DAY By DAY"><span class=header-title-text></span></a><span id=typeit-header-subtitle-desktop class="typeit header-subtitle"></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 所有文章</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/friends/ title=友情链接><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden=true></i> 友链</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/about/><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden=true></i> 关于</a></li><li class="menu-item delimiter"></li><li class="menu-item language"><span role=button aria-label=选择语言 title=选择语言>简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden=true></i></span><ul class=sub-menu><li class=menu-item>没有更多翻译</li></ul></li><li class="menu-item search" id=search-desktop><input type=text placeholder="搜索文章标题或内容 ..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i></a>
<span class="search-button search-loading" id=search-loading-desktop><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></li><li class="menu-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=liudongdong1.github.io/ title="DAY By DAY"><img class="lazyload logo" src=/liudongdong1.github.io/svg/loading.min.svg data-src=/fixit.min.svg data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x" data-sizes=auto alt=/fixit.min.svg title=/fixit.min.svg><span class=header-title-text></span></a><span id=typeit-header-subtitle-mobile class="typeit header-subtitle"></span></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder="搜索文章标题或内容 ..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i></a>
<span class="search-button search-loading" id=search-loading-mobile><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 所有文章</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/friends/ title=友情链接><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden=true></i> 友链</a></li><li class=menu-item><a class=menu-link href=/liudongdong1.github.io/about/><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden=true></i> 关于</a></li><li class="menu-item text-center"><a class=menu-link href=https://liudongdong1.github.io/ title=GitHub rel="noopener noreferrer" target=_blank><i class='fa-brands fa-github fa-fw' aria-hidden=true></i></a></li><li class="menu-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li><li class="menu-item language"><span role=button aria-label=选择语言 title=选择语言>简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden=true></i></span>
<select class=language-select onchange="location=this.value"><option disabled>没有更多翻译</option></select></li></ul></nav></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=container data-page-style=normal><aside class=toc id=toc-auto><h2 class=toc-title>目录 <i class="toc-icon fa-solid fa-angle-down fa-fw"></i></h2><div class=toc-content id=toc-content-auto></div></aside><aside class=aside-custom id=aside-sakana><div class=sakana-widget><div class=sakana-item id=takina-widget></div><div class=sakana-item id=chisato-widget></div></div><script>function initSakanaWidget(){const e=SakanaWidget.getCharacter("takina");SakanaWidget.registerCharacter("takina-slow",e),new SakanaWidget({character:"takina-slow",controls:!1,autoFit:!0,stroke:{color:"#b4b4b4",width:2}}).mount("#takina-widget");const t=SakanaWidget.getCharacter("chisato");SakanaWidget.registerCharacter("chisato-slow",t),new SakanaWidget({character:"chisato-slow",controls:!1,autoFit:!0,stroke:{color:"#b4b4b4",width:2}}).mount("#chisato-widget")}</script><script async onload=initSakanaWidget() src=https://cdn.jsdelivr.net/npm/sakana-widget@2.3.0/lib/sakana.min.js></script></aside><article class="page single"><div class=header><h1 class="single-title animate__animated animate__flipInX"><span>LossFunction</span></h1></div><div class=post-meta><div class=post-meta-line><span class=post-author><span class=author><i class="fa-solid fa-user-circle" aria-hidden=true></i>
liudongdong1</span></span>
<span class=post-category>收录于 <a href=liudongdong1.github.io/categories/ai/><i class="fa-regular fa-folder fa-fw"></i>&nbsp;AI</a></span></div><div class=post-meta-line><span title="0001-01-01 00:00:00"><i class="fa-regular fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=0001-01-01>0001-01-01</time>
</span>&nbsp;<i class="fa-solid fa-pencil-alt fa-fw"></i>&nbsp;约 881 字&nbsp;
<i class="fa-regular fa-clock fa-fw"></i>&nbsp;预计阅读 2 分钟&nbsp;<span id=busuanzi_container_page_pv class="busuanzi_visitors comment-visitors" data-flag-title=LossFunction>
<i class="fa-regular fa-eye fa-fw"></i>&nbsp;<span id=busuanzi_value_page_pv>-</span>&nbsp;次阅读
</span>&nbsp;</div></div><div class=featured-image><img class=lazyload src=/liudongdong1.github.io/svg/loading.min.svg data-src=https://cdn.pixabay.com/photo/2020/12/18/16/56/laptop-5842509__340.jpg data-srcset="https://cdn.pixabay.com/photo/2020/12/18/16/56/laptop-5842509__340.jpg, https://cdn.pixabay.com/photo/2020/12/18/16/56/laptop-5842509__340.jpg 1.5x, https://cdn.pixabay.com/photo/2020/12/18/16/56/laptop-5842509__340.jpg 2x" data-sizes=auto alt=https://cdn.pixabay.com/photo/2020/12/18/16/56/laptop-5842509__340.jpg title=https://cdn.pixabay.com/photo/2020/12/18/16/56/laptop-5842509__340.jpg></div><div class="details toc" id=toc-static kept=true><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fa-solid fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><ul><li><a href=#1-logsoftmax>1. logSoftmax</a></li><li><a href=#2-nlllosshttpspytorchorgdocsstablegeneratedtorchnnnlllosshtmlhighlightnlllosstorchnnnllloss>2. <a href="https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html?highlight=nllloss#torch.nn.NLLLoss">NLLLoss</a></a></li><li><a href=#3-crossentropyloss>3. CrossEntropyLoss</a></li><li><a href=#4-one-hot-编码ornot>4. One-Hot 编码orNot</a></li></ul></li></ul></nav></div></div><div class=content id=content><h3 id=1-logsoftmax>1. logSoftmax</h3><blockquote><p><em>CLASS</em><code>torch.nn.``LogSoftmax</code>(<em>dim=None</em>)</p><ul><li>Input: (*)(∗) where * means, any number of additional dimensions</li><li>Output: (*)(∗) , same shape as the input</li><li><strong>dim</strong> (<a href=https://docs.python.org/3/library/functions.html#int target=_blank rel="external nofollow noopener noreferrer"><em>int</em><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>) – A dimension along which LogSoftmax will be computed.<ul><li>参数dim=1表示对每一行求softmax，那么每一行的值加起来都等于1。</li></ul></li></ul></blockquote><p><img class=lazyload src=/liudongdong1.github.io/svg/loading.min.svg data-src=https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531074733359.png data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531074733359.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531074733359.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531074733359.png 2x" data-sizes=auto alt=https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531074733359.png title=https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531074733359.png></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>LogSoftmax</span>(Module):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &gt;&gt;&gt; m = nn.LogSoftmax()
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &gt;&gt;&gt; input = torch.randn(2, 3)
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &gt;&gt;&gt; output = m(input)
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    __constants__ <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;dim&#39;</span>]
</span></span><span style=display:flex><span>    dim: Optional[int]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, dim: Optional[int] <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>) <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        super(LogSoftmax, self)<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>dim <span style=color:#f92672>=</span> dim
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__setstate__</span>(self, state):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>__dict__<span style=color:#f92672>.</span>update(state)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> hasattr(self, <span style=color:#e6db74>&#39;dim&#39;</span>):
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>dim <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, input: Tensor) <span style=color:#f92672>-&gt;</span> Tensor:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> F<span style=color:#f92672>.</span>log_softmax(input, self<span style=color:#f92672>.</span>dim, _stacklevel<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>extra_repr</span>(self):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#39;dim=</span><span style=color:#e6db74>{dim}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(dim<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>dim)
</span></span></code></pre></div><h3 id=2-nlllosshttpspytorchorgdocsstablegeneratedtorchnnnlllosshtmlhighlightnlllosstorchnnnllloss>2. <a href="https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html?highlight=nllloss#torch.nn.NLLLoss" target=_blank rel="external nofollow noopener noreferrer">NLLLoss<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></h3><blockquote><p><em>CLASS</em><code>torch.nn.``NLLLoss</code>(<em>weight=None</em>, <em>size_average=None</em>, <em>ignore_index=-100</em>, <em>reduce=None</em>, <em>reduction=&lsquo;mean&rsquo;</em>)</p><ul><li><code>weight</code> should be a 1D Tensor assigning weight to each of the classes.</li><li>input has to be a Tensor of size either (minibatch, C) or (minibatch, C, d_1, d_2, &mldr;, d_K) with K≥1 for the K-dimensional case</li><li>The target that this loss expects should be a class index in the range [0, C-1][0,<em>C</em>−1] where C = number of classes</li><li>nn.NLLLoss的输入target是类别值，并不是one-hot编码格式</li></ul></blockquote><p><img class=lazyload src=/liudongdong1.github.io/svg/loading.min.svg data-src=https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531075700185.png data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531075700185.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531075700185.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531075700185.png 2x" data-sizes=auto alt=https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531075700185.png title=https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531075700185.png></p><p><img class=lazyload src=/liudongdong1.github.io/svg/loading.min.svg data-src=https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531080334224.png data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531080334224.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531080334224.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531080334224.png 2x" data-sizes=auto alt=https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531080334224.png title=https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531080334224.png></p><blockquote><p>Softmax计算出来的值范围在[0, 1]，<code>值的含义表示对应类别的概率</code>，也就是说，每行（代表每张图）中最接近于1的值对应的类别，就是该图片概率最大的类别，那么<code>经过log求值取绝对值之后，就是最接近于0的值</code>，如果此时<code>每行中的最小值对应的类别值与Target中的类别值相同</code>，那么<code>每行中的最小值求和取平均就是最小</code>，极端的情况就是0。总结一下就是，<code>input的预测值与Target的值越接近，NLLLoss求出来的值就越接近于0</code>，这不正是损失值的本意所在吗，所以NLLLoss可以用来求损失值。</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> m <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>LogSoftmax(dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> loss <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>NLLLoss()
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> <span style=color:#75715e># input is of size N x C = 3 x 5</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> input <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>randn(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>5</span>, requires_grad<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> <span style=color:#75715e># each element in target has to have 0 &lt;= value &lt; C</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> target <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>tensor([<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>4</span>])
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> output <span style=color:#f92672>=</span> loss(m(input), target)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> output<span style=color:#f92672>.</span>backward()
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> <span style=color:#75715e># 2D loss example (used, for example, with image inputs)</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> N, C <span style=color:#f92672>=</span> <span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>4</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> loss <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>NLLLoss()
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> <span style=color:#75715e># input is of size N x C x height x width</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> data <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>randn(N, <span style=color:#ae81ff>16</span>, <span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> conv <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>16</span>, C, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>))
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> m <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>LogSoftmax(dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> <span style=color:#75715e># each element in target has to have 0 &lt;= value &lt; C</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> target <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>empty(N, <span style=color:#ae81ff>8</span>, <span style=color:#ae81ff>8</span>, dtype<span style=color:#f92672>=</span>torch<span style=color:#f92672>.</span>long)<span style=color:#f92672>.</span>random_(<span style=color:#ae81ff>0</span>, C)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> output <span style=color:#f92672>=</span> loss(m(conv(data)), target)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> output<span style=color:#f92672>.</span>backward()
</span></span></code></pre></div><h3 id=3-crossentropyloss>3. CrossEntropyLoss</h3><blockquote><p><em>CLASS</em><code>torch.nn.``CrossEntropyLoss</code>(<em>weight=None</em>, <em>size_average=None</em>, <em>ignore_index=-100</em>, <em>reduce=None</em>, <em>reduction=&lsquo;mean&rsquo;</em>)</p><ul><li><code>weight</code> should be a 1D Tensor assigning weight to each of the classes.</li><li>input is expected to contain raw, unnormalized scores for each class., input has to be a Tensor of size either (minibatch, C) or (minibatch, C, d_1, d_2, &mldr;, d_K)with K*≥1 for the K-dimensional case (described later)</li><li>a class index in the range [0, C-1][0,<em>C</em>−1] as the target for each value of a 1D tensor of size minibatch;</li></ul></blockquote><p><img class=lazyload src=/liudongdong1.github.io/svg/loading.min.svg data-src=https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531080926887.png data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531080926887.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531080926887.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531080926887.png 2x" data-sizes=auto alt=https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531080926887.png title=https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210531080926887.png></p><h3 id=4-one-hot-编码ornot>4. One-Hot 编码orNot</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn <span style=color:#66d9ef>as</span> nn
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch <span style=color:#f92672>import</span> autograd
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn.functional <span style=color:#66d9ef>as</span> F
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># logsoft-max + NLLLoss</span>
</span></span><span style=display:flex><span>m <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>LogSoftmax()
</span></span><span style=display:flex><span>loss <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>NLLLoss()
</span></span><span style=display:flex><span>input <span style=color:#f92672>=</span> autograd<span style=color:#f92672>.</span>Variable(torch<span style=color:#f92672>.</span>randn(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>5</span>), requires_grad<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>target <span style=color:#f92672>=</span> autograd<span style=color:#f92672>.</span>Variable(torch<span style=color:#f92672>.</span>LongTensor([<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>4</span>]))
</span></span><span style=display:flex><span>output <span style=color:#f92672>=</span> loss(m(input), target)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;logsoftmax + nllloss output is </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(output))
</span></span><span style=display:flex><span><span style=color:#75715e># crossentripyloss</span>
</span></span><span style=display:flex><span>loss <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>CrossEntropyLoss()
</span></span><span style=display:flex><span><span style=color:#75715e># input = autograd.Variable(torch.randn(3, 5), requires_grad=True)</span>
</span></span><span style=display:flex><span>target <span style=color:#f92672>=</span> autograd<span style=color:#f92672>.</span>Variable(torch<span style=color:#f92672>.</span>LongTensor([<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>4</span>]))
</span></span><span style=display:flex><span>output <span style=color:#f92672>=</span> loss(input, target)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;crossentropy output is </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(output))
</span></span><span style=display:flex><span><span style=color:#75715e># one hot label loss</span>
</span></span><span style=display:flex><span>C <span style=color:#f92672>=</span> <span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>target <span style=color:#f92672>=</span> autograd<span style=color:#f92672>.</span>Variable(torch<span style=color:#f92672>.</span>LongTensor([<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>4</span>]))
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;target is </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(target))
</span></span><span style=display:flex><span>N <span style=color:#f92672>=</span> target <span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span><span style=color:#75715e># N 是batch-size大小</span>
</span></span><span style=display:flex><span><span style=color:#75715e># C is the number of classes.</span>
</span></span><span style=display:flex><span>labels <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>full(size<span style=color:#f92672>=</span>(N, C), fill_value<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;labels shape is </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(labels<span style=color:#f92672>.</span>shape))
</span></span><span style=display:flex><span>labels<span style=color:#f92672>.</span>scatter_(dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, index<span style=color:#f92672>=</span>torch<span style=color:#f92672>.</span>unsqueeze(target, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), value<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)  <span style=color:#75715e>#one-hot 编码</span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;labels is </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(labels))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>log_prob <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>nn<span style=color:#f92672>.</span>functional<span style=color:#f92672>.</span>log_softmax(input, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>loss <span style=color:#f92672>=</span> <span style=color:#f92672>-</span>torch<span style=color:#f92672>.</span>sum(log_prob <span style=color:#f92672>*</span> labels) <span style=color:#f92672>/</span> N
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;N is </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(N))
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;one-hot loss is </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(loss))
</span></span></code></pre></div></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span title="2023-09-28 22:17:28">更新于 2023-09-28&nbsp;</span></div><div class=post-info-license><span><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div><div class=post-info-line><div class=post-info-md><span><a href=liudongdong1.github.io/lossfunction/index.md title=阅读原始文档 class=link-to-markdown>阅读原始文档</a></span><span><a href=https://liudongdong1.github.io/edit/master/content/posts%5c%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%5cmodel%5clayer%5cLossFunction.md title=编辑此页 target=_blank rel="external nofollow noopener noreferrer" class=link-to-edit>编辑此页</a></span></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 Twitter" data-sharer=twitter data-url=liudongdong1.github.io/lossfunction/ data-title=LossFunction data-hashtags=Model><i class="fa-brands fa-twitter fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Facebook" data-sharer=facebook data-url=liudongdong1.github.io/lossfunction/ data-hashtag=Model><i class="fa-brands fa-facebook-square fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=liudongdong1.github.io/lossfunction/ data-title=LossFunction data-image=https://cdn.pixabay.com/photo/2020/12/18/16/56/laptop-5842509__340.jpg><i class="fa-brands fa-weibo fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fa-solid fa-tags fa-fw" aria-hidden=true></i>&nbsp;<a href=liudongdong1.github.io/tags/model/>Model</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=liudongdong1.github.io/>主页</a></span></section></div><div class=post-nav><a href=liudongdong1.github.io/magneticpapaers/ class=prev rel=prev title=MagneticPapers><i class="fa-solid fa-angle-left fa-fw" aria-hidden=true></i>MagneticPapers</a>
<a href=liudongdong1.github.io/logicpaper/ class=next rel=next title=LogicPaper>LogicPaper<i class="fa-solid fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></main><footer class=footer><div class=footer-container><div class="footer-line powered">由 <a href=https://gohugo.io/ target=_blank rel="external nofollow noopener noreferrer" title="Hugo 0.118.2">Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/hugo-fixit/FixIt target=_blank rel=external title="FixIt v0.2.17-RC"><img class=fixit-icon src=/liudongdong1.github.io/fixit.min.svg alt="FixIt logo">&nbsp;FixIt</a></div><div class="footer-line copyright" itemscope itemtype=http://schema.org/CreativeWork><i class="fa-regular fa-copyright fa-fw" aria-hidden=true></i>
<span itemprop=copyrightYear>2020 - 2023</span><span class=author itemprop=copyrightHolder>
<a href=https://liudongdong1.github.io/ target=_blank rel="external nofollow noopener noreferrer">LiuDongdong</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div><div class="footer-line statistics"><span class=site-time title='网站运行中 ...'><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden=true></i>&nbsp;<span class=run-times>网站运行中 ...</span></span></div><div class="footer-line ibruce"><span id=busuanzi_container_site_uv title=总访客数><i class="fa-regular fa-user fa-fw" aria-hidden=true></i>&nbsp;<span id=busuanzi_value_site_uv><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden=true></i></span></span><span id=busuanzi_container_site_pv class=footer-divider title=总访问量><i class="fa-regular fa-eye fa-fw" aria-hidden=true></i>&nbsp;<span id=busuanzi_value_site_pv><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden=true></i></span></span></div></div></footer></div><div class=widgets><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role=button aria-label=回到顶部><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><span class=variant-numeric>0%</span></div></div><a href=https://liudongdong1.github.io/ title="在 GitHub 上查看源代码" target=_blank rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115h15l12 27L250 250V0z"/><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentcolor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4l13.9-13.8C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8z" fill="currentcolor" class="octo-body"/></svg></a><div id=mask></div><div class=reading-progress-bar style=left:0;top:0;--bg-progress:#0076ff;--bg-progress-dark:#fff></div><noscript><div class=noscript-warning>FixIt 主题在启用 JavaScript 的情况下效果最佳。</div></noscript></div><link rel=stylesheet href=/liudongdong1.github.io/lib/katex/katex.min.css><link rel=stylesheet href=/liudongdong1.github.io/lib/cookieconsent/cookieconsent.min.css><script src=/liudongdong1.github.io/lib/autocomplete/autocomplete.min.js defer></script><script src=/liudongdong1.github.io/lib/algoliasearch/algoliasearch-lite.umd.min.js defer></script><script src=/liudongdong1.github.io/lib/lazysizes/lazysizes.min.js async defer></script><script src=/liudongdong1.github.io/lib/sharer/sharer.min.js async defer></script><script src=/liudongdong1.github.io/lib/typeit/index.umd.js defer></script><script src=/liudongdong1.github.io/lib/katex/katex.min.js defer></script><script src=/liudongdong1.github.io/lib/katex/auto-render.min.js defer></script><script src=/liudongdong1.github.io/lib/katex/copy-tex.min.js defer></script><script src=/liudongdong1.github.io/lib/katex/mhchem.min.js defer></script><script src=/liudongdong1.github.io/lib/cookieconsent/cookieconsent.min.js defer></script><script src=/liudongdong1.github.io/lib/pangu/pangu.min.js defer></script><script src=/liudongdong1.github.io/lib/cell-watermark/watermark.min.js defer></script><script src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js async defer></script><script>window.config={code:{copyTitle:"复制到剪贴板",editLockTitle:"锁定可编辑代码块",editUnLockTitle:"解锁可编辑代码块",editable:!0,maxShownLines:10},comment:{enable:!1},cookieconsent:{content:{dismiss:"同意",link:"了解更多",message:"本网站使用 Cookies 来改善您的浏览体验。"},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},data:{"typeit-header-subtitle-desktop":`<span style='font-family: MMT,"沐目体";'>吾日三省吾身</span>`,"typeit-header-subtitle-mobile":`<span style='font-family: MMT,"沐目体";'>吾日三省吾身</span>`},enablePWA:!0,enablePangu:!0,math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{algoliaAppID:"2R1K9SKLQZ",algoliaIndex:"index.zh-cn",algoliaSearchKey:"4a226aa1c5c98d6859e4d1386adb2bc7",highlightTag:"em",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50,type:"algolia"},siteTime:"2020-12-18T16:15:22+08:00",typeit:{cursorChar:"|",cursorSpeed:1e3,data:{"typeit-header-subtitle-desktop":["typeit-header-subtitle-desktop"],"typeit-header-subtitle-mobile":["typeit-header-subtitle-mobile"]},duration:-1,speed:100},watermark:{appendto:".wrapper>main",colspacing:30,content:'<img class="fixit-icon" src="/fixit.min.svg" alt="FixIt logo" /> FixIt 主题',enable:!0,fontfamily:"inherit",fontsize:.85,height:21,opacity:.0125,rotate:15,rowspacing:60,width:150}}</script><script src=/liudongdong1.github.io/js/theme.min.js defer></script><script src=/liudongdong1.github.io/js/custom.min.js defer></script></body></html>