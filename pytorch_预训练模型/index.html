<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <head>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>Pytorch_预训练模型 - DAY By DAY</title><meta name="author" content="LiuDongdong">
<meta name="author-link" content="https://liudongdong1.github.io/">
<meta name="description" content="1. 模型下载 import re import os import glob import torch from torch.hub import download_url_to_file from torch.hub import urlparse import torchvision.models as models def download_model(url, dst_path): parts = urlparse(url) filename = os.path.basename(parts.path) HASH_REGEX = re.compile(r&#39;-([a-f0-9]*)\.&#39;) hash_prefix = HASH_REGEX.search(filename).group(1) if os.path.exists(os.path.join(dst_path, filename)): return filename download_url_to_file(url, os.path.join(dst_path, filename), hash_prefix, True) return filename def saveToFolder(path): #其他各种模型可以在这个目录下进" /><meta name="keywords" content='Pytorch' /><meta itemprop="name" content="Pytorch_预训练模型">
<meta itemprop="description" content="1. 模型下载 import re import os import glob import torch from torch.hub import download_url_to_file from torch.hub import urlparse import torchvision.models as models def download_model(url, dst_path): parts = urlparse(url) filename = os.path.basename(parts.path) HASH_REGEX = re.compile(r&#39;-([a-f0-9]*)\.&#39;) hash_prefix = HASH_REGEX.search(filename).group(1) if os.path.exists(os.path.join(dst_path, filename)): return filename download_url_to_file(url, os.path.join(dst_path, filename), hash_prefix, True) return filename def saveToFolder(path): #其他各种模型可以在这个目录下进">
<meta itemprop="dateModified" content="2023-09-28T22:45:34+08:00" />
<meta itemprop="wordCount" content="4747"><meta itemprop="image" content="https://liudongdong1.github.io/logo.png"/>
<meta itemprop="keywords" content="Pytorch," /><meta property="og:title" content="Pytorch_预训练模型" />
<meta property="og:description" content="1. 模型下载 import re import os import glob import torch from torch.hub import download_url_to_file from torch.hub import urlparse import torchvision.models as models def download_model(url, dst_path): parts = urlparse(url) filename = os.path.basename(parts.path) HASH_REGEX = re.compile(r&#39;-([a-f0-9]*)\.&#39;) hash_prefix = HASH_REGEX.search(filename).group(1) if os.path.exists(os.path.join(dst_path, filename)): return filename download_url_to_file(url, os.path.join(dst_path, filename), hash_prefix, True) return filename def saveToFolder(path): #其他各种模型可以在这个目录下进" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://liudongdong1.github.io/pytorch_%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/" /><meta property="og:image" content="https://liudongdong1.github.io/logo.png"/><meta property="article:section" content="posts" />

<meta property="article:modified_time" content="2023-09-28T22:45:34+08:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://liudongdong1.github.io/logo.png"/>

<meta name="twitter:title" content="Pytorch_预训练模型"/>
<meta name="twitter:description" content="1. 模型下载 import re import os import glob import torch from torch.hub import download_url_to_file from torch.hub import urlparse import torchvision.models as models def download_model(url, dst_path): parts = urlparse(url) filename = os.path.basename(parts.path) HASH_REGEX = re.compile(r&#39;-([a-f0-9]*)\.&#39;) hash_prefix = HASH_REGEX.search(filename).group(1) if os.path.exists(os.path.join(dst_path, filename)): return filename download_url_to_file(url, os.path.join(dst_path, filename), hash_prefix, True) return filename def saveToFolder(path): #其他各种模型可以在这个目录下进"/>
<meta name="application-name" content="DAY By DAY">
<meta name="apple-mobile-web-app-title" content="DAY By DAY"><meta name="theme-color" data-light="#f8f8f8" data-dark="#252627" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://liudongdong1.github.io/pytorch_%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/" /><link rel="prev" href="https://liudongdong1.github.io/basic/" /><link rel="next" href="https://liudongdong1.github.io/pytorch_tools/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "Pytorch_预训练模型",
    "inLanguage": "zh-CN",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https:\/\/liudongdong1.github.io\/pytorch_%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B\/"
    },"genre": "posts","keywords": "Pytorch","wordcount":  4747 ,
    "url": "https:\/\/liudongdong1.github.io\/pytorch_%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B\/","dateModified": "2023-09-28T22:45:34+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
      "@type": "Organization",
      "name": "LiuDongdong","logo": "https:\/\/liudongdong1.github.io\/images\/person.png"},"author": {
        "@type": "Person",
        "name": "liudongdong1"
      },"description": ""
  }
  </script></head>
  <body data-header-desktop="auto" data-header-mobile="auto"><script>(window.localStorage?.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('data-theme', 'dark');</script><div class="wrapper"><script type="text/javascript"
        async
        src="https://cdnjs.cloudflare.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>
<header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper" data-github-corner="right">
    <div class="header-title">
      <a href="/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="DAY By DAY"
    title="DAY By DAY"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-desktop" class="typeit header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a
                class="menu-link"
                href="/posts/"
                
                
              ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/categories/"
                
                
              ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/tags/"
                
                
              ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/friends/"
                title="友情链接"
                
              ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/about/"
                
                
              ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li class="menu-item delimiter"></li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <ul class="sub-menu"><li class="menu-item">没有更多翻译</li></ul>
          </li><li class="menu-item search" id="search-desktop">
            <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-desktop">
            <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
              <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
            </a>
            <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
              <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
            </a>
            <span class="search-button search-loading" id="search-loading-desktop">
              <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
            </span>
          </li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li>
      </ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="/fixit.min.svg"
    title="/fixit.min.svg"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-mobile" class="typeit header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li class="search-wrapper">
            <div class="search mobile" id="search-mobile">
              <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-mobile">
              <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
              </a>
              <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
              </a>
              <span class="search-button search-loading" id="search-loading-mobile">
                <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
              </span>
            </div>
            <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
              取消
            </a>
          </li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/posts/"
                  
                  
                ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/categories/"
                  
                  
                ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/tags/"
                  
                  
                ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/friends/"
                  title="友情链接"
                  
                ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/about/"
                  
                  
                ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li
              class="menu-item text-center"
            ><a
                  class="menu-link"
                  href="/"
                  title="GitHub"
                  
                ><i class='fa-brands fa-github fa-fw' aria-hidden='true'></i> </a></li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <select class="language-select" onchange="location = this.value;"><option disabled>没有更多翻译</option></select>
          </li></ul>
    </nav>
  </div>
</header><div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
  </div>
  <div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
  </div><main class="container" data-page-style="normal"><aside class="toc" id="toc-auto"><h2 class="toc-title">目录 <i class="toc-icon fa-solid fa-angle-down fa-fw"></i></h2>
      <div class="toc-content" id="toc-content-auto"></div></aside>

  <aside class="aside-custom" id="aside-sakana">
    

<div class="sakana-widget">
  <div class="sakana-item" id="takina-widget"></div>
  <div class="sakana-item" id="chisato-widget"></div>
</div>
<script>
  function initSakanaWidget() {
    const takina = SakanaWidget.getCharacter('takina')
    SakanaWidget.registerCharacter('takina-slow', takina);
    new SakanaWidget({
      character: 'takina-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#takina-widget');

    const chisato = SakanaWidget.getCharacter('chisato')
    SakanaWidget.registerCharacter('chisato-slow', chisato);
    new SakanaWidget({
      character: 'chisato-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#chisato-widget');
  }
</script>
<script async onload="initSakanaWidget()" src="https://cdn.jsdelivr.net/npm/sakana-widget@2.3.0/lib/sakana.min.js">
</script></aside>

  <article class="page single">
    <div class="header"><h1 class="single-title animate__animated animate__flipInX">
        <span>Pytorch_预训练模型</span>
      </h1></div><div class="post-meta">
      <div class="post-meta-line"><span class="post-author"><span class="author"><i class="fa-solid fa-user-circle" aria-hidden="true"></i>
      liudongdong1</span></span>
          <span class="post-category">收录于 <a href="/categories/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;Categories</a>&ensp;<a href="/categories/ai/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;AI</a></span></div>
      <div class="post-meta-line"><span title=0001-01-01&#32;00:00:00>
            <i class="fa-regular fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="0001-01-01" >0001-01-01</time>
          </span>&nbsp;<i class="fa-solid fa-pencil-alt fa-fw"></i>&nbsp;约 4747 字&nbsp;
        <i class="fa-regular fa-clock fa-fw"></i>&nbsp;预计阅读 10 分钟&nbsp;<span id="busuanzi_container_page_pv" class="busuanzi_visitors comment-visitors" data-flag-title="Pytorch_预训练模型">
            <i class="fa-regular fa-eye fa-fw"></i>&nbsp;<span id="busuanzi_value_page_pv">-</span>&nbsp;次阅读
          </span>&nbsp;</div>
    </div><div class="featured-image"><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://cdn.stocksnap.io/img-thumbs/280h/keyboard-typing_UATQGKPFOH.jpg"
    data-srcset="https://cdn.stocksnap.io/img-thumbs/280h/keyboard-typing_UATQGKPFOH.jpg, https://cdn.stocksnap.io/img-thumbs/280h/keyboard-typing_UATQGKPFOH.jpg 1.5x, https://cdn.stocksnap.io/img-thumbs/280h/keyboard-typing_UATQGKPFOH.jpg 2x"
    data-sizes="auto"
    alt="https://cdn.stocksnap.io/img-thumbs/280h/keyboard-typing_UATQGKPFOH.jpg"
    title="https://cdn.stocksnap.io/img-thumbs/280h/keyboard-typing_UATQGKPFOH.jpg"/></div><div class="details toc" id="toc-static" kept="true">
        <div class="details-summary toc-title">
          <span>目录</span>
          <span><i class="details-icon fa-solid fa-angle-right"></i></span>
        </div>
        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#1-模型下载httpwwwcxyzjdcomarticlejorbo_li106248808">1. 模型<a href="http://www.cxyzjd.com/article/Jorbo_Li/106248808">下载</a></a></li>
        <li><a href="#2-模型查看">2. 模型查看</a></li>
        <li><a href="#3-模型初始化">3. 模型初始化</a></li>
        <li><a href="#4-构建模型">4. 构建模型</a></li>
        <li><a href="#5-使用预训练模型">5. 使用预训练模型</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
      </div><div
      class="content"
      id="content"
      
      
    ><h3 id="1-模型下载httpwwwcxyzjdcomarticlejorbo_li106248808">1. 模型<a href="http://www.cxyzjd.com/article/Jorbo_Li/106248808"target="_blank" rel="external nofollow noopener noreferrer">下载<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></h3>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716115238769.png"
    data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716115238769.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716115238769.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716115238769.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716115238769.png"
    title="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716115238769.png"/></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> glob
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torch.hub <span style="color:#f92672">import</span> download_url_to_file
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torch.hub <span style="color:#f92672">import</span> urlparse
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torchvision.models <span style="color:#66d9ef">as</span> models
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">download_model</span>(url, dst_path):
</span></span><span style="display:flex;"><span>    parts <span style="color:#f92672">=</span> urlparse(url)
</span></span><span style="display:flex;"><span>    filename <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>basename(parts<span style="color:#f92672">.</span>path)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    HASH_REGEX <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>compile(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;-([a-f0-9]*)\.&#39;</span>)
</span></span><span style="display:flex;"><span>    hash_prefix <span style="color:#f92672">=</span> HASH_REGEX<span style="color:#f92672">.</span>search(filename)<span style="color:#f92672">.</span>group(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>exists(os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(dst_path, filename)):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> filename
</span></span><span style="display:flex;"><span>    download_url_to_file(url, os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(dst_path, filename), hash_prefix, <span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> filename
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">saveToFolder</span>(path):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#其他各种模型可以在这个目录下进行搜索查看 https://github.com/pytorch/vision/tree/master/torchvision/models</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># model_urls = {</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#     &#39;vgg11&#39;: &#39;https://download.pytorch.org/models/vgg11-bbd30ac9.pth&#39;,</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#     &#39;vgg13&#39;: &#39;https://download.pytorch.org/models/vgg13-c768596a.pth&#39;,</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#     &#39;vgg16&#39;: &#39;https://download.pytorch.org/models/vgg16-397923af.pth&#39;,</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#     &#39;vgg19&#39;: &#39;https://download.pytorch.org/models/vgg19-dcbb9e9d.pth&#39;,</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#     &#39;vgg11_bn&#39;: &#39;https://download.pytorch.org/models/vgg11_bn-6002323d.pth&#39;,</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#     &#39;vgg13_bn&#39;: &#39;https://download.pytorch.org/models/vgg13_bn-abd245e5.pth&#39;,</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#     &#39;vgg16_bn&#39;: &#39;https://download.pytorch.org/models/vgg16_bn-6c64b313.pth&#39;,</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#     &#39;vgg19_bn&#39;: &#39;https://download.pytorch.org/models/vgg19_bn-c79401a0.pth&#39;,</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># }</span>
</span></span><span style="display:flex;"><span>    model_urls<span style="color:#f92672">=</span>{
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;vgg16&#39;</span>: <span style="color:#e6db74">&#39;https://download.pytorch.org/models/vgg16-397923af.pth&#39;</span>,
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> (os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>exists(path)):
</span></span><span style="display:flex;"><span>        os<span style="color:#f92672">.</span>makedirs(path)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> url <span style="color:#f92672">in</span> model_urls<span style="color:#f92672">.</span>values():
</span></span><span style="display:flex;"><span>        download_model(url, path)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">load_model</span>(model_name, model_dir):
</span></span><span style="display:flex;"><span>    model  <span style="color:#f92672">=</span> eval(<span style="color:#e6db74">&#39;models.</span><span style="color:#e6db74">%s</span><span style="color:#e6db74">(init_weights=False)&#39;</span> <span style="color:#f92672">%</span> model_name)
</span></span><span style="display:flex;"><span>    path_format <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(model_dir, <span style="color:#e6db74">&#39;</span><span style="color:#e6db74">%s</span><span style="color:#e6db74">-[a-z0-9]*.pth&#39;</span> <span style="color:#f92672">%</span> model_name)
</span></span><span style="display:flex;"><span>    model_path <span style="color:#f92672">=</span> glob<span style="color:#f92672">.</span>glob(path_format)[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>load_state_dict(torch<span style="color:#f92672">.</span>load(model_path))
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> model
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">main</span>():
</span></span><span style="display:flex;"><span>    path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;/home/iot/jupyter/root_dir/liudongdong/pytorch_demo/pretainedpth/vgg16&#39;</span>
</span></span><span style="display:flex;"><span>    saveToFolder(path)
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> load_model(<span style="color:#e6db74">&#39;vgg16&#39;</span>, path)
</span></span><span style="display:flex;"><span>    print(model)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    main()
</span></span></code></pre></div><p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716115155027.png"
    data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716115155027.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716115155027.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716115155027.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716115155027.png"
    title="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716115155027.png"/></p>
<h3 id="2-模型查看">2. 模型查看</h3>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210516230215346.png"
    data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210516230215346.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210516230215346.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210516230215346.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210516230215346.png"
    title="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210516230215346.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210516230252202.png"
    data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210516230252202.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210516230252202.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210516230252202.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210516230252202.png"
    title="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210516230252202.png"/></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>resnet<span style="color:#f92672">.</span>fc <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Linear(resnet<span style="color:#f92672">.</span>fc<span style="color:#f92672">.</span>in_features, <span style="color:#ae81ff">100</span>)
</span></span><span style="display:flex;"><span>print(resnet)   <span style="color:#75715e">#将会输出网络每一层结构, print顺序可能不是最终网络的数据</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 或者采用torchviz模块，对网络结构进行可视化， 将会生成一个pdf 网络结构图</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torchvision
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torchviz <span style="color:#f92672">import</span> make_dot
</span></span><span style="display:flex;"><span>x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">224</span>)<span style="color:#f92672">.</span>requires_grad_(<span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>model50 <span style="color:#f92672">=</span> torchvision<span style="color:#f92672">.</span>models<span style="color:#f92672">.</span>resnet50()
</span></span><span style="display:flex;"><span>y <span style="color:#f92672">=</span> model50(x)
</span></span><span style="display:flex;"><span>vis_graph <span style="color:#f92672">=</span> make_dot(y, params<span style="color:#f92672">=</span>dict(list(resnet<span style="color:#f92672">.</span>named_parameters()) <span style="color:#f92672">+</span> [(<span style="color:#e6db74">&#39;x&#39;</span>, x)]))
</span></span><span style="display:flex;"><span>vise_graph<span style="color:#f92672">.</span>view()
</span></span><span style="display:flex;"><span><span style="color:#75715e">#保存成文件形式</span>
</span></span><span style="display:flex;"><span>vise_graph<span style="color:#f92672">.</span>render(filename<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;resnet50&#39;</span>, view<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>, format<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;pdf&#39;</span>)
</span></span></code></pre></div><ul>
<li>方式二：以列表的形式</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> torchsummary <span style="color:#f92672">import</span> summary
</span></span><span style="display:flex;"><span>summary(model50, (<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">224</span>)) <span style="color:#75715e">#模型参数，输入数据的格式</span>
</span></span></code></pre></div><p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211011104049510.png"
    data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211011104049510.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211011104049510.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211011104049510.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211011104049510.png"
    title="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211011104049510.png"/></p>
<h3 id="3-模型初始化">3. 模型初始化</h3>
<blockquote>
<p>适当的权值初始化可以加速模型的训练和模型的收敛，而错误的权值初始化会导致梯度消失/爆炸，从而无法完成网络的训练，因此需要控制网络输出值的尺度范围。torch.nn.init中提供了常用的初始化方法函数，1. Xavier，kaiming系列；2. 其他方法分布</p>
</blockquote>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517095212696.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517095212696.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517095212696.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517095212696.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517095212696.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517095212696.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517095258942.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517095258942.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517095258942.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517095258942.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517095258942.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517095258942.png"/></p>
<blockquote>
<p><strong>从上图中的公式可以看出，*<em>每传播一层，输出值数据的方差就会扩大n*</em></strong> <strong><em>*倍*</em>，要想控制输出H的尺度范围，只需要控制H的方差为1，则无论经过多少层都可以维持在初始输入X的方差附近，因此*<em>权重w需要初始化方差为1/n*</em>（n为神经元的个数）</strong></p>
</blockquote>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517100543137.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517100543137.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517100543137.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517100543137.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517100543137.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517100543137.png"/></p>
<h5 id="1-xavier-均匀分布">.1. Xavier 均匀分布</h5>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517095432537.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517095432537.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517095432537.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517095432537.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517095432537.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517095432537.png"/></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> random
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">set_seed</span>(seed<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>    random<span style="color:#f92672">.</span>seed(seed)
</span></span><span style="display:flex;"><span>    np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(seed)
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">.</span>manual_seed(seed)
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>manual_seed(seed)
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>set_seed(<span style="color:#ae81ff">1</span>)  <span style="color:#75715e"># 设置随机种子</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MLP</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, neural_num, layers):
</span></span><span style="display:flex;"><span>        super(MLP, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>linears <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>ModuleList([nn<span style="color:#f92672">.</span>Linear(neural_num, neural_num, bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(layers)])
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>neural_num <span style="color:#f92672">=</span> neural_num
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> (i, linear) <span style="color:#f92672">in</span> enumerate(self<span style="color:#f92672">.</span>linears):
</span></span><span style="display:flex;"><span>            x <span style="color:#f92672">=</span> linear(x)
</span></span><span style="display:flex;"><span>            x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tanh(x)
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">&#34;layer:</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">, std:</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format(i, x<span style="color:#f92672">.</span>std()))
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> torch<span style="color:#f92672">.</span>isnan(x<span style="color:#f92672">.</span>std()):
</span></span><span style="display:flex;"><span>                print(<span style="color:#e6db74">&#34;output is nan in </span><span style="color:#e6db74">{}</span><span style="color:#e6db74"> layers&#34;</span><span style="color:#f92672">.</span>format(i))
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">initialize</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> m <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>modules():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> isinstance(m, nn<span style="color:#f92672">.</span>Linear):
</span></span><span style="display:flex;"><span>                <span style="color:#75715e">#xavier手动计算</span>
</span></span><span style="display:flex;"><span>                a <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sqrt(<span style="color:#ae81ff">6</span> <span style="color:#f92672">/</span> (self<span style="color:#f92672">.</span>neural_num <span style="color:#f92672">+</span> self<span style="color:#f92672">.</span>neural_num))
</span></span><span style="display:flex;"><span>                tanh_gain <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>calculate_gain(<span style="color:#e6db74">&#39;tanh&#39;</span>)         <span style="color:#75715e">#计算增益</span>
</span></span><span style="display:flex;"><span>                a <span style="color:#f92672">*=</span> tanh_gain
</span></span><span style="display:flex;"><span>                nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>uniform_(m<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data, <span style="color:#f92672">-</span>a, a)
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>                <span style="color:#75715e">#调用pytorch实现xavier初始化，适用于饱和激活函数</span>
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># tanh_gain = nn.init.calculate_gain(&#39;tanh&#39;)</span>
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># nn.init.xavier_uniform_(m.weight.data, gain=tanh_gain)</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#75715e"># flag = 0</span>
</span></span><span style="display:flex;"><span>flag <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> flag:
</span></span><span style="display:flex;"><span>    layer_nums <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>
</span></span><span style="display:flex;"><span>    neural_nums <span style="color:#f92672">=</span> <span style="color:#ae81ff">256</span>
</span></span><span style="display:flex;"><span>    batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">16</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>    net <span style="color:#f92672">=</span> MLP(neural_nums, layer_nums)
</span></span><span style="display:flex;"><span>    net<span style="color:#f92672">.</span>initialize()
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>    inputs <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn((batch_size, neural_nums))  <span style="color:#75715e"># normal: mean=0, std=1</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>    output <span style="color:#f92672">=</span> net(inputs)
</span></span><span style="display:flex;"><span>    print(output)
</span></span></code></pre></div><blockquote>
<p>torch.nn.init.xavier_uniform_(tensor, gain=1)</p>
<p>xavier初始化方法中服从均匀分布U(−a,a) ，分布的参数a = gain * sqrt(6/fan_in+fan_out)，</p>
<p>这里有一个gain，增益的大小是依据激活函数类型来设定</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>eg<span style="color:#960050;background-color:#1e0010">：</span>nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>xavier_uniform_(w, gain<span style="color:#f92672">=</span>nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>calculate_gain(<span style="color:#e6db74">&#39;relu&#39;</span>))
</span></span></code></pre></div></blockquote>
<h5 id="2-xavier正态分布">.2. Xavier正态分布</h5>
<blockquote>
<p>torch.nn.init.xavier_normal_(<em>tensor</em>, <em>gain=1</em>)</p>
<p>xavier初始化方法中服从正态分布，</p>
<p>mean=0,std = gain * sqrt(2/fan_in + fan_out)</p>
</blockquote>
<h5 id="3-kaiming均匀分布">.3. kaiming均匀分布</h5>
<blockquote>
<p>torch.nn.init.kaiming_uniform_(<em>tensor</em>, <em>a=0</em>, <em>mode=&lsquo;fan_in&rsquo;</em>, <em>nonlinearity=&lsquo;leaky_relu&rsquo;</em>)</p>
<p>此为均匀分布，U～（-bound, bound）, bound = sqrt(6/(1+a^2)*fan_in)</p>
<p>其中，a为激活函数的负半轴的斜率，relu是0</p>
<p>mode- 可选为fan_in 或 fan_out, fan_in使正向传播时，方差一致; fan_out使反向传播时，方差一致</p>
<p>nonlinearity- 可选 relu 和 leaky_relu ，默认值为 。 leaky_relu</p>
<p>nn.init.kaiming_uniform_(w, mode=&lsquo;fan_in&rsquo;, nonlinearity=&lsquo;relu&rsquo;)</p>
</blockquote>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517100453509.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517100453509.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517100453509.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517100453509.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517100453509.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20210517100453509.png"/></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> random
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">set_seed</span>(seed<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>    random<span style="color:#f92672">.</span>seed(seed)
</span></span><span style="display:flex;"><span>    np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(seed)
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">.</span>manual_seed(seed)
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>manual_seed(seed)
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>set_seed(<span style="color:#ae81ff">1</span>)  <span style="color:#75715e"># 设置随机种子</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MLP</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, neural_num, layers):
</span></span><span style="display:flex;"><span>        super(MLP, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>linears <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>ModuleList([nn<span style="color:#f92672">.</span>Linear(neural_num, neural_num, bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(layers)])
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>neural_num <span style="color:#f92672">=</span> neural_num
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> (i, linear) <span style="color:#f92672">in</span> enumerate(self<span style="color:#f92672">.</span>linears):
</span></span><span style="display:flex;"><span>            x <span style="color:#f92672">=</span> linear(x)
</span></span><span style="display:flex;"><span>            x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>relu(x)
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">&#34;layer:</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">, std:</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format(i, x<span style="color:#f92672">.</span>std()))
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> torch<span style="color:#f92672">.</span>isnan(x<span style="color:#f92672">.</span>std()):
</span></span><span style="display:flex;"><span>                print(<span style="color:#e6db74">&#34;output is nan in </span><span style="color:#e6db74">{}</span><span style="color:#e6db74"> layers&#34;</span><span style="color:#f92672">.</span>format(i))
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">initialize</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> m <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>modules():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> isinstance(m, nn<span style="color:#f92672">.</span>Linear):
</span></span><span style="display:flex;"><span>                <span style="color:#75715e">#kaiming初始化手动</span>
</span></span><span style="display:flex;"><span>                nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>normal_(m<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data, std<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>sqrt(<span style="color:#ae81ff">2</span> <span style="color:#f92672">/</span> self<span style="color:#f92672">.</span>neural_num))
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>                <span style="color:#75715e">#kaiming初始化</span>
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># nn.init.kaiming_normal_(m.weight.data)</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#75715e"># flag = 0</span>
</span></span><span style="display:flex;"><span>flag <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> flag:
</span></span><span style="display:flex;"><span>    layer_nums <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>
</span></span><span style="display:flex;"><span>    neural_nums <span style="color:#f92672">=</span> <span style="color:#ae81ff">256</span>
</span></span><span style="display:flex;"><span>    batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">16</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>    net <span style="color:#f92672">=</span> MLP(neural_nums, layer_nums)
</span></span><span style="display:flex;"><span>    net<span style="color:#f92672">.</span>initialize()
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>    inputs <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn((batch_size, neural_nums))  <span style="color:#75715e"># normal: mean=0, std=1</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>    output <span style="color:#f92672">=</span> net(inputs)
</span></span><span style="display:flex;"><span>    print(output)
</span></span></code></pre></div><h5 id="4-kaiming-正态分布">.4. kaiming 正态分布</h5>
<blockquote>
<p>torch.nn.init.kaiming_normal_(<em>tensor</em>, <em>a=0</em>, <em>mode=&lsquo;fan_in&rsquo;</em>, <em>nonlinearity=&lsquo;leaky_relu&rsquo;</em>)</p>
<p>此为0均值的正态分布，N～ (0,std)，其中std = sqrt(2/(1+a^2)*fan_in)</p>
<p>其中，a为激活函数的负半轴的斜率，relu是0</p>
<p>mode- 可选为fan_in 或 fan_out, fan_in使正向传播时，方差一致;fan_out使反向传播时，方差一致</p>
<p>nonlinearity- 可选 relu 和 leaky_relu ，默认值为 。 leaky_relu</p>
<p>nn.init.kaiming_normal_(w, mode=&lsquo;fan_out&rsquo;, nonlinearity=&lsquo;relu&rsquo;)</p>
</blockquote>
<h5 id="5-均匀初始化分布">.5. 均匀初始化分布</h5>
<blockquote>
<p>torch.nn.init.uniform_(<em>tensor</em>, <em>a=0</em>, <em>b=1</em>)</p>
<p>使值服从均匀分布U(a,b)</p>
</blockquote>
<h5 id="6-正态初始化分布">.6. 正态初始化分布</h5>
<blockquote>
<p>torch.nn.init.normal_(<em>tensor</em>, <em>mean=0</em>, <em>std=1</em>)</p>
<p>使值服从正态分布N(mean, std)，默认值为0，1</p>
</blockquote>
<h5 id="7-常数初始化">.7. 常数初始化</h5>
<blockquote>
<p>torch.nn.init.constant_(<em>tensor</em>, <em>val</em>)</p>
<p>使值为常数val nn.init.constant_(w, 0.3)</p>
</blockquote>
<h5 id="8-单位矩阵初始化">.8. 单位矩阵初始化</h5>
<blockquote>
<p>torch.nn.init.eye_(<em>tensor</em>)</p>
<p>将二维tensor初始化为单位矩阵（the identity matrix）</p>
</blockquote>
<h5 id="9-正交初始化">.9. 正交初始化</h5>
<blockquote>
<p>torch.nn.init.orthogonal_(<em>tensor</em>, <em>gain=1</em>)</p>
<p>使得tensor是正交的，论文:Exact solutions to the nonlinear dynamics of learning in deep linear neural networks” - Saxe, A. et al. (2013)</p>
</blockquote>
<h5 id="10-稀疏初始化">.10. 稀疏初始化</h5>
<blockquote>
<p>torch.nn.init.sparse_(<em>tensor</em>, <em>sparsity</em>, <em>std=0.01</em>)</p>
<p>从正态分布N～（0. std）中进行稀疏化，使每一个column有一部分为0</p>
<p>sparsity- 每一个column稀疏的比例，即为0的比例</p>
<p>nn.init.sparse_(w, sparsity=0.1)</p>
</blockquote>
<blockquote>
<p>注意 model.modules()和 model.children()的区别：<strong>model.modules()<strong>会迭代地遍历模型的</strong>所有子层</strong>，而**model.children()**只会遍历模型下的一层。</p>
</blockquote>
<ul>
<li><strong>对网络中某一层进行初始化</strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>self<span style="color:#f92672">.</span>conv1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">7</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>)
</span></span><span style="display:flex;"><span>init<span style="color:#f92672">.</span>xavier_uniform(self<span style="color:#f92672">.</span>conv1<span style="color:#f92672">.</span>weight)
</span></span><span style="display:flex;"><span>init<span style="color:#f92672">.</span>constant(self<span style="color:#f92672">.</span>conv1<span style="color:#f92672">.</span>bias, <span style="color:#ae81ff">0.1</span>)
</span></span></code></pre></div><ul>
<li><strong>对网络整体进行初始化</strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">weights_init</span>(m):
</span></span><span style="display:flex;"><span>    classname<span style="color:#f92672">=</span>m<span style="color:#f92672">.</span>__class__<span style="color:#f92672">.</span>__name__
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> classname<span style="color:#f92672">.</span>find(<span style="color:#e6db74">&#39;Conv&#39;</span>) <span style="color:#f92672">!=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>:
</span></span><span style="display:flex;"><span>        xavier(m<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data)
</span></span><span style="display:flex;"><span>        xavier(m<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>data)
</span></span><span style="display:flex;"><span>net <span style="color:#f92672">=</span> Net()<span style="color:#75715e">#构建网络</span>
</span></span><span style="display:flex;"><span>net<span style="color:#f92672">.</span>apply(weights_init) <span style="color:#75715e">#apply函数会递归地搜索网络内的所有module并把参数表示的函数应用到所有的module上。  </span>
</span></span><span style="display:flex;"><span> <span style="color:#75715e">#对所有的Conv层都初始化权重. </span>
</span></span></code></pre></div><ul>
<li><strong>权重初始化</strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Common practise for initialization.</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> layer <span style="color:#f92672">in</span> model<span style="color:#f92672">.</span>modules():
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> isinstance(layer, torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Conv2d):
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>kaiming_normal_(layer<span style="color:#f92672">.</span>weight, mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;fan_out&#39;</span>,
</span></span><span style="display:flex;"><span>                                      nonlinearity<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> layer<span style="color:#f92672">.</span>bias <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>            torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>constant_(layer<span style="color:#f92672">.</span>bias, val<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">elif</span> isinstance(layer, torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>BatchNorm2d):
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>constant_(layer<span style="color:#f92672">.</span>weight, val<span style="color:#f92672">=</span><span style="color:#ae81ff">1.0</span>)
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>constant_(layer<span style="color:#f92672">.</span>bias, val<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">elif</span> isinstance(layer, torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Linear):
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>xavier_normal_(layer<span style="color:#f92672">.</span>weight)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> layer<span style="color:#f92672">.</span>bias <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>            torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>constant_(layer<span style="color:#f92672">.</span>bias, val<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialization with given tensor.</span>
</span></span><span style="display:flex;"><span>layer<span style="color:#f92672">.</span>weight <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Parameter(tensor)
</span></span></code></pre></div><ul>
<li><strong>对指定层进行Finetune</strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>count <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>para_optim <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> model<span style="color:#f92672">.</span>children():
</span></span><span style="display:flex;"><span>    count <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 6 should be changed properly</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> count <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">6</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> param <span style="color:#f92672">in</span> k<span style="color:#f92672">.</span>parameters():
</span></span><span style="display:flex;"><span>            para_optim<span style="color:#f92672">.</span>append(param)
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">for</span> param <span style="color:#f92672">in</span> k<span style="color:#f92672">.</span>parameters():
</span></span><span style="display:flex;"><span>                    param<span style="color:#f92672">.</span>requires_grad <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>optimizer <span style="color:#f92672">=</span> optim<span style="color:#f92672">.</span>RMSprop(para_optim, lr)
</span></span></code></pre></div><ul>
<li><strong>对固定部分参数训练</strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 只有True的才训练</span>
</span></span><span style="display:flex;"><span>optimizer<span style="color:#f92672">.</span>SGD(filter(<span style="color:#66d9ef">lambda</span> p: p<span style="color:#f92672">.</span>requires_grad, model<span style="color:#f92672">.</span>parameters()), lr<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-3</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Net</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super(Net, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>conv1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">6</span>, <span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>conv2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">6</span>, <span style="color:#ae81ff">16</span>, <span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>		<span style="color:#75715e">#前面的参数就是False，而后面的不变</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> p <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>parameters():
</span></span><span style="display:flex;"><span>            p<span style="color:#f92672">.</span>requires_grad<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>fc1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">16</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">5</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">120</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>fc2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">120</span>, <span style="color:#ae81ff">84</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>fc3 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">84</span>, <span style="color:#ae81ff">10</span>)
</span></span></code></pre></div><ul>
<li><strong>优化</strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>optimizer <span style="color:#f92672">=</span> optim<span style="color:#f92672">.</span>Adam([
</span></span><span style="display:flex;"><span>        {<span style="color:#e6db74">&#39;params&#39;</span>: [param <span style="color:#66d9ef">for</span> name, param <span style="color:#f92672">in</span> net<span style="color:#f92672">.</span>named_parameters() <span style="color:#66d9ef">if</span> name[<span style="color:#f92672">-</span><span style="color:#ae81ff">4</span>:] <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;bias&#39;</span>],
</span></span><span style="display:flex;"><span>         <span style="color:#e6db74">&#39;lr&#39;</span>: <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> args[<span style="color:#e6db74">&#39;lr&#39;</span>]},
</span></span><span style="display:flex;"><span>        {<span style="color:#e6db74">&#39;params&#39;</span>: [param <span style="color:#66d9ef">for</span> name, param <span style="color:#f92672">in</span> net<span style="color:#f92672">.</span>named_parameters() <span style="color:#66d9ef">if</span> name[<span style="color:#f92672">-</span><span style="color:#ae81ff">4</span>:] <span style="color:#f92672">!=</span> <span style="color:#e6db74">&#39;bias&#39;</span>],
</span></span><span style="display:flex;"><span>         <span style="color:#e6db74">&#39;lr&#39;</span>: args[<span style="color:#e6db74">&#39;lr&#39;</span>], <span style="color:#e6db74">&#39;weight_decay&#39;</span>: args[<span style="color:#e6db74">&#39;weight_decay&#39;</span>]}
</span></span><span style="display:flex;"><span>    ], betas<span style="color:#f92672">=</span>(args[<span style="color:#e6db74">&#39;momentum&#39;</span>], <span style="color:#ae81ff">0.999</span>))
</span></span></code></pre></div><ul>
<li>加载部分权重</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 获得模型的键值</span>
</span></span><span style="display:flex;"><span>keys<span style="color:#f92672">=</span>[]
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> k,v <span style="color:#f92672">in</span> desnet<span style="color:#f92672">.</span>state_dict()<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> v<span style="color:#f92672">.</span>shape:
</span></span><span style="display:flex;"><span>        keys<span style="color:#f92672">.</span>append(k)
</span></span><span style="display:flex;"><span>    print(k,v<span style="color:#f92672">.</span>shape)  
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 从预训练文件中加载权重</span>
</span></span><span style="display:flex;"><span>state<span style="color:#f92672">=</span>{}
</span></span><span style="display:flex;"><span>pretrained_dict <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#39;/home/lulu/pytorch/Paper_Code/weights/densenet121-a639ec97.pth&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i,(k,v) <span style="color:#f92672">in</span> enumerate(pretrained_dict<span style="color:#f92672">.</span>items()):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> <span style="color:#e6db74">&#39;classifier&#39;</span> <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> k:
</span></span><span style="display:flex;"><span>        state[keys[i]] <span style="color:#f92672">=</span> v
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 保存权重</span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>save(state,<span style="color:#e6db74">&#39;/home/lulu/pytorch/Paper_Code/weights/densenet121.pth&#39;</span>)
</span></span></code></pre></div><h3 id="4-构建模型">4. 构建模型</h3>
<blockquote>
<ul>
<li>Sequential：<code>顺序性，各网络层之间严格按照顺序执行，常用语block构建</code></li>
<li>ModuleList：<code>迭代性，常用于大量重复网络构建，通过for循环实现重复构建</code></li>
<li>ModuleDict：<code>索引性，常用于可选择的网络层</code></li>
</ul>
</blockquote>
<h5 id="1-nnsequential">.1. nn.Sequential</h5>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># ============================ Sequential</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">LeNetSequential</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, classes):
</span></span><span style="display:flex;"><span>        super(LeNetSequential, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>features <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">6</span>, <span style="color:#ae81ff">5</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>MaxPool2d(kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">6</span>, <span style="color:#ae81ff">16</span>, <span style="color:#ae81ff">5</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>MaxPool2d(kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),)
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>classifier <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">16</span><span style="color:#f92672">*</span><span style="color:#ae81ff">5</span><span style="color:#f92672">*</span><span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">120</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">120</span>, <span style="color:#ae81ff">84</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">84</span>, classes),)
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>features(x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>view(x<span style="color:#f92672">.</span>size()[<span style="color:#ae81ff">0</span>], <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>classifier(x)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x
</span></span></code></pre></div><h5 id="2-nnmodulelist">.2. nn.ModuleList</h5>
<blockquote>
<p>功能：<code>像python的**list**一样包装多个网络层，以迭代的方式调用网络层</code></p>
<ul>
<li>append（）：在modulelist后面<strong>添加</strong>网络层</li>
<li>extend（）：<strong>拼接</strong>两个modulelist</li>
<li>insert（）：在modulelist中指定位置<strong>插入</strong>网络层</li>
</ul>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">ModuleList</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super(ModuleList, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>linears <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>ModuleList([nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">10</span>) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">20</span>)])
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> i, linear <span style="color:#f92672">in</span> enumerate(self<span style="color:#f92672">.</span>linears):
</span></span><span style="display:flex;"><span>            x <span style="color:#f92672">=</span> linear(x)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x
</span></span><span style="display:flex;"><span>net <span style="color:#f92672">=</span> ModuleList()
</span></span><span style="display:flex;"><span>print(net)
</span></span><span style="display:flex;"><span>fake_data <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>ones((<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">10</span>))
</span></span><span style="display:flex;"><span>output <span style="color:#f92672">=</span> net(fake_data)
</span></span><span style="display:flex;"><span>print(output)
</span></span></code></pre></div><h5 id="3-nnmoduledict">.3. nn.ModuleDict</h5>
<blockquote>
<p>功能：<code>像python的dict一样包装多个网络层（每一个给一个key，可通过key索引网络层）</code></p>
<ul>
<li>clear（）：清空moduleDict</li>
<li>items（）：返回可迭代的键值对（key-value pairs）</li>
<li>keys（）：返回字典的key</li>
<li>values（）：返回字典的value</li>
<li>pop（）：返回一对键值，并从字典中删除</li>
</ul>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># ============================ ModuleDict</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">ModuleDict</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super(ModuleDict, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>choices <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>ModuleDict({
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;conv&#39;</span>: nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">3</span>),
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;pool&#39;</span>: nn<span style="color:#f92672">.</span>MaxPool2d(<span style="color:#ae81ff">3</span>)
</span></span><span style="display:flex;"><span>        })
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>activations <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>ModuleDict({
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;relu&#39;</span>: nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;prelu&#39;</span>: nn<span style="color:#f92672">.</span>PReLU()
</span></span><span style="display:flex;"><span>        })
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x, choice, act):
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>choices[choice](x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>activations[act](x)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x
</span></span><span style="display:flex;"><span>net <span style="color:#f92672">=</span> ModuleDict()
</span></span><span style="display:flex;"><span>fake_img <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn((<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">32</span>, <span style="color:#ae81ff">32</span>))
</span></span><span style="display:flex;"><span>output <span style="color:#f92672">=</span> net(fake_img, <span style="color:#e6db74">&#39;conv&#39;</span>, <span style="color:#e6db74">&#39;relu&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e">#prelu输出结果有负值，改为relu后输出没有负数，可以检查是不是按照我们的想法运行的</span>
</span></span><span style="display:flex;"><span>print(output)
</span></span></code></pre></div><h3 id="5-使用预训练模型">5. 使用预训练模型</h3>
<h4 id="0-alexnet-预训练模型修改">.0. AlexNet 预训练模型修改</h4>
<h6 id="1-直接使用alexnet并添加可视化">1. 直接使用AlexNet，并添加可视化</h6>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torchvision.models <span style="color:#66d9ef">as</span> models
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torchvision.transforms <span style="color:#66d9ef">as</span> transforms
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn.functional <span style="color:#66d9ef">as</span> F 
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torchvision.utils <span style="color:#66d9ef">as</span> utils
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> cv2 
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np 
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> PIL <span style="color:#f92672">import</span> Image
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> argparse
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">input commands
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>paser <span style="color:#f92672">=</span> argparse<span style="color:#f92672">.</span>ArgumentParser()
</span></span><span style="display:flex;"><span>paser<span style="color:#f92672">.</span>add_argument(<span style="color:#e6db74">&#34;--test_img&#34;</span>, type<span style="color:#f92672">=</span>str, default<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;whippet.jpg&#39;</span>, help<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;testing image&#34;</span>)
</span></span><span style="display:flex;"><span>opt <span style="color:#f92672">=</span> paser<span style="color:#f92672">.</span>parse_args()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># function for visualizing the feature maps</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">visualize_activation_maps</span>(input, model):
</span></span><span style="display:flex;"><span>    I <span style="color:#f92672">=</span> utils<span style="color:#f92672">.</span>make_grid(input, nrow<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, normalize<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, scale_each<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>    img <span style="color:#f92672">=</span> I<span style="color:#f92672">.</span>permute((<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">0</span>))<span style="color:#f92672">.</span>cpu()<span style="color:#f92672">.</span>numpy()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    conv_results <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> input
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> idx, operation <span style="color:#f92672">in</span> enumerate(model<span style="color:#f92672">.</span>features):
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> operation(x)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> idx <span style="color:#f92672">in</span> {<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">9</span>, <span style="color:#ae81ff">11</span>}:
</span></span><span style="display:flex;"><span>            conv_results<span style="color:#f92672">.</span>append(x)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">5</span>):
</span></span><span style="display:flex;"><span>        conv_result <span style="color:#f92672">=</span> conv_results[i]
</span></span><span style="display:flex;"><span>        N, C, H, W <span style="color:#f92672">=</span> conv_result<span style="color:#f92672">.</span>size()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        mean_acti_map <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>mean(conv_result, <span style="color:#ae81ff">1</span>, <span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        mean_acti_map <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>interpolate(mean_acti_map, size<span style="color:#f92672">=</span>[<span style="color:#ae81ff">224</span>,<span style="color:#ae81ff">224</span>], mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;bilinear&#39;</span>, align_corners<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        map_grid <span style="color:#f92672">=</span> utils<span style="color:#f92672">.</span>make_grid(mean_acti_map, nrow<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, normalize<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, scale_each<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        map_grid <span style="color:#f92672">=</span> map_grid<span style="color:#f92672">.</span>permute((<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">0</span>))<span style="color:#f92672">.</span>mul(<span style="color:#ae81ff">255</span>)<span style="color:#f92672">.</span>byte()<span style="color:#f92672">.</span>cpu()<span style="color:#f92672">.</span>numpy()
</span></span><span style="display:flex;"><span>        map_grid <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>applyColorMap(map_grid, cv2<span style="color:#f92672">.</span>COLORMAP_JET)
</span></span><span style="display:flex;"><span>        map_grid <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>cvtColor(map_grid, cv2<span style="color:#f92672">.</span>COLOR_BGR2RGB)
</span></span><span style="display:flex;"><span>        map_grid <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>float32(map_grid) <span style="color:#f92672">/</span> <span style="color:#ae81ff">255</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        visual_acti_map <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.6</span> <span style="color:#f92672">*</span> img <span style="color:#f92672">+</span> <span style="color:#ae81ff">0.4</span> <span style="color:#f92672">*</span> map_grid
</span></span><span style="display:flex;"><span>        tensor_visual_acti_map <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>from_numpy(visual_acti_map)<span style="color:#f92672">.</span>permute(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        file_name_visual_acti_map <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;conv</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">_activation_map.jpg&#39;</span><span style="color:#f92672">.</span>format(i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        utils<span style="color:#f92672">.</span>save_image(tensor_visual_acti_map, file_name_visual_acti_map)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># main </span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    data transforms, for pre-processing the input testing image before feeding into the net
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    data_transforms <span style="color:#f92672">=</span> transforms<span style="color:#f92672">.</span>Compose([
</span></span><span style="display:flex;"><span>        transforms<span style="color:#f92672">.</span>Resize((<span style="color:#ae81ff">224</span>,<span style="color:#ae81ff">224</span>)),             <span style="color:#75715e"># resize the input to 224x224</span>
</span></span><span style="display:flex;"><span>        transforms<span style="color:#f92672">.</span>ToTensor(),              <span style="color:#75715e"># put the input to tensor format</span>
</span></span><span style="display:flex;"><span>        transforms<span style="color:#f92672">.</span>Normalize([<span style="color:#ae81ff">0.485</span>, <span style="color:#ae81ff">0.456</span>, <span style="color:#ae81ff">0.406</span>], [<span style="color:#ae81ff">0.229</span>, <span style="color:#ae81ff">0.224</span>, <span style="color:#ae81ff">0.225</span>])  <span style="color:#75715e"># normalize the input</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># the normalization is based on images from ImageNet</span>
</span></span><span style="display:flex;"><span>    ])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># obtain the file path of the testing image</span>
</span></span><span style="display:flex;"><span>    test_image_dir <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;./alexnet_images&#39;</span>
</span></span><span style="display:flex;"><span>    test_image_filepath <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(test_image_dir, opt<span style="color:#f92672">.</span>test_img)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#print(test_image_filepath)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># open the testing image</span>
</span></span><span style="display:flex;"><span>    img <span style="color:#f92672">=</span> Image<span style="color:#f92672">.</span>open(test_image_filepath)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;original image&#39;s shape: &#34;</span> <span style="color:#f92672">+</span> str(img<span style="color:#f92672">.</span>size))
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># pre-process the input</span>
</span></span><span style="display:flex;"><span>    transformed_img <span style="color:#f92672">=</span> data_transforms(img)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;transformed image&#39;s shape: &#34;</span> <span style="color:#f92672">+</span> str(transformed_img<span style="color:#f92672">.</span>shape))
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># form a batch with only one image</span>
</span></span><span style="display:flex;"><span>    batch_img <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>unsqueeze(transformed_img, <span style="color:#ae81ff">0</span>)  <span style="color:#75715e">#Returns a new tensor with a dimension of size one inserted at the specified position.</span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;image batch&#39;s shape: &#34;</span> <span style="color:#f92672">+</span> str(batch_img<span style="color:#f92672">.</span>shape))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># load pre-trained AlexNet model</span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">feed the input into the pre-trained alexnet to get the output&#34;</span>)
</span></span><span style="display:flex;"><span>    alexnet <span style="color:#f92672">=</span> models<span style="color:#f92672">.</span>alexnet(pretrained<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># put the model to eval mode for testing</span>
</span></span><span style="display:flex;"><span>    alexnet<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># obtain the output of the model</span>
</span></span><span style="display:flex;"><span>    output <span style="color:#f92672">=</span> alexnet(batch_img)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;output vector&#39;s shape: &#34;</span> <span style="color:#f92672">+</span> str(output<span style="color:#f92672">.</span>shape))
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># obtain the activation maps</span>
</span></span><span style="display:flex;"><span>    visualize_activation_maps(batch_img, alexnet)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># map the class no. to the corresponding label</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#39;class_names_ImageNet.txt&#39;</span>) <span style="color:#66d9ef">as</span> labels:
</span></span><span style="display:flex;"><span>        classes <span style="color:#f92672">=</span> [i<span style="color:#f92672">.</span>strip() <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> labels<span style="color:#f92672">.</span>readlines()]
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># print the first 5 classes to see the labels</span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">print the first 5 classes to see the lables&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">5</span>):
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;class &#34;</span> <span style="color:#f92672">+</span> str(i) <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;: &#34;</span> <span style="color:#f92672">+</span> str(classes[i]))
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># sort the probability vector in descending order</span>
</span></span><span style="display:flex;"><span>    sorted, indices <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>sort(output, descending<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>    percentage <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>softmax(output, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">*</span> <span style="color:#ae81ff">100.0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># obtain the first 5 classes (with the highest probability) the input belongs to</span>
</span></span><span style="display:flex;"><span>    results <span style="color:#f92672">=</span> [(classes[i], percentage[i]<span style="color:#f92672">.</span>item()) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> indices[<span style="color:#ae81ff">0</span>][:<span style="color:#ae81ff">5</span>]]
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">print the first 5 classes the testing image belongs to&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">5</span>):
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">: </span><span style="color:#e6db74">{:.4f}</span><span style="color:#e6db74">%&#39;</span><span style="color:#f92672">.</span>format(results[i][<span style="color:#ae81ff">0</span>], results[i][<span style="color:#ae81ff">1</span>]))
</span></span></code></pre></div><h6 id="2-修改alexnet最后一层">2. 修改Alexnet最后一层</h6>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torchvision.models <span style="color:#66d9ef">as</span> models
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> models<span style="color:#f92672">.</span>AlexNet()
</span></span><span style="display:flex;"><span>print(model)
</span></span><span style="display:flex;"><span><span style="color:#75715e">#修改网络的第一个卷积层的输入为4通道，输出的结果预测为10个类别</span>
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>features[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">=</span>nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">11</span>, <span style="color:#ae81ff">11</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">4</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>classifier[<span style="color:#ae81ff">6</span>] <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">4096</span>,<span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(model)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>model <span style="color:#f92672">=</span> cifar10_cnn<span style="color:#f92672">.</span>CIFAR10_Nettest()
</span></span><span style="display:flex;"><span>pretrained_dict <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#39;models/cifar10_statedict.pkl&#39;</span>)
</span></span><span style="display:flex;"><span>model_dict <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>state_dict()
</span></span><span style="display:flex;"><span>pretrained_dict <span style="color:#f92672">=</span> {k: v <span style="color:#66d9ef">for</span> k, v <span style="color:#f92672">in</span> pretrained_dict<span style="color:#f92672">.</span>items() <span style="color:#66d9ef">if</span> k <span style="color:#f92672">in</span> model_dict}
</span></span><span style="display:flex;"><span>model_dict<span style="color:#f92672">.</span>update(pretrained_dict)
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>load_state_dict(model_dict)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(model)
</span></span><span style="display:flex;"><span>new_model_dict <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>state_dict()
</span></span><span style="display:flex;"><span>dict_name <span style="color:#f92672">=</span> list(new_model_dict)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i, p <span style="color:#f92672">in</span> enumerate(dict_name):
</span></span><span style="display:flex;"><span>    print(i, p)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;before change:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>,new_model_dict[<span style="color:#e6db74">&#39;classifier.5.bias&#39;</span>])
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>classifier[<span style="color:#ae81ff">5</span>]<span style="color:#f92672">=</span>nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">1024</span>,<span style="color:#ae81ff">17</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>change_model_dict <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>state_dict()
</span></span><span style="display:flex;"><span>new_dict_name <span style="color:#f92672">=</span> list(change_model_dict)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;after change:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>,change_model_dict[<span style="color:#e6db74">&#39;classifier.5.bias&#39;</span>])
</span></span></code></pre></div><p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716225130620.png"
    data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716225130620.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716225130620.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716225130620.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716225130620.png"
    title="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716225130620.png"/></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torchvision <span style="color:#f92672">import</span> models
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">BuildAlexNet</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, model_type, n_output):
</span></span><span style="display:flex;"><span>        super(BuildAlexNet, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model_type <span style="color:#f92672">=</span> model_type
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> model_type <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;pre&#39;</span>:
</span></span><span style="display:flex;"><span>            model <span style="color:#f92672">=</span> models<span style="color:#f92672">.</span>alexnet(pretrained<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>features <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>features
</span></span><span style="display:flex;"><span>            fc1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">9216</span>, <span style="color:#ae81ff">4096</span>)
</span></span><span style="display:flex;"><span>            fc1<span style="color:#f92672">.</span>bias <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>classifier[<span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>bias
</span></span><span style="display:flex;"><span>            fc1<span style="color:#f92672">.</span>weight <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>classifier[<span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>weight
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            fc2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">4096</span>, <span style="color:#ae81ff">4096</span>)
</span></span><span style="display:flex;"><span>            fc2<span style="color:#f92672">.</span>bias <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>classifier[<span style="color:#ae81ff">4</span>]<span style="color:#f92672">.</span>bias
</span></span><span style="display:flex;"><span>            fc2<span style="color:#f92672">.</span>weight <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>classifier[<span style="color:#ae81ff">4</span>]<span style="color:#f92672">.</span>weight
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>classifier <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>Dropout(),
</span></span><span style="display:flex;"><span>                    fc1,
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>Dropout(),
</span></span><span style="display:flex;"><span>                    fc2,
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">4096</span>, n_output))  
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># </span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#            model.classifier[6]==nn.Linear(4096,n_output)</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#            self.classifier = model.classifier</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> model_type <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;new&#39;</span>:
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>features <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">11</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>ReLU(inplace <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>MaxPool2d(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">0</span>),
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">192</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>MaxPool2d(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">0</span>),
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">192</span>, <span style="color:#ae81ff">384</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>ReLU(inplace <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">384</span>, <span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>MaxPool2d(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">0</span>))
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>classifier <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>Dropout(),
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">9216</span>, <span style="color:#ae81ff">4096</span>),
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>Dropout(),
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">4096</span>, <span style="color:#ae81ff">4096</span>),
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">4096</span>, n_output))
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>features(x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>view(x<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>), <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        out  <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>classifier(x)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> out
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torch.autograd <span style="color:#f92672">import</span> Variable
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;__main__&#39;</span>:
</span></span><span style="display:flex;"><span>    model_type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;pre&#39;</span>
</span></span><span style="display:flex;"><span>    n_output <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>    alexnet <span style="color:#f92672">=</span> BuildAlexNet(model_type, n_output)
</span></span><span style="display:flex;"><span>    print(alexnet)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>rand(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">224</span>,<span style="color:#ae81ff">224</span>)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>float32)
</span></span><span style="display:flex;"><span>    x_ts <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>from_numpy(x)
</span></span><span style="display:flex;"><span>    x_in <span style="color:#f92672">=</span> Variable(x_ts)
</span></span><span style="display:flex;"><span>    y <span style="color:#f92672">=</span> alexnet(x_in)
</span></span></code></pre></div><h4 id="1-resnet参数修改">.1. ResNet参数修改</h4>
<blockquote>
<p>resnet网络最后一层分类层fc是对1000种类型进行划分，对于自己的数据集，如果只有9类</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># coding=UTF-8</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torchvision.models <span style="color:#66d9ef">as</span> models
</span></span><span style="display:flex;"><span><span style="color:#75715e">#调用模型</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> models<span style="color:#f92672">.</span>resnet50(pretrained<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e">#提取fc层中固定的参数</span>
</span></span><span style="display:flex;"><span>fc_features <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>fc<span style="color:#f92672">.</span>in_features
</span></span><span style="display:flex;"><span><span style="color:#75715e">#修改类别为9</span>
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>fc <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(fc_features, <span style="color:#ae81ff">9</span>)
</span></span></code></pre></div><h4 id="2-增减卷积层">.2. 增减卷积层</h4>
<blockquote>
<p>1、先建立好自己的网络（与预训练的模型类似，要不谈何fine-tune）</p>
<p>2、然后将预训练模型参数与自己搭建的网络不一致的部分参数去掉</p>
<p>3、将保留的合适的参数读入网络初始化，实现fine-tune的效果</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># -*- coding:utf-8 -*-</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#####################</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#建立自己的网络模型net</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#####################</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">###然后读出预训练模型参数以resnet152为例，我不是利用程序下载的，我是习惯了下载好存储在文件夹中</span>
</span></span><span style="display:flex;"><span>pretrained_dict <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>load(save_path)
</span></span><span style="display:flex;"><span>model_dict <span style="color:#f92672">=</span> net<span style="color:#f92672">.</span>state_dict()   <span style="color:#75715e">#(读出搭建的网络的参数，以便后边更新之后初始化）</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">####去除不属于model_dict的键值</span>
</span></span><span style="display:flex;"><span>pretrained_dict<span style="color:#f92672">=</span>{ k : v <span style="color:#66d9ef">for</span> k, v <span style="color:#f92672">in</span> pretrained_dict<span style="color:#f92672">.</span>items() <span style="color:#66d9ef">if</span> k <span style="color:#f92672">in</span> model_dict}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">###更新现有的model_dict的值</span>
</span></span><span style="display:flex;"><span>model_dict<span style="color:#f92672">.</span>update(pretrained_dict)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">##加载模型需要的参数</span>
</span></span><span style="display:flex;"><span>net<span style="color:#f92672">.</span>load_state_dict(model_dict)
</span></span></code></pre></div><h4 id="3-imagenet计算多层卷积特征">.3. ImageNet计算多层卷积特征</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">FeatureExtractor</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Helper class to extract several convolution features from the given
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    pre-trained model.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Attributes:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        _model, torch.nn.Module.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        _layers_to_extract, list&lt;str&gt; or set&lt;str&gt;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Example:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &gt;&gt;&gt; model = torchvision.models.resnet152(pretrained=True)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &gt;&gt;&gt; model = torch.nn.Sequential(collections.OrderedDict(
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                list(model.named_children())[:-1]))
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &gt;&gt;&gt; conv_representation = FeatureExtractor(
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                pretrained_model=model,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                layers_to_extract={&#39;layer1&#39;, &#39;layer2&#39;, &#39;layer3&#39;, &#39;layer4&#39;})(image)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, pretrained_model, layers_to_extract):
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module<span style="color:#f92672">.</span>__init__(self)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>_model <span style="color:#f92672">=</span> pretrained_model
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>_model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>_layers_to_extract <span style="color:#f92672">=</span> set(layers_to_extract)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>            conv_representation <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> name, layer <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>_model<span style="color:#f92672">.</span>named_children():
</span></span><span style="display:flex;"><span>                x <span style="color:#f92672">=</span> layer(x)
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">if</span> name <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>_layers_to_extract:
</span></span><span style="display:flex;"><span>                    conv_representation<span style="color:#f92672">.</span>append(x)
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> conv_representation
</span></span></code></pre></div><h4 id="4-训练特定层冻结其它层">4. 训练特定层，冻结其它层</h4>
<blockquote>
<p>将模型起始的一些层的权重保持不变，重新训练后面的层，得到新的权重。在这个过程中，可多次进行尝试，从而能够依据结果找到 frozen layers 和 retrain layers 之间的最佳搭配。 如何使用预训练模型，是由数据集大小和新旧数据集(预训练的数据集和自己要解决的数据集)之间数据的相似度来决定的。</p>
<ul>
<li><code>requires_grad</code>为False来冻结网络参数</li>
<li>**filter(lambda p: p.requires_grad, model.parameters())**过滤掉requires_grad=false的层</li>
</ul>
</blockquote>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716230659569.png"
    data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716230659569.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716230659569.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716230659569.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716230659569.png"
    title="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210716230659569.png"/></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#首先自己新定义一个网络</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">CNN</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, block, layers, num_classes<span style="color:#f92672">=</span><span style="color:#ae81ff">9</span>): 
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#自己新定义的CNN与继承的ResNet网络结构大体相同，即除了新增层，其他层的层名与ResNet的相同。</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>inplanes <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span> 
</span></span><span style="display:flex;"><span>        super(ResNet, self)<span style="color:#f92672">.</span>__init__() <span style="color:#75715e">#继承ResNet网络结构</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>conv1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">7</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>) 
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>bn1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>BatchNorm2d(<span style="color:#ae81ff">64</span>) 
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>relu <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>) 
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>maxpool <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>MaxPool2d(kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>) 
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>layer1 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_make_layer(block, <span style="color:#ae81ff">64</span>, layers[<span style="color:#ae81ff">0</span>]) 
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>layer2 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_make_layer(block, <span style="color:#ae81ff">128</span>, layers[<span style="color:#ae81ff">1</span>], stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>) 
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>layer3 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_make_layer(block, <span style="color:#ae81ff">256</span>, layers[<span style="color:#ae81ff">2</span>], stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>) 
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>layer4 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_make_layer(block, <span style="color:#ae81ff">512</span>, layers[<span style="color:#ae81ff">3</span>], stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>) 
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>avgpool <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>AvgPool2d(<span style="color:#ae81ff">7</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#新增一个反卷积层 </span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>convtranspose1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>ConvTranspose2d(<span style="color:#ae81ff">2048</span>, <span style="color:#ae81ff">2048</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, output_padding<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, groups<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>, dilation<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>) 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#新增一个最大池化层 </span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>maxpool2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>MaxPool2d(kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>) 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#将原来的fc层改成fclass层 </span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>fclass <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">2048</span>, num_classes) <span style="color:#75715e">#原来的fc层：self.fc = nn.Linear(512 * block.expansion, num_classes)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> m <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>modules(): <span style="color:#75715e">#</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> isinstance(m, nn<span style="color:#f92672">.</span>Conv2d): 
</span></span><span style="display:flex;"><span>                n <span style="color:#f92672">=</span> m<span style="color:#f92672">.</span>kernel_size[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">*</span> m<span style="color:#f92672">.</span>kernel_size[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">*</span> m<span style="color:#f92672">.</span>out_channels <span style="color:#75715e">#</span>
</span></span><span style="display:flex;"><span>                m<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>normal_(<span style="color:#ae81ff">0</span>, math<span style="color:#f92672">.</span>sqrt(<span style="color:#ae81ff">2.</span> <span style="color:#f92672">/</span> n)) 
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">elif</span> isinstance(m, nn<span style="color:#f92672">.</span>BatchNorm2d): 
</span></span><span style="display:flex;"><span>                    m<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>fill_(<span style="color:#ae81ff">1</span>) 
</span></span><span style="display:flex;"><span>                    m<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>zero_() 
</span></span><span style="display:flex;"><span>                    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_make_layer</span>(self, block, planes, blocks, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>): 
</span></span><span style="display:flex;"><span>                        downsample <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span> 
</span></span><span style="display:flex;"><span>                        <span style="color:#66d9ef">if</span> stride <span style="color:#f92672">!=</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">or</span> self<span style="color:#f92672">.</span>inplanes <span style="color:#f92672">!=</span> planes <span style="color:#f92672">*</span> block<span style="color:#f92672">.</span>expansion: 
</span></span><span style="display:flex;"><span>                            downsample <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential( 
</span></span><span style="display:flex;"><span>                                nn<span style="color:#f92672">.</span>Conv2d(self<span style="color:#f92672">.</span>inplanes, planes <span style="color:#f92672">*</span> block<span style="color:#f92672">.</span>expansion, 
</span></span><span style="display:flex;"><span>                                          kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, stride<span style="color:#f92672">=</span>stride, bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>), 
</span></span><span style="display:flex;"><span>                                nn<span style="color:#f92672">.</span>BatchNorm2d(planes <span style="color:#f92672">*</span> block<span style="color:#f92672">.</span>expansion), 
</span></span><span style="display:flex;"><span>                            ) 
</span></span><span style="display:flex;"><span>                            layers <span style="color:#f92672">=</span> [ ] 
</span></span><span style="display:flex;"><span>                            layers<span style="color:#f92672">.</span>append(block(self<span style="color:#f92672">.</span>inplanes, planes, stride, downsample)) 
</span></span><span style="display:flex;"><span>                            self<span style="color:#f92672">.</span>inplanes <span style="color:#f92672">=</span> planes <span style="color:#f92672">*</span> block<span style="color:#f92672">.</span>expansion 
</span></span><span style="display:flex;"><span>                            <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1</span>, blocks): 
</span></span><span style="display:flex;"><span>                                layers<span style="color:#f92672">.</span>append(block(self<span style="color:#f92672">.</span>inplanes, planes)) 
</span></span><span style="display:flex;"><span>                                <span style="color:#66d9ef">return</span> nn<span style="color:#f92672">.</span>Sequential(<span style="color:#f92672">*</span>layers) 
</span></span><span style="display:flex;"><span>                            <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x): 
</span></span><span style="display:flex;"><span>                                x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv1(x) 
</span></span><span style="display:flex;"><span>                                x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>bn1(x) 
</span></span><span style="display:flex;"><span>                                x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>relu(x) 
</span></span><span style="display:flex;"><span>                                x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>maxpool(x) 
</span></span><span style="display:flex;"><span>                                x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>layer1(x) 
</span></span><span style="display:flex;"><span>                                x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>layer2(x) 
</span></span><span style="display:flex;"><span>                                x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>layer3(x) 
</span></span><span style="display:flex;"><span>                                x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>layer4(x) 
</span></span><span style="display:flex;"><span>                                x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>avgpool(x) 
</span></span><span style="display:flex;"><span>                                <span style="color:#75715e">#3个新加层的forward </span>
</span></span><span style="display:flex;"><span>                                x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>view(x<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>), <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>) 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                                <span style="color:#75715e">#因为接下来的self.convtranspose1层的输入通道是2048</span>
</span></span><span style="display:flex;"><span>                                x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>convtranspose1(x) 
</span></span><span style="display:flex;"><span>                                x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>maxpool2(x) 
</span></span><span style="display:flex;"><span>                                x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>view(x<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>), <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                                <span style="color:#75715e">#因为接下来的self.fclass层的输入通道是2048 </span>
</span></span><span style="display:flex;"><span>                                x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>fclass(x) 
</span></span><span style="display:flex;"><span>                                <span style="color:#66d9ef">return</span> x
</span></span><span style="display:flex;"><span>                            <span style="color:#75715e">#加载model </span>
</span></span><span style="display:flex;"><span>                            resnet50 <span style="color:#f92672">=</span> models<span style="color:#f92672">.</span>resnet50(pretrained<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>) 
</span></span><span style="display:flex;"><span>                            cnn <span style="color:#f92672">=</span> CNN(Bottleneck, [<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">6</span>, <span style="color:#ae81ff">3</span>]) <span style="color:#75715e">#创建一个自己新定义的网络对象cnn。</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#微调全连接层</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> torchvision<span style="color:#f92672">.</span>models<span style="color:#f92672">.</span>resnet18(pretrained<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> param <span style="color:#f92672">in</span> model<span style="color:#f92672">.</span>parameters():
</span></span><span style="display:flex;"><span>    param<span style="color:#f92672">.</span>requires_grad <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>fc <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">512</span>, <span style="color:#ae81ff">100</span>)  <span style="color:#75715e"># Replace the last fc layer</span>
</span></span><span style="display:flex;"><span>optimizer <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>optim<span style="color:#f92672">.</span>SGD(model<span style="color:#f92672">.</span>fc<span style="color:#f92672">.</span>parameters(), lr<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-2</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.9</span>, weight_decay<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-4</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#以较大的学习率微调全连接层，较小的学习率微调卷积层</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> torchvision<span style="color:#f92672">.</span>models<span style="color:#f92672">.</span>resnet18(pretrained<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>finetuned_parameters <span style="color:#f92672">=</span> list(map(id, model<span style="color:#f92672">.</span>fc<span style="color:#f92672">.</span>parameters()))
</span></span><span style="display:flex;"><span>conv_parameters <span style="color:#f92672">=</span> (p <span style="color:#66d9ef">for</span> p <span style="color:#f92672">in</span> model<span style="color:#f92672">.</span>parameters() <span style="color:#66d9ef">if</span> id(p) <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> finetuned_parameters)
</span></span><span style="display:flex;"><span>parameters <span style="color:#f92672">=</span> [{<span style="color:#e6db74">&#39;params&#39;</span>: conv_parameters, <span style="color:#e6db74">&#39;lr&#39;</span>: <span style="color:#ae81ff">1e-3</span>}, 
</span></span><span style="display:flex;"><span>              {<span style="color:#e6db74">&#39;params&#39;</span>: model<span style="color:#f92672">.</span>fc<span style="color:#f92672">.</span>parameters()}]
</span></span><span style="display:flex;"><span>optimizer <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>optim<span style="color:#f92672">.</span>SGD(parameters, lr<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-2</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.9</span>, weight_decay<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-4</span>)
</span></span></code></pre></div><h4 id="5-keypointrcnn_resnet50_fpn-模型使用">.5. keypointrcnn_resnet50_fpn 模型使用</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torchvision
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_model</span>(num_kpts,train_kptHead<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,train_fpn<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>):
</span></span><span style="display:flex;"><span>    is_available <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>is_available()
</span></span><span style="display:flex;"><span>    device <span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>device(<span style="color:#e6db74">&#39;cuda:0&#39;</span> <span style="color:#66d9ef">if</span> is_available <span style="color:#66d9ef">else</span> <span style="color:#e6db74">&#39;cpu&#39;</span>)
</span></span><span style="display:flex;"><span>    dtype <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>FloatTensor <span style="color:#66d9ef">if</span> is_available <span style="color:#66d9ef">else</span> torch<span style="color:#f92672">.</span>FloatTensor
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> torchvision<span style="color:#f92672">.</span>models<span style="color:#f92672">.</span>detection<span style="color:#f92672">.</span>keypointrcnn_resnet50_fpn(pretrained<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i,param <span style="color:#f92672">in</span> enumerate(model<span style="color:#f92672">.</span>parameters()):
</span></span><span style="display:flex;"><span>        param<span style="color:#f92672">.</span>requires_grad <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> train_kptHead<span style="color:#f92672">!=</span><span style="color:#66d9ef">False</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">for</span> i, param <span style="color:#f92672">in</span> enumerate(model<span style="color:#f92672">.</span>roi_heads<span style="color:#f92672">.</span>keypoint_head<span style="color:#f92672">.</span>parameters()):
</span></span><span style="display:flex;"><span>          <span style="color:#66d9ef">if</span> i<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span><span style="color:#f92672">&gt;=</span>model<span style="color:#f92672">.</span>roi_heads<span style="color:#f92672">.</span>keypoint_head<span style="color:#f92672">.</span>__len__()<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span><span style="color:#f92672">-</span>train_kptHead:
</span></span><span style="display:flex;"><span>            param<span style="color:#f92672">.</span>requires_grad <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> train_fpn<span style="color:#f92672">==</span><span style="color:#66d9ef">True</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">for</span> param <span style="color:#f92672">in</span> model<span style="color:#f92672">.</span>backbone<span style="color:#f92672">.</span>fpn<span style="color:#f92672">.</span>parameters():
</span></span><span style="display:flex;"><span>        param<span style="color:#f92672">.</span>requires_grad <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    out <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>ConvTranspose2d(<span style="color:#ae81ff">512</span>, num_kpts, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">4</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>roi_heads<span style="color:#f92672">.</span>keypoint_predictor<span style="color:#f92672">.</span>kps_score_lowres <span style="color:#f92672">=</span> out
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> model, device, dtype
</span></span><span style="display:flex;"><span><span style="color:#75715e">#model, device, dtype=get_model(2)</span>
</span></span></code></pre></div><p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201021161049583.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201021161049583.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201021161049583.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201021161049583.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201021161049583.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201021161049583.png"/></p>
</div>
<div class="post-footer" id="post-footer">
  <div class="post-info">
    <div class="post-info-line">
      <div class="post-info-mod">
        <span title=2023-09-28&#32;22:45:34>更新于 2023-09-28&nbsp;</span>
      </div><div class="post-info-license">
          <span><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span>
        </div></div>
    <div class="post-info-line">
      <div class="post-info-md"><span><a href="/pytorch_%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/index.md" title="阅读原始文档" class="link-to-markdown">阅读原始文档</a></span><span><a href="https://liudongdong1.github.io/edit/master/content/posts%5c%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%5cpytorch%5cPytorch_%e9%a2%84%e8%ae%ad%e7%bb%83%e6%a8%a1%e5%9e%8b.md" title="编辑此页"target="_blank" rel="external nofollow noopener noreferrer" class="link-to-edit">编辑此页</a></span></div>
      <div class="post-info-share">
        <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="https://liudongdong1.github.io/pytorch_%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/" data-title="Pytorch_预训练模型" data-hashtags="Pytorch"><i class="fa-brands fa-twitter fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="https://liudongdong1.github.io/pytorch_%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/" data-hashtag="Pytorch"><i class="fa-brands fa-facebook-square fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="https://liudongdong1.github.io/pytorch_%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/" data-title="Pytorch_预训练模型" data-image="https://cdn.stocksnap.io/img-thumbs/280h/keyboard-typing_UATQGKPFOH.jpg"><i class="fa-brands fa-weibo fa-fw" aria-hidden="true"></i></a>
  </span>
      </div>
    </div>
  </div>

  <div class="post-info-more">
    <section class="post-tags"><i class="fa-solid fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/pytorch/">Pytorch</a></section>
    <section>
      <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
    </section>
  </div>

  <div class="post-nav"><a href="/basic/" class="prev" rel="prev" title="PytorchBasic"><i class="fa-solid fa-angle-left fa-fw" aria-hidden="true"></i>PytorchBasic</a>
      <a href="/pytorch_tools/" class="next" rel="next" title="pytorch_Tools">pytorch_Tools<i class="fa-solid fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article></main><footer class="footer">
    <div class="footer-container"><div class="footer-line powered">由 <a href="https://gohugo.io/" target="_blank" rel="external nofollow noopener noreferrer" title="Hugo 0.118.2">Hugo</a> 强力驱动 | 主题 - <a href="https://github.com/hugo-fixit/FixIt" target="_blank" rel="external" title="FixIt v0.2.17-RC"><img class="fixit-icon" src="/fixit.min.svg" alt="FixIt logo" />&nbsp;FixIt</a>
        </div><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">2020 - 2023</span><span class="author" itemprop="copyrightHolder">
              <a href="https://liudongdong1.github.io/"target="_blank" rel="external nofollow noopener noreferrer">LiuDongdong</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div><div class="footer-line statistics"><span class="site-time" title='网站运行中 ...'><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden="true"></i>&nbsp;<span class="run-times">网站运行中 ...</span></span></div><div class="footer-line ibruce">
          <span id="busuanzi_container_site_uv" title='总访客数'><i class="fa-regular fa-user fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span><span id="busuanzi_container_site_pv" class="footer-divider" title='总访问量'><i class="fa-regular fa-eye fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span>
        </div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="回到顶部"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric">0%</span>
        </div></div><a href="https://liudongdong1.github.io/" title="在 GitHub 上查看源代码"target="_blank" rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><div id="mask"></div><div class="reading-progress-bar" style="left: 0;top: 0;--bg-progress: #0076ff;--bg-progress-dark: #fff;"></div><noscript>
    <div class="noscript-warning">FixIt 主题在启用 JavaScript 的情况下效果最佳。</div>
  </noscript>
</div><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script src="/lib/autocomplete/autocomplete.min.js" defer></script><script src="/lib/algoliasearch/algoliasearch-lite.umd.min.js" defer></script><script src="/lib/lazysizes/lazysizes.min.js" async defer></script><script src="/lib/sharer/sharer.min.js" async defer></script><script src="/lib/typeit/index.umd.js" defer></script><script src="/lib/katex/katex.min.js" defer></script><script src="/lib/katex/auto-render.min.js" defer></script><script src="/lib/katex/copy-tex.min.js" defer></script><script src="/lib/katex/mhchem.min.js" defer></script><script src="/lib/cookieconsent/cookieconsent.min.js" defer></script><script src="/lib/pangu/pangu.min.js" defer></script><script src="/lib/cell-watermark/watermark.min.js" defer></script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async defer></script><script>window.config={"code":{"copyTitle":"复制到剪贴板","editLockTitle":"锁定可编辑代码块","editUnLockTitle":"解锁可编辑代码块","editable":true,"maxShownLines":10},"comment":{"enable":false},"cookieconsent":{"content":{"dismiss":"同意","link":"了解更多","message":"本网站使用 Cookies 来改善您的浏览体验。"},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"data":{"typeit-header-subtitle-desktop":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e","typeit-header-subtitle-mobile":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e"},"enablePWA":true,"enablePangu":true,"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"2R1K9SKLQZ","algoliaIndex":"index.zh-cn","algoliaSearchKey":"4a226aa1c5c98d6859e4d1386adb2bc7","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"},"siteTime":"2020-12-18T16:15:22+08:00","typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"typeit-header-subtitle-desktop":["typeit-header-subtitle-desktop"],"typeit-header-subtitle-mobile":["typeit-header-subtitle-mobile"]},"duration":-1,"speed":100},"watermark":{"appendto":".wrapper\u003emain","colspacing":30,"content":"\u003cimg class=\"fixit-icon\" src=\"/fixit.min.svg\" alt=\"FixIt logo\" /\u003e FixIt 主题","enable":true,"fontfamily":"inherit","fontsize":0.85,"height":21,"opacity":0.0125,"rotate":15,"rowspacing":60,"width":150}};</script><script src="/js/theme.min.js" defer></script><script src="/js/custom.min.js" defer></script></body>
</html>
