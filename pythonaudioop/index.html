<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <head>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>pythoAudioOp - DAY By DAY</title><meta name="author" content="LiuDongdong">
<meta name="author-link" content="https://liudongdong1.github.io/">
<meta name="description" content="语音信号有三个重要的参数：声道数、取样频率和量化位数。 声道数：可以是单声道或者是双声道 采样频率：一秒内对声音信号的采集次数，44100Hz采" /><meta name="keywords" content='Voice' /><meta itemprop="name" content="pythoAudioOp">
<meta itemprop="description" content="语音信号有三个重要的参数：声道数、取样频率和量化位数。 声道数：可以是单声道或者是双声道 采样频率：一秒内对声音信号的采集次数，44100Hz采"><meta itemprop="datePublished" content="2020-11-19T07:56:09+00:00" />
<meta itemprop="dateModified" content="2023-09-24T17:00:03+08:00" />
<meta itemprop="wordCount" content="10143"><meta itemprop="image" content="/logo.png"/>
<meta itemprop="keywords" content="Voice," /><meta property="og:title" content="pythoAudioOp" />
<meta property="og:description" content="语音信号有三个重要的参数：声道数、取样频率和量化位数。 声道数：可以是单声道或者是双声道 采样频率：一秒内对声音信号的采集次数，44100Hz采" />
<meta property="og:type" content="article" />
<meta property="og:url" content="liudongdong1.github.io/pythonaudioop/" /><meta property="og:image" content="/logo.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-11-19T07:56:09+00:00" />
<meta property="article:modified_time" content="2023-09-24T17:00:03+08:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="/logo.png"/>

<meta name="twitter:title" content="pythoAudioOp"/>
<meta name="twitter:description" content="语音信号有三个重要的参数：声道数、取样频率和量化位数。 声道数：可以是单声道或者是双声道 采样频率：一秒内对声音信号的采集次数，44100Hz采"/>
<meta name="application-name" content="DAY By DAY">
<meta name="apple-mobile-web-app-title" content="DAY By DAY"><meta name="theme-color" data-light="#f8f8f8" data-dark="#252627" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="liudongdong1.github.io/pythonaudioop/" /><link rel="prev" href="liudongdong1.github.io/recommandation/" /><link rel="next" href="liudongdong1.github.io/devicesurvey/" /><link rel="stylesheet" href="/liudongdong1.github.io/css/style.min.css"><link rel="stylesheet" href="/liudongdong1.github.io/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/liudongdong1.github.io/lib/animate/animate.min.css"><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "pythoAudioOp",
    "inLanguage": "zh-CN",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "liudongdong1.github.io\/pythonaudioop\/"
    },"genre": "posts","keywords": "Voice","wordcount":  10143 ,
    "url": "liudongdong1.github.io\/pythonaudioop\/","datePublished": "2020-11-19T07:56:09+00:00","dateModified": "2023-09-24T17:00:03+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
      "@type": "Organization",
      "name": "LiuDongdong","logo": "\/images\/person.png"},"author": {
        "@type": "Person",
        "name": "liudongdong1"
      },"description": ""
  }
  </script></head>
  <body data-header-desktop="auto" data-header-mobile="auto"><script>(window.localStorage?.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('data-theme', 'dark');</script><div class="wrapper"><header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper" data-github-corner="right">
    <div class="header-title">
      <a href="liudongdong1.github.io/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="DAY By DAY"
    title="DAY By DAY"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-desktop" class="typeit header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/posts/"
                
                
              ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/categories/"
                
                
              ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/tags/"
                
                
              ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/friends/"
                title="友情链接"
                
              ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/about/"
                
                
              ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li class="menu-item delimiter"></li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <ul class="sub-menu"><li class="menu-item">没有更多翻译</li></ul>
          </li><li class="menu-item search" id="search-desktop">
            <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-desktop">
            <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
              <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
            </a>
            <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
              <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
            </a>
            <span class="search-button search-loading" id="search-loading-desktop">
              <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
            </span>
          </li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li>
      </ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="liudongdong1.github.io/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="/fixit.min.svg"
    title="/fixit.min.svg"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-mobile" class="typeit header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li class="search-wrapper">
            <div class="search mobile" id="search-mobile">
              <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-mobile">
              <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
              </a>
              <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
              </a>
              <span class="search-button search-loading" id="search-loading-mobile">
                <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
              </span>
            </div>
            <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
              取消
            </a>
          </li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/posts/"
                  
                  
                ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/categories/"
                  
                  
                ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/tags/"
                  
                  
                ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/friends/"
                  title="友情链接"
                  
                ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/about/"
                  
                  
                ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li
              class="menu-item text-center"
            ><a
                  class="menu-link"
                  href="https://liudongdong1.github.io/"
                  title="GitHub"
                  rel="noopener noreferrer" target="_blank"
                ><i class='fa-brands fa-github fa-fw' aria-hidden='true'></i> </a></li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <select class="language-select" onchange="location = this.value;"><option disabled>没有更多翻译</option></select>
          </li></ul>
    </nav>
  </div>
</header><div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
  </div>
  <div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
  </div><main class="container" data-page-style="normal"><aside class="toc" id="toc-auto"><h2 class="toc-title">目录 <i class="toc-icon fa-solid fa-angle-down fa-fw"></i></h2>
      <div class="toc-content" id="toc-content-auto"></div></aside>

  <aside class="aside-custom" id="aside-sakana">
    

<div class="sakana-widget">
  <div class="sakana-item" id="takina-widget"></div>
  <div class="sakana-item" id="chisato-widget"></div>
</div>
<script>
  function initSakanaWidget() {
    const takina = SakanaWidget.getCharacter('takina')
    SakanaWidget.registerCharacter('takina-slow', takina);
    new SakanaWidget({
      character: 'takina-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#takina-widget');

    const chisato = SakanaWidget.getCharacter('chisato')
    SakanaWidget.registerCharacter('chisato-slow', chisato);
    new SakanaWidget({
      character: 'chisato-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#chisato-widget');
  }
</script>
<script async onload="initSakanaWidget()" src="https://cdn.jsdelivr.net/npm/sakana-widget@2.3.0/lib/sakana.min.js">
</script></aside>

  <article class="page single">
    <div class="header"><h1 class="single-title animate__animated animate__flipInX">
        <span>pythoAudioOp</span>
      </h1></div><div class="post-meta">
      <div class="post-meta-line"><span class="post-author"><span class="author"><i class="fa-solid fa-user-circle" aria-hidden="true"></i>
      liudongdong1</span></span>
          <span class="post-category">收录于 <a href="liudongdong1.github.io/categories/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;Categories</a>&ensp;<a href="liudongdong1.github.io/categories/ai/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;AI</a></span></div>
      <div class="post-meta-line"><span title=2020-11-19&#32;07:56:09>
            <i class="fa-regular fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2020-11-19" >2020-11-19</time>
          </span>&nbsp;<i class="fa-solid fa-pencil-alt fa-fw"></i>&nbsp;约 10143 字&nbsp;
        <i class="fa-regular fa-clock fa-fw"></i>&nbsp;预计阅读 21 分钟&nbsp;<span id="busuanzi_container_page_pv" class="busuanzi_visitors comment-visitors" data-flag-title="pythoAudioOp">
            <i class="fa-regular fa-eye fa-fw"></i>&nbsp;<span id="busuanzi_value_page_pv">-</span>&nbsp;次阅读
          </span>&nbsp;</div>
    </div><div class="featured-image"><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/illuminated-bridge-and-city-at-night.jpg"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/illuminated-bridge-and-city-at-night.jpg, https://gitee.com/github-25970295/blogImage/raw/master/img/illuminated-bridge-and-city-at-night.jpg 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/illuminated-bridge-and-city-at-night.jpg 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/illuminated-bridge-and-city-at-night.jpg"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/illuminated-bridge-and-city-at-night.jpg"/></div><div class="details toc" id="toc-static" kept="true">
        <div class="details-summary toc-title">
          <span>目录</span>
          <span><i class="details-icon fa-solid fa-angle-right"></i></span>
        </div>
        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#1-文件读写">1. 文件读写</a></li>
        <li><a href="#2-信号处理">2. 信号处理</a></li>
        <li><a href="#3-语音识别">3. 语音识别</a></li>
        <li><a href="#4-主动降噪anc">4. 主动降噪（ANC）</a></li>
        <li><a href="#5-声源定位">5. 声源定位</a></li>
        <li><a href="#6-声源分离">6. 声源分离</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
      </div><div
      class="content"
      id="content"
      
      
    ><blockquote>
<p>语音信号有三个重要的参数：声道数、取样频率和量化位数。</p>
<ul>
<li><strong>声道数</strong>：可以是单声道或者是双声道</li>
<li><strong>采样频率</strong>：一秒内对声音信号的采集次数，44100Hz采样频率意味着每秒钟信号被分解成44100份。换句话说，每隔144100秒就会存储一次，如果采样率高，那么媒体播放音频时会感觉信号是连续的。</li>
<li><strong>量化位数</strong>：用多少bit表达一次采样所采集的数据，通常有8bit、16bit、24bit和32bit等几种</li>
</ul>
</blockquote>
<h3 id="1-文件读写">1. 文件读写</h3>
<h3 id="2-信号处理">2. 信号处理</h3>
<blockquote>
<p><code>语音信号是一个非平稳的时变信号</code>，但<code>语音信号是由声门的激励脉冲通过声道形成</code>的，而<code>声道(人的口腔、鼻腔)的肌肉运动是缓慢</code>的，所以<code>“短时间”(10~30ms)</code>内可以认为语音信号是<code>平稳时不变</code>的。由此构成了语音信号的<code>“短时分析技术”</code>。在短时分析中，将语音信号分为一段一段的语音帧，每一帧一般取10~30ms，我们的研究就建立在每一帧的语音特征分析上。提取的不同的语音特征参数对应着不同的语音信号分析方法：<code>时域分析、频域分析、倒谱域分析</code>&hellip;由于语音信号最重要的感知特性反映在<code>功率谱</code>上，而相位变化只起到很小的作用，所有语音频域分析更加重要。</p>
</blockquote>
<h4 id="20-预加重">2.0. 预加重</h4>
<blockquote>
<p>所谓预加重是指在信号发送之<code>前</code>，<code>先对模拟信号的高频部分进行适当的提升</code>，在接收到信号之<code>后</code>，进行<code>逆处理，即去加重</code>。预加重和去加重技术可以<code>使信号在传输中高频损耗的影响降低</code>，也可以是噪声的频谱发生变化，这是模拟降噪的原理。声道的终端是口和唇，<code>口唇辐射对低频影响比较小，但是对高频段影响比较大</code>，欲加重技术技术为了提升高频分辨率，欲加重的传递函数是$H(z)=1−aZ^{-1}$。</p>
</blockquote>
<h4 id="21-信号窗">2.1. 信号窗</h4>
<blockquote>
<p>通常对信号截断、分帧需要加窗，因为截断都有频域能量泄露，而窗函数可以减少截断带来的影响。<code>时域加窗会导致主瓣变宽而旁瓣得到明显降低，并且最大幅值也有所降低。</code></p>
<ul>
<li>傅里叶变换后主要的特征有频率、幅值和相位，加窗对相位的影响是线性的，所以一般不用考虑。</li>
<li>加窗对<code>频率和幅值的影响是关联的</code>，对于时域的单个频率信号，加窗之后的频谱就是将窗谱的谱峰位置平移到信号的频率处，然后进行垂直缩放。说明加窗的影响取决于窗的功率谱，也就容易理解为什么总常看到对窗特征主瓣、旁瓣等的描述。</li>
<li><code>主瓣变宽</code>就可能与附近的频率的谱相叠加，意味着<code>更难找到叠加后功率谱中最大的频率点</code>，即降低了频率分辨率，较难定位中心频率。<code>旁瓣多</code>意味着信号<code>功率泄露多，主瓣被削弱了，即幅值精度降低了</code>。</li>
</ul>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121163030377.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121163030377.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121163030377.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121163030377.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121163030377.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121163030377.png"/></p>
<blockquote>
<p>通常时域上加窗更为普遍，时域截断效应带来了频谱的泄漏，窗函数是为了减小这个截断效应，被设计成一组加权系数w(n)。域加窗在时域上表现的是点乘，因此在频域上则表现为卷积。卷积可以被看成是一个平滑的过程，相当于一组具有特定函数形状的滤波器，因此，原始信号中在某一频率点上的能量会结合滤波器的形状表现出来，从而减小泄漏。</p>
<ul>
<li>对线性调频信号(LFM)的时域加窗会导致主瓣变宽而旁瓣得到明显降低，并且最大幅值也有所降低</li>
</ul>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211102110346914.png"
    data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211102110346914.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211102110346914.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211102110346914.png 2x"
    data-sizes="auto"
    alt="时域加窗"
    title="时域加窗"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211102110541564.png"
    data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211102110541564.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211102110541564.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211102110541564.png 2x"
    data-sizes="auto"
    alt="频率加窗"
    title="频率加窗"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121162806166.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121162806166.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121162806166.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121162806166.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121162806166.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121162806166.png"/></p>
<blockquote>
<p>如果仅要求<code>精确读出主瓣频率，而不考虑幅值精度</code>，则可选用主瓣宽度比较窄而便于分辨的矩形窗，例如测量物体的自振频率等；如果分析窄带信号，且有较强的干扰噪声，则应选用旁瓣幅度小的窗函数，如汉宁窗、三角窗等；对于<code>随时间按指数衰减的函数</code>，可采用<code>指数窗</code>来提高信噪比。</p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121162342722.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121162342722.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121162342722.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121162342722.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121162342722.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121162342722.png"/></p>
<h4 id="22-信号分帧">2.2. 信号分帧</h4>
<blockquote>
<p>在分帧中，相邻两帧之间会有一部分重叠，帧长(wlen) = 重叠(overlap)+帧移(inc)，如果相邻两帧之间不重叠，那么由于窗函数的形状，截取到的语音帧边缘会出现损失，所以要设置重叠部分。inc为帧移，表示后一帧第前一帧的偏移量，fs表示采样率，fn表示一段语音信号的分帧数。</p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121163426097.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121163426097.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121163426097.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121163426097.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121163426097.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121163426097.png"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121163512186.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121163512186.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121163512186.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121163512186.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121163512186.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121163512186.png"/></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#没有加窗的语音分帧</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> wave
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#75715e">#import math</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">enframe</span>(signal, nw, inc):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;将音频信号转化为帧。
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    参数含义：
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    signal:原始音频型号
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    nw:每一帧的长度(这里指采样点的长度，即采样频率乘以时间间隔)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    inc:相邻帧的间隔（同上定义）
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    signal_length<span style="color:#f92672">=</span>len(signal) <span style="color:#75715e">#信号总长度</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> signal_length<span style="color:#f92672">&lt;=</span>nw: <span style="color:#75715e">#若信号长度小于一个帧的长度，则帧数定义为1</span>
</span></span><span style="display:flex;"><span>        nf<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>: <span style="color:#75715e">#否则，计算帧的总长度</span>
</span></span><span style="display:flex;"><span>        nf<span style="color:#f92672">=</span>int(np<span style="color:#f92672">.</span>ceil((<span style="color:#ae81ff">1.0</span><span style="color:#f92672">*</span>signal_length<span style="color:#f92672">-</span>nw<span style="color:#f92672">+</span>inc)<span style="color:#f92672">/</span>inc))
</span></span><span style="display:flex;"><span>    pad_length<span style="color:#f92672">=</span>int((nf<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">*</span>inc<span style="color:#f92672">+</span>nw) <span style="color:#75715e">#所有帧加起来总的铺平后的长度</span>
</span></span><span style="display:flex;"><span>    zeros<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>zeros((pad_length<span style="color:#f92672">-</span>signal_length,)) <span style="color:#75715e">#不够的长度使用0填补，类似于FFT中的扩充数组操作</span>
</span></span><span style="display:flex;"><span>    pad_signal<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>concatenate((signal,zeros)) <span style="color:#75715e">#填补后的信号记为pad_signal</span>
</span></span><span style="display:flex;"><span>    indices<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>tile(np<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">0</span>,nw),(nf,<span style="color:#ae81ff">1</span>))<span style="color:#f92672">+</span>np<span style="color:#f92672">.</span>tile(np<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">0</span>,nf<span style="color:#f92672">*</span>inc,inc),(nw,<span style="color:#ae81ff">1</span>))<span style="color:#f92672">.</span>T  <span style="color:#75715e">#相当于对所有帧的时间点进行抽取，得到nf*nw长度的矩阵</span>
</span></span><span style="display:flex;"><span>    indices<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>array(indices,dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>int32) <span style="color:#75715e">#将indices转化为矩阵</span>
</span></span><span style="display:flex;"><span>    frames<span style="color:#f92672">=</span>pad_signal[indices] <span style="color:#75715e">#得到帧信号</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#    win=np.tile(winfunc(nw),(nf,1))  #window窗函数，这里默认取1</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#    return frames*win   #返回帧信号矩阵</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> frames
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">wavread</span>(filename):
</span></span><span style="display:flex;"><span>    f <span style="color:#f92672">=</span> wave<span style="color:#f92672">.</span>open(filename,<span style="color:#e6db74">&#39;rb&#39;</span>)
</span></span><span style="display:flex;"><span>    params <span style="color:#f92672">=</span> f<span style="color:#f92672">.</span>getparams()
</span></span><span style="display:flex;"><span>    nchannels, sampwidth, framerate, nframes <span style="color:#f92672">=</span> params[:<span style="color:#ae81ff">4</span>]
</span></span><span style="display:flex;"><span>    strData <span style="color:#f92672">=</span> f<span style="color:#f92672">.</span>readframes(nframes)<span style="color:#75715e">#读取音频，字符串格式</span>
</span></span><span style="display:flex;"><span>    waveData <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>fromstring(strData,dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>int16)<span style="color:#75715e">#将字符串转化为int</span>
</span></span><span style="display:flex;"><span>    f<span style="color:#f92672">.</span>close()
</span></span><span style="display:flex;"><span>    waveData <span style="color:#f92672">=</span> waveData<span style="color:#f92672">*</span><span style="color:#ae81ff">1.0</span><span style="color:#f92672">/</span>(max(abs(waveData)))<span style="color:#75715e">#wave幅值归一化</span>
</span></span><span style="display:flex;"><span>    waveData <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>reshape(waveData,[nframes,nchannels])<span style="color:#f92672">.</span>T
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> waveData
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>filepath <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;./data/&#34;</span> <span style="color:#75715e">#添加路径</span>
</span></span><span style="display:flex;"><span>dirname<span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>listdir(filepath) <span style="color:#75715e">#得到文件夹下的所有文件名称 </span>
</span></span><span style="display:flex;"><span>filename <span style="color:#f92672">=</span> filepath<span style="color:#f92672">+</span>dirname[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>data <span style="color:#f92672">=</span> wavread(filename)
</span></span><span style="display:flex;"><span>nw <span style="color:#f92672">=</span> <span style="color:#ae81ff">512</span>
</span></span><span style="display:flex;"><span>inc <span style="color:#f92672">=</span> <span style="color:#ae81ff">128</span>
</span></span><span style="display:flex;"><span>Frame <span style="color:#f92672">=</span> enframe(data[<span style="color:#ae81ff">0</span>], nw, inc) 
</span></span><span style="display:flex;"><span><span style="color:#75715e">#加窗的语音分帧</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">enframe</span>(signal, nw, inc, winfunc):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;将音频信号转化为帧。
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    参数含义：
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    signal:原始音频型号
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    nw:每一帧的长度(这里指采样点的长度，即采样频率乘以时间间隔)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    inc:相邻帧的间隔（同上定义）
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    signal_length<span style="color:#f92672">=</span>len(signal) <span style="color:#75715e">#信号总长度</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> signal_length<span style="color:#f92672">&lt;=</span>nw: <span style="color:#75715e">#若信号长度小于一个帧的长度，则帧数定义为1</span>
</span></span><span style="display:flex;"><span>        nf<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>: <span style="color:#75715e">#否则，计算帧的总长度</span>
</span></span><span style="display:flex;"><span>        nf<span style="color:#f92672">=</span>int(np<span style="color:#f92672">.</span>ceil((<span style="color:#ae81ff">1.0</span><span style="color:#f92672">*</span>signal_length<span style="color:#f92672">-</span>nw<span style="color:#f92672">+</span>inc)<span style="color:#f92672">/</span>inc))
</span></span><span style="display:flex;"><span>    pad_length<span style="color:#f92672">=</span>int((nf<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">*</span>inc<span style="color:#f92672">+</span>nw) <span style="color:#75715e">#所有帧加起来总的铺平后的长度</span>
</span></span><span style="display:flex;"><span>    zeros<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>zeros((pad_length<span style="color:#f92672">-</span>signal_length,)) <span style="color:#75715e">#不够的长度使用0填补，类似于FFT中的扩充数组操作</span>
</span></span><span style="display:flex;"><span>    pad_signal<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>concatenate((signal,zeros)) <span style="color:#75715e">#填补后的信号记为pad_signal</span>
</span></span><span style="display:flex;"><span>    indices<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>tile(np<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">0</span>,nw),(nf,<span style="color:#ae81ff">1</span>))<span style="color:#f92672">+</span>np<span style="color:#f92672">.</span>tile(np<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">0</span>,nf<span style="color:#f92672">*</span>inc,inc),(nw,<span style="color:#ae81ff">1</span>))<span style="color:#f92672">.</span>T  <span style="color:#75715e">#相当于对所有帧的时间点进行抽取，得到nf*nw长度的矩阵</span>
</span></span><span style="display:flex;"><span>    indices<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>array(indices,dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>int32) <span style="color:#75715e">#将indices转化为矩阵</span>
</span></span><span style="display:flex;"><span>    frames<span style="color:#f92672">=</span>pad_signal[indices] <span style="color:#75715e">#得到帧信号</span>
</span></span><span style="display:flex;"><span>    win<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>tile(winfunc,(nf,<span style="color:#ae81ff">1</span>))  <span style="color:#75715e">#window窗函数，这里默认取1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> frames<span style="color:#f92672">*</span>win   <span style="color:#75715e">#返回帧信号矩阵</span>
</span></span></code></pre></div><h4 id="23--短时时域处理">2.3.  短时时域处理</h4>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121184731295.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121184731295.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121184731295.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121184731295.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121184731295.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121184731295.png"/></p>
<ul>
<li><code>短时能量和短时平均幅度</code>
<ul>
<li><code>区分浊音和清音段</code>，因为浊音的短时能量E(i)比清音大很多；</li>
<li><code>区分声母和韵母的分界</code>和<code>无话段和有话段的分界</code></li>
</ul>
</li>
<li><code>短时平均过零率</code>
<ul>
<li>可以从<code>背景噪声中找出语音信号</code></li>
<li>可以用于判断<code>寂静无话段与有话段的起点和终止位置</code>。</li>
<li>在<code>背景噪声较小的时候，用平均能量识别较为有效</code>，在<code>背景噪声较大</code>的时候，用短时平均过零率识别较为有效。</li>
</ul>
</li>
<li>短时自相关函数:
<ul>
<li>主要应用于<code>端点检测</code>和<code>基音的提取</code>，在韵母基因频率整数倍处将出现峰值特性，通常根据除R(0)外的第一峰值来估计基音，而在声母的短时自相关函数中看不到明显的峰值。</li>
</ul>
</li>
<li>短时平均幅度差函数:
<ul>
<li>用于检测基音周期，而且在计算上比短时自相关函数更加简单。</li>
</ul>
</li>
</ul>
<h5 id="230--傅里叶变换">2.3.0.  傅里叶变换</h5>
<ul>
<li>frequency bin: 频点采用相等的间隔，这间隔通常frequency bin（频率窗口）或FFT bin表示。</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt 
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy.fft <span style="color:#66d9ef">as</span> fft
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>rcParams[<span style="color:#e6db74">&#39;font.sans-serif&#39;</span>]<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;SimHei&#39;</span>] <span style="color:#75715e">#用来正常显示中文标签</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>rcParams[<span style="color:#e6db74">&#39;axes.unicode_minus&#39;</span>]<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span> <span style="color:#75715e">#用来正常显示符号</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Fs <span style="color:#f92672">=</span> <span style="color:#ae81ff">1000</span>;            <span style="color:#75715e"># 采样频率</span>
</span></span><span style="display:flex;"><span>T <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span><span style="color:#f92672">/</span>Fs;             <span style="color:#75715e"># 采样周期</span>
</span></span><span style="display:flex;"><span>L <span style="color:#f92672">=</span> <span style="color:#ae81ff">1000</span>;             <span style="color:#75715e"># 信号长度</span>
</span></span><span style="display:flex;"><span>t <span style="color:#f92672">=</span> [i<span style="color:#f92672">*</span>T <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(L)]
</span></span><span style="display:flex;"><span>t <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(t)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>S <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.2</span><span style="color:#f92672">+</span><span style="color:#ae81ff">0.7</span><span style="color:#f92672">*</span>np<span style="color:#f92672">.</span>cos(<span style="color:#ae81ff">2</span><span style="color:#f92672">*</span>np<span style="color:#f92672">.</span>pi<span style="color:#f92672">*</span><span style="color:#ae81ff">50</span><span style="color:#f92672">*</span>t<span style="color:#f92672">+</span><span style="color:#ae81ff">20</span><span style="color:#f92672">/</span><span style="color:#ae81ff">180</span><span style="color:#f92672">*</span>np<span style="color:#f92672">.</span>pi) <span style="color:#f92672">+</span> <span style="color:#ae81ff">0.2</span><span style="color:#f92672">*</span>np<span style="color:#f92672">.</span>cos(<span style="color:#ae81ff">2</span><span style="color:#f92672">*</span>np<span style="color:#f92672">.</span>pi<span style="color:#f92672">*</span><span style="color:#ae81ff">100</span><span style="color:#f92672">*</span>t<span style="color:#f92672">+</span><span style="color:#ae81ff">70</span><span style="color:#f92672">/</span><span style="color:#ae81ff">180</span><span style="color:#f92672">*</span>np<span style="color:#f92672">.</span>pi) ;
</span></span><span style="display:flex;"><span><span style="color:#75715e">#经过快速傅里叶变换得到一个复数数组，复数的模代表的是振幅，复数的辐角代表初相位</span>
</span></span><span style="display:flex;"><span>complex_array <span style="color:#f92672">=</span> fft<span style="color:#f92672">.</span>fft(S)
</span></span><span style="display:flex;"><span>print(complex_array<span style="color:#f92672">.</span>shape)  <span style="color:#75715e"># (1000,) </span>
</span></span><span style="display:flex;"><span>print(complex_array<span style="color:#f92672">.</span>dtype)  <span style="color:#75715e"># complex128 </span>
</span></span><span style="display:flex;"><span>print(complex_array[<span style="color:#ae81ff">1</span>])  <span style="color:#75715e"># (-2.360174309695419e-14+2.3825789764340993e-13j)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#################################</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">311</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>grid(linestyle<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;:&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(<span style="color:#ae81ff">1000</span><span style="color:#f92672">*</span>t[<span style="color:#ae81ff">1</span>:<span style="color:#ae81ff">51</span>], S[<span style="color:#ae81ff">1</span>:<span style="color:#ae81ff">51</span>], label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;S&#39;</span>)  <span style="color:#75715e"># y是1000个相加后的正弦序列</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;t（毫秒）&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;S(t)幅值&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;叠加信号图&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">###################################</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">312</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e">#复数数组 经过逆向傅里叶变换得到合成的函数值数组</span>
</span></span><span style="display:flex;"><span>S_ifft <span style="color:#f92672">=</span> fft<span style="color:#f92672">.</span>ifft(complex_array)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># S_new是ifft变换后的序列</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(<span style="color:#ae81ff">1000</span><span style="color:#f92672">*</span>t[<span style="color:#ae81ff">1</span>:<span style="color:#ae81ff">51</span>], S_ifft[<span style="color:#ae81ff">1</span>:<span style="color:#ae81ff">51</span>], label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;S_ifft&#39;</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;orangered&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;t（毫秒）&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;S_ifft(t)幅值&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;ifft变换图&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>grid(linestyle<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;:&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">###################################</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 得到分解波的频率序列</span>
</span></span><span style="display:flex;"><span>freqs <span style="color:#f92672">=</span> fft<span style="color:#f92672">.</span>fftfreq(t<span style="color:#f92672">.</span>size, t[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">-</span> t[<span style="color:#ae81ff">0</span>])
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 复数的模为信号的振幅（能量大小）</span>
</span></span><span style="display:flex;"><span>pows <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>abs(complex_array)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">313</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;FFT变换,频谱图&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;Frequency 频率&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;Power 功率&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>tick_params(labelsize<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>grid(linestyle<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;:&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(freqs[freqs <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>], pows[freqs <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>], c<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;orangered&#39;</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Frequency&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>tight_layout()
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122000001935.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122000001935.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122000001935.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122000001935.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122000001935.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122000001935.png"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211102112057675.png"
    data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211102112057675.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211102112057675.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211102112057675.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211102112057675.png"
    title="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20211102112057675.png"/></p>
<blockquote>
<p>mel频率倒谱系数(MFCC)，线性预测系数(LPC)，线性预测倒谱系数(LPCC)，线谱频率(LSF)，离散小波变换(DWT)，感知线性预测(PLP)</p>
</blockquote>
<h5 id="231-短时傅里叶变换">2.3.1. 短时傅里叶变换</h5>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#绘制语音信号的频谱图</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> scipy.io <span style="color:#f92672">import</span> wavfile
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sampling_freq, audio <span style="color:#f92672">=</span> wavfile<span style="color:#f92672">.</span>read(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;C:\Windows\media\Windows Background.wav&#34;</span>)   <span style="color:#75715e"># 读取文件</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>audio <span style="color:#f92672">=</span> audio <span style="color:#f92672">/</span> np<span style="color:#f92672">.</span>max(audio)   <span style="color:#75715e"># 归一化，标准化</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 应用傅里叶变换</span>
</span></span><span style="display:flex;"><span>fft_signal <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>fft<span style="color:#f92672">.</span>fft(audio)
</span></span><span style="display:flex;"><span>print(fft_signal)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># [-0.04022912+0.j         -0.04068997-0.00052721j -0.03933007-0.00448355j</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#  ... -0.03947908+0.00298096j -0.03933007+0.00448355j -0.04068997+0.00052721j]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>fft_signal <span style="color:#f92672">=</span> abs(fft_signal)
</span></span><span style="display:flex;"><span>print(fft_signal)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># [0.04022912 0.04069339 0.0395848  ... 0.08001755 0.09203427 0.12889393]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 建立时间轴</span>
</span></span><span style="display:flex;"><span>Freq <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">0</span>, len(fft_signal))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 绘制语音信号的</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure()
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(Freq, fft_signal, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;blue&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;Freq (in kHz)&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;Amplitude&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">wav_to_frame</span>(wave_data, win_len, win_shift):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    进行分帧操作
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    :param wave_data: 原始的数据
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    :param win_len: 滑动窗长
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    :param win_shift: 滑动间隔
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    :return: 分帧之后的结果，输出一个帧矩阵
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    num_frames <span style="color:#f92672">=</span> (len(wave_data) <span style="color:#f92672">-</span> win_len) <span style="color:#f92672">//</span> win_shift <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>    results <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(num_frames):
</span></span><span style="display:flex;"><span>        results<span style="color:#f92672">.</span>append(wave_data[i<span style="color:#f92672">*</span>win_shift:i<span style="color:#f92672">*</span>win_shift <span style="color:#f92672">+</span> win_len])
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>array(results)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">spectrum_power</span>(frames, NFFT):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    计算每一帧傅立叶变换以后的功率谱
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    参数说明：
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    frames:audio2frame函数计算出来的帧矩阵
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    NFFT:FFT的大小
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 功率谱等于每一点的幅度平方/NFFT</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">1.0</span><span style="color:#f92672">/</span>NFFT <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>square(spectrum_magnitude(frames, NFFT))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">spectrum_magnitude</span>(frames, NFFT):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;计算每一帧经过FFT变幻以后的频谱的幅度，若frames的大小为N*L,则返回矩阵的大小为N*NFFT
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    参数：
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    frames:即audio2frame函数中的返回值矩阵，帧矩阵
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    NFFT:FFT变换的数组大小,如果帧长度小于NFFT，则帧的其余部分用0填充铺满
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    complex_spectrum <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>fft<span style="color:#f92672">.</span>rfft(frames, NFFT)    <span style="color:#75715e"># 对frames进行FFT变换</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 返回频谱的幅度值</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>absolute(complex_spectrum)
</span></span></code></pre></div><h5 id="232-梅尔频率倒谱系数">2.3.2 梅尔频率倒谱系数</h5>
<blockquote>
<p><strong>梅尔频率倒谱系数</strong>(MFCC)，MFCC首先计算信号的功率谱，然后用滤波器组和离散余弦变换的组合来提取特征。人耳在接收声音时呈现非线性状态，对高频的更不敏感，因此<code>Mel刻度在低频区分辨度较高</code>，在高频区分辨度较低，<code>与频率之间的换算</code>关系。滤波器组中的每个滤波器都是三角形的，<code>中心频率为f(m)</code> ，中心频率处的响应为1，并向0线性减小，直到达到两个相邻滤波器的中心频率，其中响应为0，<code>各f(m)之间的间隔随着m值的增大而增宽</code>。</p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121215912320.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121215912320.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121215912320.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121215912320.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121215912320.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121215912320.png"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121221407705.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121221407705.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121221407705.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121221407705.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121221407705.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121221407705.png"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121221423367.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121221423367.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121221423367.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121221423367.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121221423367.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121221423367.png"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121215252948.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121215252948.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121215252948.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121215252948.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121215252948.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121215252948.png"/></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> scipy.io.wavfile
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> scipy.fftpack <span style="color:#f92672">import</span> dct
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sample_rate, signal <span style="color:#f92672">=</span> scipy<span style="color:#f92672">.</span>io<span style="color:#f92672">.</span>wavfile<span style="color:#f92672">.</span>read(<span style="color:#e6db74">&#39;OSR_us_000_0010_8k.wav&#39;</span>) 
</span></span><span style="display:flex;"><span>signal <span style="color:#f92672">=</span> signal[<span style="color:#ae81ff">0</span>:int(<span style="color:#ae81ff">3.5</span> <span style="color:#f92672">*</span> sample_rate)]  <span style="color:#75715e"># 我们只取前3.5s</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 欲加重处理</span>
</span></span><span style="display:flex;"><span>emphasized_signal <span style="color:#f92672">=</span> numpy<span style="color:#f92672">.</span>append(signal[<span style="color:#ae81ff">0</span>], signal[<span style="color:#ae81ff">1</span>:] <span style="color:#f92672">-</span> pre_emphasis <span style="color:#f92672">*</span> signal[:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 分帧</span>
</span></span><span style="display:flex;"><span>frame_length, frame_step <span style="color:#f92672">=</span> frame_size <span style="color:#f92672">*</span> sample_rate, frame_stride <span style="color:#f92672">*</span> sample_rate  <span style="color:#75715e"># 从秒转换为采样点</span>
</span></span><span style="display:flex;"><span>signal_length <span style="color:#f92672">=</span> len(emphasized_signal)
</span></span><span style="display:flex;"><span>frame_length <span style="color:#f92672">=</span> int(round(frame_length))
</span></span><span style="display:flex;"><span>frame_step <span style="color:#f92672">=</span> int(round(frame_step))
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 确保我们至少有1帧</span>
</span></span><span style="display:flex;"><span>num_frames <span style="color:#f92672">=</span> int(numpy<span style="color:#f92672">.</span>ceil(float(numpy<span style="color:#f92672">.</span>abs(signal_length <span style="color:#f92672">-</span> frame_length)) <span style="color:#f92672">/</span> frame_step))  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>pad_signal_length <span style="color:#f92672">=</span> num_frames <span style="color:#f92672">*</span> frame_step <span style="color:#f92672">+</span> frame_length
</span></span><span style="display:flex;"><span>z <span style="color:#f92672">=</span> numpy<span style="color:#f92672">.</span>zeros((pad_signal_length <span style="color:#f92672">-</span> signal_length))
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 填充信号，确保所有帧的采样数相等，而不从原始信号中截断任何采样</span>
</span></span><span style="display:flex;"><span>pad_signal <span style="color:#f92672">=</span> numpy<span style="color:#f92672">.</span>append(emphasized_signal, z) 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>indices <span style="color:#f92672">=</span> numpy<span style="color:#f92672">.</span>tile(numpy<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">0</span>, frame_length), (num_frames, <span style="color:#ae81ff">1</span>)) <span style="color:#f92672">+</span> numpy<span style="color:#f92672">.</span>tile(numpy<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">0</span>, num_frames <span style="color:#f92672">*</span> frame_step, frame_step), (frame_length, <span style="color:#ae81ff">1</span>))<span style="color:#f92672">.</span>T
</span></span><span style="display:flex;"><span>frames <span style="color:#f92672">=</span> pad_signal[indices<span style="color:#f92672">.</span>astype(numpy<span style="color:#f92672">.</span>int32, copy<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)]
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 加窗处理</span>
</span></span><span style="display:flex;"><span>frames <span style="color:#f92672">*=</span> numpy<span style="color:#f92672">.</span>hamming(frame_length)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># FFT 变换</span>
</span></span><span style="display:flex;"><span>mag_frames <span style="color:#f92672">=</span> numpy<span style="color:#f92672">.</span>absolute(numpy<span style="color:#f92672">.</span>fft<span style="color:#f92672">.</span>rfft(frames, NFFT))   <span style="color:#75715e"># fft的幅度(magnitude)</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 计算功率谱</span>
</span></span><span style="display:flex;"><span>pow_frames <span style="color:#f92672">=</span> ((<span style="color:#ae81ff">1.0</span> <span style="color:#f92672">/</span> NFFT) <span style="color:#f92672">*</span> ((mag_frames) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>))  <span style="color:#75715e"># 功率谱</span>
</span></span><span style="display:flex;"><span>nfilt <span style="color:#f92672">=</span> <span style="color:#ae81ff">40</span>
</span></span><span style="display:flex;"><span>low_freq_mel <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>high_freq_mel <span style="color:#f92672">=</span> (<span style="color:#ae81ff">2595</span> <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>log10(<span style="color:#ae81ff">1</span> <span style="color:#f92672">+</span> (sample_rate <span style="color:#f92672">/</span> <span style="color:#ae81ff">2</span>) <span style="color:#f92672">/</span> <span style="color:#ae81ff">700</span>))  <span style="color:#75715e"># 将Hz转换为Mel</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 我们要做40个滤波器组，为此需要42个点，这意味着在们需要low_freq_mel和high_freq_mel之间线性间隔40个点</span>
</span></span><span style="display:flex;"><span>mel_points <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linspace(low_freq_mel, high_freq_mel, nfilt <span style="color:#f92672">+</span> <span style="color:#ae81ff">2</span>)  <span style="color:#75715e"># 使得Mel scale间距相等</span>
</span></span><span style="display:flex;"><span>hz_points <span style="color:#f92672">=</span> (<span style="color:#ae81ff">700</span> <span style="color:#f92672">*</span> (<span style="color:#ae81ff">10</span> <span style="color:#f92672">**</span> (mel_points <span style="color:#f92672">/</span> <span style="color:#ae81ff">2595</span>) <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>))  <span style="color:#75715e"># 将Mel转换回-Hz</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># bin = sample_rate/NFFT    # frequency bin的计算公式</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># bins = hz_points/bin=hz_points*NFFT/ sample_rate    # 得出每个hz_point中有多少frequency bin</span>
</span></span><span style="display:flex;"><span>bins <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>floor((NFFT <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>) <span style="color:#f92672">*</span> hz_points <span style="color:#f92672">/</span> sample_rate)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>fbank <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros((nfilt, int(np<span style="color:#f92672">.</span>floor(NFFT <span style="color:#f92672">/</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>))))
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> m <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1</span>, nfilt <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>    f_m_minus <span style="color:#f92672">=</span> int(bins[m <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>])  <span style="color:#75715e"># 左</span>
</span></span><span style="display:flex;"><span>    f_m <span style="color:#f92672">=</span> int(bins[m])  <span style="color:#75715e"># 中</span>
</span></span><span style="display:flex;"><span>    f_m_plus <span style="color:#f92672">=</span> int(bins[m <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>])  <span style="color:#75715e"># 右</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(f_m_minus, f_m):
</span></span><span style="display:flex;"><span>        fbank[m <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>, k] <span style="color:#f92672">=</span> (k <span style="color:#f92672">-</span> bins[m <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>]) <span style="color:#f92672">/</span> (bins[m] <span style="color:#f92672">-</span> bins[m <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(f_m, f_m_plus):
</span></span><span style="display:flex;"><span>        fbank[m <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>, k] <span style="color:#f92672">=</span> (bins[m <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>] <span style="color:#f92672">-</span> k) <span style="color:#f92672">/</span> (bins[m <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>] <span style="color:#f92672">-</span> bins[m])
</span></span><span style="display:flex;"><span>filter_banks <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>dot(pow_frames, fbank<span style="color:#f92672">.</span>T)
</span></span><span style="display:flex;"><span>filter_banks <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>where(filter_banks <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>, np<span style="color:#f92672">.</span>finfo(float)<span style="color:#f92672">.</span>eps, filter_banks)  <span style="color:#75715e"># 数值稳定性</span>
</span></span><span style="display:flex;"><span>filter_banks <span style="color:#f92672">=</span> <span style="color:#ae81ff">20</span> <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>log10(filter_banks)  <span style="color:#75715e"># dB</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#梅尔频率倒谱系数（MFCCs）</span>
</span></span><span style="display:flex;"><span>mfcc <span style="color:#f92672">=</span> dct(filter_banks, type<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, norm<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;ortho&#39;</span>)[:, <span style="color:#ae81ff">1</span> : (num_ceps <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>)] <span style="color:#75715e"># 保持在2-13</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 均值归一化处理</span>
</span></span><span style="display:flex;"><span>mfcc <span style="color:#f92672">-=</span> (numpy<span style="color:#f92672">.</span>mean(mfcc, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>) <span style="color:#f92672">+</span> <span style="color:#ae81ff">1e-8</span>)
</span></span></code></pre></div><h5 id="233-频谱图">2.3.3. 频谱图</h5>
<blockquote>
<p><strong>频谱图</strong>表示语音信号的功率随频率变化的规律，<code>信号频率与能量的关系</code>用频谱表示，频谱图的<strong>横轴为频率</strong>，变化为采样率的一半（奈奎斯特采样定理），**纵轴为频率的强度（功率），**以分贝（dB）为单位</p>
</blockquote>
<blockquote>
<p><strong>语谱图</strong>： 横坐标是时间**，<strong><code>纵坐标是频率</code></strong>，<strong>坐标点值为语音数据能量</strong>，**<code>能量值的大小是通过颜色来表示的</code>，颜色越深表示该点的能量越强。<code>一条条横方向的条纹，称为“声纹”</code>。</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-matlab" data-lang="matlab"><span style="display:flex;"><span>[Y,FS]=audioread(<span style="color:#e6db74">&#39;p225_355_wb.wav&#39;</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">% specgram(Y,2048,44100,2048,1536);</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">%Y1为波形数据</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">%FFT帧长2048点(在44100Hz频率时约为46ms)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">%采样频率44.1KHz</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">%加窗长度，一般与帧长相等</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">%帧重叠长度，此处取为帧长的3/4</span>
</span></span><span style="display:flex;"><span>specgram(Y,<span style="color:#ae81ff">2048</span>,FS,<span style="color:#ae81ff">2048</span>,<span style="color:#ae81ff">1536</span>);
</span></span><span style="display:flex;"><span>xlabel(<span style="color:#e6db74">&#39;时间(s)&#39;</span>)
</span></span><span style="display:flex;"><span>ylabel(<span style="color:#e6db74">&#39;频率(Hz)&#39;</span>)
</span></span><span style="display:flex;"><span>title(<span style="color:#e6db74">&#39;“概率”语谱图&#39;</span>)
</span></span></code></pre></div><p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121234847152.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121234847152.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121234847152.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121234847152.png 2x"
    data-sizes="auto"
    alt="功率谱计算"
    title="功率谱计算"/></p>
<h5 id="234-librosa-库使用httpswwwcnblogscomlxp-neverp11561355html">2.3.4. <a href="https://www.cnblogs.com/LXP-Never/p/11561355.html"target="_blank" rel="external nofollow noopener noreferrer">Librosa 库使用<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></h5>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt 
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> librosa
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> librosa.display
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>y, sr <span style="color:#f92672">=</span> librosa<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#39;./train_wb.wav&#39;</span>, sr<span style="color:#f92672">=</span><span style="color:#ae81ff">16000</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 提取 MFCC feature</span>
</span></span><span style="display:flex;"><span>mfccs <span style="color:#f92672">=</span> librosa<span style="color:#f92672">.</span>feature<span style="color:#f92672">.</span>mfcc(y<span style="color:#f92672">=</span>y, sr<span style="color:#f92672">=</span>sr, n_mfcc<span style="color:#f92672">=</span><span style="color:#ae81ff">40</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 提取 mel spectrogram feature</span>
</span></span><span style="display:flex;"><span>melspec <span style="color:#f92672">=</span> librosa<span style="color:#f92672">.</span>feature<span style="color:#f92672">.</span>melspectrogram(y, sr, n_fft<span style="color:#f92672">=</span><span style="color:#ae81ff">1024</span>, hop_length<span style="color:#f92672">=</span><span style="color:#ae81ff">512</span>, n_mels<span style="color:#f92672">=</span><span style="color:#ae81ff">128</span>)
</span></span><span style="display:flex;"><span>logmelspec <span style="color:#f92672">=</span> librosa<span style="color:#f92672">.</span>power_to_db(melspec)       <span style="color:#75715e"># 转换为对数刻度</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 绘制 mel 频谱图</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure()
</span></span><span style="display:flex;"><span>librosa<span style="color:#f92672">.</span>display<span style="color:#f92672">.</span>specshow(logmelspec, sr<span style="color:#f92672">=</span>sr, x_axis<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;time&#39;</span>, y_axis<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;mel&#39;</span>, cmp<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;jet&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>colorbar(format<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">%+2.0f</span><span style="color:#e6db74"> dB&#39;</span>)        <span style="color:#75715e"># 右边的色度条</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Beat wavform&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><h5 id="235--线性预测系数lpc">2.3.5.  线性预测系数(LPC)</h5>
<blockquote>
<p><code>共振峰出现的频率称为共振峰频率</code>。因此，使用这种技术，<code>通过计算滑动窗口上的线性预测系数</code>，并在<code>随后的线性预测滤波器[17]的频谱中找到峰值</code>，可以预测语音信号中共振峰的位置。LPC有助于在低比特率下对高质量语音进行编码[13,26,27]。从线性预测倒谱系数(LPCC)、对数面积比(LAR)、反射系数(RC)、线谱频率(LSF)和反正弦系数(Arcus Sine coefficients)[13]可以推导出LPC的其他特征。<code>有效地从给定的语音[16]中选择声道信息</code>。</p>
</blockquote>
<h5 id="236-线性预测倒谱系数lpcc">2.3.6. 线性预测倒谱系数(LPCC)</h5>
<blockquote>
<p>横轴是时间轴，纵轴是振幅轴, 高频语音信号的倒谱分析给出了低频域[29]的小源滤波器可分性。低阶倒谱系数对谱斜率敏感，而高阶倒谱系数对噪声[15]敏感。</p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201122095224766.png"
    data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201122095224766.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201122095224766.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201122095224766.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201122095224766.png"
    title="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201122095224766.png"/></p>
<h5 id="237-线谱频率lsf">2.3.7. 线谱频率(LSF)</h5>
<blockquote>
<p>LSF图能够在不影响合成语音质量的前提下，<code>将传输线性预测信息的比特率降低25% ~ 30%</code>。除量子化外，预测器的LSF图也适用于插值。从理论上讲，将lsf域平方量化误差与感知相关的对数谱相联系的灵敏度矩阵是对角的[41,42], LSF在语音压缩领域的应用最为突出，并扩展到说话人识别和语音识别领域。LSF还被应用于动物噪音识别、个人工具识别和金融市场分析。LSF的优点包括其对光谱灵敏度的定位能力，它们可以表征带宽和共振位置，并强调了谱峰定位的重要方面。</p>
</blockquote>
<h5 id="238-小波变换">2.3.8. 小波变换</h5>
<blockquote>
<p>小波变换是一种信号处理技术，可以<code>高效地表示现实生活中的非平稳信号</code>。它能够在时域和频域同时从瞬态信号中挖掘信息。<code>小波变换将信号分解成一组称为小波的基本函数</code>。小波由一个称为母波的原型小波通过扩展和移位得到。小波变换的主要特点是利用可变窗口扫描频谱，提高了分析的时间分辨率.DWT确实为有效的语音分析[51]提供了足够的频带数。由于输入信号的长度是有限的，由于边界[50]处的不连续性，使得小波系数在边界处的变化非常大。</p>
</blockquote>
<h5 id="239-感知线性预测plp">2.3.9. 感知线性预测(PLP)</h5>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122101238672.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122101238672.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122101238672.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122101238672.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122101238672.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122101238672.png"/></p>
<table>
<thead>
<tr>
<th></th>
<th>滤波器系数</th>
<th>滤波器的形状</th>
<th>建模方法</th>
<th>速度的计算</th>
<th>系数类型</th>
<th>抗噪声能力</th>
<th>对量化/附加噪声的灵敏度</th>
<th>可靠性</th>
<th>捕获频率</th>
</tr>
</thead>
<tbody>
<tr>
<td>Mel倒频谱系数(MFCC)</td>
<td>Mel</td>
<td>三角形</td>
<td>人类听觉系统</td>
<td>高</td>
<td>倒频谱</td>
<td>中等</td>
<td>中等</td>
<td>高</td>
<td>低</td>
</tr>
<tr>
<td>线性预测系数(LPC)</td>
<td>线性预测</td>
<td>线性</td>
<td>人类声道</td>
<td>高</td>
<td>自相关系数</td>
<td>高</td>
<td>高</td>
<td>高</td>
<td>低</td>
</tr>
<tr>
<td>线性预测倒谱系数(LPCC)</td>
<td>线性预测</td>
<td>线性</td>
<td>人类声道</td>
<td>中等</td>
<td>倒频谱</td>
<td>高</td>
<td>高</td>
<td>中等</td>
<td>低&amp;中等</td>
</tr>
<tr>
<td>谱线频率(LSF)</td>
<td>线性预测</td>
<td>线性</td>
<td>人类声道</td>
<td>中等</td>
<td>频谱</td>
<td>高</td>
<td>高</td>
<td>中等</td>
<td>低&amp;中等</td>
</tr>
<tr>
<td>离散小波变换(DWT)</td>
<td>低通&amp;高通</td>
<td>-</td>
<td>-</td>
<td>高</td>
<td>小波</td>
<td>中等</td>
<td>中等</td>
<td>中等</td>
<td>低&amp;中等</td>
</tr>
<tr>
<td>感知线性预测(PLP)</td>
<td>Bark</td>
<td>梯形</td>
<td>人类听觉系统</td>
<td>中等</td>
<td>倒频谱&amp;自相关</td>
<td>中等</td>
<td>中等</td>
<td>中等</td>
<td>低&amp;中等</td>
</tr>
</tbody>
</table>
<h4 id="24-采样下采样">2.4. 采样&amp;下采样</h4>
<blockquote>
<p><code>奈奎斯特采样定理</code>，只有采样频率高于声音信号最高<strong>频率</strong>的两倍时，才能把数字信号表示的声音还原成为原来的声音。<code>带宽</code>：采样频率的一半，最高频率等于采样频率的一半。</p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121223210707.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121223210707.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121223210707.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121223210707.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121223210707.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121223210707.png"/></p>
<h5 id="241-插值法">2.4.1. 插值法</h5>
<blockquote>
<p>Volodymyr Kuleshov的论文中使用抗混叠滤波器对语音信号进行下采样，再通过三次样条插值把下采样信号上采样到相同的长度。</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> scipy.signal <span style="color:#f92672">import</span> decimate
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> librosa 
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np 
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt 
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> scipy <span style="color:#f92672">import</span> interpolate
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">upsample</span>(x_lr, r):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    上采样，每隔一步去掉语音波形的r个点，然后用三次样条插值的方法把去掉的点补回来，有机会可以画图看看
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    :param x_lr:    音频数据
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    :param r:       样条插值前个数
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    :return:        样条插值后的音频信号
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    x_lr <span style="color:#f92672">=</span> x_lr<span style="color:#f92672">.</span>flatten()                   <span style="color:#75715e"># 把x_lr数组折叠成一维的数组</span>
</span></span><span style="display:flex;"><span>    x_hr_len <span style="color:#f92672">=</span> len(x_lr) <span style="color:#f92672">*</span> r
</span></span><span style="display:flex;"><span>    i_lr <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(x_hr_len, step<span style="color:#f92672">=</span>r)
</span></span><span style="display:flex;"><span>    i_hr <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(x_hr_len)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    f <span style="color:#f92672">=</span> interpolate<span style="color:#f92672">.</span>splrep(i_lr, x_lr)      <span style="color:#75715e"># 样条曲线插值系数</span>
</span></span><span style="display:flex;"><span>    x_sp <span style="color:#f92672">=</span> interpolate<span style="color:#f92672">.</span>splev(i_hr, f)       <span style="color:#75715e"># 给定样条表示的节点和系数，返回在节点处的样条值</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> x_sp
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yt, wav_fs <span style="color:#f92672">=</span> librosa<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#34;./48k/p225_001.wav&#34;</span>, sr<span style="color:#f92672">=</span><span style="color:#ae81ff">16000</span>, mono<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>x_lr <span style="color:#f92672">=</span> decimate(yt, <span style="color:#ae81ff">2</span>)          <span style="color:#75715e"># 应用抗混叠滤波器后对信号进行下采样，获得低分辨率音频，下采样因子scale=2</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(len(yt))
</span></span><span style="display:flex;"><span>print(len(x_lr))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>specgram(yt, Fs<span style="color:#f92672">=</span><span style="color:#ae81ff">16000</span>, scale_by_freq<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, sides<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;default&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>x_lr <span style="color:#f92672">=</span> upsample(x_lr, <span style="color:#ae81ff">2</span>)       <span style="color:#75715e"># 上采样</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>specgram(x_lr, Fs<span style="color:#f92672">=</span><span style="color:#ae81ff">16000</span>, scale_by_freq<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, sides<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;default&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><h5 id="242-重采样下采样">2.4.2. 重采样（下采样）</h5>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> librosa 
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> scipy <span style="color:#f92672">import</span> signal
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span>y, wav_fs <span style="color:#f92672">=</span> librosa<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#34;./48k/p225_001.wav&#34;</span>, sr<span style="color:#f92672">=</span><span style="color:#ae81ff">16000</span>, mono<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>) 
</span></span><span style="display:flex;"><span><span style="color:#75715e">#沿给定轴使用傅立叶方法重新采样x到num个样本</span>
</span></span><span style="display:flex;"><span>f <span style="color:#f92672">=</span> signal<span style="color:#f92672">.</span>resample(y, len(y)<span style="color:#f92672">//</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>f <span style="color:#f92672">=</span> signal<span style="color:#f92672">.</span>resample(f, len(y))
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>specgram(y, Fs<span style="color:#f92672">=</span><span style="color:#ae81ff">16000</span>, scale_by_freq<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, sides<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;default&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>specgram(f, Fs<span style="color:#f92672">=</span><span style="color:#ae81ff">16000</span>, scale_by_freq<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, sides<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;default&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span><span style="display:flex;"><span><span style="color:#75715e">#         方法二</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> librosa 
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> scipy <span style="color:#f92672">import</span> signal
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>y, wav_fs <span style="color:#f92672">=</span> librosa<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#34;./48k/p225_001.wav&#34;</span>, sr<span style="color:#f92672">=</span><span style="color:#ae81ff">16000</span>, mono<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>) 
</span></span><span style="display:flex;"><span>audio8k <span style="color:#f92672">=</span> librosa<span style="color:#f92672">.</span>core<span style="color:#f92672">.</span>resample(y, wav_fs, wav_fs<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>)            <span style="color:#75715e"># 下采样率 16000--&gt;8000</span>
</span></span><span style="display:flex;"><span>audio8k <span style="color:#f92672">=</span> librosa<span style="color:#f92672">.</span>core<span style="color:#f92672">.</span>resample(audio8k, wav_fs<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>, wav_fs)    <span style="color:#75715e"># 上采样率 8000--&gt;16000，并不恢复高频部分</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>specgram(y, Fs<span style="color:#f92672">=</span><span style="color:#ae81ff">16000</span>, scale_by_freq<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, sides<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;default&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>specgram(audio8k, Fs<span style="color:#f92672">=</span><span style="color:#ae81ff">16000</span>, scale_by_freq<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, sides<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;default&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><h4 id="25-滤波">2.5. 滤波</h4>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201121231447009.png"
    data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201121231447009.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201121231447009.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201121231447009.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201121231447009.png"
    title="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201121231447009.png"/></p>
<h5 id="251-butterworth低通滤波器">2.5.1. butterworth低通滤波器</h5>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121231628339.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121231628339.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121231628339.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121231628339.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121231628339.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121231628339.png"/></p>
<h5 id="252-切比雪夫i形状滤波器">2.5.2. 切比雪夫I形状滤波器</h5>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121231833697.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121231833697.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121231833697.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121231833697.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121231833697.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121231833697.png"/></p>
<h5 id="253-切比雪夫2形状滤波器">2.5.3. 切比雪夫2形状滤波器</h5>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121231923712.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121231923712.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121231923712.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121231923712.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121231923712.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121231923712.png"/></p>
<h5 id="254-椭圆低通滤波器">2.5.4. 椭圆低通滤波器</h5>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121232013593.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121232013593.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121232013593.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121232013593.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121232013593.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121232013593.png"/></p>
<h5 id="255--频域滤波">2.5.5.  频域滤波</h5>
<blockquote>
<p>含噪信号是高能信号与低能噪声叠加的信号，可以通过傅里叶变换的频域滤波实现降噪。https://github.com/LXP-Neve/data/blob/master/machine_learning_date/noised.wav</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy.fft <span style="color:#66d9ef">as</span> nf
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> scipy.io.wavfile <span style="color:#66d9ef">as</span> wf
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 读取音频文件</span>
</span></span><span style="display:flex;"><span>sample_rate, noised_sigs <span style="color:#f92672">=</span> wf<span style="color:#f92672">.</span>read(<span style="color:#e6db74">&#39;./da_data/noised.wav&#39;</span>)
</span></span><span style="display:flex;"><span>print(sample_rate)  <span style="color:#75715e"># sample_rate：采样率44100</span>
</span></span><span style="display:flex;"><span>print(noised_sigs<span style="color:#f92672">.</span>shape)    <span style="color:#75715e"># noised_sigs:存储音频中每个采样点的采样位移(220500,)</span>
</span></span><span style="display:flex;"><span>times <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(noised_sigs<span style="color:#f92672">.</span>size) <span style="color:#f92672">/</span> sample_rate
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure(<span style="color:#e6db74">&#39;Filter&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">221</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Time Domain&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">16</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;Signal&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">12</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>tick_params(labelsize<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>grid(linestyle<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;:&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(times[:<span style="color:#ae81ff">178</span>], noised_sigs[:<span style="color:#ae81ff">178</span>], c<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;orangered&#39;</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Noised&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 傅里叶变换后，绘制频域图像</span>
</span></span><span style="display:flex;"><span>freqs <span style="color:#f92672">=</span> nf<span style="color:#f92672">.</span>fftfreq(times<span style="color:#f92672">.</span>size, times[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">-</span> times[<span style="color:#ae81ff">0</span>])
</span></span><span style="display:flex;"><span>complex_array <span style="color:#f92672">=</span> nf<span style="color:#f92672">.</span>fft(noised_sigs)
</span></span><span style="display:flex;"><span>pows <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>abs(complex_array)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">222</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Frequency Domain&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">16</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;Power&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">12</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>tick_params(labelsize<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>grid(linestyle<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;:&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 指数增长坐标画图</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>semilogy(freqs[freqs <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>], pows[freqs <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>], c<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;limegreen&#39;</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Noised&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 寻找能量最大的频率值</span>
</span></span><span style="display:flex;"><span>fund_freq <span style="color:#f92672">=</span> freqs[pows<span style="color:#f92672">.</span>argmax()]
</span></span><span style="display:flex;"><span><span style="color:#75715e"># where函数寻找那些需要抹掉的复数的索引</span>
</span></span><span style="display:flex;"><span>noised_indices <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>where(freqs <span style="color:#f92672">!=</span> fund_freq)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 复制一个复数数组的副本，避免污染原始数据</span>
</span></span><span style="display:flex;"><span>filter_complex_array <span style="color:#f92672">=</span> complex_array<span style="color:#f92672">.</span>copy()
</span></span><span style="display:flex;"><span>filter_complex_array[noised_indices] <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>filter_pows <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>abs(filter_complex_array)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">224</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;Frequency&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">12</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;Power&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">12</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>tick_params(labelsize<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>grid(linestyle<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;:&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(freqs[freqs <span style="color:#f92672">&gt;=</span> <span style="color:#ae81ff">0</span>], filter_pows[freqs <span style="color:#f92672">&gt;=</span> <span style="color:#ae81ff">0</span>], c<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;dodgerblue&#39;</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Filter&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>filter_sigs <span style="color:#f92672">=</span> nf<span style="color:#f92672">.</span>ifft(filter_complex_array)<span style="color:#f92672">.</span>real
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">223</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;Time&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">12</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;Signal&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">12</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>tick_params(labelsize<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>grid(linestyle<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;:&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(times[:<span style="color:#ae81ff">178</span>], filter_sigs[:<span style="color:#ae81ff">178</span>], c<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;hotpink&#39;</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Filter&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>wf<span style="color:#f92672">.</span>write(<span style="color:#e6db74">&#39;./da_data/filter.wav&#39;</span>, sample_rate, filter_sigs)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><h4 id="26-信号增强">2.6. 信号增强</h4>
<h5 id="261-加噪声">2.6.1. 加噪声</h5>
<ul>
<li>控制噪声因子</li>
</ul>
<blockquote>
<p>添加的噪声为均值为0，标准差为1的高斯白噪声，有两种方法对数据进行加噪。</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">add_noise1</span>(x, w<span style="color:#f92672">=</span><span style="color:#ae81ff">0.004</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># w：噪声因子</span>
</span></span><span style="display:flex;"><span>    output <span style="color:#f92672">=</span> x <span style="color:#f92672">+</span> w <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(loc<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, scale<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, size<span style="color:#f92672">=</span>len(x))
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> output
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Augmentation <span style="color:#f92672">=</span> add_noise1(x<span style="color:#f92672">=</span>wav_data, w<span style="color:#f92672">=</span><span style="color:#ae81ff">0.004</span>)
</span></span></code></pre></div><ul>
<li>控制信噪比</li>
</ul>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121233538338.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121233538338.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121233538338.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121233538338.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121233538338.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201121233538338.png"/></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">add_noise2</span>(x, snr):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># snr：生成的语音信噪比</span>
</span></span><span style="display:flex;"><span>    P_signal <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sum(abs(x) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>) <span style="color:#f92672">/</span> len(x)  <span style="color:#75715e"># 信号功率</span>
</span></span><span style="display:flex;"><span>    P_noise <span style="color:#f92672">=</span> P_signal <span style="color:#f92672">/</span> <span style="color:#ae81ff">10</span> <span style="color:#f92672">**</span> (snr <span style="color:#f92672">/</span> <span style="color:#ae81ff">10.0</span>)  <span style="color:#75715e"># 噪声功率</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> x <span style="color:#f92672">+</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>randn(len(x)) <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>sqrt(P_noise)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Augmentation <span style="color:#f92672">=</span> add_noise2(x<span style="color:#f92672">=</span>wav_data, snr<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>)
</span></span></code></pre></div><h5 id="262-波形位移">2.6.2. 波形位移</h5>
<blockquote>
<p>语音波形移动使用numpy.roll函数向右移动shift距离</p>
<p>numpy.roll(a, shift, axis=None)</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">time_shift</span>(x, shift):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># shift：移动的长度</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>roll(x, int(shift))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Augmentation <span style="color:#f92672">=</span> time_shift(wav_data, shift<span style="color:#f92672">=</span>fs<span style="color:#f92672">//</span><span style="color:#ae81ff">2</span>)
</span></span></code></pre></div><h5 id="263-波形拉伸">2.6.3. 波形拉伸</h5>
<blockquote>
<p>在不影响音高的情况下改变声音的速度 / 持续时间。这可以使用librosa的time_stretch函数来实现。</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">time_stretch</span>(x, rate):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># rate：拉伸的尺寸，</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># rate &gt; 1 加快速度</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># rate &lt; 1 放慢速度</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> librosa<span style="color:#f92672">.</span>effects<span style="color:#f92672">.</span>time_stretch(x, rate)
</span></span><span style="display:flex;"><span>Augmentation <span style="color:#f92672">=</span> time_stretch(wav_data, rate<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span></code></pre></div><h5 id="264-音高修正">2.6.4. 音高修正</h5>
<blockquote>
<p>音高修正只改变音高而不影响音速，我发现-5到5之间的步数更合适。</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">pitch_shifting</span>(x, sr, n_steps, bins_per_octave<span style="color:#f92672">=</span><span style="color:#ae81ff">12</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># sr: 音频采样率</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># n_steps: 要移动多少步</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># bins_per_octave: 每个八度音阶(半音)多少步</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> librosa<span style="color:#f92672">.</span>effects<span style="color:#f92672">.</span>pitch_shift(x, sr, n_steps, bins_per_octave<span style="color:#f92672">=</span>bins_per_octave)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 向上移三音（如果bins_per_octave为12，则六步）</span>
</span></span><span style="display:flex;"><span>Augmentation <span style="color:#f92672">=</span> pitch_shifting(wav_data, sr<span style="color:#f92672">=</span>fs, n_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">6</span>, bins_per_octave<span style="color:#f92672">=</span><span style="color:#ae81ff">12</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 向上移三音（如果bins_per_octave为24，则3步）</span>
</span></span><span style="display:flex;"><span>Augmentation <span style="color:#f92672">=</span> pitch_shifting(wav_data, sr<span style="color:#f92672">=</span>fs, n_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, bins_per_octave<span style="color:#f92672">=</span><span style="color:#ae81ff">24</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 向下移三音（如果bins_per_octave为12，则六步）</span>
</span></span><span style="display:flex;"><span>Augmentation <span style="color:#f92672">=</span> pitch_shifting(wav_data, sr<span style="color:#f92672">=</span>fs, n_steps<span style="color:#f92672">=-</span><span style="color:#ae81ff">6</span>, bins_per_octave<span style="color:#f92672">=</span><span style="color:#ae81ff">12</span>)
</span></span></code></pre></div><h4 id="27-语音度量">2.7. 语音度量</h4>
<h5 id="271-信噪比snr">2.7.1. 信噪比SNR</h5>
<blockquote>
<p>有用信号功率与噪声功率的比（此处功率为平均功率），也等于幅度比的平方。</p>
</blockquote>
<h5 id="272-峰值信噪比psnr">2.7.2. 峰值信噪比（PSNR）</h5>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122001115395.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122001115395.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122001115395.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122001115395.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122001115395.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122001115395.png"/></p>
<h5 id="273-分段信噪比segsnr">2.7.3. 分段信噪比（SegSNR）</h5>
<blockquote>
<p>由于语音信号是一种缓慢变化的短时平稳信号，因而在不同时间段上的信噪比也应不一样。为了改善上面的问题，可以采用分段信噪比。<code>分段信噪比</code>即是<code>先对语音进行分帧</code>，然后<code>对每一帧语音求信噪比，最好求均值</code>。</p>
</blockquote>
<h3 id="3-语音识别">3. 语音识别</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> scipy.io.wavfile <span style="color:#66d9ef">as</span> wf
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> python_speech_features <span style="color:#66d9ef">as</span> sf
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> hmmlearn.hmm <span style="color:#66d9ef">as</span> hl
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 1. 读取training文件夹中的训练音频样本，每个音频对应一个mfcc矩阵，每个mfcc都有一个类别(apple...)</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">search_file</span>(directory):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    :param directory: 训练音频的路径
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    :return: 字典{&#39;apple&#39;:[url, url, url ... ], &#39;banana&#39;:[...]}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 使传过来的directory匹配当前操作系统</span>
</span></span><span style="display:flex;"><span>    directory <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>normpath(directory)
</span></span><span style="display:flex;"><span>    objects <span style="color:#f92672">=</span> {}
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># curdir：当前目录</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># subdirs: 当前目录下的所有子目录</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># files: 当前目录下的所有文件名</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> curdir, subdirs, files <span style="color:#f92672">in</span> os<span style="color:#f92672">.</span>walk(directory):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> file <span style="color:#f92672">in</span> files:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> file<span style="color:#f92672">.</span>endswith(<span style="color:#e6db74">&#39;.wav&#39;</span>):
</span></span><span style="display:flex;"><span>                label <span style="color:#f92672">=</span> curdir<span style="color:#f92672">.</span>split(os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>sep)[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]  <span style="color:#75715e"># os.path.sep为路径分隔符</span>
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">if</span> label <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> objects:
</span></span><span style="display:flex;"><span>                    objects[label] <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 把路径添加到label对应的列表中</span>
</span></span><span style="display:flex;"><span>                path <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(curdir, file)
</span></span><span style="display:flex;"><span>                objects[label]<span style="color:#f92672">.</span>append(path)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> objects
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 读取训练集数据</span>
</span></span><span style="display:flex;"><span>train_samples <span style="color:#f92672">=</span> search_file(<span style="color:#e6db74">&#39;../machine_learning_date/speeches/training&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">2. 把所有类别为apple的mfcc合并在一起，形成训练集。
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    训练集:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    train_x：[mfcc1,mfcc2,mfcc3,...],[mfcc1,mfcc2,mfcc3,...]...
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    train_y：[apple],[banana]...
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">由上述训练集样本可以训练一个用于匹配apple的HMM。&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>train_x, train_y <span style="color:#f92672">=</span> [], []
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 遍历字典</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> label, filenames <span style="color:#f92672">in</span> train_samples<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># [(&#39;apple&#39;, [&#39;url1,,url2...&#39;])</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># [(&#34;banana&#34;),(&#34;url1,url2,url3...&#34;)]...</span>
</span></span><span style="display:flex;"><span>    mfccs <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([])
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> filename <span style="color:#f92672">in</span> filenames:
</span></span><span style="display:flex;"><span>        sample_rate, sigs <span style="color:#f92672">=</span> wf<span style="color:#f92672">.</span>read(filename)
</span></span><span style="display:flex;"><span>        mfcc <span style="color:#f92672">=</span> sf<span style="color:#f92672">.</span>mfcc(sigs, sample_rate)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> len(mfccs) <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>            mfccs <span style="color:#f92672">=</span> mfcc
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            mfccs <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>append(mfccs, mfcc, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>    train_x<span style="color:#f92672">.</span>append(mfccs)
</span></span><span style="display:flex;"><span>    train_y<span style="color:#f92672">.</span>append(label)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 3.训练模型，有7个句子，创建了7个模型</span>
</span></span><span style="display:flex;"><span>models <span style="color:#f92672">=</span> {}
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> mfccs, label <span style="color:#f92672">in</span> zip(train_x, train_y):
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> hl<span style="color:#f92672">.</span>GaussianHMM(n_components<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>, covariance_type<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;diag&#39;</span>, n_iter<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>)
</span></span><span style="display:flex;"><span>    models[label] <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>fit(mfccs)  <span style="color:#75715e"># # {&#39;apple&#39;:object, &#39;banana&#39;:object ...}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">4. 读取testing文件夹中的测试样本，
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    测试集数据：
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        test_x  [mfcc1, mfcc2, mfcc3...]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        test_y  [apple, banana, lime]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>test_samples <span style="color:#f92672">=</span> search_file(<span style="color:#e6db74">&#39;../machine_learning_date/speeches/testing&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>test_x, test_y <span style="color:#f92672">=</span> [], []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> label, filenames <span style="color:#f92672">in</span> test_samples<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>    mfccs <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([])
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> filename <span style="color:#f92672">in</span> filenames:
</span></span><span style="display:flex;"><span>        sample_rate, sigs <span style="color:#f92672">=</span> wf<span style="color:#f92672">.</span>read(filename)
</span></span><span style="display:flex;"><span>        mfcc <span style="color:#f92672">=</span> sf<span style="color:#f92672">.</span>mfcc(sigs, sample_rate)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> len(mfccs) <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>            mfccs <span style="color:#f92672">=</span> mfcc
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            mfccs <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>append(mfccs, mfcc, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>    test_x<span style="color:#f92672">.</span>append(mfccs)
</span></span><span style="display:flex;"><span>    test_y<span style="color:#f92672">.</span>append(label)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 5.测试模型</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#    1. 分别使用7个HMM模型，对测试样本计算score得分。</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#    2. 取7个模型中得分最高的模型所属类别作为预测类别。</span>
</span></span><span style="display:flex;"><span>pred_test_y <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> mfccs <span style="color:#f92672">in</span> test_x:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 判断mfccs与哪一个HMM模型更加匹配</span>
</span></span><span style="display:flex;"><span>    best_score, best_label <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>, <span style="color:#66d9ef">None</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 遍历7个模型</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> label, model <span style="color:#f92672">in</span> models<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>        score <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>score(mfccs)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> (best_score <span style="color:#f92672">is</span> <span style="color:#66d9ef">None</span>) <span style="color:#f92672">or</span> (best_score <span style="color:#f92672">&lt;</span> score):
</span></span><span style="display:flex;"><span>            best_score <span style="color:#f92672">=</span> score
</span></span><span style="display:flex;"><span>            best_label <span style="color:#f92672">=</span> label
</span></span><span style="display:flex;"><span>    pred_test_y<span style="color:#f92672">.</span>append(best_label)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(test_y)   <span style="color:#75715e"># [&#39;apple&#39;, &#39;banana&#39;, &#39;kiwi&#39;, &#39;lime&#39;, &#39;orange&#39;, &#39;peach&#39;, &#39;pineapple&#39;]</span>
</span></span><span style="display:flex;"><span>print(pred_test_y)  <span style="color:#75715e"># [&#39;apple&#39;, &#39;banana&#39;, &#39;kiwi&#39;, &#39;lime&#39;, &#39;orange&#39;, &#39;peach&#39;, &#39;pineapple&#39;]</span>
</span></span></code></pre></div><h3 id="4-主动降噪anc">4. 主动降噪（ANC）</h3>
<blockquote>
<p>通过降噪系统产生与外界噪音相等的反向声波，将噪声中和，从而实现降噪的效果。所有的声音都由一定的频谱组成，如果可找到一种声音，其频率、振幅与所要消除的噪声完全一样，只是相位刚好相反(相差$180^o$)就可以将这噪声完全抵消。ANC降噪对2KHZ以下的信号噪声降噪效果比较好，<strong>对高频噪声降噪效果很差</strong>。原因为高频信号波长短，对相位偏差也比较敏感，导致ANC对高频噪声降噪效果差。<strong>一般高频噪声可以被耳机物理的遮蔽屏蔽掉</strong>，这种降噪被称为被动降噪。</p>
</blockquote>
<blockquote>
<p>被动降噪：被动式降噪也就是物理降噪，被动式降噪是指利用物理特性将外部噪声与耳朵隔绝开，主要通过耳机的头梁设计得紧一些、耳罩腔体进行声学优化、耳罩内部放上吸声材料……等等来实现耳机的物理隔音。被动降噪对高频率声音（如人声）的隔绝非常有效，一般可使噪声降低大约为15-20dB。</p>
</blockquote>
<h4 id="41-enc降噪">4.1. ENC降噪</h4>
<blockquote>
<p>ENC（Environmental Noise Cancellation，环境降噪技术），能有效抑制90%的反向环境噪声，由此降低环境噪声最高可达35dB以上，让游戏玩家可以更加自由的语音沟通。通过双麦克风阵列，精准计算通话者说话的方位，在保护主方向目标语音的同时，去除环境中的各种干扰噪声。</p>
</blockquote>
<h4 id="42-dsp降噪">4.2. DSP降噪</h4>
<blockquote>
<p>DSP是英文(digital signal processing)的简写。主要是针对高、低频噪声。工作原理是<code>麦克风收集外部环境噪音</code>，然后系统<code>复制一个与外界环境噪音相等的反向声波，将噪音抵消</code>，从而达到更好的降噪效果。DSP降噪的原理和ANC降噪相似。但DSP降噪正反向噪音直接在系统内部相互中和抵消。</p>
</blockquote>
<h4 id="43-cvc降噪">4.3. CVC降噪</h4>
<blockquote>
<p>CVC（Clear Voice Capture）是通话软件降噪技术。主要针对通话过程中产生的回声。通过全双工麦克风消噪软件，提供通话的回声和环境噪音消除功能，是目前蓝牙通话耳机中最先进的降噪技术。</p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122102106150.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122102106150.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122102106150.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122102106150.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122102106150.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122102106150.png"/></p>
<h3 id="5-声源定位">5. 声源定位</h3>
<blockquote>
<p>FRIDA和MUSIC算法的鲁棒性较好，其次是SRP-PHAT和TOPS，再次WAVES和CSSM算法。</p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122140742280.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122140742280.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122140742280.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122140742280.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122140742280.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122140742280.png"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122134459424.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122134459424.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122134459424.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122134459424.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122134459424.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122134459424.png"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122134526910.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122134526910.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122134526910.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122134526910.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122134526910.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122134526910.png"/></p>
<h4 id="51-gcc-srp">5.1. GCC-SRP</h4>
<blockquote>
<p>互相关方法具有计算量小，实时性好而被大多数系统中使用，其<code>基于阵元之间的差异时间差</code>(Time-Delay/Frequency-Delay)进而<code>提取出声源距离阵元的位置信息</code>，根据不同的麦克风对就可以在三维空间中唯一确定一个声源. 基本思想是在可能的空间点中做波束合成，然后根据合成后的各个方向上的功率最大值认为是声源方法。用GCC-PHAT方法得到具有陡峭峰值互相关函数，找到互相关最大时的点，结合采样频率Fs与与麦克风间距dFs与与麦克风间距d，就可以得到方向信息。</p>
</blockquote>
<ul>
<li>互相关可以用来描述两个信号之间的相似性;离散信号xk,yk的互相关函数定义为:<img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122140953113.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122140953113.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122140953113.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122140953113.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122140953113.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122140953113.png"/></li>
<li>取使得互相关系数最大的延时值作为TDOA的估计:<img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122141017679.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122141017679.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122141017679.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122141017679.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122141017679.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122141017679.png"/></li>
<li><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122141236829.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122141236829.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122141236829.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122141236829.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122141236829.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122141236829.png"/><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122141341097.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122141341097.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122141341097.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122141341097.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122141341097.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122141341097.png"/></li>
</ul>
<h4 id="52-music">5.2. Music</h4>
<h4 id="53-tops">5.3. TOPS</h4>
<blockquote>
<p>通过信号和噪声子空间多个频率成分的正交关系估计声源方位，TOPS可用于一维和二维阵列.</p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122142655944.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122142655944.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122142655944.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122142655944.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122142655944.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122142655944.png"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122142715490.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122142715490.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122142715490.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122142715490.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122142715490.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122142715490.png"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201122142737407.png"
    data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201122142737407.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201122142737407.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201122142737407.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201122142737407.png"
    title="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20201122142737407.png"/></p>
<ul>
<li>窄带编辑</li>
</ul>
<blockquote>
<p><strong>窄带意味着信号在阵列上的延迟比信号的时域宽度小得多，从而信号包络沿这列的延迟可以忽略不计，故阵列孔径内的各振元复包络不变。反之，若复包络有变化，则通常认为是宽带信号。</strong></p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122142946919.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122142946919.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122142946919.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122142946919.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122142946919.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122142946919.png"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143322461.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143322461.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143322461.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143322461.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143322461.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143322461.png"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143400195.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143400195.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143400195.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143400195.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143400195.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143400195.png"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143441337.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143441337.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143441337.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143441337.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143441337.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143441337.png"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143700814.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143700814.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143700814.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143700814.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143700814.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143700814.png"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122144036148.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122144036148.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122144036148.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122144036148.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122144036148.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122144036148.png"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143945998.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143945998.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143945998.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143945998.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143945998.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122143945998.png"/></p>
<h4 id="54-frida">5.4. FRIDA</h4>
<h3 id="6-声源分离">6. 声源分离</h3>
<h4 id="61-ml-based">6.1. ML based</h4>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122145237780.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122145237780.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122145237780.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122145237780.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122145237780.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122145237780.png"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031150702720.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031150702720.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031150702720.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031150702720.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031150702720.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031150702720.png"/></p>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122145545772.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122145545772.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122145545772.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122145545772.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122145545772.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201122145545772.png"/></p>
<p>波束形成技术(BF, beamforming) 2.盲源分离技术(BSS, blind source seperation) 3.时频掩码技术(T-F masking, time-frequency masking)</p>
<blockquote>
<p>一般使用理想二值掩蔽方法来生产mask，对于时频表示的语音信号，输出有几个信号就会生成几个mask矩阵，以两个说话人为例，在每个时频点比较两个说话人语音能量的大小，将能量大的一方的mask矩阵对应位置的值设为1，另一个mask矩阵的对应位置设为0。</p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031152021286.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031152021286.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031152021286.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031152021286.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031152021286.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031152021286.png"/></p>
<h4 id="62--deep-clustering">6.2.  Deep Clustering</h4>
<blockquote>
<p>Deep Clustering算法训练神经网络为输入特征中的每个元素生成一个具有区分性的嵌入向量（embedding），之后利用聚类算法，如K-means，对生产的embedding进行聚类，得出不同类别即是不同说话人的信号分离结果图。Deep Clustering性能和泛化性能(训练在英文，测试在中文等情况)都比较好，但缺点是它不是一个end to end的方法，因为聚类方法不能训练。</p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031152325894.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031152325894.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031152325894.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031152325894.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031152325894.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031152325894.png"/></p>
<blockquote>
<p>TasNet（Time-domain Audio Separation Network）是时域的方法(直接输入混合语音，不经过STFT等变化得到声音特征)，由编码器、分离网络、解码组成，与频域方法相比，编码过程不是固定的而是网络学到的(论文中认为对于语音而言STFT并不一定是最佳编码方式，有两点证实了此观点，论文中对编码器输出增加非负的约束会使模型变差，对编解码器增加互逆的关联约束使模型变差，即同一信号经过编码器再经过解码器得到同一信号)，通过分离网络得到两个mask，学到的mask与编码器输出相乘再经过解码器得分离的声音，训练过程使用前文提到的PIT方法，编解码器都是一维卷积（相当于全连接层线性变换），实验结果展示幅度和相位信息都被编码器学习到了特征之中。</p>
</blockquote>
<p><img
    class="lazyload"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031152501949.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031152501949.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031152501949.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031152501949.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031152501949.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201031152501949.png"/></p>
<ul>
<li><a href="https://www.youtube.com/watch?v=n7y2rLAnd5I"target="_blank" rel="external nofollow noopener noreferrer">Lightweight and Optimized Sound Source Localization and Tracking Methods for Open and Closed Microphone Array Configurations<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
</ul>
<p>学习链接：</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/77275353"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/77275353<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
</ul>
</div>
<div class="post-footer" id="post-footer">
  <div class="post-info">
    <div class="post-info-line">
      <div class="post-info-mod">
        <span title=2023-09-24&#32;17:00:03>更新于 2023-09-24&nbsp;</span>
      </div><div class="post-info-license">
          <span><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span>
        </div></div>
    <div class="post-info-line">
      <div class="post-info-md"><span><a href="liudongdong1.github.io/pythonaudioop/index.md" title="阅读原始文档" class="link-to-markdown">阅读原始文档</a></span><span><a href="https://liudongdong1.github.io/edit/master/content/posts%5cAIOT%5cVoiceRelative%5cpythonAudioOp.md" title="编辑此页"target="_blank" rel="external nofollow noopener noreferrer" class="link-to-edit">编辑此页</a></span></div>
      <div class="post-info-share">
        <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="liudongdong1.github.io/pythonaudioop/" data-title="pythoAudioOp" data-hashtags="Voice"><i class="fa-brands fa-twitter fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="liudongdong1.github.io/pythonaudioop/" data-hashtag="Voice"><i class="fa-brands fa-facebook-square fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="liudongdong1.github.io/pythonaudioop/" data-title="pythoAudioOp" data-image="https://gitee.com/github-25970295/blogImage/raw/master/img/illuminated-bridge-and-city-at-night.jpg"><i class="fa-brands fa-weibo fa-fw" aria-hidden="true"></i></a>
  </span>
      </div>
    </div>
  </div>

  <div class="post-info-more">
    <section class="post-tags"><i class="fa-solid fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="liudongdong1.github.io/tags/voice/">Voice</a></section>
    <section>
      <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="liudongdong1.github.io/">主页</a></span>
    </section>
  </div>

  <div class="post-nav"><a href="liudongdong1.github.io/recommandation/" class="prev" rel="prev" title="Recommandation"><i class="fa-solid fa-angle-left fa-fw" aria-hidden="true"></i>Recommandation</a>
      <a href="liudongdong1.github.io/devicesurvey/" class="next" rel="next" title="DeviceSurvey">DeviceSurvey<i class="fa-solid fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article></main><footer class="footer">
    <div class="footer-container"><div class="footer-line powered">由 <a href="https://gohugo.io/" target="_blank" rel="external nofollow noopener noreferrer" title="Hugo 0.118.2">Hugo</a> 强力驱动 | 主题 - <a href="https://github.com/hugo-fixit/FixIt" target="_blank" rel="external" title="FixIt v0.2.17-RC"><img class="fixit-icon" src="/liudongdong1.github.io/fixit.min.svg" alt="FixIt logo" />&nbsp;FixIt</a>
        </div><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">2020 - 2023</span><span class="author" itemprop="copyrightHolder">
              <a href="https://liudongdong1.github.io/"target="_blank" rel="external nofollow noopener noreferrer">LiuDongdong</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div><div class="footer-line statistics"><span class="site-time" title='网站运行中 ...'><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden="true"></i>&nbsp;<span class="run-times">网站运行中 ...</span></span></div><div class="footer-line ibruce">
          <span id="busuanzi_container_site_uv" title='总访客数'><i class="fa-regular fa-user fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span><span id="busuanzi_container_site_pv" class="footer-divider" title='总访问量'><i class="fa-regular fa-eye fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span>
        </div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="回到顶部"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric">0%</span>
        </div></div><a href="https://liudongdong1.github.io/" title="在 GitHub 上查看源代码"target="_blank" rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><div id="mask"></div><div class="reading-progress-bar" style="left: 0;top: 0;--bg-progress: #0076ff;--bg-progress-dark: #fff;"></div><noscript>
    <div class="noscript-warning">FixIt 主题在启用 JavaScript 的情况下效果最佳。</div>
  </noscript>
</div><link rel="stylesheet" href="/liudongdong1.github.io/lib/katex/katex.min.css"><link rel="stylesheet" href="/liudongdong1.github.io/lib/cookieconsent/cookieconsent.min.css"><script src="/liudongdong1.github.io/lib/autocomplete/autocomplete.min.js" defer></script><script src="/liudongdong1.github.io/lib/algoliasearch/algoliasearch-lite.umd.min.js" defer></script><script src="/liudongdong1.github.io/lib/lazysizes/lazysizes.min.js" async defer></script><script src="/liudongdong1.github.io/lib/sharer/sharer.min.js" async defer></script><script src="/liudongdong1.github.io/lib/typeit/index.umd.js" defer></script><script src="/liudongdong1.github.io/lib/katex/katex.min.js" defer></script><script src="/liudongdong1.github.io/lib/katex/auto-render.min.js" defer></script><script src="/liudongdong1.github.io/lib/katex/copy-tex.min.js" defer></script><script src="/liudongdong1.github.io/lib/katex/mhchem.min.js" defer></script><script src="/liudongdong1.github.io/lib/cookieconsent/cookieconsent.min.js" defer></script><script src="/liudongdong1.github.io/lib/pangu/pangu.min.js" defer></script><script src="/liudongdong1.github.io/lib/cell-watermark/watermark.min.js" defer></script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async defer></script><script>window.config={"code":{"copyTitle":"复制到剪贴板","editLockTitle":"锁定可编辑代码块","editUnLockTitle":"解锁可编辑代码块","editable":true,"maxShownLines":10},"comment":{"enable":false},"cookieconsent":{"content":{"dismiss":"同意","link":"了解更多","message":"本网站使用 Cookies 来改善您的浏览体验。"},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"data":{"typeit-header-subtitle-desktop":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e","typeit-header-subtitle-mobile":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e"},"enablePWA":true,"enablePangu":true,"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"2R1K9SKLQZ","algoliaIndex":"index.zh-cn","algoliaSearchKey":"4a226aa1c5c98d6859e4d1386adb2bc7","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"},"siteTime":"2020-12-18T16:15:22+08:00","typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"typeit-header-subtitle-desktop":["typeit-header-subtitle-desktop"],"typeit-header-subtitle-mobile":["typeit-header-subtitle-mobile"]},"duration":-1,"speed":100},"watermark":{"appendto":".wrapper\u003emain","colspacing":30,"content":"\u003cimg class=\"fixit-icon\" src=\"/fixit.min.svg\" alt=\"FixIt logo\" /\u003e FixIt 主题","enable":true,"fontfamily":"inherit","fontsize":0.85,"height":21,"opacity":0.0125,"rotate":15,"rowspacing":60,"width":150}};</script><script src="/liudongdong1.github.io/js/theme.min.js" defer></script><script src="/liudongdong1.github.io/js/custom.min.js" defer></script></body>
</html>
