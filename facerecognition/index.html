<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <head>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>FaceRecognition - DAY By DAY</title><meta name="author" content="LiuDongdong">
<meta name="author-link" content="https://liudongdong1.github.io/">
<meta name="description" content="1. 人脸检测问题 在实际工程应用中，常常会面临非常复杂的工况。一方面算法准确度会受到很多因素影响，例如目标遮挡、光线变化、小尺寸人脸等等。另一方" /><meta name="keywords" content='FaceRecognition' /><meta itemprop="name" content="FaceRecognition">
<meta itemprop="description" content="1. 人脸检测问题 在实际工程应用中，常常会面临非常复杂的工况。一方面算法准确度会受到很多因素影响，例如目标遮挡、光线变化、小尺寸人脸等等。另一方">
<meta itemprop="dateModified" content="2023-09-28T22:42:10+08:00" />
<meta itemprop="wordCount" content="7883"><meta itemprop="image" content="https://liudongdong1.github.io/logo.png"/>
<meta itemprop="keywords" content="FaceRecognition," /><meta property="og:title" content="FaceRecognition" />
<meta property="og:description" content="1. 人脸检测问题 在实际工程应用中，常常会面临非常复杂的工况。一方面算法准确度会受到很多因素影响，例如目标遮挡、光线变化、小尺寸人脸等等。另一方" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://liudongdong1.github.io/facerecognition/" /><meta property="og:image" content="https://liudongdong1.github.io/logo.png"/><meta property="article:section" content="posts" />

<meta property="article:modified_time" content="2023-09-28T22:42:10+08:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://liudongdong1.github.io/logo.png"/>

<meta name="twitter:title" content="FaceRecognition"/>
<meta name="twitter:description" content="1. 人脸检测问题 在实际工程应用中，常常会面临非常复杂的工况。一方面算法准确度会受到很多因素影响，例如目标遮挡、光线变化、小尺寸人脸等等。另一方"/>
<meta name="application-name" content="DAY By DAY">
<meta name="apple-mobile-web-app-title" content="DAY By DAY"><meta name="theme-color" data-light="#f8f8f8" data-dark="#252627" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://liudongdong1.github.io/facerecognition/" /><link rel="prev" href="https://liudongdong1.github.io/faiss/" /><link rel="next" href="https://liudongdong1.github.io/examplesdl4j/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "FaceRecognition",
    "inLanguage": "zh-CN",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https:\/\/liudongdong1.github.io\/facerecognition\/"
    },"genre": "posts","keywords": "FaceRecognition","wordcount":  7883 ,
    "url": "https:\/\/liudongdong1.github.io\/facerecognition\/","dateModified": "2023-09-28T22:42:10+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
      "@type": "Organization",
      "name": "LiuDongdong","logo": "https:\/\/liudongdong1.github.io\/images\/person.png"},"author": {
        "@type": "Person",
        "name": "liudongdong1"
      },"description": ""
  }
  </script></head>
  <body data-header-desktop="auto" data-header-mobile="auto"><script>(window.localStorage?.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('data-theme', 'dark');</script><div class="wrapper"><script type="text/javascript"
        async
        src="https://cdnjs.cloudflare.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>
<header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper" data-github-corner="right">
    <div class="header-title">
      <a href="/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="DAY By DAY"
    title="DAY By DAY"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-desktop" class="typeit header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a
                class="menu-link"
                href="/posts/"
                
                
              ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/categories/"
                
                
              ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/tags/"
                
                
              ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/friends/"
                title="友情链接"
                
              ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/about/"
                
                
              ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li class="menu-item delimiter"></li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <ul class="sub-menu"><li class="menu-item">没有更多翻译</li></ul>
          </li><li class="menu-item search" id="search-desktop">
            <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-desktop">
            <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
              <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
            </a>
            <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
              <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
            </a>
            <span class="search-button search-loading" id="search-loading-desktop">
              <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
            </span>
          </li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li>
      </ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="/fixit.min.svg"
    title="/fixit.min.svg"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-mobile" class="typeit header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li class="search-wrapper">
            <div class="search mobile" id="search-mobile">
              <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-mobile">
              <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
              </a>
              <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
              </a>
              <span class="search-button search-loading" id="search-loading-mobile">
                <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
              </span>
            </div>
            <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
              取消
            </a>
          </li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/posts/"
                  
                  
                ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/categories/"
                  
                  
                ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/tags/"
                  
                  
                ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/friends/"
                  title="友情链接"
                  
                ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/about/"
                  
                  
                ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li
              class="menu-item text-center"
            ><a
                  class="menu-link"
                  href="/"
                  title="GitHub"
                  
                ><i class='fa-brands fa-github fa-fw' aria-hidden='true'></i> </a></li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <select class="language-select" onchange="location = this.value;"><option disabled>没有更多翻译</option></select>
          </li></ul>
    </nav>
  </div>
</header><div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
  </div>
  <div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
  </div><main class="container" data-page-style="normal"><aside class="toc" id="toc-auto"><h2 class="toc-title">目录 <i class="toc-icon fa-solid fa-angle-down fa-fw"></i></h2>
      <div class="toc-content" id="toc-content-auto"></div></aside>

  <aside class="aside-custom" id="aside-sakana">
    

<div class="sakana-widget">
  <div class="sakana-item" id="takina-widget"></div>
  <div class="sakana-item" id="chisato-widget"></div>
</div>
<script>
  function initSakanaWidget() {
    const takina = SakanaWidget.getCharacter('takina')
    SakanaWidget.registerCharacter('takina-slow', takina);
    new SakanaWidget({
      character: 'takina-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#takina-widget');

    const chisato = SakanaWidget.getCharacter('chisato')
    SakanaWidget.registerCharacter('chisato-slow', chisato);
    new SakanaWidget({
      character: 'chisato-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#chisato-widget');
  }
</script>
<script async onload="initSakanaWidget()" src="https://cdn.jsdelivr.net/npm/sakana-widget@2.3.0/lib/sakana.min.js">
</script></aside>

  <article class="page single">
    <div class="header"><h1 class="single-title animate__animated animate__flipInX">
        <span>FaceRecognition</span>
      </h1></div><div class="post-meta">
      <div class="post-meta-line"><span class="post-author"><span class="author"><i class="fa-solid fa-user-circle" aria-hidden="true"></i>
      liudongdong1</span></span>
          <span class="post-category">收录于 <a href="/categories/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;Categories</a>&ensp;<a href="/categories/ai/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;AI</a></span></div>
      <div class="post-meta-line"><span title=0001-01-01&#32;00:00:00>
            <i class="fa-regular fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="0001-01-01" >0001-01-01</time>
          </span>&nbsp;<i class="fa-solid fa-pencil-alt fa-fw"></i>&nbsp;约 7883 字&nbsp;
        <i class="fa-regular fa-clock fa-fw"></i>&nbsp;预计阅读 16 分钟&nbsp;<span id="busuanzi_container_page_pv" class="busuanzi_visitors comment-visitors" data-flag-title="FaceRecognition">
            <i class="fa-regular fa-eye fa-fw"></i>&nbsp;<span id="busuanzi_value_page_pv">-</span>&nbsp;次阅读
          </span>&nbsp;</div>
    </div><div class="featured-image"><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/laptop-notebook-working-outside.jpg"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/laptop-notebook-working-outside.jpg, https://gitee.com/github-25970295/blogImage/raw/master/img/laptop-notebook-working-outside.jpg 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/laptop-notebook-working-outside.jpg 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/laptop-notebook-working-outside.jpg"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/laptop-notebook-working-outside.jpg"/></div><div class="details toc" id="toc-static" kept="true">
        <div class="details-summary toc-title">
          <span>目录</span>
          <span><i class="details-icon fa-solid fa-angle-right"></i></span>
        </div>
        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#1-人脸检测问题">1. 人脸检测问题</a></li>
    <li><a href="#2-工业界常用算法">2. 工业界常用算法</a>
      <ul>
        <li><a href="#21-mtcnn">2.1. MTCNN</a></li>
        <li><a href="#22-faceboxesretinaface-mnetlffd">2.2. <strong>FaceBoxes、RetinaFace mnet、LFFD</strong></a></li>
        <li><a href="#23-centerface">2.3. CenterFace</a></li>
        <li><a href="#24-dlibhttpswwwlfduciedugohlkepythonlibsta-lib">2.4. <a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#ta-lib">dlib</a></a></li>
      </ul>
    </li>
    <li><a href="#3-论文阅读">3. 论文阅读</a>
      <ul>
        <li><a href="#paper-blazeface">Paper: BlazeFace</a></li>
        <li><a href="#paper-facenet">Paper: FaceNet</a></li>
        <li><a href="#paper-viplfacenet">Paper: VIPLFaceNet</a></li>
      </ul>
    </li>
    <li><a href="#4-开源项目">4. 开源项目</a>
      <ul>
        <li><a href="#41-dbfacehttpsgithubcomdluniondbface"><a href="https://github.com/dlunion/DBFace">4.1. DBFace</a></a></li>
        <li><a href="#42-rotation-invariant-facedetection">4.2. Rotation-Invariant FaceDetection</a></li>
        <li><a href="#43-opencvopenvino实现人脸httpssoftwareintelcomen-usopenvino-toolkitchoose-downloadinnovatorcont-0026250"><a href="https://software.intel.com/en-us/openvino-toolkit/choose-download?innovator=CONT-0026250">4.3. OpenCV+OpenVINO实现人脸</a></a></li>
        <li><a href="#44-face_recognition-库使用httpsgithubcomageitgeyface_recognition">4.4. <a href="https://github.com/ageitgey/face_recognition">Face_Recognition 库使用</a></a></li>
        <li><a href="#45-insightfacehttpsgithubcomdeepinsightinsightface">4.5. <a href="https://github.com/deepinsight/insightface">InsightFace</a></a></li>
        <li><a href="#46-seetaface6httpsgithubcomtensorflowerseetaface6python">4.6. <a href="https://github.com/tensorflower/seetaFace6Python">SeetaFace6</a></a></li>
        <li><a href="#47-ultra-light-generic-face-detectorhttpsgithubcomlinzaerultra-light-fast-generic-face-detector-1mb">4.7. <a href="https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB">Ultra-Light-Generic-Face-Detector</a></a></li>
        <li><a href="#48-comprefacehttpsgithubcomexadel-inccompreface">4.8. <a href="https://github.com/exadel-inc/CompreFace">CompreFace</a></a></li>
        <li><a href="#49-tfacehttpsgithubcomtencenttface">4.9. <a href="https://github.com/Tencent/TFace">TFace</a></a></li>
      </ul>
    </li>
    <li><a href="#5-facesearching">5. FaceSearching</a>
      <ul>
        <li><a href="#50-基于gpu优化的检索方案">5.0. 基于GPU优化的检索方案</a></li>
        <li><a href="#51-分布式人脸检索系统框图">5.1. <strong>分布式人脸检索系统框图</strong></a></li>
        <li><a href="#52-人脸动态库方案">5.2. <strong>人脸动态库方案</strong></a></li>
        <li><a href="#53--es分布式人脸检索方案">5.3.  ES分布式人脸检索方案</a></li>
        <li><a href="#54-基于rocksdb的分布式特征索引方案">5.4. 基于RocksDB的分布式特征索引方案</a></li>
        <li><a href="#55--基于小特征加速比对的检索方案">5.5.  基于小特征加速比对的检索方案</a></li>
      </ul>
    </li>
    <li><a href="#6-数据集学习链接">6. 数据集&amp;学习链接</a></li>
  </ul>
</nav></div>
      </div><div
      class="content"
      id="content"
      
      
    ><p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716092214886.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716092214886.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716092214886.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716092214886.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716092214886.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716092214886.png"/></p>
<h2 id="1-人脸检测问题">1. 人脸检测问题</h2>
<p>在实际工程应用中，常常会面临非常复杂的工况。一方面算法准确度会受到很多因素影响，例如目标遮挡、光线变化、小尺寸人脸等等。另一方面算法的推理时间也会受到很多因素的影响，例如硬件性能，目标数量，图片尺寸等等。下面是几种工程中常见的问题。</p>
<ul>
<li><strong>人脸遮挡</strong>，或者人脸角度较大，都会直接导致目标不完整，对于检测算法召回率有很大影响</li>
<li><strong>暗光</strong>，光线不充足条件下，导致成像质量不高，会影响检测算法召回率</li>
<li><strong>低分辨率</strong>，低分辨率导致人脸尺寸过小</li>
<li><strong>人脸数量过多</strong>，图片中人脸数量多，对检测算法要求较高。例如多目标靠的太近，对于NMS算法会是一种考验，另外数量过多会影响某些算法(图像金字塔类型)的时间复杂度，例如MTCNN</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716092748448.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716092748448.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716092748448.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716092748448.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716092748448.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716092748448.png"/></p>
<blockquote>
<p><strong>基于特征的算法</strong>就是通过提取图像中的特征和人脸特征进行匹配，如果匹配上了就说明是人脸，反之则不是。提取的特征是人为设计的特征，例如Haar，FHOG，特征提取完之后，再利用分类器去进行判断。通俗的说就是采用模板匹配，就是用人脸的模板图像与待检测的图像中的各个位置进行匹配，匹配的内容就是提取的特征，然后再利用分类器进行判断是否有人脸</p>
</blockquote>
<blockquote>
<p><strong>基于图像的算法</strong>，将图像分为很多小窗口，然后分别判断每个小窗是否有人脸。通常基于图像的方法依赖于统计分析和机器学习，通过统计分析或者学习的过程来找到人脸和非人脸之间的统计关系来进行人脸检测。最具代表性的就是CNN，CNN用来做人脸检测也是目前效果最好，速度最快的。后面着重介绍CNN相关人脸检测算法。</p>
</blockquote>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219112426981.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219112426981.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219112426981.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219112426981.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219112426981.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219112426981.png"/></p>
<h2 id="2-工业界常用算法">2. 工业界常用算法</h2>
<h3 id="21-mtcnn">2.1. MTCNN</h3>
<blockquote>
<p>MTCNN是kaipeng Zhang在本科阶段研究出来的，它是一个3级联的CNN网络，分为PNet，RNet，ONet，层层递进。PNet的输入是原图经过图像金字塔之后不同尺寸的图片，最后结果由ONet输出。</p>
</blockquote>
<!-- raw HTML omitted -->
<h3 id="22-faceboxesretinaface-mnetlffd">2.2. <strong>FaceBoxes、RetinaFace mnet、LFFD</strong></h3>
<blockquote>
<p>属于One Stage 算法，FaceBoxes类似于SSD算法框架，采用多尺度特征层融合方式，采用anchor proposal，在不同尺度特征层上进行检测，这样就顾及到多尺度的人脸检测，FaceBoxes的文章旨在CPU上实现实时检测。</p>
</blockquote>
<h3 id="23-centerface">2.3. CenterFace</h3>
<blockquote>
<p>最新开源的一个人脸检测算法，github上同名项目。目前从数据来看，效果最好。</p>
<p>在实际工程应用中，要根据部署环境来选择人脸检测算法。例如在多人脸抓拍的场景，就不能选择MTCNN这类级联的算法，因为级联网络的推理速度与人脸数成反比，受人脸数量影响较大，MTCNN适用于人脸考勤或者人证对比的场景，只可能出现固定数量人脸的场景。</p>
</blockquote>
<h3 id="24-dlibhttpswwwlfduciedugohlkepythonlibsta-lib">2.4. <a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#ta-lib"target="_blank" rel="external nofollow noopener noreferrer">dlib<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></h3>
<blockquote>
<p>dlib 安装失败问题：</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>pip install cmake
</span></span><span style="display:flex;"><span>pip install dlib
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#方法二</span>
</span></span><span style="display:flex;"><span>pip install dlib<span style="color:#f92672">==</span>19.6.1 
</span></span><span style="display:flex;"><span><span style="color:#75715e">#方法三： 离线安装</span>
</span></span><span style="display:flex;"><span>pip install dlib-19.21.0.tar.gz
</span></span></code></pre></div><blockquote>
<p>一个人脸算法库，并且开源。不管你是用c++还是python，都可以直接使用dlib来做检测.</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#opencv-python, dlib</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> cv2
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> dlib
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load the detector</span>
</span></span><span style="display:flex;"><span>detector <span style="color:#f92672">=</span> dlib<span style="color:#f92672">.</span>get_frontal_face_detector()
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load the predictor</span>
</span></span><span style="display:flex;"><span>predictor <span style="color:#f92672">=</span> dlib<span style="color:#f92672">.</span>shape_predictor(<span style="color:#e6db74">&#34;shape_predictor_68_face_landmarks.dat&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># read the image</span>
</span></span><span style="display:flex;"><span>img <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>imread(<span style="color:#e6db74">&#34;face.jpg&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Convert image into grayscale</span>
</span></span><span style="display:flex;"><span>gray <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>cvtColor(src<span style="color:#f92672">=</span>img, code<span style="color:#f92672">=</span>cv2<span style="color:#f92672">.</span>COLOR_BGR2GRAY)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Use detector to find landmarks</span>
</span></span><span style="display:flex;"><span>faces <span style="color:#f92672">=</span> detector(gray)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> face <span style="color:#f92672">in</span> faces:
</span></span><span style="display:flex;"><span>    x1 <span style="color:#f92672">=</span> face<span style="color:#f92672">.</span>left() <span style="color:#75715e"># left point</span>
</span></span><span style="display:flex;"><span>    y1 <span style="color:#f92672">=</span> face<span style="color:#f92672">.</span>top() <span style="color:#75715e"># top point</span>
</span></span><span style="display:flex;"><span>    x2 <span style="color:#f92672">=</span> face<span style="color:#f92672">.</span>right() <span style="color:#75715e"># right point</span>
</span></span><span style="display:flex;"><span>    y2 <span style="color:#f92672">=</span> face<span style="color:#f92672">.</span>bottom() <span style="color:#75715e"># bottom point</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Create landmark object</span>
</span></span><span style="display:flex;"><span>    landmarks <span style="color:#f92672">=</span> predictor(image<span style="color:#f92672">=</span>gray, box<span style="color:#f92672">=</span>face)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Loop through all the points</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> n <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">68</span>):
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> landmarks<span style="color:#f92672">.</span>part(n)<span style="color:#f92672">.</span>x
</span></span><span style="display:flex;"><span>        y <span style="color:#f92672">=</span> landmarks<span style="color:#f92672">.</span>part(n)<span style="color:#f92672">.</span>y
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Draw a circle</span>
</span></span><span style="display:flex;"><span>        cv2<span style="color:#f92672">.</span>circle(img<span style="color:#f92672">=</span>img, center<span style="color:#f92672">=</span>(x, y), radius<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, color<span style="color:#f92672">=</span>(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">255</span>, <span style="color:#ae81ff">0</span>), thickness<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># show the image</span>
</span></span><span style="display:flex;"><span>cv2<span style="color:#f92672">.</span>imshow(winname<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Face&#34;</span>, mat<span style="color:#f92672">=</span>img)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Delay between every fram</span>
</span></span><span style="display:flex;"><span>cv2<span style="color:#f92672">.</span>waitKey(delay<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Close all windows</span>
</span></span><span style="display:flex;"><span>cv2<span style="color:#f92672">.</span>destroyAllWindows()
</span></span></code></pre></div><p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/20200826082312.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/20200826082312.png, https://gitee.com/github-25970295/blogImage/raw/master/img/20200826082312.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/20200826082312.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/20200826082312.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/20200826082312.png"/></p>
<h2 id="3-论文阅读">3. 论文阅读</h2>
<p><strong>level</strong>: CVPR
<strong>author</strong>: Valentin Bazarevsky  (GoogleResearch)
<strong>date</strong>: 2019
<strong>keyword</strong>:</p>
<ul>
<li>face detect</li>
</ul>
<hr>
<h3 id="paper-blazeface">Paper: BlazeFace</h3>
<!-- raw HTML omitted -->
<h4 id="summary">Summary</h4>
<ol>
<li>present a lightweight and well-performing face detector tailored for mobile GPU inference, run 200-1000+on flagshship devices.</li>
<li>supporting to any augmented reality pipeline that requires an accurate facial region of interest as an input for task-specific models, such as 2D/3D facial keypoint or geometry estimation, facial features or expression classification, and face region segmentation.</li>
<li><strong>Relative to speed:</strong>
<ul>
<li>a very compact feature extractor convolutional neural network related in structure to MobleNetV1.</li>
<li>a novel GPU-friendly anchor scheme modified from SSD, aimed at effective GPU utilization.</li>
</ul>
</li>
<li><strong>Related to prediction quality:</strong> a tie resolution strategy alternative to non-maximum suppression that achieves stabler,smoother tie resolution between overlapping predictions.</li>
</ol>
<h4 id="system-overview">System Overview</h4>
<blockquote>
<p>BlazeFace model produces 6 facial keypoint coordinates (for eye centers, ear tragions, mouth center, and nose tip) that allow us to estimate <strong>face rotation</strong>, alleviating the requirement of significant translation and rotation invariance in subsequent processing steps;</p>
</blockquote>
<p>【<strong>Model architecture design</strong>】</p>
<ul>
<li><strong>Enlarging the receptive field sizes:</strong>
<ul>
<li>increasing the kernel size of the depthwise part is relatively cheap, and employ 5*5 kernels in model architecture bottlenecks, trading the kernel size increase for the decrease in the total amount of such bottlenecks required to reach a particular receptive field size.  <!-- raw HTML omitted -->这块看不懂<!-- raw HTML omitted --></li>
</ul>
</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/20200831120241.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/20200831120241.png, https://gitee.com/github-25970295/blogImage/raw/master/img/20200831120241.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/20200831120241.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/20200831120241.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/20200831120241.png"/></p>
<ul>
<li><strong>Feature extractor:</strong> the extractor takes an RGB input of 128*128 pixels and consists of a 2D convolution followed by 5 single BlazeBlocks and 6 double BlazeBlocks.</li>
<li><strong>Anchor scheme:</strong> SSD-like object detection models rely on pre-defined fixed-size base bounding boxes called priors, or anchors in Faster-R-CNN terminology.
<ul>
<li>adopt an alternative anchor scheme that stops at the 8*8 feature map dimensions without further downsampling,</li>
<li>replace 2 anchors per pixel in each of the 8*8, 4*4 and 2*2 resolutions by 6 anchors at  8*8;</li>
<li>due to limited variance in human face aspect ratios, limiting the anchors to the 1:1 aspect ratio was found sufficient for accurate face detection;</li>
</ul>
</li>
<li><strong>Post-processing:</strong> replacing the suppression algorithm wiht a blending strategy that estimates the regression parameters of a bounding box as a weighted mean between the overlapping predictions;</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/20200831121558.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/20200831121558.png, https://gitee.com/github-25970295/blogImage/raw/master/img/20200831121558.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/20200831121558.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/20200831121558.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/20200831121558.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/20200831121622.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/20200831121622.png, https://gitee.com/github-25970295/blogImage/raw/master/img/20200831121622.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/20200831121622.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/20200831121622.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/20200831121622.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/20200831121809.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/20200831121809.png, https://gitee.com/github-25970295/blogImage/raw/master/img/20200831121809.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/20200831121809.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/20200831121809.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/20200831121809.png"/></p>
<h4 id="notes-font-colororange去加强了解font">Notes <!-- raw HTML omitted -->去加强了解<!-- raw HTML omitted --></h4>
<ul>
<li><i class="fa-regular fa-square fa-fw" aria-hidden="true"></i> 几种常见模型里面的计算</li>
</ul>
<p><strong>level</strong>:   CCF_A   CVPR
<strong>author</strong>:  FlorianSchroff <a href="mailto:fschroff@google.com">fschroff@google.com</a> GoogleInc
<strong>date</strong>: 2015
<strong>keyword</strong>:</p>
<ul>
<li>AI, FaceRecognition</li>
</ul>
<hr>
<h3 id="paper-facenet">Paper: FaceNet</h3>
<!-- raw HTML omitted -->
<ol>
<li>present a system, FaceNet that directly learns  a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity, further used by face recognition, verification, and clustering.</li>
<li>FaceNet directly trains its output to be a compact 128-D embedding using a triplet based loss function based on LMNN, the triplets consist of two matching face thumbnails and a non-matching face thumbnail and the loss aims  to separate the positive pair form the negative by a distance margin. The thumbnails are tight crops of the face area, no 2D or 3D alignment, other than scale and translation is performed.</li>
</ol>
<h4 id="research-objective">Research Objective</h4>
<p><strong>previous work:</strong></p>
<ul>
<li><!-- raw HTML omitted -->Zeiler&amp;Fergus[22] model <!-- raw HTML omitted -->: multiple interleaved layers of convolutions, non-linear activations, local response normalizations, and max pooling layers.</li>
<li><!-- raw HTML omitted -->Inception model of Szegedy et al.<!-- raw HTML omitted --> : use  mixed layers that run several different convolutional and pooling layers in parallel and concatenate their responses</li>
<li>using a complex system of multiple stages combining the output of a deep convolutional network with PCA for dimensionality reduction and SVM for classification</li>
<li>ZHanyao et al.  : employ deep network to warp faces into a canonical frontal view and then learn CNN that classifies each face as belonging to a known identity, PCA on the network output in conjunction with an ensemble of SVM is used</li>
<li>Taigman et al. : multi-stage approach that aligns faces to a general 3D shape model.</li>
<li>sun et al. : propose a compact and therefore relatively cheap to compute network.</li>
</ul>
<h4 id="methods">Methods</h4>
<ul>
<li>
<p><strong>Problem Formulation</strong>:</p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104544427.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104544427.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104544427.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104544427.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104544427.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104544427.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104603166.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104603166.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104603166.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104603166.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104603166.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104603166.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104625390.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104625390.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104625390.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104625390.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104625390.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104625390.png"/></p>
</li>
<li>
<p><strong>system overview</strong>:</p>
</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104451015.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104451015.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104451015.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104451015.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104451015.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104451015.png"/></p>
<p><strong>[FaceNet Model1]</strong></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104704084.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104704084.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104704084.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104704084.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104704084.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104704084.png"/></p>
<p>**[FaceNet Model2]**based on GoogLeNet styleInceptionmodels[16]</p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104856005.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104856005.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104856005.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104856005.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104856005.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200301104856005.png"/></p>
<h4 id="notes">Notes</h4>
<ul>
<li>curriculum learning : describes a type of learning in which you first start out with only easy examples of a task and then gradually increase the task difficulty.
<ul>
<li>code available: <a href="https://github.com/vkakerbeck/Progressively-Growing-Networks"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/vkakerbeck/Progressively-Growing-Networks<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
</ul>
</li>
<li>Progressively Growing Neural Networks:grow networks during training and to learn new image categories</li>
<li>LMNN</li>
</ul>
<!-- raw HTML omitted -->
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200305173050782.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200305173050782.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200305173050782.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200305173050782.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200305173050782.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200305173050782.png"/></p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Triplet_loss"target="_blank" rel="external nofollow noopener noreferrer">triplet based loss<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200305175940694.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200305175940694.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200305175940694.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200305175940694.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200305175940694.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200305175940694.png"/></p>
<p><strong>level</strong>:   CVPR   CCF_A
<strong>author</strong>: XinLiu (CAS)
<strong>date</strong>: 2016
<strong>keyword</strong>:</p>
<ul>
<li>FaceRecognition</li>
</ul>
<hr>
<h3 id="paper-viplfacenet">Paper: VIPLFaceNet</h3>
<!-- raw HTML omitted -->
<h4 id="research-objective-1">Research Objective</h4>
<ul>
<li><strong>Application Area</strong>: Face recognition</li>
</ul>
<h4 id="proble-statement">Proble Statement</h4>
<ul>
<li>a conventional face recognition system consists of four modules,face detection,face alignment, face representation, and identity classification.</li>
<li>main challenges of face representation:
<ul>
<li>small inter-person appearance difference caused by similar facial configurations</li>
<li>large intra-person appearance variations due to large intrinsic variations and diverse extrinsic imaging factors, such as head pose, expression, aging, and illumination.</li>
</ul>
</li>
</ul>
<p>previous work:</p>
<ul>
<li>
<p>Face Representation before DL</p>
</li>
<li>
<p>Hand Craft features: Gabor wavelets, local Binary Pattern, SIFT, Historgram of Oriented Gradients</p>
</li>
<li>
<p>Deep learning Methods:</p>
<ul>
<li>DeepFace : 1. 3D model based face alignment to frontalize facial images with large pose. 2.large scale training set with 4 million face images of 4000 identities. 3.Deep convolutional neural network with the local connected layer that learns separate kernel for each spatial position. 4.A siamese network architecture to learn deep metric based on the features of the deep convolutional network</li>
<li>DeepID, DeepID2, DeepID2+</li>
<li>Learning face representation from scratch.</li>
<li>FaceNet</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304122129244.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304122129244.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304122129244.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304122129244.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304122129244.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304122129244.png"/></p>
</li>
</ul>
<h4 id="methods-1">Methods</h4>
<ul>
<li><strong>system overview</strong>:</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304122158473.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304122158473.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304122158473.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304122158473.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304122158473.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304122158473.png"/></p>
<p>【Optimation 1】Fast Normalization Layer</p>
<p>Data normalization can speed up convergence, which is recently extended as the batch normalization algorithms.</p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304152727485.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304152727485.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304152727485.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304152727485.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304152727485.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304152727485.png"/></p>
<p><strong>Face Detection:</strong>  using face detection toolkit by VIPL lab of CAS,</p>
<p>**Facial Landmark Location: **coarse to fine auto-encoder networks(CFAN) to detect five facial landmarks in the face.</p>
<p><strong>Face Normalization:</strong> the face image is normalized to 256*256 pixels using five facial landmarks.</p>
<h4 id="evaluation">Evaluation</h4>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304153238679.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304153238679.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304153238679.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304153238679.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304153238679.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200304153238679.png"/></p>
<h4 id="conclusion">Conclusion</h4>
<ul>
<li>propose and release an open source deep face recognition model, VIPFaceNet, with high-accuracy and low computational cost.</li>
<li>reduces 40% computation cost and cuts down 40% error rate on LFW compared with AlexNet</li>
<li>pure C++ code</li>
</ul>
<h4 id="notes-font-colororange去加强了解font-1">Notes <!-- raw HTML omitted -->去加强了解<!-- raw HTML omitted --></h4>
<ul>
<li><i class="fa-regular fa-square fa-fw" aria-hidden="true"></i> 学习使用AlexNet模型  simplest with 5 convolutional layer and 3 fully-connected layers</li>
<li><i class="fa-regular fa-square fa-fw" aria-hidden="true"></i> 学习使用LFW模型</li>
<li><i class="fa-regular fa-square fa-fw" aria-hidden="true"></i> Learning face representation from scratch. arXivpreprintarXiv:1411.7923,2014</li>
<li><i class="fa-regular fa-square fa-fw" aria-hidden="true"></i> GoogleNet 模型</li>
<li><i class="fa-regular fa-square fa-fw" aria-hidden="true"></i> VGGNet模型</li>
</ul>
<h2 id="4-开源项目">4. 开源项目</h2>
<h3 id="41-dbfacehttpsgithubcomdluniondbface"><a href="https://github.com/dlunion/DBFace"target="_blank" rel="external nofollow noopener noreferrer">4.1. DBFace<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></h3>
<ul>
<li>DBFace 是一个轻量级的实时人脸识别方法，其有着更快的识别速度与更高的精度。下图展示了多种人脸检测方法在 WiderFace 数据集上的测试效果。可以看到不仅 DBFace 模型的大小最小，其在 Easy、medium、Hard 三个测试任务中均取得了最高的识别精度。</li>
<li>WiderFace 是一个关于人脸检测的基准跑分数据集，其中包含 32,203 张图片以及在各方面剧烈的 393,703 张人脸，数据集具有从简单到困难等不同难度的任务。</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716091843597.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716091843597.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716091843597.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716091843597.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716091843597.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716091843597.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716091856713.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716091856713.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716091856713.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716091856713.png 2x"
    data-sizes="auto"
    alt="image-20200716091856713"
    title="image-20200716091856713"/></p>
<h3 id="42-rotation-invariant-facedetection">4.2. Rotation-Invariant FaceDetection</h3>
<p>Real-Time Rotation-Invariant Face Detection with Progressive Calibration Networks</p>
<p>PCN 会抽选识别候选面部图像块，并将朝下的图像块翻转至正向，这样就会减半 RIP 的角度范围，即从 [−180° , 180° ] 到 [−90° , 90° ]。然后旋转过的面部图像块会进一步区分朝向并校准到垂直向的 [−45° , 45° ] 范围，这样又会减半 RIP 的角度范围。最后，PCN 会分辨到底这些候选图像块是不是人脸，并预测出精确的 RIP 角度。</p>
<p>通过将校准过程分割为几个渐进的步骤，且在早期校准步骤只预测粗略的朝向，PCN 最后能实现精确的校准。此外，每一个校准步骤可以简单地旋转-90°、90°和 180°，因此额外的计算量非常低，这也就是为什么该检测项目能在 CPU 上实时运行的重要原因。通过在逐渐降低的 RIP 范围内执行二元分类（是人脸或不是人脸），PCN 能在 360° RIP 旋转角度内准确地检测到人脸，而本项目重点就是实现这样旋转不变的人脸检测器。</p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716091914764.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716091914764.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716091914764.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716091914764.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716091914764.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716091914764.png"/></p>
<p>论文图 3：uepeng Shi 等研究者提出的 PCN 概览，它会逐渐降低旋转的角度范围，并最终预测人脸及其旋转的角度。这种能处理不同旋转方向的人脸检测器有非常高的准确率，因为它会先将候选人脸旋转至正向再预测。此外，这种方法同样有非常小的计算量，该 GitHub 项目表示它甚至可以在 CPU 上实时检测人脸。</p>
<h3 id="43-opencvopenvino实现人脸httpssoftwareintelcomen-usopenvino-toolkitchoose-downloadinnovatorcont-0026250"><a href="https://software.intel.com/en-us/openvino-toolkit/choose-download?innovator=CONT-0026250"target="_blank" rel="external nofollow noopener noreferrer">4.3. OpenCV+OpenVINO实现人脸<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></h3>
<ul>
<li>支持35点分布表示出左眼、右眼、鼻子、嘴巴、左侧眉毛、右侧眉毛、人脸轮廓</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">/</span> 加载LANDMARK
</span></span><span style="display:flex;"><span>Net mkNet <span style="color:#f92672">=</span> readNetFromModelOptimizer(landmark_xml, landmark_bin);
</span></span><span style="display:flex;"><span>mkNet<span style="color:#f92672">.</span>setPreferableBackend(DNN_BACKEND_INFERENCE_ENGINE);
</span></span><span style="display:flex;"><span>mkNet<span style="color:#f92672">.</span>setPreferableTarget(DNN_TARGET_CPU);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">//</span> 加载网络
</span></span><span style="display:flex;"><span>Net net <span style="color:#f92672">=</span> cv::dnn::readNetFromTensorflow(tensorflowWeightFile, tensorflowConfigFile);
</span></span><span style="display:flex;"><span>net<span style="color:#f92672">.</span>setPreferableBackend(DNN_BACKEND_INFERENCE_ENGINE);
</span></span><span style="display:flex;"><span>net<span style="color:#f92672">.</span>setPreferableTarget(DNN_TARGET_CPU);
</span></span><span style="display:flex;"><span>Mat frame;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">while</span> (true) {
</span></span><span style="display:flex;"><span>    bool ret <span style="color:#f92672">=</span> cap<span style="color:#f92672">.</span>read(frame);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (<span style="color:#960050;background-color:#1e0010">!</span>ret) {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">break</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">//</span> flip(frame, frame, <span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>    cv::Mat inputBlob <span style="color:#f92672">=</span> cv::dnn::blobFromImage(frame, <span style="color:#ae81ff">1.0</span>, cv::Size(<span style="color:#ae81ff">300</span>, <span style="color:#ae81ff">300</span>),
</span></span><span style="display:flex;"><span>        Scalar(<span style="color:#ae81ff">104.0</span>, <span style="color:#ae81ff">177.0</span>, <span style="color:#ae81ff">123.0</span>), false, false);
</span></span><span style="display:flex;"><span>    net<span style="color:#f92672">.</span>setInput(inputBlob, <span style="color:#e6db74">&#34;data&#34;</span>);
</span></span><span style="display:flex;"><span>    cv::Mat detection <span style="color:#f92672">=</span> net<span style="color:#f92672">.</span>forward(<span style="color:#e6db74">&#34;detection_out&#34;</span>);
</span></span><span style="display:flex;"><span>    cv::Mat detectionMat(detection<span style="color:#f92672">.</span>size[<span style="color:#ae81ff">2</span>], detection<span style="color:#f92672">.</span>size[<span style="color:#ae81ff">3</span>], CV_32F, detection<span style="color:#f92672">.</span>ptr<span style="color:#f92672">&lt;</span>float<span style="color:#f92672">&gt;</span>());
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> (int i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>; i <span style="color:#f92672">&lt;</span> detectionMat<span style="color:#f92672">.</span>rows; i<span style="color:#f92672">++</span>)
</span></span><span style="display:flex;"><span>    {
</span></span><span style="display:flex;"><span>        float confidence <span style="color:#f92672">=</span> detectionMat<span style="color:#f92672">.</span>at<span style="color:#f92672">&lt;</span>float<span style="color:#f92672">&gt;</span>(i, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> (confidence <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0.5</span>)
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            int x1 <span style="color:#f92672">=</span> static_cast<span style="color:#f92672">&lt;</span>int<span style="color:#f92672">&gt;</span>(detectionMat<span style="color:#f92672">.</span>at<span style="color:#f92672">&lt;</span>float<span style="color:#f92672">&gt;</span>(i, <span style="color:#ae81ff">3</span>) <span style="color:#f92672">*</span> w);
</span></span><span style="display:flex;"><span>            int y1 <span style="color:#f92672">=</span> static_cast<span style="color:#f92672">&lt;</span>int<span style="color:#f92672">&gt;</span>(detectionMat<span style="color:#f92672">.</span>at<span style="color:#f92672">&lt;</span>float<span style="color:#f92672">&gt;</span>(i, <span style="color:#ae81ff">4</span>) <span style="color:#f92672">*</span> h);
</span></span><span style="display:flex;"><span>            int x2 <span style="color:#f92672">=</span> static_cast<span style="color:#f92672">&lt;</span>int<span style="color:#f92672">&gt;</span>(detectionMat<span style="color:#f92672">.</span>at<span style="color:#f92672">&lt;</span>float<span style="color:#f92672">&gt;</span>(i, <span style="color:#ae81ff">5</span>) <span style="color:#f92672">*</span> w);
</span></span><span style="display:flex;"><span>            int y2 <span style="color:#f92672">=</span> static_cast<span style="color:#f92672">&lt;</span>int<span style="color:#f92672">&gt;</span>(detectionMat<span style="color:#f92672">.</span>at<span style="color:#f92672">&lt;</span>float<span style="color:#f92672">&gt;</span>(i, <span style="color:#ae81ff">6</span>) <span style="color:#f92672">*</span> h);
</span></span><span style="display:flex;"><span>            Mat roi <span style="color:#f92672">=</span> frame(Range(y1, y2), Range(x1, x2));
</span></span><span style="display:flex;"><span>            Mat blob <span style="color:#f92672">=</span> blobFromImage(roi, <span style="color:#ae81ff">1.0</span>, Size(<span style="color:#ae81ff">60</span>, <span style="color:#ae81ff">60</span>), Scalar(), false, false);
</span></span><span style="display:flex;"><span>            mkNet<span style="color:#f92672">.</span>setInput(blob);
</span></span><span style="display:flex;"><span>            Mat landmark_data <span style="color:#f92672">=</span> mkNet<span style="color:#f92672">.</span>forward();
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">//</span> printf(<span style="color:#e6db74">&#34;rows: </span><span style="color:#e6db74">%d</span><span style="color:#e6db74"> </span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">, cols : </span><span style="color:#e6db74">%d</span><span style="color:#e6db74"> </span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, landmark_data<span style="color:#f92672">.</span>rows, landmark_data<span style="color:#f92672">.</span>cols);
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> (int i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>; i <span style="color:#f92672">&lt;</span> landmark_data<span style="color:#f92672">.</span>cols; i <span style="color:#f92672">+=</span> <span style="color:#ae81ff">2</span>) {
</span></span><span style="display:flex;"><span>                float x <span style="color:#f92672">=</span> landmark_data<span style="color:#f92672">.</span>at<span style="color:#f92672">&lt;</span>float<span style="color:#f92672">&gt;</span>(<span style="color:#ae81ff">0</span>, i)<span style="color:#f92672">*</span>roi<span style="color:#f92672">.</span>cols<span style="color:#f92672">+</span>x1;
</span></span><span style="display:flex;"><span>                float y <span style="color:#f92672">=</span> landmark_data<span style="color:#f92672">.</span>at<span style="color:#f92672">&lt;</span>float<span style="color:#f92672">&gt;</span>(<span style="color:#ae81ff">0</span>, i <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>)<span style="color:#f92672">*</span>roi<span style="color:#f92672">.</span>rows<span style="color:#f92672">+</span>y1;
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">//</span> mkList<span style="color:#f92672">.</span>push_back(Point(x, y));
</span></span><span style="display:flex;"><span>                circle(frame, Point(x, y), <span style="color:#ae81ff">2</span>, Scalar(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">255</span>), <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">0</span>);
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>            cv::rectangle(frame, cv::Point(x1, y1), cv::Point(x2, y2), cv::Scalar(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">255</span>, <span style="color:#ae81ff">0</span>), <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">8</span>);
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    imshow(<span style="color:#e6db74">&#34;Face-Detection Demo&#34;</span>, frame);
</span></span><span style="display:flex;"><span>    char c <span style="color:#f92672">=</span> waitKey(<span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (c <span style="color:#f92672">==</span> <span style="color:#ae81ff">27</span>) {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">break</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h3 id="44-face_recognition-库使用httpsgithubcomageitgeyface_recognition">4.4. <a href="https://github.com/ageitgey/face_recognition"target="_blank" rel="external nofollow noopener noreferrer">Face_Recognition 库使用<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>pip install face_recognition
</span></span></code></pre></div><blockquote>
<p>Face Recognition 是一个基于 Python 的人脸识别库，它还提供了一个命令行工具，让你通过命令行对任意文件夹中的图像进行人脸识别操作。 该库使用 dlib 顶尖的深度学习人脸识别技术构建，在户外脸部检测数据库基准(Labeled Faces in the Wild benchmark)上的准确率高达 99.38%。</p>
</blockquote>
<blockquote>
<p>batch_face_locations(images, number_of_times_to_upsample=1, batch_size=128)：</p>
<p>使用cnn面部检测器返回图像中二维人脸的边界框数组，如果您正在使用<a href="https://cloud.tencent.com/product/gpu?from=10680"target="_blank" rel="external nofollow noopener noreferrer">GPU<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>，这可以更快的给您结果，因为GPU可以一次处理批次的图像。如果您不使用GPU，则不需要此功能。</p>
<h5 id="参数">参数：</h5>
<ul>
<li>images - 图像列表（每个作为numpy数组）</li>
<li>number_of_times_to_upsample - 用于对图像进行采样的次数。较高的数字找到较小的脸。</li>
<li>batch_size - 每个GPU处理批次中包含的图像数量。</li>
</ul>
<h5 id="返回">返回：</h5>
<p>一个可以在css（上，右，下，左）顺序中找到的人脸位置的元组列表</p>
</blockquote>
<blockquote>
<p>compare_faces(known_face_encodings, face_encoding_to_check, tolerance=0.6)： 将候选编码的面部编码列表进行比较，以查看它们是否匹配。</p>
<h5 id="参数-1">参数：</h5>
<ul>
<li>known_face_encodings - 已知面部编码的列表</li>
<li>face_encoding_to_check - 与已知面部编码的列表进行比较的单面编码</li>
<li>tolerance - 面孔之间的距离要考虑多少。越小越严格， 0.6是典型的最佳性能。</li>
</ul>
<h5 id="返回-1">返回：</h5>
<p>一个True / False值的列表，指出哪个known_face_encodings匹配要检查的面部编码</p>
</blockquote>
<blockquote>
<p>face_distance(face_encodings, face_to_compare)： 给出面部编码列表，将其与已知的面部编码进行比较，并为每个比较的人脸获得欧几里得距离。距离告诉你面孔是如何相似的。</p>
<h5 id="参数-2">参数：</h5>
<ul>
<li>face_encodings - 要比较的面部编码列表</li>
<li>face_to_compare - 要比较的面部编码</li>
</ul>
<h5 id="返回-2">返回：</h5>
<p>一个numpy ndarray，每个面的距离与“faces”数组的顺序相同</p>
</blockquote>
<blockquote>
<p>face_encodings(face_image, known_face_locations=None, num_jitters=1)：</p>
<p>给定图像，返回图像中每个面部的128维面部编码。</p>
<h5 id="参数-3">参数：</h5>
<ul>
<li>face_image - 包含一个或多个面的图像</li>
<li>known_face_locations - 可选 - 如果您已经知道它们，每个面的边框。</li>
<li>num_jitters - 计算编码时重新采样多少次。更高更准确，但更慢（即100是100倍慢）</li>
</ul>
<h5 id="返回-3">返回：</h5>
<p>128个面部编码的列表（图像中的每个脸部一个）</p>
</blockquote>
<blockquote>
<p>face_landmarks(face_image, face_locations=None)：给定图像，返回图像中每个脸部的脸部特征位置（眼睛，鼻子等）的指令</p>
<h5 id="参数-4">参数：</h5>
<ul>
<li>face_image - 要搜索的图像</li>
<li>face_locations - 可选地提供要检查的面部位置的列表。</li>
</ul>
<h5 id="返回-4">返回：</h5>
<p>面部特征位置（眼睛，鼻子等）的列表</p>
</blockquote>
<blockquote>
<p>face_locations(img, number_of_times_to_upsample=1, model=&lsquo;hog&rsquo;)：</p>
<p>返回图像中人脸的边框数组</p>
<h5 id="参数-5">参数：</h5>
<ul>
<li>img - 一个图像（作为一个numpy数组）</li>
<li>number_of_times_to_upsample - 用于对图像进行上采样的次数多少次。较高的数字找到较小的脸。</li>
<li>model - 要使用的面部检测模型。“hog”在CPU上不太准确，但速度更快。“cnn”是一个更准确的深入学习模式，GPU / CUDA加速（如果可用）。默认为“hog”。</li>
</ul>
<h5 id="返回-5">返回：</h5>
<p>一个可以在css（上，右，下，左）顺序中找到的表面位置的元组列表</p>
</blockquote>
<blockquote>
<p>load_image_file(file, mode=&lsquo;RGB&rsquo;)：</p>
<p>将图像文件（.jpg，.png等）加载到numpy数组中</p>
<h5 id="参数-6">参数：</h5>
<ul>
<li>file - 要加载的图像文件名或文件对象</li>
<li>mode - 将图像转换为格式。只支持“RGB”（8位RGB，3声道）和“L”（黑白）。</li>
</ul>
<h5 id="返回-6">返回：</h5>
<p>图像内容为numpy数组</p>
</blockquote>
<ul>
<li>人脸识别并检测绘制关键点</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> face_recognition
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> cv2
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> time
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> threading <span style="color:#f92672">import</span> Thread
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> PyQt5.QtCore <span style="color:#f92672">import</span> <span style="color:#f92672">*</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> PIL <span style="color:#f92672">import</span> Image, ImageDraw, ImageFont
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Face_Recognizer</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, camera_id <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>basefolder<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;../../data/face&#34;</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>faces,self<span style="color:#f92672">.</span>faceNames<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>initFaceData()
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    @function: 初始化人脸数据，从已经存储的文件加载name和对应的人脸 encoding
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">initFaceData</span>(self):
</span></span><span style="display:flex;"><span>        known_faces<span style="color:#f92672">=</span>[]
</span></span><span style="display:flex;"><span>        known_faceNames<span style="color:#f92672">=</span>[]
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> file <span style="color:#f92672">in</span> os<span style="color:#f92672">.</span>listdir(self<span style="color:#f92672">.</span>basefolder):
</span></span><span style="display:flex;"><span>            filepath<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(self<span style="color:#f92672">.</span>basefolder,file)
</span></span><span style="display:flex;"><span>            <span style="color:#75715e">#print(filepath)</span>
</span></span><span style="display:flex;"><span>            image<span style="color:#f92672">=</span>face_recognition<span style="color:#f92672">.</span>load_image_file(filepath)
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>                imageEncoding<span style="color:#f92672">=</span>face_recognition<span style="color:#f92672">.</span>face_encodings(image)[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>                known_faceNames<span style="color:#f92672">.</span>append(file<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;.&#39;</span>)[<span style="color:#ae81ff">0</span>])
</span></span><span style="display:flex;"><span>                known_faces<span style="color:#f92672">.</span>append(imageEncoding)
</span></span><span style="display:flex;"><span>                print(known_faceNames[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">except</span>:
</span></span><span style="display:flex;"><span>                print(<span style="color:#e6db74">&#34;file don&#39;t detect face&#34;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> known_faces,known_faceNames
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#This function will take a sample frame</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#save the picture of the given user in a folder</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#returns the path of the saved image</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">saveFaceImage</span>(self,imgdata, face_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;user&#39;</span>):
</span></span><span style="display:flex;"><span>        face_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">.png&#39;</span><span style="color:#f92672">.</span>format(face_name)
</span></span><span style="display:flex;"><span>        facesavepath<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(self<span style="color:#f92672">.</span>basefolder, face_name)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>            cv2<span style="color:#f92672">.</span>imwrite(facesavepath, imgdata)
</span></span><span style="display:flex;"><span>            time<span style="color:#f92672">.</span>sleep(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">except</span>:
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">&#34;Can&#39;t Save File&#34;</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    @function: 如果图片数据中包含人脸，则添加人脸的编码和name信息
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    @parameters：
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        imgdata: 人脸数据
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        face_names: 名称数据
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    @return
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        true: 录入人脸信息成功
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        false: 录入人脸信息失败
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">faceRegister</span>(self,originimage,face_name):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#imgdata = face_recognition.load_image_file(self.face_image_path)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># if face_name not in self.faceNames:</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#     imgdata = cv2.resize(originimage, (0, 0), fx=0.25, fy=0.25)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#     face_encoding = face_recognition.face_encodings(imgdata)[0]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#     self.faces.append(face_encoding)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#     self.faceNames.append(face_name)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#     print(&#34;faceRegister: add facecoding ok&#34;)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># self.saveFaceImage(originimage,face_name)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># print(&#34;faceRegister: save face ok&#34;)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># return True</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> face_name <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>faceNames:
</span></span><span style="display:flex;"><span>                imgdata <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>resize(originimage, (<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>), fx<span style="color:#f92672">=</span><span style="color:#ae81ff">0.25</span>, fy<span style="color:#f92672">=</span><span style="color:#ae81ff">0.25</span>)
</span></span><span style="display:flex;"><span>                face_encoding <span style="color:#f92672">=</span> face_recognition<span style="color:#f92672">.</span>face_encodings(imgdata)[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>                self<span style="color:#f92672">.</span>faces<span style="color:#f92672">.</span>append(face_encoding)
</span></span><span style="display:flex;"><span>                self<span style="color:#f92672">.</span>faceNames<span style="color:#f92672">.</span>append(face_name)
</span></span><span style="display:flex;"><span>                print(<span style="color:#e6db74">&#34;faceRegister: add facecoding ok&#34;</span>)
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>saveFaceImage(originimage,face_name)
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">&#34;faceRegister: save face ok&#34;</span>)
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span> <span style="color:#66d9ef">as</span> err:
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">&#34;No face found in the image&#34;</span>,err)
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        @parameter: face_name: 用户名称
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        @return: 如果列表包含用户名称，则返回 true； 否则返回false；
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">nameContain</span>(self, face_name):
</span></span><span style="display:flex;"><span>        registered <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>        namelist<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>listdir(self<span style="color:#f92672">.</span>basefolder)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> <span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">.png&#39;</span><span style="color:#f92672">.</span>format(face_name) <span style="color:#f92672">in</span> namelist:
</span></span><span style="display:flex;"><span>            registered<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> registered
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    @function: 从一张图片中识别人脸信息
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    @parameters: 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        targetPath: 待识别的图片路径
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    @returns: 识别用户的姓名信息
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">getFaceNameFromFile</span>(self,targetPath):
</span></span><span style="display:flex;"><span>        name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;None&#34;</span>
</span></span><span style="display:flex;"><span>        image<span style="color:#f92672">=</span>face_recognition<span style="color:#f92672">.</span>load_image_file(targetPath)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>            face_encoding<span style="color:#f92672">=</span>face_recognition<span style="color:#f92672">.</span>face_encodings(image)[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>            matches <span style="color:#f92672">=</span> face_recognition<span style="color:#f92672">.</span>compare_faces(self<span style="color:#f92672">.</span>faces, face_encoding)
</span></span><span style="display:flex;"><span>            face_distances <span style="color:#f92672">=</span> face_recognition<span style="color:#f92672">.</span>face_distance(self<span style="color:#f92672">.</span>faces, face_encoding)
</span></span><span style="display:flex;"><span>            best_match_index <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argmin(face_distances)
</span></span><span style="display:flex;"><span>            <span style="color:#75715e">#print(&#34;最小距离： &#34;,face_distances[best_match_index])</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e">#print(face_distances)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> matches[best_match_index]:
</span></span><span style="display:flex;"><span>                name <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>faceNames[best_match_index]
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> name
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span> <span style="color:#66d9ef">as</span> e:
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">&#34;file don&#39;t detect face&#34;</span>,e)
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> name   
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    @function: 从一张图片编码中识别人脸信息
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    @parameters: 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        targetEncoding: 待识别的图片 特征编码
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    @returns: 识别用户的姓名信息
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">getFaceNameFromEncoding</span>(self,targetEncoding):
</span></span><span style="display:flex;"><span>        name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;None&#34;</span>
</span></span><span style="display:flex;"><span>        matches <span style="color:#f92672">=</span> face_recognition<span style="color:#f92672">.</span>compare_faces(self<span style="color:#f92672">.</span>faces, targetEncoding)
</span></span><span style="display:flex;"><span>        face_distances <span style="color:#f92672">=</span> face_recognition<span style="color:#f92672">.</span>face_distance(self<span style="color:#f92672">.</span>faces, targetEncoding)
</span></span><span style="display:flex;"><span>        best_match_index <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argmin(face_distances)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;最小距离： &#34;</span>,face_distances[best_match_index])
</span></span><span style="display:flex;"><span>        print(face_distances)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> matches[best_match_index]:
</span></span><span style="display:flex;"><span>            name <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>faceNames[best_match_index]
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> name
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">compareToDatabase</span>(self, unknown_face_encoding<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> self<span style="color:#f92672">.</span>is_running:
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>is_running <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>m_thread <span style="color:#f92672">=</span> Thread(target<span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_compareToDatabase )
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>m_thread<span style="color:#f92672">.</span>start()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_compareToDatabase</span>(self,originimage):
</span></span><span style="display:flex;"><span>        authenticated <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#imgdata = cv2.resize(originimage, (0, 0), fx=0.25, fy=0.25)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#imgdata=originimage</span>
</span></span><span style="display:flex;"><span>        small_frame <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>resize(originimage, (<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>), fx<span style="color:#f92672">=</span><span style="color:#ae81ff">0.25</span>, fy<span style="color:#f92672">=</span><span style="color:#ae81ff">0.25</span>)
</span></span><span style="display:flex;"><span>        rgb_small_frame <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>cvtColor(small_frame,cv2<span style="color:#f92672">.</span>COLOR_BGR2RGB)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        face_landmarks_list <span style="color:#f92672">=</span> face_recognition<span style="color:#f92672">.</span>face_landmarks(rgb_small_frame)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        face_locations <span style="color:#f92672">=</span> face_recognition<span style="color:#f92672">.</span>face_locations(rgb_small_frame, model<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;cnn&#34;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span>(len(face_locations)<span style="color:#f92672">&gt;</span><span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34;Unknown&#34;</span>
</span></span><span style="display:flex;"><span>        face_encoding <span style="color:#f92672">=</span> face_recognition<span style="color:#f92672">.</span>face_encodings(rgb_small_frame, face_locations)[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        print(type(self<span style="color:#f92672">.</span>faces),type(face_encoding))
</span></span><span style="display:flex;"><span>        matches <span style="color:#f92672">=</span> face_recognition<span style="color:#f92672">.</span>compare_faces(self<span style="color:#f92672">.</span>faces, face_encoding)
</span></span><span style="display:flex;"><span>        face_distances <span style="color:#f92672">=</span> face_recognition<span style="color:#f92672">.</span>face_distance(self<span style="color:#f92672">.</span>faces, face_encoding)
</span></span><span style="display:flex;"><span>        best_match_index <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argmin(face_distances)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#print(&#34;最小距离： &#34;,face_distances[best_match_index])</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#print(face_distances)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> matches[best_match_index]:
</span></span><span style="display:flex;"><span>            name <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>faceNames[best_match_index]
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;_compareToDataset&#34;</span>,name,face_locations)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> face_landmarks <span style="color:#f92672">in</span> face_landmarks_list:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> facial_feature <span style="color:#f92672">in</span> face_landmarks<span style="color:#f92672">.</span>keys():
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">for</span> pt_pos <span style="color:#f92672">in</span> face_landmarks[facial_feature]:
</span></span><span style="display:flex;"><span>                        cv2<span style="color:#f92672">.</span>circle(originimage, (pt_pos[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>,pt_pos[<span style="color:#ae81ff">1</span>]<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>), <span style="color:#ae81ff">1</span>, (<span style="color:#ae81ff">255</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>), <span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>                        cv2<span style="color:#f92672">.</span>circle(originimage, (pt_pos[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>,pt_pos[<span style="color:#ae81ff">1</span>]<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>), <span style="color:#ae81ff">5</span>, color<span style="color:#f92672">=</span>(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">255</span>, <span style="color:#ae81ff">0</span>))
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#process_this_frame = not process_this_frame</span>
</span></span><span style="display:flex;"><span>        top, right, bottom, left<span style="color:#f92672">=</span>face_locations[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>        top<span style="color:#f92672">=</span>top<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>
</span></span><span style="display:flex;"><span>        right<span style="color:#f92672">=</span>right<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>
</span></span><span style="display:flex;"><span>        bottom<span style="color:#f92672">=</span>bottom<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>
</span></span><span style="display:flex;"><span>        left<span style="color:#f92672">=</span>left<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Draw a box around the face</span>
</span></span><span style="display:flex;"><span>        cv2<span style="color:#f92672">.</span>rectangle(originimage, (left, top), (right, bottom), (<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">255</span>), <span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Draw a label with a name below the face</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#cv2.rectangle(originimage, (left-20, bottom - 60), (right+20, bottom+20), (0, 0, 255), cv2.FILLED)</span>
</span></span><span style="display:flex;"><span>        font <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>FONT_HERSHEY_DUPLEX
</span></span><span style="display:flex;"><span>        img_PIL <span style="color:#f92672">=</span> Image<span style="color:#f92672">.</span>fromarray(originimage)
</span></span><span style="display:flex;"><span>        font <span style="color:#f92672">=</span> ImageFont<span style="color:#f92672">.</span>truetype(<span style="color:#e6db74">&#39;../icons/方正康体简体.TTF&#39;</span>, <span style="color:#ae81ff">40</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 字体颜色</span>
</span></span><span style="display:flex;"><span>        fillColor <span style="color:#f92672">=</span> (<span style="color:#ae81ff">255</span>,<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 文字输出位置</span>
</span></span><span style="display:flex;"><span>        position <span style="color:#f92672">=</span> (left <span style="color:#f92672">-</span> <span style="color:#ae81ff">100</span>, bottom <span style="color:#f92672">-</span> <span style="color:#ae81ff">30</span>)
</span></span><span style="display:flex;"><span>        textinfo <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;欢迎</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">登录&#34;</span><span style="color:#f92672">.</span>format(name)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 需要先把输出的中文字符转换成Unicode编码形式</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> isinstance(textinfo, str):
</span></span><span style="display:flex;"><span>            textinfo <span style="color:#f92672">=</span> textinfo<span style="color:#f92672">.</span>decode(<span style="color:#e6db74">&#39;utf8&#39;</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>        draw <span style="color:#f92672">=</span> ImageDraw<span style="color:#f92672">.</span>Draw(img_PIL)
</span></span><span style="display:flex;"><span>        draw<span style="color:#f92672">.</span>text(position, textinfo, font<span style="color:#f92672">=</span>font, fill<span style="color:#f92672">=</span>fillColor)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 使用PIL中的save方法保存图片到本地</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># img_PIL.save(&#39;02.jpg&#39;, &#39;jpeg&#39;)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 转换回OpenCV格式</span>
</span></span><span style="display:flex;"><span>        originimage <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>cvtColor(np<span style="color:#f92672">.</span>asarray(img_PIL),cv2<span style="color:#f92672">.</span>COLOR_RGB2BGR)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>       <span style="color:#75715e"># cv2.putText(originimage,&#34;欢迎{}登录&#34;.format(name), (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)</span>
</span></span><span style="display:flex;"><span>        cv2<span style="color:#f92672">.</span>imwrite(<span style="color:#e6db74">&#34;tmp.png&#34;</span> , originimage)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#self.im_s.new_image.emit(&#34;.tmp.png&#34;)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Display the resulting image</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#cv2.imshow(&#39;Video&#39;, imgdata)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> originimage,name 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">removeFaceData</span>(self, face_name):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">pass</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">paint_chinese_opencv</span>(self,im,chinese,pos,color):
</span></span><span style="display:flex;"><span>        img_PIL <span style="color:#f92672">=</span> Image<span style="color:#f92672">.</span>fromarray(cv2<span style="color:#f92672">.</span>cvtColor(im,cv2<span style="color:#f92672">.</span>COLOR_BGR2RGB))
</span></span><span style="display:flex;"><span>        font <span style="color:#f92672">=</span> ImageFont<span style="color:#f92672">.</span>truetype(<span style="color:#e6db74">&#39;NotoSansCJK-Bold.ttc&#39;</span>,<span style="color:#ae81ff">25</span>)
</span></span><span style="display:flex;"><span>        fillColor <span style="color:#f92672">=</span> color <span style="color:#75715e">#(255,0,0)</span>
</span></span><span style="display:flex;"><span>        position <span style="color:#f92672">=</span> pos <span style="color:#75715e">#(100,100)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> isinstance(chinese,str):
</span></span><span style="display:flex;"><span>            chinese <span style="color:#f92672">=</span> chinese<span style="color:#f92672">.</span>decode(<span style="color:#e6db74">&#39;utf-8&#39;</span>)
</span></span><span style="display:flex;"><span>        draw <span style="color:#f92672">=</span> ImageDraw<span style="color:#f92672">.</span>Draw(img_PIL)
</span></span><span style="display:flex;"><span>        draw<span style="color:#f92672">.</span>text(position,chinese,font<span style="color:#f92672">=</span>font,fill<span style="color:#f92672">=</span>fillColor)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        img <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>cvtColor(np<span style="color:#f92672">.</span>asarray(img_PIL),cv2<span style="color:#f92672">.</span>COLOR_RGB2BGR)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> img
</span></span><span style="display:flex;"><span><span style="color:#75715e">#编写一个测试</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">functionTest</span>():
</span></span><span style="display:flex;"><span>    capture <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>VideoCapture(<span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>    faceServer<span style="color:#f92672">=</span>Face_Recognizer(<span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>    i<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;liudongdong&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">while</span> <span style="color:#66d9ef">True</span>:
</span></span><span style="display:flex;"><span>        ret, frame <span style="color:#f92672">=</span> capture<span style="color:#f92672">.</span>read()
</span></span><span style="display:flex;"><span>        frame <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>flip(frame,<span style="color:#ae81ff">1</span>)   <span style="color:#75715e">#镜像操作</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        key <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>waitKey(<span style="color:#ae81ff">50</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#print(key)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> key  <span style="color:#f92672">==</span> ord(<span style="color:#e6db74">&#39;q&#39;</span>):  <span style="color:#75715e">#判断是哪一个键按下</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> faceServer<span style="color:#f92672">.</span>faceRegister(frame,name):
</span></span><span style="display:flex;"><span>                print(<span style="color:#e6db74">&#34;人脸信息录入成功&#34;</span>)
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">else</span>: print(<span style="color:#e6db74">&#34;人脸信息录入失败&#34;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> key <span style="color:#f92672">==</span> ord(<span style="color:#e6db74">&#39;r&#39;</span>):
</span></span><span style="display:flex;"><span>            frame,name<span style="color:#f92672">=</span>faceServer<span style="color:#f92672">.</span>_compareToDatabase(frame)
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">&#34;识别名称，&#34;</span>,name)
</span></span><span style="display:flex;"><span>        cv2<span style="color:#f92672">.</span>imshow(<span style="color:#e6db74">&#34;video&#34;</span>, frame)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#cv2.imshow(&#39;Video&#39;, imgdata)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> key<span style="color:#f92672">==</span> ord(<span style="color:#e6db74">&#39;b&#39;</span>):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    cv2<span style="color:#f92672">.</span>destroyAllWindows()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;__main__&#39;</span>:
</span></span><span style="display:flex;"><span>    functionTest()
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># while i&lt;50:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#     i=i+1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#     ret, frame = video_capture.read()</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#     cv2.imshow(&#39;Video&#39;, frame)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#     if i&lt;10:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#         if faceServer.faceRegister(frame,name):</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#             print(&#34;人脸信息录入成功&#34;)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#         else: print(&#34;人脸信息录入失败&#34;)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#     else:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#         imgdata,name=faceServer._compareToDatabase(frame)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#         cv2.imshow(&#39;Video&#39;, imgdata)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#         print(&#34;识别姓名： name=&#34;,name)</span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;&#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">recognizer = Face_Recognizer()
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">recognizer.registerFace()
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">recognizer.saveFaceImage(&#39;Kareem&#39;)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;&#39;&#39;</span>
</span></span></code></pre></div><p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210723155206990.png"
    data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210723155206990.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210723155206990.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210723155206990.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210723155206990.png"
    title="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210723155206990.png"/></p>
<ul>
<li>检测图像中所有人脸</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># -*- coding: utf-8 -*-</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 检测人脸</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> face_recognition
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> cv2
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 读取图片并识别人脸</span>
</span></span><span style="display:flex;"><span>img <span style="color:#f92672">=</span> face_recognition<span style="color:#f92672">.</span>load_image_file(<span style="color:#e6db74">&#34;1.png&#34;</span>)
</span></span><span style="display:flex;"><span>face_locations <span style="color:#f92672">=</span> face_recognition<span style="color:#f92672">.</span>face_locations(img)
</span></span><span style="display:flex;"><span>print (face_locations)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 调用opencv函数显示图片</span>
</span></span><span style="display:flex;"><span>img <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>imread(<span style="color:#e6db74">&#34;1.png&#34;</span>)
</span></span><span style="display:flex;"><span>cv2<span style="color:#f92672">.</span>namedWindow(<span style="color:#e6db74">&#34;原图&#34;</span>)
</span></span><span style="display:flex;"><span>cv2<span style="color:#f92672">.</span>imshow(<span style="color:#e6db74">&#34;原图&#34;</span>, img)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 遍历每个人脸，并标注</span>
</span></span><span style="display:flex;"><span>faceNum <span style="color:#f92672">=</span> len(face_locations)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">0</span>, faceNum):
</span></span><span style="display:flex;"><span>    top <span style="color:#f92672">=</span>  face_locations[i][<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>    right <span style="color:#f92672">=</span>  face_locations[i][<span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>    bottom <span style="color:#f92672">=</span> face_locations[i][<span style="color:#ae81ff">2</span>]
</span></span><span style="display:flex;"><span>    left <span style="color:#f92672">=</span> face_locations[i][<span style="color:#ae81ff">3</span>]
</span></span><span style="display:flex;"><span>    start <span style="color:#f92672">=</span> (left, top)
</span></span><span style="display:flex;"><span>    end <span style="color:#f92672">=</span> (right, bottom)
</span></span><span style="display:flex;"><span>    color <span style="color:#f92672">=</span> (<span style="color:#ae81ff">55</span>,<span style="color:#ae81ff">255</span>,<span style="color:#ae81ff">155</span>)
</span></span><span style="display:flex;"><span>    thickness <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>    cv2<span style="color:#f92672">.</span>rectangle(img, start, end, color, thickness)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 显示识别结果</span>
</span></span><span style="display:flex;"><span>cv2<span style="color:#f92672">.</span>namedWindow(<span style="color:#e6db74">&#34;识别&#34;</span>)
</span></span><span style="display:flex;"><span>cv2<span style="color:#f92672">.</span>imshow(<span style="color:#e6db74">&#34;识别&#34;</span>, img)
</span></span><span style="display:flex;"><span>cv2<span style="color:#f92672">.</span>waitKey(<span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>cv2<span style="color:#f92672">.</span>destroyAllWindows()
</span></span></code></pre></div><ul>
<li>人脸匹配</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 导入库</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> face_recognition
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 制作所有可用图像的列表</span>
</span></span><span style="display:flex;"><span>images <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>listdir(<span style="color:#e6db74">&#39;images&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 加载图像</span>
</span></span><span style="display:flex;"><span>image_to_be_matched <span style="color:#f92672">=</span> face_recognition<span style="color:#f92672">.</span>load_image_file(<span style="color:#e6db74">&#39;my_image.jpg&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 将加载图像编码为特征向量</span>
</span></span><span style="display:flex;"><span>image_to_be_matched_encoded <span style="color:#f92672">=</span> face_recognition<span style="color:#f92672">.</span>face_encodings(
</span></span><span style="display:flex;"><span>   image_to_be_matched)[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 遍历每张图像</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> image <span style="color:#f92672">in</span> images:
</span></span><span style="display:flex;"><span>   <span style="color:#75715e"># 加载图像</span>
</span></span><span style="display:flex;"><span>   current_image <span style="color:#f92672">=</span> face_recognition<span style="color:#f92672">.</span>load_image_file(<span style="color:#e6db74">&#34;images/&#34;</span> <span style="color:#f92672">+</span> image)
</span></span><span style="display:flex;"><span>   <span style="color:#75715e"># 将加载图像编码为特征向量</span>
</span></span><span style="display:flex;"><span>   current_image_encoded <span style="color:#f92672">=</span> face_recognition<span style="color:#f92672">.</span>face_encodings(current_image)[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>   <span style="color:#75715e"># 将你的图像和图像对比，看是否为同一人</span>
</span></span><span style="display:flex;"><span>   result <span style="color:#f92672">=</span> face_recognition<span style="color:#f92672">.</span>compare_faces(
</span></span><span style="display:flex;"><span>       [image_to_be_matched_encoded], current_image_encoded)
</span></span><span style="display:flex;"><span>   <span style="color:#75715e"># 检查是否一致</span>
</span></span><span style="display:flex;"><span>   <span style="color:#66d9ef">if</span> result[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">==</span> <span style="color:#66d9ef">True</span>:
</span></span><span style="display:flex;"><span>       print (<span style="color:#e6db74">&#34;Matched: &#34;</span> <span style="color:#f92672">+</span> image)
</span></span><span style="display:flex;"><span>   <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>       print (<span style="color:#e6db74">&#34;Not matched: &#34;</span> <span style="color:#f92672">+</span> image)
</span></span></code></pre></div><ul>
<li>检测标记人脸特征</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># -*- coding: utf-8 -*-</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 自动识别人脸特征</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> PIL <span style="color:#f92672">import</span> Image, ImageDraw
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> face_recognition
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 将jpg文件加载到numpy 数组中</span>
</span></span><span style="display:flex;"><span>image <span style="color:#f92672">=</span> face_recognition<span style="color:#f92672">.</span>load_image_file(<span style="color:#e6db74">&#34;my_image.jpg&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e">#查找图像中所有面部的所有面部特征</span>
</span></span><span style="display:flex;"><span>face_landmarks_list <span style="color:#f92672">=</span> face_recognition<span style="color:#f92672">.</span>face_landmarks(image)
</span></span><span style="display:flex;"><span><span style="color:#75715e">#打印发现的脸张数</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;I found </span><span style="color:#e6db74">{}</span><span style="color:#e6db74"> face(s) in this photograph.&#34;</span><span style="color:#f92672">.</span>format(len(face_landmarks_list)))
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> face_landmarks <span style="color:#f92672">in</span> face_landmarks_list:
</span></span><span style="display:flex;"><span>   <span style="color:#75715e">#打印此图像中每个面部特征的位置</span>
</span></span><span style="display:flex;"><span>    facial_features <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;chin&#39;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;left_eyebrow&#39;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;right_eyebrow&#39;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;nose_bridge&#39;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;nose_tip&#39;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;left_eye&#39;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;right_eye&#39;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;top_lip&#39;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;bottom_lip&#39;</span>
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> facial_feature <span style="color:#f92672">in</span> facial_features:
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;The </span><span style="color:#e6db74">{}</span><span style="color:#e6db74"> in this face has the following points: </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format(facial_feature, face_landmarks[facial_feature]))
</span></span><span style="display:flex;"><span>   <span style="color:#75715e">#让我们在图像中描绘出每个人脸特征！</span>
</span></span><span style="display:flex;"><span>    pil_image <span style="color:#f92672">=</span> Image<span style="color:#f92672">.</span>fromarray(image)
</span></span><span style="display:flex;"><span>    d <span style="color:#f92672">=</span> ImageDraw<span style="color:#f92672">.</span>Draw(pil_image)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> facial_feature <span style="color:#f92672">in</span> facial_features:
</span></span><span style="display:flex;"><span>        d<span style="color:#f92672">.</span>line(face_landmarks[facial_feature], width<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>    pil_image<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><h3 id="45-insightfacehttpsgithubcomdeepinsightinsightface">4.5. <a href="https://github.com/deepinsight/insightface"target="_blank" rel="external nofollow noopener noreferrer">InsightFace<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></h3>
<blockquote>
<p>InsightFace is an open source 2D&amp;3D deep face analysis toolbox, mainly based on MXNet. This module can help researcher/engineer to <code>develop deep face recognition algorithms quickly by only two steps</code>: <code>download the binary dataset and run the training script</code>.</p>
</blockquote>
<ul>
<li>Face Detection</li>
</ul>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219111717005.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219111717005.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219111717005.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219111717005.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219111717005.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219111717005.png"/></p>
<h3 id="46-seetaface6httpsgithubcomtensorflowerseetaface6python">4.6. <a href="https://github.com/tensorflower/seetaFace6Python"target="_blank" rel="external nofollow noopener noreferrer">SeetaFace6<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#类似face_recognition 库，可以快捷使用</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#人脸检测</span>
</span></span><span style="display:flex;"><span>FACE_DETECT <span style="color:#f92672">=</span> <span style="color:#ae81ff">0x00000001</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#人脸跟踪</span>
</span></span><span style="display:flex;"><span>FACE_TRACK <span style="color:#f92672">=</span> <span style="color:#ae81ff">0x00000002</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#人脸识别（特征提取）</span>
</span></span><span style="display:flex;"><span>FACERECOGNITION <span style="color:#f92672">=</span> <span style="color:#ae81ff">0x00000004</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#rgb活体检测</span>
</span></span><span style="display:flex;"><span>LIVENESS <span style="color:#f92672">=</span> <span style="color:#ae81ff">0x00000008</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#人脸5点关键点检测</span>
</span></span><span style="display:flex;"><span>LANDMARKER5 <span style="color:#f92672">=</span> <span style="color:#ae81ff">0x00000010</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#人脸68点关键点检测</span>
</span></span><span style="display:flex;"><span>LANDMARKER68 <span style="color:#f92672">=</span> <span style="color:#ae81ff">0x00000020</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#带遮挡识别的人脸5点关键点检测</span>
</span></span><span style="display:flex;"><span>LANDMARKER_MASK <span style="color:#f92672">=</span> <span style="color:#ae81ff">0x00000040</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#人脸姿态角度方向评估</span>
</span></span><span style="display:flex;"><span>FACE_POSE_EX <span style="color:#f92672">=</span> <span style="color:#ae81ff">0x00000080</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#性别识别</span>
</span></span><span style="display:flex;"><span>FACE_GENDER <span style="color:#f92672">=</span> <span style="color:#ae81ff">0x00000100</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#年龄识别</span>
</span></span><span style="display:flex;"><span>FACE_AGE <span style="color:#f92672">=</span> <span style="color:#ae81ff">0x00000200</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">Predict</span>(self, frame: np<span style="color:#f92672">.</span>array, face: SeetaRect,
</span></span><span style="display:flex;"><span>                   points: List[SeetaPointF]) <span style="color:#f92672">-&gt;</span> int:
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        单帧rgb活体检测
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        :param frame: 原始图像
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        :param face: 人脸区域
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        :param points:  人脸关键点位置
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        :return:  活体检测结果
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        0:真实人脸
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        1:攻击人脸（假人脸）
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        2:无法判断（人脸成像质量不好）
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>check_init(LIVENESS)
</span></span><span style="display:flex;"><span>        seetaImageData <span style="color:#f92672">=</span> get_seetaImageData_by_numpy(frame)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>_Predict(seetaImageData, face, points)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">compare_feature_np</span>(self, feature1: np<span style="color:#f92672">.</span>array, feature2: np<span style="color:#f92672">.</span>array) <span style="color:#f92672">-&gt;</span> float:
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        使用numpy 计算，比较人脸特征值相似度
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">       :param feature1: 人脸特征值1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        :param feature2: 人脸特征值2
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        :return: 人脸相似度
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        dot <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sum(np<span style="color:#f92672">.</span>multiply(feature1, feature2))
</span></span><span style="display:flex;"><span>        norm <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linalg<span style="color:#f92672">.</span>norm(feature1) <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>linalg<span style="color:#f92672">.</span>norm(feature2)
</span></span><span style="display:flex;"><span>        dist <span style="color:#f92672">=</span> dot <span style="color:#f92672">/</span> norm
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> float(dist)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">PredictAge</span>(self,frame: np<span style="color:#f92672">.</span>array) <span style="color:#f92672">-&gt;</span> int:
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        检测一张只有人脸的图片,识别出年龄
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        :param frame: 原图
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        :param face: 人脸检测框
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        :param points: 人脸关键点
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        :return: 年龄大小
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>check_init(FACE_AGE)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> frame<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">!=</span><span style="color:#ae81ff">256</span> <span style="color:#f92672">or</span> frame<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>]<span style="color:#f92672">!=</span><span style="color:#ae81ff">256</span>:
</span></span><span style="display:flex;"><span>            seetaImageData <span style="color:#f92672">=</span> get_seetaImageData_by_numpy(cv2<span style="color:#f92672">.</span>resize(frame,(<span style="color:#ae81ff">256</span>,<span style="color:#ae81ff">256</span>)))
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            seetaImageData <span style="color:#f92672">=</span> get_seetaImageData_by_numpy(frame)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>_PredictAge(seetaImageData)
</span></span></code></pre></div><h3 id="47-ultra-light-generic-face-detectorhttpsgithubcomlinzaerultra-light-fast-generic-face-detector-1mb">4.7. <a href="https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB"target="_blank" rel="external nofollow noopener noreferrer">Ultra-Light-Generic-Face-Detector<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></h3>
<blockquote>
<ul>
<li><i class="fa-regular fa-square fa-fw" aria-hidden="true"></i> <a href="https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB/tree/master/widerface_evaluate"target="_blank" rel="external nofollow noopener noreferrer">Widerface test code<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><i class="fa-regular fa-square fa-fw" aria-hidden="true"></i> <a href="https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB/tree/master/ncnn"target="_blank" rel="external nofollow noopener noreferrer">NCNN C++ inference code<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> (<a href="https://github.com/vealocia"target="_blank" rel="external nofollow noopener noreferrer">vealocia<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>)</li>
<li><i class="fa-regular fa-square fa-fw" aria-hidden="true"></i> <a href="https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB/tree/master/MNN"target="_blank" rel="external nofollow noopener noreferrer">MNN C++ inference code<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>, <a href="https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB/tree/master/MNN/python"target="_blank" rel="external nofollow noopener noreferrer">MNN Python inference code<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><i class="fa-regular fa-square fa-fw" aria-hidden="true"></i> <a href="https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB/tree/master/caffe/model"target="_blank" rel="external nofollow noopener noreferrer">Caffe model<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> and <a href="https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB/tree/master/caffe"target="_blank" rel="external nofollow noopener noreferrer">onnx2caffe conversion code<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><i class="fa-regular fa-square fa-fw" aria-hidden="true"></i> <a href="https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB/blob/master/caffe/ultra_face_caffe_inference.py"target="_blank" rel="external nofollow noopener noreferrer">Caffe python inference code<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> and <a href="https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB/blob/master/caffe/ultra_face_opencvdnn_inference.py"target="_blank" rel="external nofollow noopener noreferrer">OpencvDNN inference code<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><i class="fa-regular fa-square fa-fw" aria-hidden="true"></i> 如果要使用的话，可以学习这个项目源代码</li>
</ul>
</blockquote>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/20210324090933.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/20210324090933.png, https://gitee.com/github-25970295/blogImage/raw/master/img/20210324090933.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/20210324090933.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/20210324090933.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/20210324090933.png"/></p>
<h3 id="48-comprefacehttpsgithubcomexadel-inccompreface">4.8. <a href="https://github.com/exadel-inc/CompreFace"target="_blank" rel="external nofollow noopener noreferrer">CompreFace<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></h3>
<blockquote>
<p>CompreFace provides <code>REST API</code> for <code>face recognition</code>, <code>face verification</code>, <code>face detection</code>, <code>landmark detection</code>, <code>age</code>, and <code>gender recognition</code>. The solution also features a <code>role management system</code> that allows you to easily control who has access to your Face Recognition Services.</p>
</blockquote>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210611170456149.png"
    data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210611170456149.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210611170456149.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210611170456149.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210611170456149.png"
    title="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210611170456149.png"/></p>
<h3 id="49-tfacehttpsgithubcomtencenttface">4.9. <a href="https://github.com/Tencent/TFace"target="_blank" rel="external nofollow noopener noreferrer">TFace<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></h3>
<blockquote>
<p>基于可信人脸识别的理念，TFace重点关注人脸识别领域的四个研究方向：精准、公平、可解释以及隐私。</p>
</blockquote>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210625104637590.png"
    data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210625104637590.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210625104637590.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210625104637590.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210625104637590.png"
    title="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210625104637590.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210625104702814.png"
    data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210625104702814.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210625104702814.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210625104702814.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210625104702814.png"
    title="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210625104702814.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210625104719037.png"
    data-srcset="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210625104719037.png, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210625104719037.png 1.5x, https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210625104719037.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210625104719037.png"
    title="https://gitee.com/github-25970295/blogpictureV2/raw/master/image-20210625104719037.png"/></p>
<ul>
<li><strong><a href="https://arxiv.org/abs/2004.00288"target="_blank" rel="external nofollow noopener noreferrer">CurricularFace<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></strong> 一种用于人脸识别基础模型训练的损失函数，发表于CVPR2020， 主要的思路是将课程学习的思想结合到常用的人脸识别损失函数，训练过程中自动挖掘困难样本，先易后难渐进学习，提升识别模型训练鲁棒性及难样本识别性能。</li>
<li><strong><a href="https://arxiv.org/abs/2002.03662"target="_blank" rel="external nofollow noopener noreferrer">DDL<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></strong> 一种用于提升特定场景下人脸识别性能的方法，发表于ECCV2020，主要的思路是针对某一特定场景的难样本，为其寻找一个合适的教师场景，通过拉近两种场景下的人脸相似度分布，从而提升该场景下困难样本的识别性能。</li>
<li><strong><a href="https://arxiv.org/abs/2106.05519"target="_blank" rel="external nofollow noopener noreferrer">CIFP<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></strong> 一种提升个体识别公平性的方法，发表于CVPR2021, 提出了基于误报率惩罚的损失函数，即通过增加实例误报率（FPR）的一致性来减轻人脸识别偏差。</li>
<li><strong><a href="https://arxiv.org/abs/2103.05977"target="_blank" rel="external nofollow noopener noreferrer">SDD-FIQA<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></strong> 一种基于人脸识别相似度分布的无监督人脸质量评估方法，发表于CVPR2021, 通过计算同人和非同人相似度分布的韦氏距离作为目标图像的质量分伪标签， 最终通过图像+质量伪标签训练得到质量分模型。</li>
<li><strong><a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Spherical_Confidence_Learning_for_Face_Recognition_CVPR_2021_paper.pdf"target="_blank" rel="external nofollow noopener noreferrer">SCF<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></strong> 一种基于人脸特征置信度的人脸识别方法，发表于CVPR2021, 核心思想包含两点：a. 将人脸样本特征从确定向量升级为概率分布，从而获得额外刻画样本识别置信度的能力；b. 提出适配于超球流形r-radius von Mises Fisher分布建模特征，理论可解释性与方法收敛性较PFE更佳。</li>
</ul>
<h2 id="5-facesearching">5. FaceSearching</h2>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124037238.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124037238.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124037238.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124037238.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124037238.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124037238.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219112540276.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219112540276.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219112540276.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219112540276.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219112540276.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219112540276.png"/></p>
<ol>
<li>单机由于内存和CPU性能限制，能够支持的人脸检索数始终都有上限，所以必须进行集群设计来提高容量。</li>
<li>10亿级别的人脸库存储是一个问题，按每张图片50K的大小都会是TB级别了。</li>
<li>10亿级别人脸库建模需要很长时间。</li>
<li>10亿级别人脸库检索响应时间能否做到秒级。</li>
<li>10亿级别人脸库检索TPS能到多少。</li>
</ol>
<h3 id="50-基于gpu优化的检索方案">5.0. 基于GPU优化的检索方案</h3>
<blockquote>
<p><strong>数据并行+模型并行</strong>： 首先是数据并行，每个GPU上去预测它自己的数据batch，得到人脸特征，然后对特征进行一个多机汇总，得到完整的F。同时，我们把参数矩阵W均匀拆分到多机不同的显卡上，比如第一个GPU负责计算每张图属于第1-10万类的概率，下一GPU负责第10万到20万类，这样依次进行。可考虑使用浮点运算能力更高的GPU来实现.</p>
</blockquote>
<h3 id="51-分布式人脸检索系统框图">5.1. <strong>分布式人脸检索系统框图</strong></h3>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219113002358.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219113002358.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219113002358.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219113002358.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219113002358.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219113002358.png"/></p>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219123840814.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219123840814.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219123840814.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219123840814.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219123840814.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219123840814.png"/></p>
<h3 id="52-人脸动态库方案">5.2. <strong>人脸动态库方案</strong></h3>
<blockquote>
<p>在内部验证阶段，使用单机存储固定特征个数（可能是一千万个）的特征库，每个特征对应记录ID、时间戳、摄像机编号等信息。每天新增的特征形成一个单独的小特征库，每天定时把小特征库合并到大特征库，并把大特征库中最旧的同量特征删除，保持特征库的大小。在检索时先对全库进行1:N，根据阈值过滤出部分记录后，再抽取对应记录的额外信息，与页面检索条件进行匹配，返回结果。</p>
</blockquote>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124313646.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124313646.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124313646.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124313646.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124313646.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124313646.png"/></p>
<h3 id="53--es分布式人脸检索方案">5.3.  ES分布式人脸检索方案</h3>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124437959.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124437959.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124437959.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124437959.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124437959.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124437959.png"/></p>
<h3 id="54-基于rocksdb的分布式特征索引方案">5.4. 基于RocksDB的分布式特征索引方案</h3>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124854164.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124854164.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124854164.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124854164.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124854164.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219124854164.png"/></p>
<h3 id="55--基于小特征加速比对的检索方案">5.5.  基于小特征加速比对的检索方案</h3>
<p><img
    class="lazyload"
    src="/svg/loading.min.svg"
    data-src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219125047175.png"
    data-srcset="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219125047175.png, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219125047175.png 1.5x, https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219125047175.png 2x"
    data-sizes="auto"
    alt="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219125047175.png"
    title="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20201219125047175.png"/></p>
<h2 id="6-数据集学习链接">6. 数据集&amp;学习链接</h2>
<ul>
<li>
<p><a href="https://dataware.cc/tag/%E4%BA%BA%E8%84%B8%E6%95%B0%E6%8D%AE%E9%9B%86/"target="_blank" rel="external nofollow noopener noreferrer">人脸数据集<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</li>
<li>
<p><a href="https://blog.csdn.net/yimin_tank/article/details/82703121"target="_blank" rel="external nofollow noopener noreferrer">分布式检索<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/vugfNwlH8a7uOIpmhg2Nig"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/vugfNwlH8a7uOIpmhg2Nig<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</li>
<li>
<p><a href="https://zhuanlan.zhihu.com/p/35968767"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/35968767<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</li>
<li>
<p><a href="https://segmentfault.com/a/1190000019224111"target="_blank" rel="external nofollow noopener noreferrer">人脸检索方案<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</li>
</ul>
<blockquote>
<p>cv2.imread() 读取图片数据为空的问题：</p>
<p>im = cv2.imdecode(np.fromfile(file,dtype=np.uint8),-1)   使用该函数代替即可解决问题。</p>
</blockquote>
</div>
<div class="post-footer" id="post-footer">
  <div class="post-info">
    <div class="post-info-line">
      <div class="post-info-mod">
        <span title=2023-09-28&#32;22:42:10>更新于 2023-09-28&nbsp;</span>
      </div><div class="post-info-license">
          <span><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span>
        </div></div>
    <div class="post-info-line">
      <div class="post-info-md"><span><a href="/facerecognition/index.md" title="阅读原始文档" class="link-to-markdown">阅读原始文档</a></span><span><a href="https://liudongdong1.github.io/edit/master/content/posts%5c%e8%a7%86%e8%a7%89%e8%bf%90%e5%8a%a8%5cFaceRecognition%5cFaceRecognition.md" title="编辑此页"target="_blank" rel="external nofollow noopener noreferrer" class="link-to-edit">编辑此页</a></span></div>
      <div class="post-info-share">
        <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="https://liudongdong1.github.io/facerecognition/" data-title="FaceRecognition" data-hashtags="FaceRecognition"><i class="fa-brands fa-twitter fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="https://liudongdong1.github.io/facerecognition/" data-hashtag="FaceRecognition"><i class="fa-brands fa-facebook-square fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="https://liudongdong1.github.io/facerecognition/" data-title="FaceRecognition" data-image="https://gitee.com/github-25970295/blogImage/raw/master/img/laptop-notebook-working-outside.jpg"><i class="fa-brands fa-weibo fa-fw" aria-hidden="true"></i></a>
  </span>
      </div>
    </div>
  </div>

  <div class="post-info-more">
    <section class="post-tags"><i class="fa-solid fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/facerecognition/">FaceRecognition</a></section>
    <section>
      <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
    </section>
  </div>

  <div class="post-nav"><a href="/faiss/" class="prev" rel="prev" title="Faiss"><i class="fa-solid fa-angle-left fa-fw" aria-hidden="true"></i>Faiss</a>
      <a href="/examplesdl4j/" class="next" rel="next" title="ExamplesDL4J">ExamplesDL4J<i class="fa-solid fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article></main><footer class="footer">
    <div class="footer-container"><div class="footer-line powered">由 <a href="https://gohugo.io/" target="_blank" rel="external nofollow noopener noreferrer" title="Hugo 0.118.2">Hugo</a> 强力驱动 | 主题 - <a href="https://github.com/hugo-fixit/FixIt" target="_blank" rel="external" title="FixIt v0.2.17-RC"><img class="fixit-icon" src="/fixit.min.svg" alt="FixIt logo" />&nbsp;FixIt</a>
        </div><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">2020 - 2023</span><span class="author" itemprop="copyrightHolder">
              <a href="https://liudongdong1.github.io/"target="_blank" rel="external nofollow noopener noreferrer">LiuDongdong</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div><div class="footer-line statistics"><span class="site-time" title='网站运行中 ...'><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden="true"></i>&nbsp;<span class="run-times">网站运行中 ...</span></span></div><div class="footer-line ibruce">
          <span id="busuanzi_container_site_uv" title='总访客数'><i class="fa-regular fa-user fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span><span id="busuanzi_container_site_pv" class="footer-divider" title='总访问量'><i class="fa-regular fa-eye fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span>
        </div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="回到顶部"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric">0%</span>
        </div></div><a href="https://liudongdong1.github.io/" title="在 GitHub 上查看源代码"target="_blank" rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><div id="mask"></div><div class="reading-progress-bar" style="left: 0;top: 0;--bg-progress: #0076ff;--bg-progress-dark: #fff;"></div><noscript>
    <div class="noscript-warning">FixIt 主题在启用 JavaScript 的情况下效果最佳。</div>
  </noscript>
</div><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script src="/lib/autocomplete/autocomplete.min.js" defer></script><script src="/lib/algoliasearch/algoliasearch-lite.umd.min.js" defer></script><script src="/lib/lazysizes/lazysizes.min.js" async defer></script><script src="/lib/sharer/sharer.min.js" async defer></script><script src="/lib/typeit/index.umd.js" defer></script><script src="/lib/katex/katex.min.js" defer></script><script src="/lib/katex/auto-render.min.js" defer></script><script src="/lib/katex/copy-tex.min.js" defer></script><script src="/lib/katex/mhchem.min.js" defer></script><script src="/lib/cookieconsent/cookieconsent.min.js" defer></script><script src="/lib/pangu/pangu.min.js" defer></script><script src="/lib/cell-watermark/watermark.min.js" defer></script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async defer></script><script>window.config={"code":{"copyTitle":"复制到剪贴板","editLockTitle":"锁定可编辑代码块","editUnLockTitle":"解锁可编辑代码块","editable":true,"maxShownLines":10},"comment":{"enable":false},"cookieconsent":{"content":{"dismiss":"同意","link":"了解更多","message":"本网站使用 Cookies 来改善您的浏览体验。"},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"data":{"typeit-header-subtitle-desktop":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e","typeit-header-subtitle-mobile":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e"},"enablePWA":true,"enablePangu":true,"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"2R1K9SKLQZ","algoliaIndex":"index.zh-cn","algoliaSearchKey":"4a226aa1c5c98d6859e4d1386adb2bc7","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"},"siteTime":"2020-12-18T16:15:22+08:00","typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"typeit-header-subtitle-desktop":["typeit-header-subtitle-desktop"],"typeit-header-subtitle-mobile":["typeit-header-subtitle-mobile"]},"duration":-1,"speed":100},"watermark":{"appendto":".wrapper\u003emain","colspacing":30,"content":"\u003cimg class=\"fixit-icon\" src=\"/fixit.min.svg\" alt=\"FixIt logo\" /\u003e FixIt 主题","enable":true,"fontfamily":"inherit","fontsize":0.85,"height":21,"opacity":0.0125,"rotate":15,"rowspacing":60,"width":150}};</script><script src="/js/theme.min.js" defer></script><script src="/js/custom.min.js" defer></script></body>
</html>
