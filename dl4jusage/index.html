<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <head>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>DL4J - DAY By DAY</title><meta name="author" content="LiuDongdong">
<meta name="author-link" content="https://liudongdong1.github.io/">
<meta name="description" content="Eclipse Deeplearning4j is the first commercial-grade, open-source, distributed deep-learning library written for Java and Scala. Integrated with Hadoop and Apache Spark, DL4J brings AI to business environments for use on distributed GPUs and CPUs.
1. DataPrepare Deeplearning4j works with a lot of different data types, such as images, CSV, plain text, images, audio, video and, pretty much any other data type you can think of.
.1. RecordReader .2. DataSetIterator ScoreIterationListener - (Source, Javadoc) - Logs the loss function score every N training iterations PerformanceListener - (Source, Javadoc) - Logs performance (examples per sec, minibatches per sec, ETL time), and optionally score, every N training iterations." /><meta name="keywords" content='Model, Java' /><meta itemprop="name" content="DL4J">
<meta itemprop="description" content="Eclipse Deeplearning4j is the first commercial-grade, open-source, distributed deep-learning library written for Java and Scala. Integrated with Hadoop and Apache Spark, DL4J brings AI to business environments for use on distributed GPUs and CPUs.
1. DataPrepare Deeplearning4j works with a lot of different data types, such as images, CSV, plain text, images, audio, video and, pretty much any other data type you can think of.
.1. RecordReader .2. DataSetIterator ScoreIterationListener - (Source, Javadoc) - Logs the loss function score every N training iterations PerformanceListener - (Source, Javadoc) - Logs performance (examples per sec, minibatches per sec, ETL time), and optionally score, every N training iterations.">
<meta itemprop="dateModified" content="2023-09-28T22:55:05+08:00" />
<meta itemprop="wordCount" content="3092"><meta itemprop="image" content="/logo.png"/>
<meta itemprop="keywords" content="Model,Java," /><meta property="og:title" content="DL4J" />
<meta property="og:description" content="Eclipse Deeplearning4j is the first commercial-grade, open-source, distributed deep-learning library written for Java and Scala. Integrated with Hadoop and Apache Spark, DL4J brings AI to business environments for use on distributed GPUs and CPUs.
1. DataPrepare Deeplearning4j works with a lot of different data types, such as images, CSV, plain text, images, audio, video and, pretty much any other data type you can think of.
.1. RecordReader .2. DataSetIterator ScoreIterationListener - (Source, Javadoc) - Logs the loss function score every N training iterations PerformanceListener - (Source, Javadoc) - Logs performance (examples per sec, minibatches per sec, ETL time), and optionally score, every N training iterations." />
<meta property="og:type" content="article" />
<meta property="og:url" content="liudongdong1.github.io/dl4jusage/" /><meta property="og:image" content="/logo.png"/><meta property="article:section" content="posts" />

<meta property="article:modified_time" content="2023-09-28T22:55:05+08:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="/logo.png"/>

<meta name="twitter:title" content="DL4J"/>
<meta name="twitter:description" content="Eclipse Deeplearning4j is the first commercial-grade, open-source, distributed deep-learning library written for Java and Scala. Integrated with Hadoop and Apache Spark, DL4J brings AI to business environments for use on distributed GPUs and CPUs.
1. DataPrepare Deeplearning4j works with a lot of different data types, such as images, CSV, plain text, images, audio, video and, pretty much any other data type you can think of.
.1. RecordReader .2. DataSetIterator ScoreIterationListener - (Source, Javadoc) - Logs the loss function score every N training iterations PerformanceListener - (Source, Javadoc) - Logs performance (examples per sec, minibatches per sec, ETL time), and optionally score, every N training iterations."/>
<meta name="application-name" content="DAY By DAY">
<meta name="apple-mobile-web-app-title" content="DAY By DAY"><meta name="theme-color" data-light="#f8f8f8" data-dark="#252627" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="liudongdong1.github.io/dl4jusage/" /><link rel="prev" href="liudongdong1.github.io/dropout/" /><link rel="next" href="liudongdong1.github.io/dimstransfor/" /><link rel="stylesheet" href="/liudongdong1.github.io/css/style.min.css"><link rel="stylesheet" href="/liudongdong1.github.io/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/liudongdong1.github.io/lib/animate/animate.min.css"><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "DL4J",
    "inLanguage": "zh-CN",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "liudongdong1.github.io\/dl4jusage\/"
    },"genre": "posts","keywords": "Model, Java","wordcount":  3092 ,
    "url": "liudongdong1.github.io\/dl4jusage\/","dateModified": "2023-09-28T22:55:05+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
      "@type": "Organization",
      "name": "LiuDongdong","logo": "\/images\/person.png"},"author": {
        "@type": "Person",
        "name": "liudongdong1"
      },"description": ""
  }
  </script></head>
  <body data-header-desktop="auto" data-header-mobile="auto"><script>(window.localStorage?.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('data-theme', 'dark');</script><div class="wrapper"><header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper" data-github-corner="right">
    <div class="header-title">
      <a href="liudongdong1.github.io/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="DAY By DAY"
    title="DAY By DAY"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-desktop" class="typeit header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/posts/"
                
                
              ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/categories/"
                
                
              ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/tags/"
                
                
              ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/friends/"
                title="友情链接"
                
              ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/liudongdong1.github.io/about/"
                
                
              ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li class="menu-item delimiter"></li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <ul class="sub-menu"><li class="menu-item">没有更多翻译</li></ul>
          </li><li class="menu-item search" id="search-desktop">
            <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-desktop">
            <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
              <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
            </a>
            <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
              <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
            </a>
            <span class="search-button search-loading" id="search-loading-desktop">
              <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
            </span>
          </li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li>
      </ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="liudongdong1.github.io/" title="DAY By DAY"><img
    class="lazyload logo"
    src="/liudongdong1.github.io/svg/loading.min.svg"
    data-src="/fixit.min.svg"
    data-srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x"
    data-sizes="auto"
    alt="/fixit.min.svg"
    title="/fixit.min.svg"/><span class="header-title-text"></span></a><span id="typeit-header-subtitle-mobile" class="typeit header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li class="search-wrapper">
            <div class="search mobile" id="search-mobile">
              <input type="text" placeholder="搜索文章标题或内容 ..." id="search-input-mobile">
              <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                <i class="fa-solid fa-search fa-fw" aria-hidden="true"></i>
              </a>
              <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                <i class="fa-solid fa-times-circle fa-fw" aria-hidden="true"></i>
              </a>
              <span class="search-button search-loading" id="search-loading-mobile">
                <i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
              </span>
            </div>
            <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
              取消
            </a>
          </li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/posts/"
                  
                  
                ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 所有文章</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/categories/"
                  
                  
                ><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden="true"></i> 分类</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/tags/"
                  
                  
                ><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> 标签</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/friends/"
                  title="友情链接"
                  
                ><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden="true"></i> 友链</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/liudongdong1.github.io/about/"
                  
                  
                ><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden="true"></i> 关于</a></li><li
              class="menu-item text-center"
            ><a
                  class="menu-link"
                  href="https://liudongdong1.github.io/"
                  title="GitHub"
                  rel="noopener noreferrer" target="_blank"
                ><i class='fa-brands fa-github fa-fw' aria-hidden='true'></i> </a></li><li class="menu-item theme-switch" title="切换主题">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li><li class="menu-item language">
            <span role="button" aria-label="选择语言" title="选择语言">简体中文<i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden="true"></i>
            </span>
            <select class="language-select" onchange="location = this.value;"><option disabled>没有更多翻译</option></select>
          </li></ul>
    </nav>
  </div>
</header><div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
  </div>
  <div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
  </div><main class="container" data-page-style="normal"><aside class="toc" id="toc-auto"><h2 class="toc-title">目录 <i class="toc-icon fa-solid fa-angle-down fa-fw"></i></h2>
      <div class="toc-content" id="toc-content-auto"></div></aside>

  <aside class="aside-custom" id="aside-sakana">
    

<div class="sakana-widget">
  <div class="sakana-item" id="takina-widget"></div>
  <div class="sakana-item" id="chisato-widget"></div>
</div>
<script>
  function initSakanaWidget() {
    const takina = SakanaWidget.getCharacter('takina')
    SakanaWidget.registerCharacter('takina-slow', takina);
    new SakanaWidget({
      character: 'takina-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#takina-widget');

    const chisato = SakanaWidget.getCharacter('chisato')
    SakanaWidget.registerCharacter('chisato-slow', chisato);
    new SakanaWidget({
      character: 'chisato-slow',
      controls: false,
      autoFit: true,
      stroke: {
        color: "#b4b4b4",
        width: 2
      }
    }).mount('#chisato-widget');
  }
</script>
<script async onload="initSakanaWidget()" src="https://cdn.jsdelivr.net/npm/sakana-widget@2.3.0/lib/sakana.min.js">
</script></aside>

  <article class="page single">
    <div class="header"><h1 class="single-title animate__animated animate__flipInX">
        <span>DL4J</span>
      </h1></div><div class="post-meta">
      <div class="post-meta-line"><span class="post-author"><span class="author"><i class="fa-solid fa-user-circle" aria-hidden="true"></i>
      liudongdong1</span></span>
          <span class="post-category">收录于 <a href="liudongdong1.github.io/categories/ai/"><i class="fa-regular fa-folder fa-fw"></i>&nbsp;AI</a></span></div>
      <div class="post-meta-line"><span title=0001-01-01&#32;00:00:00>
            <i class="fa-regular fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="0001-01-01" >0001-01-01</time>
          </span>&nbsp;<i class="fa-solid fa-pencil-alt fa-fw"></i>&nbsp;约 3092 字&nbsp;
        <i class="fa-regular fa-clock fa-fw"></i>&nbsp;预计阅读 15 分钟&nbsp;<span id="busuanzi_container_page_pv" class="busuanzi_visitors comment-visitors" data-flag-title="DL4J">
            <i class="fa-regular fa-eye fa-fw"></i>&nbsp;<span id="busuanzi_value_page_pv">-</span>&nbsp;次阅读
          </span>&nbsp;</div>
    </div><div class="details toc" id="toc-static" kept="true">
        <div class="details-summary toc-title">
          <span>目录</span>
          <span><i class="details-icon fa-solid fa-angle-right"></i></span>
        </div>
        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#1-dataprepare">1. DataPrepare</a></li>
        <li><a href="#2-datasetload">2. DatasetLoad</a></li>
        <li><a href="#3-modelhttpsdeeplearning4jkonduitaimodel-zoooverview">3. <a href="https://deeplearning4j.konduit.ai/model-zoo/overview">Model</a></a></li>
        <li><a href="#4-train">4. Train</a></li>
        <li><a href="#5-evaluate">5. Evaluate</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
      </div><div
      class="content"
      id="content"
      
      
    ><blockquote>
<p><a href="https://deeplearning4j.konduit.ai/getting-started/cheat-sheet"target="_blank" rel="external nofollow noopener noreferrer">Eclipse Deeplearning4j<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> is the first <code>commercial-grade</code>, <code>open-source</code>, <code>distributed deep-learning library</code> written for Java and Scala.<code> Integrated with Hadoop and Apache Spark</code>, DL4J brings AI to business environments for use on distributed GPUs and CPUs.</p>
</blockquote>
<h3 id="1-dataprepare">1. DataPrepare</h3>
<blockquote>
<p>Deeplearning4j works with a lot of different data types, such as images, CSV, plain text, images, audio, video and, pretty much any other data type you can think of.</p>
</blockquote>
<h4 id="1-recordreader">.1. RecordReader</h4>
<h4 id="2-datasetiterator">.2. DataSetIterator</h4>
<ul>
<li><strong>ScoreIterationListener</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/optimize/listeners/ScoreIterationListener.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>, Javadoc) - <code>Logs the loss function score every N training iterations</code></li>
<li><strong>PerformanceListener</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/optimize/listeners/PerformanceListener.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>, Javadoc) - Logs performance (examples<code> per sec, minibatches per sec, ETL time), and optionally score, every N training iterations.</code></li>
<li><strong>EvaluativeListener</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/optimize/listeners/EvaluativeListener.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>, Javadoc) - Evaluates network performance on a test set every N iterations or epochs. Also has a system for callbacks, to (for example) save the evaluation results.</li>
<li><strong>CheckpointListener</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/optimize/listeners/CheckpointListener.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>, Javadoc) - S<code>ave network checkpoints periodically - based on epochs, iterations or time (or some combination of all three).</code></li>
<li><strong>StatsListener</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-ui-parent/deeplearning4j-ui-model/src/main/java/org/deeplearning4j/ui/stats/StatsListener.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Main listener for DL4J&rsquo;s web-based network training user interface. See <a href="">visualization page</a> for more details.</li>
<li><strong>CollectScoresIterationListener</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/optimize/listeners/CollectScoresIterationListener.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>, Javadoc) - Similar to ScoreIterationListener, but stores scores internally in a list (for later retrieval) instead of logging scores</li>
<li><strong>TimeIterationListener</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/optimize/listeners/TimeIterationListener.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>, Javadoc) - Attempts to estimate time until training completion, based on current speed and specified total number of iterations</li>
</ul>
<h3 id="2-datasetload">2. DatasetLoad</h3>
<h4 id="1-dataset">.1. DataSet</h4>
<h4 id="2-indarray">.2. INDArray</h4>
<h3 id="3-modelhttpsdeeplearning4jkonduitaimodel-zoooverview">3. <a href="https://deeplearning4j.konduit.ai/model-zoo/overview"target="_blank" rel="external nofollow noopener noreferrer">Model<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></h3>
<ul>
<li><strong>AlexNet</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/AlexNet.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>)</li>
<li><strong>Darknet19</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/Darknet19.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>)</li>
<li><strong>FaceNetNN4Small2</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/FaceNetNN4Small2.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>)</li>
<li><strong>InceptionResNetV1</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/InceptionResNetV1.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>)</li>
<li><strong>LeNet</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/LeNet.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>)</li>
<li><strong>ResNet50</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/ResNet50.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>)</li>
<li><strong>SimpleCNN</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/SimpleCNN.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>)</li>
<li><strong>TextGenerationLSTM</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/TextGenerationLSTM.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>)</li>
<li><strong>TinyYOLO</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/TinyYOLO.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>)</li>
<li><strong>VGG16</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/VGG16.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>)</li>
<li><strong>VGG19</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/VGG19.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>)</li>
</ul>
<h4 id="1-layers">1. Layers</h4>
<h5 id="1-feed-forward-layers">.1. <a href="">Feed-Forward Layers</a></h5>
<ul>
<li><strong>DenseLayer</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/layers/feedforward/dense/DenseLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - A simple/standard <code>fully-connected layer</code></li>
<li><strong>EmbeddingLayer</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/layers/feedforward/embedding/EmbeddingLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Takes <code>positive integer indexes as input</code>, <code>outputs vectors</code>. Only usable as first layer in a model. Mathematically equivalent (when bias is enabled) to DenseLayer with one-hot input, but more efficient. See also: EmbeddingSequenceLayer.</li>
</ul>
<h5 id="2-output-layers">.2. <a href="">Output Layers</a></h5>
<ul>
<li><strong>OutputLayer</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/OutputLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Output layer for <code>standard classification/regression in MLPs/CNNs.</code> Has a fully connected DenseLayer built in. 2d input/output (i.e.,<code> row vector per example</code>).</li>
<li><strong>LossLayer</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/LossLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Output layer <code>without parameters - only loss function and activation function</code>. 2d input/output (i.e., row vector per example). Unlike Outputlayer, restricted to n In = n Out.</li>
<li><strong>RnnOutputLayer</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/RnnOutputLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Output layer for recurrent neural networks. <code>3d (time series) input and output.</code> Has time distributed fully connected layer built in.</li>
<li><strong>RnnLossLayer</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/RnnLossLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - The &rsquo;no parameter&rsquo; version of RnnOutputLayer. 3d (time series) input and output.</li>
<li><strong>CnnLossLayer</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/CnnLossLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Used with CNNs, where a prediction must be made at each spatial location of the output (for example: segmentation or denoising).<code> No parameters, 4d input/output with shape [minibatch, depth, height, width]. ``When using softmax, this is applied depthwise at each spatial location.</code></li>
<li><strong>Cnn3DLossLayer</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/Cnn3DLossLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - used with 3D CNNs, where a preduction must be made at each spatial location (x/y/z) of the output. Layer has no parameters, 5d data in either NCDHW or NDHWC (&ldquo;channels first&rdquo; or &ldquo;channels last&rdquo;) format (configurable). Supports masking. When using Softmax, this is applied along channels at each spatial location.</li>
<li><strong>Yolo2OutputLayer</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/objdetect/Yolo2OutputLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Implentation of the<code> YOLO 2 model for object detection in images</code></li>
<li><strong>CenterLossOutputLayer</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/CenterLossOutputLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - A version of OutputLayer that also<code> attempts to minimize the intra-class distance of examples' activations</code> - i.e., &ldquo;If example x is in class Y, ensure that embedding(x) is close to average(embedding(y)) for all examples y in Y&rdquo;</li>
</ul>
<h5 id="3-convolutional-layers">.3. <a href="">Convolutional Layers</a></h5>
<ul>
<li><strong>ConvolutionLayer</strong> / Convolution2D - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/ConvolutionLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Standard 2d convolutional neural network layer.<code> Inputs and outputs have 4 dimensions with shape [minibatch,depthIn,heightIn,widthIn] and [minibatch,depthOut,heightOut,widthOut] respectively.</code></li>
<li><strong>Convolution1DLayer</strong> / Convolution1D - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/Convolution1DLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Standard 1d convolution layer</li>
<li><strong>Convolution3DLayer</strong> / Convolution3D - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/Convolution3D.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Standard 3D convolution layer. Supports both <code>NDHWC (&quot;channels last&quot;)</code> and <code>NCDHW (&quot;channels first&quot;)</code> activations format.</li>
<li><strong>Deconvolution2DLayer</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/layers/convolution/Deconvolution2DLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - also known as transpose or fractionally strided convolutions. Can be considered a &ldquo;reversed&rdquo; ConvolutionLayer; output size is generally larger than the input, whilst maintaining the spatial connection structure.</li>
<li><strong>SeparableConvolution2DLayer</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/layers/convolution/SeparableConvolution2DLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - <code>depthwise separable convolution layer</code></li>
<li><strong>SubsamplingLayer</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/layers/convolution/subsampling/SubsamplingLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Implements standard<code> 2d spatial pooling for CNNs - with max, average and p-norm pooling available.</code></li>
<li><strong>Subsampling1DLayer</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/Subsampling1DLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - 1D version of the subsampling layer.</li>
<li><strong>Upsampling2D</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/layers/convolution/upsampling/Upsampling2D.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Upscale CNN activations by repeating the row/column values</li>
<li><strong>Upsampling1D</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/layers/convolution/upsampling/Upsampling1D.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - 1D version of the upsampling layer</li>
<li><strong>Cropping2D</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/convolutional/Cropping2D.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) -<code> Cropping layer for 2D convolutional neural networks</code></li>
<li><strong>DepthwiseConvolution2D</strong> (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/DepthwiseConvolution2D.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>)- 2d depthwise convolution layer</li>
<li><strong>ZeroPaddingLayer</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/layers/convolution/ZeroPaddingLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Very simple layer that <code>adds the specified amount of zero padding to edges of the 4d input activations.</code></li>
<li><strong>ZeroPadding1DLayer</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/layers/convolution/ZeroPadding1DLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - 1D version of ZeroPaddingLayer</li>
<li><strong>SpaceToDepth</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/SpaceToDepthLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - This operation <code>takes 4D array in, and moves data from spatial dimensions (HW) to channels (C) for given blockSize</code></li>
<li><strong>SpaceToBatch</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/SpaceToBatchLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Transforms data from a tensor from 2 spatial dimensions into batch dimension according to the &ldquo;blocks&rdquo; specified</li>
</ul>
<h5 id="4-recurrent-layers">.4. <a href="">Recurrent Layers</a></h5>
<ul>
<li><strong>LSTM</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/LSTM.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - LSTM RNN without peephole connections. Supports CuDNN.</li>
<li><strong>GravesLSTM</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/GravesLSTM.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - LSTM RNN with peephole connections. Does <em>not</em> support CuDNN (thus for GPUs, LSTM should be used in preference).</li>
<li><strong>GravesBidirectionalLSTM</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/GravesBidirectionalLSTM.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - A bidirectional LSTM implementation with peephole connections. Equivalent to Bidirectional(ADD, GravesLSTM). Due to addition of Bidirecitonal wrapper (below), has been deprecated on master.</li>
<li><strong>Bidirectional</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/recurrent/Bidirectional.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - A &lsquo;wrapper&rsquo; layer - converts any standard uni-directional RNN into a bidirectional RNN (doubles number of params - forward/backward nets have independent parameters). Activations from forward/backward nets may be either added, multiplied, averaged or concatenated.</li>
<li><strong>SimpleRnn</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/recurrent/SimpleRnn.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - A standard/&lsquo;vanilla&rsquo; RNN layer. Usually not effective in practice with long time series dependencies - LSTM is generally preferred.</li>
<li><strong>LastTimeStep</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/recurrent/LastTimeStep.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - A &lsquo;wrapper&rsquo; layer - extracts out the last time step of the (non-bidirectional) RNN layer it wraps. 3d input with shape [minibatch, size, timeSeriesLength], 2d output with shape [minibatch, size].</li>
<li>EmbeddingSequenceLayer: (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/EmbeddingSequenceLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - A version of EmbeddingLayer that expects fixed-length number (inputLength) of integers/indices per example as input, ranged from 0 to numClasses - 1. This input thus has shape [numExamples, inputLength] or shape [numExamples, 1, inputLength]. The output of this layer is 3D (sequence/time series), namely of shape [numExamples, nOut, inputLength]. Can only be used as the first layer for a network.</li>
</ul>
<h5 id="5-unsupervised-layers">.5. <a href="">Unsupervised Layers</a></h5>
<ul>
<li><strong>VariationalAutoencoder</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/variational/VariationalAutoencoder.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - A variational autoencoder implementation with MLP/dense layers for the encoder and decoder. Supports multiple different types of <a href="https://github.com/eclipse/deeplearning4j/tree/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/variational"target="_blank" rel="external nofollow noopener noreferrer">reconstruction distributions<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><strong>AutoEncoder</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/AutoEncoder.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - <code>Standard denoising autoencoder layer</code></li>
</ul>
<h5 id="6-other-layers">.6. <a href="">Other Layers</a></h5>
<ul>
<li><strong>GlobalPoolingLayer</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/GlobalPoolingLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Implements both pooling over time (for RNNs/time series - input size [minibatch, size, timeSeriesLength], out [minibatch, size]) and global spatial pooling (for CNNs - input size [minibatch, depth, h, w], out [minibatch, depth]). Available pooling modes: sum, average, max and p-norm.</li>
<li><strong>ActivationLayer</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/ActivationLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Applies an activation function (only) to the input activations. Note that most DL4J layers have activation functions built in as a config option.</li>
<li><strong>DropoutLayer</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/DropoutLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Implements dropout as a separate/single layer. Note that most DL4J layers have a &ldquo;built-in&rdquo; dropout configuration option.</li>
<li><strong>BatchNormalization</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/BatchNormalization.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Batch normalization for 2d (feedforward), 3d (time series) or 4d (CNN) activations. For time series, parameter sharing across time; for CNNs, parameter sharing across spatial locations (but not depth).</li>
<li><strong>LocalResponseNormalization</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/LocalResponseNormalization.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Local response normalization layer for CNNs. Not frequently used in modern CNN architectures.</li>
<li><strong>FrozenLayer</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/misc/FrozenLayer.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Usually not used directly by users - added as part of transfer learning, to freeze a layer&rsquo;s parameters such that they don&rsquo;t change during further training.</li>
<li><strong>LocallyConnected2D</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/LocallyConnected2D.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - a 2d locally connected layer, assumes input is 4d data in NCHW (&ldquo;channels first&rdquo;) format.</li>
<li><strong>LocallyConected1D</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/LocallyConnected1D.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - a 1d locally connected layer, assumes input is 3d data in NCW ([minibatch, size, sequenceLength]) format</li>
</ul>
<h5 id="7-graph-vertices">.7. <a href="">Graph Vertices</a></h5>
<ul>
<li><strong>ElementWiseVertex</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/graph/ElementWiseVertex.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Performs an element-wise operation on the inputs - add, subtract, product, average, max</li>
<li><strong>L2NormalizeVertex</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/graph/L2NormalizeVertex.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - normalizes the input activations by dividing by the L2 norm for each example. i.e., out &lt;- out / l2Norm(out)</li>
<li><strong>L2Vertex</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/graph/L2Vertex.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - calculates the L2 distance between the two input arrays, for each example separately. Output is a single value, for each input value.</li>
<li><strong>MergeVertex</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/graph/L2Vertex.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - merge the input activations along dimension 1, to make a larger output array. For CNNs, this implements merging along the depth/channels dimension</li>
<li><strong>PreprocessorVertex</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/graph/PreprocessorVertex.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - a simple GraphVertex that contains an InputPreProcessor only</li>
<li><strong>ReshapeVertex</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/graph/ReshapeVertex.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Performs arbitrary activation array reshaping. The preprocessors in the next section should usually be preferred.</li>
<li><strong>ScaleVertex</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/graph/ScaleVertex.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - implements simple multiplicative scaling of the inputs - i.e., out = scalar * input</li>
<li><strong>ShiftVertex</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/graph/ShiftVertex.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - implements simple scalar element-wise addition on the inputs - i.e., out = input + scalar</li>
<li><strong>StackVertex</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/graph/StackVertex.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - used to stack all inputs along the minibatch dimension. Analogous to MergeVertex, but along dimension 0 (minibatch) instead of dimension 1 (nOut/channels)</li>
<li><strong>SubsetVertex</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/graph/SubsetVertex.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - used to get a contiguous subset of the input activations along dimension 1. For example, two SubsetVertex instances could be used to split the activations from an input array into two separate activations. Essentially the opposite of MergeVertex.</li>
<li><strong>UnstackVertex</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/graph/UnstackVertex.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - similar to SubsetVertex, but along dimension 0 (minibatch) instead of dimension 1 (nOut/channels). Opposite of StackVertex</li>
</ul>
<h5 id="8-inputpreprocessors">.8. <a href="">InputPreProcessors</a></h5>
<ul>
<li><strong>CnnToFeedForwardPreProcessor</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/preprocessor/CnnToFeedForwardPreProcessor.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - handles the activation reshaping necessary to <code>transition from a CNN layer (ConvolutionLayer, SubsamplingLayer, etc) to DenseLayer/OutputLayer etc</code>.</li>
<li><strong>CnnToRnnPreProcessor</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/preprocessor/CnnToRnnPreProcessor.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - handles reshaping necessary to transition from a (effectively, time distributed) CNN layer to a RNN layer.</li>
<li><strong>ComposableInputPreProcessor</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/preprocessor/ComposableInputPreProcessor.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - simple class that allows <code>multiple preprocessors to be chained + used on a single layer</code></li>
<li><strong>FeedForwardToCnnPreProcessor</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/preprocessor/FeedForwardToCnnPreProcessor.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - handles activation reshaping to transition <code>from a row vector (per example) to a CNN layer.</code> Note that this transition/preprocessor only makes sense if the activations are actually CNN activations, but have been &lsquo;flattened&rsquo; to a row vector.</li>
<li><strong>FeedForwardToRnnPreProcessor</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/preprocessor/FeedForwardToRnnPreProcessor.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - handles transition from <code>a (time distributed) feed-forward layer to a RNN layer</code></li>
<li><strong>RnnToCnnPreProcessor</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/preprocessor/RnnToCnnPreProcessor.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - handles transition from a sequence of CNN activations with shape <code>[minibatch, depth*height*width, timeSeriesLength]</code> to time-distributed <code>[numExamples*timeSeriesLength, numChannels, inputWidth, inputHeight]</code> format</li>
<li><strong>RnnToFeedForwardPreProcessor</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/preprocessor/RnnToFeedForwardPreProcessor.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - handles transition from time series activations (shape <code>[minibatch,size,timeSeriesLength]</code>) to time-distributed feed-forward (shape <code>[minibatch*tsLength,size]</code>) activations.</li>
</ul>
<h4 id="2-configurations">2. Configurations</h4>
<h5 id="1-activation">.1. Activation</h5>
<blockquote>
<p>Activation functions can be defined in one of two ways: (a) By passing an <a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/activations/Activation.java"target="_blank" rel="external nofollow noopener noreferrer">Activation<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> enumeration value to the configuration - for example, <code>.activation(Activation.TANH)</code> (b) By passing an <a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/activations/IActivation.java"target="_blank" rel="external nofollow noopener noreferrer">IActivation<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> instance - for example, <code>.activation(new ActivationSigmoid())</code></p>
</blockquote>
<ul>
<li><strong>CUBE</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/activations/impl/ActivationCube.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - <code>f(x) = x^3</code></li>
<li><strong>ELU</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/activations/impl/ActivationELU.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Exponential linear unit (<a href="https://arxiv.org/abs/1511.07289"target="_blank" rel="external nofollow noopener noreferrer">Reference<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>)</li>
<li><strong>HARDSIGMOID</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/activations/impl/ActivationHardSigmoid.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - a piecewise linear version of the standard sigmoid activation function. <code>f(x) = min(1, max(0, 0.2*x + 0.5))</code></li>
<li><strong>HARDTANH</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/activations/impl/ActivationHardTanH.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - a piecewise linear version of the standard tanh activation function.</li>
<li><strong>IDENTITY</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/activations/impl/ActivationIdentity.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - a &rsquo;no op&rsquo; activation function: <code>f(x) = x</code></li>
<li><strong>LEAKYRELU</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/activations/impl/ActivationLReLU.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - leaky rectified linear unit. <code>f(x) = max(0, x) + alpha * min(0, x)</code> with <code>alpha=0.01</code> by default.</li>
<li><strong>RATIONALTANH</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/activations/impl/ActivationRationalTanh.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - <code>tanh(y) ~ sgn(y) * { 1 - 1/(1+|y|+y^2+1.41645*y^4)}</code> which approximates <code>f(x) = 1.7159 * tanh(2x/3)</code>, but should be faster to execute. (<a href="https://arxiv.org/abs/1508.01292"target="_blank" rel="external nofollow noopener noreferrer">Reference<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>)</li>
<li><strong>RELU</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/activations/impl/ActivationReLU.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - standard rectified linear unit: <code>f(x) = x</code> if <code>x&gt;0</code> or <code>f(x) = 0</code> otherwise</li>
<li><strong>RRELU</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/activations/impl/ActivationRReLU.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - randomized rectified linear unit. Deterministic during test time. (<a href="https://arxiv.org/abs/1505.00853"target="_blank" rel="external nofollow noopener noreferrer">Reference<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>)</li>
<li><strong>SIGMOID</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/activations/impl/ActivationSigmoid.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - standard sigmoid activation function, <code>f(x) = 1 / (1 + exp(-x))</code></li>
<li><strong>SOFTMAX</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/activations/impl/ActivationSoftmax.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - standard softmax activation function</li>
<li><strong>SOFTPLUS</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/activations/impl/ActivationSoftPlus.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - <code>f(x) = log(1+e^x)</code> - shape is similar to a smooth version of the RELU activation function</li>
<li><strong>SOFTSIGN</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/activations/impl/ActivationSoftSign.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - <code>f(x) = x / (1+|x|)</code> - somewhat similar in shape to the standard tanh activation function (faster to calculate).</li>
<li><strong>TANH</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/activations/impl/ActivationTanH.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - standard tanh (hyperbolic tangent) activation function</li>
<li><strong>RECTIFIEDTANH</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/activations/impl/ActivationRectifiedTanh.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - <code>f(x) = max(0, tanh(x))</code></li>
<li><strong>SELU</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/activations/impl/ActivationSELU.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - scaled exponential linear unit - used with <a href="https://arxiv.org/abs/1706.02515"target="_blank" rel="external nofollow noopener noreferrer">self normalizing neural networks<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><strong>SWISH</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/activations/impl/ActivationSwish.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Swish activation function, <code>f(x) = x * sigmoid(x)</code> (<a href="https://arxiv.org/abs/1710.05941"target="_blank" rel="external nofollow noopener noreferrer">Reference<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>)</li>
</ul>
<h5 id="2-weight-initialization">.2. Weight Initialization</h5>
<blockquote>
<ul>
<li>
<p>Weight initialization are usually defined using the <a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/weights/WeightInit.java"target="_blank" rel="external nofollow noopener noreferrer">WeightInit<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> enumeration.</p>
</li>
<li>
<p>Custom weight initializations can be specified using <code>.weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0, 1))</code> for example. As for master (but not 0.9.1 release) <code>.weightInit(new NormalDistribution(0, 1))</code> is also possible, which is equivalent to the previous approach.</p>
</li>
</ul>
</blockquote>
<ul>
<li><strong>DISTRIBUTION</strong>: Sample weights from a provided distribution (specified via <code>dist</code> configuration method</li>
<li><strong>ZERO</strong>: Generate weights as zeros</li>
<li><strong>ONES</strong>: All weights are set to 1</li>
<li><strong>SIGMOID_UNIFORM</strong>: A version of XAVIER_UNIFORM for sigmoid activation functions. U(-r,r) with r=4*sqrt(6/(fanIn + fanOut))</li>
<li><strong>NORMAL</strong>: Normal/Gaussian distribution, with mean 0 and standard deviation 1/sqrt(fanIn). This is the initialization recommented in <a href="https://arxiv.org/abs/1706.02515"target="_blank" rel="external nofollow noopener noreferrer">Klambauer et al. 2017, &ldquo;Self-Normalizing Neural Network&rdquo;<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> paper. Equivalent to DL4J&rsquo;s XAVIER_FAN_IN and LECUN_NORMAL (i.e. Keras&rsquo; &ldquo;lecun_normal&rdquo;)</li>
<li><strong>LECUN_UNIFORM</strong>: Uniform U[-a,a] with a=3/sqrt(fanIn).</li>
<li><strong>UNIFORM</strong>: Uniform U[-a,a] with a=1/sqrt(fanIn). &ldquo;Commonly used heuristic&rdquo; as per Glorot and Bengio 2010</li>
<li><strong>XAVIER</strong>: As per <a href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf"target="_blank" rel="external nofollow noopener noreferrer">Glorot and Bengio 2010<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>: Gaussian distribution with mean 0, variance 2.0/(fanIn + fanOut)</li>
<li><strong>XAVIER_UNIFORM</strong>: As per <a href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf"target="_blank" rel="external nofollow noopener noreferrer">Glorot and Bengio 2010<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>: Uniform distribution U(-s,s) with s = sqrt(6/(fanIn + fanOut))</li>
<li><strong>XAVIER_FAN_IN</strong>: Similar to Xavier, but 1/fanIn -&gt; Caffe originally used this.</li>
<li><strong>RELU</strong>: <a href="https://arxiv.org/abs/1502.01852"target="_blank" rel="external nofollow noopener noreferrer">He et al. (2015), &ldquo;Delving Deep into Rectifiers&rdquo;<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>. Normal distribution with variance 2.0/nIn</li>
<li><strong>RELU_UNIFORM</strong>: <a href="https://arxiv.org/abs/1502.01852"target="_blank" rel="external nofollow noopener noreferrer">He et al. (2015), &ldquo;Delving Deep into Rectifiers&rdquo;<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>. Uniform distribution U(-s,s) with s = sqrt(6/fanIn)</li>
<li><strong>IDENTITY</strong>: Weights are set to an identity matrix. Note: can only be used with square weight matrices</li>
<li><strong>VAR_SCALING_NORMAL_FAN_IN</strong>: Gaussian distribution with mean 0, variance 1.0/(fanIn)</li>
<li><strong>VAR_SCALING_NORMAL_FAN_OUT</strong>: Gaussian distribution with mean 0, variance 1.0/(fanOut)</li>
<li><strong>VAR_SCALING_NORMAL_FAN_AVG</strong>: Gaussian distribution with mean 0, variance 1.0/((fanIn + fanOut)/2)</li>
<li><strong>VAR_SCALING_UNIFORM_FAN_IN</strong>: Uniform U[-a,a] with a=3.0/(fanIn)</li>
<li><strong>VAR_SCALING_UNIFORM_FAN_OUT</strong>: Uniform U[-a,a] with a=3.0/(fanOut)</li>
<li><strong>VAR_SCALING_UNIFORM_FAN_AVG</strong>: Uniform U[-a,a] with a=3.0/((fanIn + fanOut)/2)</li>
</ul>
<h4 id="3-updaters">3. Updaters</h4>
<ul>
<li><strong>AdaDelta</strong> - (<a href="https://github.com/eclipse/deeplearning4j/tree/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/learning/config/AdaDelta.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - <a href="https://arxiv.org/abs/1212.5701"target="_blank" rel="external nofollow noopener noreferrer">Reference<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><strong>AdaGrad</strong> - (<a href="https://github.com/eclipse/deeplearning4j/tree/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/learning/config/AdaGrad.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - <a href="http://jmlr.org/papers/v12/duchi11a.html"target="_blank" rel="external nofollow noopener noreferrer">Reference<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><strong>AdaMax</strong> - (<a href="https://github.com/eclipse/deeplearning4j/tree/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/learning/config/AdaMax.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - A variant of the Adam updater - <a href="https://arxiv.org/abs/1412.6980"target="_blank" rel="external nofollow noopener noreferrer">Reference<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><strong>Adam</strong> - (<a href="https://github.com/eclipse/deeplearning4j/tree/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/learning/config/Adam.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>)</li>
<li><strong>Nadam</strong> - (<a href="https://github.com/eclipse/deeplearning4j/tree/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/learning/config/Nadam.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - A variant of the Adam updater, using the Nesterov mementum update rule - <a href="https://arxiv.org/abs/1609.04747"target="_blank" rel="external nofollow noopener noreferrer">Reference<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><strong>Nesterovs</strong> - (<a href="https://github.com/eclipse/deeplearning4j/tree/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/learning/config/Nesterovs.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Nesterov momentum updater</li>
<li><strong>NoOp</strong> - (<a href="https://github.com/eclipse/deeplearning4j/tree/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/learning/config/NoOp.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - A &rsquo;no operation&rsquo; updater. That is, gradients are not modified at all by this updater. Mathematically equivalent to the SGD updater with a learning rate of 1.0</li>
<li><strong>RmsProp</strong> - (<a href="https://github.com/eclipse/deeplearning4j/tree/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/learning/config/RmsProp.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - <a href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf"target="_blank" rel="external nofollow noopener noreferrer">Reference - slide 29<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><strong>Sgd</strong> - (<a href="https://github.com/eclipse/deeplearning4j/tree/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/learning/config/Sgd.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Standard stochastic gradient descent updater. This updater applies a learning rate only.</li>
</ul>
<h4 id="4-learning-rate-schedules">4. Learning Rate Schedules</h4>
<ul>
<li><strong>ExponentialSchedule</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/schedule/ExponentialSchedule.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Implements <code>value(i) = initialValue * gamma^i</code></li>
<li><strong>InverseSchedule</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/schedule/InverseSchedule.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Implements <code>value(i) = initialValue * (1 + gamma * i)^(-power)</code></li>
<li><strong>MapSchedule</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/schedule/MapSchedule.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Learning rate schedule based on a user-provided map. Note that the provided map must have a value for iteration/epoch 0. Has a builder class to conveniently define a schedule.</li>
<li><strong>PolySchedule</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/schedule/PolySchedule.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Implements <code>value(i) = initialValue * (1 + i/maxIter)^(-power)</code></li>
<li><strong>SigmoidSchedule</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/schedule/SigmoidSchedule.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Implements <code>value(i) = initialValue * 1.0 / (1 + exp(-gamma * (iter - stepSize)))</code></li>
<li><strong>StepSchedule</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/schedule/StepSchedule.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Implements <code>value(i) = initialValue * gamma^( floor(iter/step) )</code></li>
</ul>
<p>SaveLoad</p>
<ul>
<li><code>MultiLayerNetwork.save(File)</code> and <code>MultiLayerNetwork.load(File)</code>;</li>
<li>using the <a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/util/ModelSerializer.java"target="_blank" rel="external nofollow noopener noreferrer">ModelSerializer<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> class;</li>
</ul>
<h4 id="5-example">5. Example</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-java" data-lang="java"><span style="display:flex;"><span>MultiLayerConfiguration conf <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> NeuralNetConfiguration<span style="color:#f92672">.</span><span style="color:#a6e22e">Builder</span><span style="color:#f92672">()</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">seed</span><span style="color:#f92672">(</span>1234<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// parameters below are copied to every layer in the network
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// for inputs like dropOut() or activation() you should do this per layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// only specify the parameters you need
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">updater</span><span style="color:#f92672">(</span><span style="color:#66d9ef">new</span> AdaGrad<span style="color:#f92672">())</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">activation</span><span style="color:#f92672">(</span>Activation<span style="color:#f92672">.</span><span style="color:#a6e22e">RELU</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">dropOut</span><span style="color:#f92672">(</span>0<span style="color:#f92672">.</span><span style="color:#a6e22e">8</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">l1</span><span style="color:#f92672">(</span>0<span style="color:#f92672">.</span><span style="color:#a6e22e">001</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">l2</span><span style="color:#f92672">(</span>1e<span style="color:#f92672">-</span>4<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">weightInit</span><span style="color:#f92672">(</span>WeightInit<span style="color:#f92672">.</span><span style="color:#a6e22e">XAVIER</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">weightInit</span><span style="color:#f92672">(</span>Distribution<span style="color:#f92672">.</span><span style="color:#a6e22e">TruncatedNormalDistribution</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">cudnnAlgoMode</span><span style="color:#f92672">(</span>ConvolutionLayer<span style="color:#f92672">.</span><span style="color:#a6e22e">AlgoMode</span><span style="color:#f92672">.</span><span style="color:#a6e22e">PREFER_FASTEST</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">gradientNormalization</span><span style="color:#f92672">(</span>GradientNormalization<span style="color:#f92672">.</span><span style="color:#a6e22e">RenormalizeL2PerLayer</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">gradientNormalizationThreshold</span><span style="color:#f92672">(</span>1e<span style="color:#f92672">-</span>3<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">list</span><span style="color:#f92672">()</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// layers in the network, added sequentially
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// parameters set per-layer override the parameters above
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">layer</span><span style="color:#f92672">(</span><span style="color:#66d9ef">new</span> DenseLayer<span style="color:#f92672">.</span><span style="color:#a6e22e">Builder</span><span style="color:#f92672">().</span><span style="color:#a6e22e">nIn</span><span style="color:#f92672">(</span>numInputs<span style="color:#f92672">).</span><span style="color:#a6e22e">nOut</span><span style="color:#f92672">(</span>numHiddenNodes<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">.</span><span style="color:#a6e22e">weightInit</span><span style="color:#f92672">(</span>WeightInit<span style="color:#f92672">.</span><span style="color:#a6e22e">XAVIER</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">.</span><span style="color:#a6e22e">build</span><span style="color:#f92672">())</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">layer</span><span style="color:#f92672">(</span><span style="color:#66d9ef">new</span> ActivationLayer<span style="color:#f92672">(</span>Activation<span style="color:#f92672">.</span><span style="color:#a6e22e">RELU</span><span style="color:#f92672">))</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">layer</span><span style="color:#f92672">(</span><span style="color:#66d9ef">new</span> ConvolutionLayer<span style="color:#f92672">.</span><span style="color:#a6e22e">Builder</span><span style="color:#f92672">(</span>1<span style="color:#f92672">,</span>1<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">.</span><span style="color:#a6e22e">nIn</span><span style="color:#f92672">(</span>1024<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">.</span><span style="color:#a6e22e">nOut</span><span style="color:#f92672">(</span>2048<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">.</span><span style="color:#a6e22e">stride</span><span style="color:#f92672">(</span>1<span style="color:#f92672">,</span>1<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">.</span><span style="color:#a6e22e">convolutionMode</span><span style="color:#f92672">(</span>ConvolutionMode<span style="color:#f92672">.</span><span style="color:#a6e22e">Same</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">.</span><span style="color:#a6e22e">weightInit</span><span style="color:#f92672">(</span>WeightInit<span style="color:#f92672">.</span><span style="color:#a6e22e">XAVIER</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">.</span><span style="color:#a6e22e">activation</span><span style="color:#f92672">(</span>Activation<span style="color:#f92672">.</span><span style="color:#a6e22e">IDENTITY</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">.</span><span style="color:#a6e22e">build</span><span style="color:#f92672">())</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">layer</span><span style="color:#f92672">(</span><span style="color:#66d9ef">new</span> GravesLSTM<span style="color:#f92672">.</span><span style="color:#a6e22e">Builder</span><span style="color:#f92672">()</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">.</span><span style="color:#a6e22e">activation</span><span style="color:#f92672">(</span>Activation<span style="color:#f92672">.</span><span style="color:#a6e22e">TANH</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">.</span><span style="color:#a6e22e">nIn</span><span style="color:#f92672">(</span>inputNum<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">.</span><span style="color:#a6e22e">nOut</span><span style="color:#f92672">(</span>100<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">.</span><span style="color:#a6e22e">build</span><span style="color:#f92672">())</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">layer</span><span style="color:#f92672">(</span><span style="color:#66d9ef">new</span> OutputLayer<span style="color:#f92672">.</span><span style="color:#a6e22e">Builder</span><span style="color:#f92672">(</span>LossFunction<span style="color:#f92672">.</span><span style="color:#a6e22e">NEGATIVELOGLIKELIHOOD</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">.</span><span style="color:#a6e22e">weightInit</span><span style="color:#f92672">(</span>WeightInit<span style="color:#f92672">.</span><span style="color:#a6e22e">XAVIER</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">.</span><span style="color:#a6e22e">activation</span><span style="color:#f92672">(</span>Activation<span style="color:#f92672">.</span><span style="color:#a6e22e">SOFTMAX</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">.</span><span style="color:#a6e22e">nIn</span><span style="color:#f92672">(</span>numHiddenNodes<span style="color:#f92672">).</span><span style="color:#a6e22e">nOut</span><span style="color:#f92672">(</span>numOutputs<span style="color:#f92672">).</span><span style="color:#a6e22e">build</span><span style="color:#f92672">())</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">pretrain</span><span style="color:#f92672">(</span><span style="color:#66d9ef">false</span><span style="color:#f92672">).</span><span style="color:#a6e22e">backprop</span><span style="color:#f92672">(</span><span style="color:#66d9ef">true</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">build</span><span style="color:#f92672">();</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>MultiLayerNetwork neuralNetwork <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> MultiLayerNetwork<span style="color:#f92672">(</span>conf<span style="color:#f92672">);</span>
</span></span></code></pre></div><h3 id="4-train">4. Train</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-java" data-lang="java"><span style="display:flex;"><span>ParentPathLabelGenerator labelMaker <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> ParentPathLabelGenerator<span style="color:#f92672">();</span>
</span></span><span style="display:flex;"><span>File mainPath <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> File<span style="color:#f92672">(</span>System<span style="color:#f92672">.</span><span style="color:#a6e22e">getProperty</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;user.dir&#34;</span><span style="color:#f92672">),</span> <span style="color:#e6db74">&#34;dl4j-examples/src/main/resources/animals/&#34;</span><span style="color:#f92672">);</span>
</span></span><span style="display:flex;"><span>FileSplit fileSplit <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> FileSplit<span style="color:#f92672">(</span>mainPath<span style="color:#f92672">,</span> NativeImageLoader<span style="color:#f92672">.</span><span style="color:#a6e22e">ALLOWED_FORMATS</span><span style="color:#f92672">,</span> rng<span style="color:#f92672">);</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">int</span> numExamples <span style="color:#f92672">=</span> Math<span style="color:#f92672">.</span><span style="color:#a6e22e">toIntExact</span><span style="color:#f92672">(</span>fileSplit<span style="color:#f92672">.</span><span style="color:#a6e22e">length</span><span style="color:#f92672">());</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">int</span> numLabels <span style="color:#f92672">=</span> fileSplit<span style="color:#f92672">.</span><span style="color:#a6e22e">getRootDir</span><span style="color:#f92672">().</span><span style="color:#a6e22e">listFiles</span><span style="color:#f92672">(</span>File<span style="color:#f92672">::</span>isDirectory<span style="color:#f92672">).</span><span style="color:#a6e22e">length</span><span style="color:#f92672">;</span> <span style="color:#75715e">//This only works if your root is clean: only label subdirs.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>BalancedPathFilter pathFilter <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> BalancedPathFilter<span style="color:#f92672">(</span>rng<span style="color:#f92672">,</span> labelMaker<span style="color:#f92672">,</span> numExamples<span style="color:#f92672">,</span> numLabels<span style="color:#f92672">,</span> maxPathsPerLabel<span style="color:#f92672">);</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>InputSplit<span style="color:#f92672">[]</span> inputSplit <span style="color:#f92672">=</span> fileSplit<span style="color:#f92672">.</span><span style="color:#a6e22e">sample</span><span style="color:#f92672">(</span>pathFilter<span style="color:#f92672">,</span> splitTrainTest<span style="color:#f92672">,</span> 1 <span style="color:#f92672">-</span> splitTrainTest<span style="color:#f92672">);</span>
</span></span><span style="display:flex;"><span>InputSplit trainData <span style="color:#f92672">=</span> inputSplit<span style="color:#f92672">[</span>0<span style="color:#f92672">];</span>
</span></span><span style="display:flex;"><span>InputSplit testData <span style="color:#f92672">=</span> inputSplit<span style="color:#f92672">[</span>1<span style="color:#f92672">];</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">boolean</span> shuffle <span style="color:#f92672">=</span> <span style="color:#66d9ef">false</span><span style="color:#f92672">;</span>
</span></span><span style="display:flex;"><span>ImageTransform flipTransform1 <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> FlipImageTransform<span style="color:#f92672">(</span>rng<span style="color:#f92672">);</span>
</span></span><span style="display:flex;"><span>ImageTransform flipTransform2 <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> FlipImageTransform<span style="color:#f92672">(</span><span style="color:#66d9ef">new</span> Random<span style="color:#f92672">(</span>123<span style="color:#f92672">));</span>
</span></span><span style="display:flex;"><span>ImageTransform warpTransform <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> WarpImageTransform<span style="color:#f92672">(</span>rng<span style="color:#f92672">,</span> 42<span style="color:#f92672">);</span>
</span></span><span style="display:flex;"><span>List<span style="color:#f92672">&lt;</span>Pair<span style="color:#f92672">&lt;</span>ImageTransform<span style="color:#f92672">,</span>Double<span style="color:#f92672">&gt;&gt;</span> pipeline <span style="color:#f92672">=</span> Arrays<span style="color:#f92672">.</span><span style="color:#a6e22e">asList</span><span style="color:#f92672">(</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">new</span> Pair<span style="color:#f92672">&lt;&gt;(</span>flipTransform1<span style="color:#f92672">,</span>0<span style="color:#f92672">.</span><span style="color:#a6e22e">9</span><span style="color:#f92672">),</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">new</span> Pair<span style="color:#f92672">&lt;&gt;(</span>flipTransform2<span style="color:#f92672">,</span>0<span style="color:#f92672">.</span><span style="color:#a6e22e">8</span><span style="color:#f92672">),</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">new</span> Pair<span style="color:#f92672">&lt;&gt;(</span>warpTransform<span style="color:#f92672">,</span>0<span style="color:#f92672">.</span><span style="color:#a6e22e">5</span><span style="color:#f92672">));</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ImageTransform transform <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> PipelineImageTransform<span style="color:#f92672">(</span>pipeline<span style="color:#f92672">,</span>shuffle<span style="color:#f92672">);</span>
</span></span><span style="display:flex;"><span>DataNormalization scaler <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> ImagePreProcessingScaler<span style="color:#f92672">(</span>0<span style="color:#f92672">,</span> 1<span style="color:#f92672">);</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// training dataset
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>ImageRecordReader recordReaderTrain <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> ImageRecordReader<span style="color:#f92672">(</span>height<span style="color:#f92672">,</span> width<span style="color:#f92672">,</span> channels<span style="color:#f92672">,</span> labelMaker<span style="color:#f92672">);</span>
</span></span><span style="display:flex;"><span>recordReader<span style="color:#f92672">.</span><span style="color:#a6e22e">initialize</span><span style="color:#f92672">(</span>trainData<span style="color:#f92672">,</span> <span style="color:#66d9ef">null</span><span style="color:#f92672">);</span>
</span></span><span style="display:flex;"><span>DataSetIterator trainingIterator <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> RecordReaderDataSetIterator<span style="color:#f92672">(</span>recordReaderTrain<span style="color:#f92672">,</span> batchSize<span style="color:#f92672">,</span> 1<span style="color:#f92672">,</span> numLabels<span style="color:#f92672">);</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// testing dataset
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>ImageRecordReader recordReaderTest <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> ImageRecordReader<span style="color:#f92672">(</span>height<span style="color:#f92672">,</span> width<span style="color:#f92672">,</span> channels<span style="color:#f92672">,</span> labelMaker<span style="color:#f92672">);</span>
</span></span><span style="display:flex;"><span>recordReader<span style="color:#f92672">.</span><span style="color:#a6e22e">initialize</span><span style="color:#f92672">(</span>testData<span style="color:#f92672">,</span> <span style="color:#66d9ef">null</span><span style="color:#f92672">);</span>
</span></span><span style="display:flex;"><span>DataSetIterator testingIterator <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> RecordReaderDataSetIterator<span style="color:#f92672">(</span>recordReaderTest<span style="color:#f92672">,</span> batchSize<span style="color:#f92672">,</span> 1<span style="color:#f92672">,</span> numLabels<span style="color:#f92672">);</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// early stopping configuration, model saver, and trainer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>EarlyStoppingModelSaver saver <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> LocalFileModelSaver<span style="color:#f92672">(</span>System<span style="color:#f92672">.</span><span style="color:#a6e22e">getProperty</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;user.dir&#34;</span><span style="color:#f92672">));</span>
</span></span><span style="display:flex;"><span>EarlyStoppingConfiguration esConf <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> EarlyStoppingConfiguration<span style="color:#f92672">.</span><span style="color:#a6e22e">Builder</span><span style="color:#f92672">()</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">epochTerminationConditions</span><span style="color:#f92672">(</span><span style="color:#66d9ef">new</span> MaxEpochsTerminationCondition<span style="color:#f92672">(</span>50<span style="color:#f92672">))</span> <span style="color:#75715e">//Max of 50 epochs
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">evaluateEveryNEpochs</span><span style="color:#f92672">(</span>1<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">iterationTerminationConditions</span><span style="color:#f92672">(</span><span style="color:#66d9ef">new</span> MaxTimeIterationTerminationCondition<span style="color:#f92672">(</span>20<span style="color:#f92672">,</span> TimeUnit<span style="color:#f92672">.</span><span style="color:#a6e22e">MINUTES</span><span style="color:#f92672">))</span> <span style="color:#75715e">//Max of 20 minutes
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">scoreCalculator</span><span style="color:#f92672">(</span><span style="color:#66d9ef">new</span> DataSetLossCalculator<span style="color:#f92672">(</span>testingIterator<span style="color:#f92672">,</span> <span style="color:#66d9ef">true</span><span style="color:#f92672">))</span>     <span style="color:#75715e">//Calculate test set score
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">modelSaver</span><span style="color:#f92672">(</span>saver<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span><span style="color:#a6e22e">build</span><span style="color:#f92672">();</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>EarlyStoppingTrainer trainer <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> EarlyStoppingTrainer<span style="color:#f92672">(</span>esConf<span style="color:#f92672">,</span> neuralNetwork<span style="color:#f92672">,</span> trainingIterator<span style="color:#f92672">);</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// begin training
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>trainer<span style="color:#f92672">.</span><span style="color:#a6e22e">fit</span><span style="color:#f92672">();</span>
</span></span></code></pre></div><h3 id="5-evaluate">5. Evaluate</h3>
<ul>
<li><strong>Evaluation</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/evaluation/classification/Evaluation.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Used for the evaluation of <code>multi-class classifiers </code>(assumes standard one-hot labels, and softmax probability distribution over N classes for predictions). Calculates a number of metrics - accuracy, precision, recall, F1, F-beta, Matthews correlation coefficient, confusion matrix. Optionally calculates top N accuracy, custom binary decision thresholds, and cost arrays (for non-binary case). Typically used for softmax + mcxent/negative-log-likelihood networks.</li>
<li><strong>EvaluationBinary</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/evaluation/classification/EvaluationBinary.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - A multi-label binary version of the Evaluation class. Each network output is assumed to be a <code>separate/independent binary class, with probability 0 to 1 independent of all other outputs. </code>Typically used for sigmoid + binary cross entropy networks.</li>
<li><strong>EvaluationCalibration</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/evaluation/classification/EvaluationCalibration.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Used to evaluation the calibration of a binary or multi-class classifier. Produces reliability diagrams, residual plots, and histograms of probabilities. Export plots to HTML using <a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-core/src/main/java/org/deeplearning4j/evaluation/EvaluationTools.java"target="_blank" rel="external nofollow noopener noreferrer">EvaluationTools<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>.exportevaluationCalibrationToHtmlFile method</li>
<li><strong>ROC</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/evaluation/classification/ROC.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - Used for single output binary classifiers only - i.e., networks with nOut(1) + sigmoid, or nOut(2) + softmax. Supports 2 modes: thresholded (approximate) or exact (the default). Calculates area under ROC curve, area under precision-recall curve. Plot ROC and P-R curves to HTML using <a href="https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-core/src/main/java/org/deeplearning4j/evaluation/EvaluationTools.java"target="_blank" rel="external nofollow noopener noreferrer">EvaluationTools<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><strong>ROCBinary</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/evaluation/classification/ROCBinary.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - a version of ROC that is used for multi-label binary networks (i.e., sigmoid + binary cross entropy), where each network output is assumed to be an independent binary variable.</li>
<li><strong>ROCMultiClass</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/evaluation/classification/ROCMultiClass.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - a version of <code>ROC that is used for multi-class (non-binary) networks (i.e., softmax + mcxent/negative-log-likelihood networks)</code>. As ROC metrics are only defined for binary classification, this treats the multi-class output as a set of &lsquo;one-vs-all&rsquo; binary classification problems.</li>
<li><strong>RegressionEvaluation</strong> - (<a href="https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/evaluation/regression/RegressionEvaluation.java"target="_blank" rel="external nofollow noopener noreferrer">Source<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>) - An evaluation class used for r<code>egression models (including multi-output regression models). </code>Reports metrics such as mean-squared error <code>(MSE), mean-absolute error,</code> etc for each output/column.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-java" data-lang="java"><span style="display:flex;"><span><span style="color:#75715e">// returns evaluation class with accuracy, precision, recall, and other class statistics
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>Evaluation eval <span style="color:#f92672">=</span> neuralNetwork<span style="color:#f92672">.</span><span style="color:#a6e22e">eval</span><span style="color:#f92672">(</span>testIterator<span style="color:#f92672">);</span>
</span></span><span style="display:flex;"><span>System<span style="color:#f92672">.</span><span style="color:#a6e22e">out</span><span style="color:#f92672">.</span><span style="color:#a6e22e">println</span><span style="color:#f92672">(</span>eval<span style="color:#f92672">.</span><span style="color:#a6e22e">accuracy</span><span style="color:#f92672">());</span>
</span></span><span style="display:flex;"><span>System<span style="color:#f92672">.</span><span style="color:#a6e22e">out</span><span style="color:#f92672">.</span><span style="color:#a6e22e">println</span><span style="color:#f92672">(</span>eval<span style="color:#f92672">.</span><span style="color:#a6e22e">precision</span><span style="color:#f92672">());</span>
</span></span><span style="display:flex;"><span>System<span style="color:#f92672">.</span><span style="color:#a6e22e">out</span><span style="color:#f92672">.</span><span style="color:#a6e22e">println</span><span style="color:#f92672">(</span>eval<span style="color:#f92672">.</span><span style="color:#a6e22e">recall</span><span style="color:#f92672">());</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// ROC for Area Under Curve on multi-class datasets (not binary classes)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>ROCMultiClass roc <span style="color:#f92672">=</span> neuralNetwork<span style="color:#f92672">.</span><span style="color:#a6e22e">doEvaluation</span><span style="color:#f92672">(</span>testIterator<span style="color:#f92672">,</span> <span style="color:#66d9ef">new</span> ROCMultiClass<span style="color:#f92672">());</span>
</span></span><span style="display:flex;"><span>System<span style="color:#f92672">.</span><span style="color:#a6e22e">out</span><span style="color:#f92672">.</span><span style="color:#a6e22e">println</span><span style="color:#f92672">(</span>roc<span style="color:#f92672">.</span><span style="color:#a6e22e">calculateAverageAuc</span><span style="color:#f92672">());</span>
</span></span><span style="display:flex;"><span>System<span style="color:#f92672">.</span><span style="color:#a6e22e">out</span><span style="color:#f92672">.</span><span style="color:#a6e22e">println</span><span style="color:#f92672">(</span>roc<span style="color:#f92672">.</span><span style="color:#a6e22e">calculateAverageAucPR</span><span style="color:#f92672">());</span>
</span></span></code></pre></div></div>
<div class="post-footer" id="post-footer">
  <div class="post-info">
    <div class="post-info-line">
      <div class="post-info-mod">
        <span title=2023-09-28&#32;22:55:05>更新于 2023-09-28&nbsp;</span>
      </div><div class="post-info-license">
          <span><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span>
        </div></div>
    <div class="post-info-line">
      <div class="post-info-md"><span><a href="liudongdong1.github.io/dl4jusage/index.md" title="阅读原始文档" class="link-to-markdown">阅读原始文档</a></span><span><a href="https://liudongdong1.github.io/edit/master/content/posts%5c%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%5cjavaDL%5cDL4JUsage.md" title="编辑此页"target="_blank" rel="external nofollow noopener noreferrer" class="link-to-edit">编辑此页</a></span></div>
      <div class="post-info-share">
        <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="liudongdong1.github.io/dl4jusage/" data-title="DL4J" data-hashtags="Model,Java"><i class="fa-brands fa-twitter fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="liudongdong1.github.io/dl4jusage/" data-hashtag="Model"><i class="fa-brands fa-facebook-square fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="liudongdong1.github.io/dl4jusage/" data-title="DL4J"><i class="fa-brands fa-weibo fa-fw" aria-hidden="true"></i></a>
  </span>
      </div>
    </div>
  </div>

  <div class="post-info-more">
    <section class="post-tags"><i class="fa-solid fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="liudongdong1.github.io/tags/model/">Model</a>,&nbsp;<a href="liudongdong1.github.io/tags/java/">Java</a></section>
    <section>
      <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="liudongdong1.github.io/">主页</a></span>
    </section>
  </div>

  <div class="post-nav"><a href="liudongdong1.github.io/dropout/" class="prev" rel="prev" title="Dropout"><i class="fa-solid fa-angle-left fa-fw" aria-hidden="true"></i>Dropout</a>
      <a href="liudongdong1.github.io/dimstransfor/" class="next" rel="next" title="DimsTransfor">DimsTransfor<i class="fa-solid fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article></main><footer class="footer">
    <div class="footer-container"><div class="footer-line powered">由 <a href="https://gohugo.io/" target="_blank" rel="external nofollow noopener noreferrer" title="Hugo 0.118.2">Hugo</a> 强力驱动 | 主题 - <a href="https://github.com/hugo-fixit/FixIt" target="_blank" rel="external" title="FixIt v0.2.17-RC"><img class="fixit-icon" src="/liudongdong1.github.io/fixit.min.svg" alt="FixIt logo" />&nbsp;FixIt</a>
        </div><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">2020 - 2023</span><span class="author" itemprop="copyrightHolder">
              <a href="https://liudongdong1.github.io/"target="_blank" rel="external nofollow noopener noreferrer">LiuDongdong</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div><div class="footer-line statistics"><span class="site-time" title='网站运行中 ...'><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden="true"></i>&nbsp;<span class="run-times">网站运行中 ...</span></span></div><div class="footer-line ibruce">
          <span id="busuanzi_container_site_uv" title='总访客数'><i class="fa-regular fa-user fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span><span id="busuanzi_container_site_pv" class="footer-divider" title='总访问量'><i class="fa-regular fa-eye fa-fw" aria-hidden="true"></i>&nbsp;<span id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span></span>
        </div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="回到顶部"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric">0%</span>
        </div></div><a href="https://liudongdong1.github.io/" title="在 GitHub 上查看源代码"target="_blank" rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><div id="mask"></div><div class="reading-progress-bar" style="left: 0;top: 0;--bg-progress: #0076ff;--bg-progress-dark: #fff;"></div><noscript>
    <div class="noscript-warning">FixIt 主题在启用 JavaScript 的情况下效果最佳。</div>
  </noscript>
</div><link rel="stylesheet" href="/liudongdong1.github.io/lib/katex/katex.min.css"><link rel="stylesheet" href="/liudongdong1.github.io/lib/cookieconsent/cookieconsent.min.css"><script src="/liudongdong1.github.io/lib/autocomplete/autocomplete.min.js" defer></script><script src="/liudongdong1.github.io/lib/algoliasearch/algoliasearch-lite.umd.min.js" defer></script><script src="/liudongdong1.github.io/lib/lazysizes/lazysizes.min.js" async defer></script><script src="/liudongdong1.github.io/lib/sharer/sharer.min.js" async defer></script><script src="/liudongdong1.github.io/lib/typeit/index.umd.js" defer></script><script src="/liudongdong1.github.io/lib/katex/katex.min.js" defer></script><script src="/liudongdong1.github.io/lib/katex/auto-render.min.js" defer></script><script src="/liudongdong1.github.io/lib/katex/copy-tex.min.js" defer></script><script src="/liudongdong1.github.io/lib/katex/mhchem.min.js" defer></script><script src="/liudongdong1.github.io/lib/cookieconsent/cookieconsent.min.js" defer></script><script src="/liudongdong1.github.io/lib/pangu/pangu.min.js" defer></script><script src="/liudongdong1.github.io/lib/cell-watermark/watermark.min.js" defer></script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async defer></script><script>window.config={"code":{"copyTitle":"复制到剪贴板","editLockTitle":"锁定可编辑代码块","editUnLockTitle":"解锁可编辑代码块","editable":true,"maxShownLines":10},"comment":{"enable":false},"cookieconsent":{"content":{"dismiss":"同意","link":"了解更多","message":"本网站使用 Cookies 来改善您的浏览体验。"},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"data":{"typeit-header-subtitle-desktop":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e","typeit-header-subtitle-mobile":"\u003cspan style='font-family: MMT,\"沐目体\";'\u003e吾日三省吾身\u003c/span\u003e"},"enablePWA":true,"enablePangu":true,"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"2R1K9SKLQZ","algoliaIndex":"index.zh-cn","algoliaSearchKey":"4a226aa1c5c98d6859e4d1386adb2bc7","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"},"siteTime":"2020-12-18T16:15:22+08:00","typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"typeit-header-subtitle-desktop":["typeit-header-subtitle-desktop"],"typeit-header-subtitle-mobile":["typeit-header-subtitle-mobile"]},"duration":-1,"speed":100},"watermark":{"appendto":".wrapper\u003emain","colspacing":30,"content":"\u003cimg class=\"fixit-icon\" src=\"/fixit.min.svg\" alt=\"FixIt logo\" /\u003e FixIt 主题","enable":true,"fontfamily":"inherit","fontsize":0.85,"height":21,"opacity":0.0125,"rotate":15,"rowspacing":60,"width":150}};</script><script src="/liudongdong1.github.io/js/theme.min.js" defer></script><script src="/liudongdong1.github.io/js/custom.min.js" defer></script></body>
</html>
